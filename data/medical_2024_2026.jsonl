{"venue": "ICLR", "search_title": "MOTOR: A Time-to-Event Foundation Model For StructuredMedical...", "url": "https://iclr.cc/virtual/2024/poster/18777", "year": 2024, "abstract_snippet": "We present a self-supervised, time-to-event (TTE) foundation model called MOTOR (Many Outcome Time Oriented Representations) which is pretrained on ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/poster/18777", "full_title": "MOTOR: A Time-to-Event Foundation Model For Structured Medical Records", "abstract": "We present a self-supervised, time-to-event (TTE) foundation model called MOTOR (Many Outcome Time Oriented Representations) which is pretrained on timestamped sequences of events in electronic health records (EHR) and health insurance claims. TTE models are used for estimating the probability distribution of the time until a specific event occurs, which is an important task in medical settings. TTE models provide many advantages over classification using fixed time horizons, including naturally handling censored observations, but are challenging to train with limited labeled data. MOTOR addresses this challenge by pretraining on up to 55M patient records (9B clinical events). We evaluate MOTOR's transfer learning performance on 19 tasks, across 3 patient databases (a private EHR system, MIMIC-IV, and Merative claims data). Task-specific models adapted from MOTOR improve time-dependent C statistics by 4.6\\% over state-of-the-art, improve label efficiency by up to 95\\%, and are more robust to temporal distributional shifts. We further evaluate cross-site portability by adapting our MOTOR foundation model for six prediction tasks on the MIMIC-IV dataset, where it outperforms all baselines. MOTOR is the first foundation model for medical TTE predictions and we release a 143M parameter pretrained model for research use at https://huggingface.co/StanfordShahLab/motor-t-base.", "summary_cn": "MOTOR是首个用于医疗时间到事件预测的基础模型，通过自监督预训练处理电子健康记录，在19个任务中提升预测性能、标签效率和鲁棒性。", "keywords": ["时间到事件模型", "电子健康记录", "自监督学习", "基础模型", "转移学习", "预测性能"], "triple": {"method": "自监督预训练于55M患者记录", "result": "在19个任务中C统计量提升4.6%，标签效率提高95%", "contribution": "首个医疗TTE基础模型，提升预测鲁棒性和跨站点可移植性"}}
{"venue": "ICLR", "search_title": "Reliable and Diverse Evaluation of LLMMedicalKnowledge Mastery", "url": "https://iclr.cc/virtual/2025/poster/29535", "year": 2025, "abstract_snippet": "Mastering medical knowledge is crucial for medical -specific LLMs. However, despite the existence of medical benchmarks like MedQA, a unified framework that ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/29535", "full_title": "Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery", "abstract": "Mastering medical knowledge is crucial for medical-specific LLMs. However, despite the existence of medical benchmarks like MedQA, a unified framework that fully leverages existing knowledge bases to evaluate LLMs' mastery of medical knowledge is still lacking. We propose PretexEval, a novel framework that dynamically generates reliable and diverse test samples to evaluate LLMs for any given medical knowledge base. We notice that test samples produced directly from knowledge bases by templates or LLMs may introduce factual errors and also lack diversity. To address these issues, our framework employs predicate equivalence transformations to produce a series of variants for any given medical knowledge point. Finally, these produced predicate variants are converted into textual language, resulting in a series of reliable and diverse test samples. Here, we use our proposed framework to systematically investigate the mastery of medical factual knowledge of 12 well-known LLMs, based on two knowledge bases that are crucial for clinical diagnosis and treatment. The evaluation results illustrate that current LLMs still exhibit significant deficiencies in fully mastering medical knowledge, despite achieving considerable success on some famous public benchmarks. These new findings provide valuable insights for developing medical-specific LLMs, highlighting that current LLMs urgently need to strengthen their comprehensive and in-depth mastery of medical knowledge before being applied to real-world medical scenarios.", "summary_cn": "提出PretexEval框架，通过谓词等价变换动态生成可靠多样的测试样本，评估12个知名LLM对医学知识的掌握。结果显示，尽管在公共基准上表现良好，LLM在全面掌握医学知识方面仍有显著不足。", "keywords": ["医学知识评估", "LLM评估框架", "谓词等价变换", "测试样本生成", "临床知识库", "多样性评估"], "triple": {"method": "谓词等价变换生成测试样本", "result": "LLM在医学知识掌握上存在显著不足", "contribution": "提供可靠多样的评估框架与洞察"}}
{"venue": "ICLR", "search_title": "ICLR Poster StabilizedMedicalImage Attacks", "url": "https://iclr.cc/virtual/2021/poster/3344", "year": 2021, "abstract_snippet": "Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease diagnosis. However, a threat to these systems arises that ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster StabilizedMedicalImage Attacks", "abstract": null}
{"venue": "ICLR", "search_title": "medicalimage understanding with pretrained vision language models", "url": "https://iclr.cc/virtual/2023/poster/11569", "year": 2023, "abstract_snippet": "We conduct extensive experiments on thirteen different medical datasets across various modalities, showing that our well-designed prompts greatly improve the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "medicalimage understanding with pretrained vision language models", "abstract": null}
{"venue": "ICLR", "search_title": "Solving Inverse Problems inMedicalImaging with Score-Based ...", "url": "https://iclr.cc/virtual/2022/poster/7035", "year": 2022, "abstract_snippet": "Apr 24, 2022 ... Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Solving Inverse Problems inMedicalImaging with Score-Based ...", "abstract": null}
{"venue": "ICLR", "search_title": "Autoencoders with Normalizing Flows forMedicalImages Anomaly ...", "url": "https://iclr.cc/virtual/2023/poster/11150", "year": 2023, "abstract_snippet": "Anomaly detection from medical images is an important task for clinical screening and diagnosis. In general, a large dataset of normal images are available ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Autoencoders with Normalizing Flows forMedicalImages Anomaly ...", "abstract": null}
{"venue": "ICLR", "search_title": "MedicalEvent Data Standard (MEDS): Facilitating Machine ...", "url": "https://iclr.cc/virtual/2024/23574", "year": 2024, "abstract_snippet": "We introduce the Medical Event Data Standard (MEDS), a lightweight schema for enabling machine learning over electronic health record (EHR) data.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/23574", "full_title": "Medical Event Data Standard (MEDS): Facilitating Machine Learning for Health", "abstract": "We introduce the Medical Event Data Standard (MEDS), a lightweight schema for enabling machine learning over electronic health record (EHR) data. Unlike common data models and data interoperability formats, MEDS is a minimal standard designed for maximum interoperability across datasets, existing tools, and model architectures. By providing a simple standardization layer between datasets and model-specific code, MEDS will enable more reproducible, robust, computationally performant, and collaborative machine learning research using EHR data. We highlight several existing MEDS integrations with models, datasets, and tools, and invite the community for further development and adoption.", "summary_cn": "提出医学事件数据标准（MEDS），作为轻量级模式，旨在提升电子健康记录数据的机器学习互操作性与可复现性。", "keywords": ["医学事件数据标准", "电子健康记录", "机器学习", "互操作性", "数据标准化", "可复现研究"], "triple": {"method": "设计轻量级数据模式", "result": "提升数据集、工具与模型的互操作性", "contribution": "促进基于EHR的机器学习研究可复现与协作"}}
{"venue": "ICLR", "search_title": "MMed-RAG: Versatile Multimodal RAG System forMedicalVision ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/a559a5a8aa5ae6682ced009ad97cdb16-Abstract-Conference.html", "year": 2025, "abstract_snippet": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/a559a5a8aa5ae6682ced009ad97cdb16-Abstract-Conference.html", "full_title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models", "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models often suffer from factual hallucination, which can lead to incorrect diagnoses. Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to address these issues. However, the amount of high-quality data and distribution shifts between training data and deployment data limit the application of fine-tuning methods. Although RAG is lightweight and effective, existing RAG-based approaches are not sufficiently general to different medical domains and can potentially cause misalignment issues, both between modalities and between the model and the ground truth. In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts selection, and a provable RAG-based preference fine-tuning strategy. These innovations make the RAG process sufficiently general and reliable, significantly improving alignment when introducing retrieved contexts. Experimental results across five medical datasets (involving radiology, ophthalmology, pathology) on medical VQA and report generation demonstrate that MMed-RAG can achieve an average improvement of 43.8% in factual accuracy in the factual accuracy of Med-LVLMs.", "summary_cn": "提出MMed-RAG多模态检索增强生成系统，通过领域感知检索和自适应选择，提升医疗视觉语言模型的事实准确性，在多个医学数据集上平均提升43.8%。", "keywords": ["检索增强生成", "医疗视觉语言模型", "多模态", "事实准确性", "领域感知检索", "自适应选择"], "triple": {"method": "领域感知检索、自适应选择、基于RAG的偏好微调", "result": "在五个医学数据集上平均提升事实准确性43.8%", "contribution": "提出通用可靠的MMed-RAG系统，增强医疗模型事实性"}}
{"venue": "ICLR", "search_title": "Deep Reinforcement Learning for Cost-EffectiveMedicalDiagnosis", "url": "https://iclr.cc/virtual/2023/poster/11964", "year": 2023, "abstract_snippet": "Deep Reinforcement Learning for Cost-Effective Medical Diagnosis. Zheng Yu, Yikuan Li, Joseph Kim, Kaixuan Huang, Yuan Luo, Mengdi Wang.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Deep Reinforcement Learning for Cost-EffectiveMedicalDiagnosis", "abstract": null}
{"venue": "ICLR", "search_title": "Enhancing SmallMedicalLearners with Privacy-preserving ...", "url": "https://iclr.cc/virtual/2024/poster/17369", "year": 2024, "abstract_snippet": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting. xinlu zhang · Shiyang Li · Xianjun Yang · Chenxin Tian · Yao Qin · Linda Petzold.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/poster/17369", "full_title": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting", "abstract": "The ICLR Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "该研究提出一种隐私保护的情境提示方法，用于增强小型医学模型性能，通过上下文学习提升准确性同时保护数据隐私。", "keywords": ["隐私保护", "情境提示", "小型医学模型", "上下文学习", "数据隐私", "模型增强"], "triple": {"method": "隐私保护的情境提示", "result": "提升小型医学模型性能", "contribution": "增强准确性并保护数据隐私"}}
{"venue": "ICLR", "search_title": "[Tiny] Synthetic-based retrieval of patientmedicaldata - ICLR 2026", "url": "https://iclr.cc/virtual/2025/32180", "year": 2025, "abstract_snippet": "Medical retrieval systems play a crucial role in facilitating an accurate and efficient diagnosis by allowing physicians to access relevant radiological reports ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32180", "full_title": "[Tiny] Synthetic-based retrieval of patient medical data", "abstract": "Medical retrieval systems play a crucial role in facilitating an accurate and efficient diagnosis by allowing physicians to access relevant radiological reports and patient descriptions. However, the development of such systems is often hindered by the limited availability of high-quality labeled data due to privacy concerns and data scarcity. In this work, we propose an approach to address this challenge by using synthetic data generation using Large Language Models (LLMs). Our experiments show that synthetic data is useful for improving retrieval performance in various tasks, both in training modes entirely on synthetic data and in a mixed-with-real-data mode.", "summary_cn": "本研究利用大语言模型生成合成数据，以解决医疗检索系统因隐私和数据稀缺导致的高质量标注数据不足问题，实验表明合成数据能有效提升检索性能。", "keywords": ["合成数据", "医疗检索", "大语言模型", "数据稀缺", "隐私保护", "检索性能"], "triple": {"method": "使用大语言模型生成合成数据", "result": "合成数据提升检索性能", "contribution": "解决医疗数据稀缺问题"}}
{"venue": "ICLR", "search_title": "ICLR Poster Time-to-Event Pretraining for 3DMedicalImaging", "url": "https://iclr.cc/virtual/2025/poster/27661", "year": 2025, "abstract_snippet": "To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/27661", "full_title": "Time-to-Event Pretraining for 3D Medical Imaging", "abstract": "With the rise of medical foundation models and the growing availability of imaging data, scalable pretraining techniques offer a promising way to identify imaging biomarkers predictive of future disease risk. While current self-supervised methods for 3D medical imaging models capture local structural features like organ morphology, they fail to link pixel biomarkers with long-term health outcomes due to a missing context problem. Current approaches lack the temporal context necessary to identify biomarkers correlated with disease progression, as they rely on supervision derived only from images and concurrent text descriptions. To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision from paired, longitudinal electronic health records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D images) and time-to-event distributions across thousands of EHR-derived tasks, our method improves outcome prediction, achieving an average AUROC increase of 23.7% and a 29.4% gain in Harrell’s C-index across 8 benchmark tasks. Importantly, these gains are achieved without sacrificing diagnostic classification performance. This study lays the foundation for integrating longitudinal EHR and 3D imaging data to advance clinical risk prediction.", "summary_cn": "提出时间-事件预训练框架，利用纵向电子健康记录为3D医学影像模型提供时间监督，显著提升疾病风险预测性能，不损害诊断分类。", "keywords": ["时间-事件预训练", "3D医学影像", "电子健康记录", "疾病风险预测", "纵向数据", "成像生物标志物"], "triple": {"method": "利用纵向EHR数据的时间监督进行预训练", "result": "AUROC平均提升23.7%，C-index提升29.4%", "contribution": "整合纵向EHR与3D影像，提升临床风险预测"}}
{"venue": "ICLR", "search_title": "ICLR Poster FairTune: Optimizing Parameter Efficient Fine Tuning ...", "url": "https://iclr.cc/virtual/2024/poster/19237", "year": 2024, "abstract_snippet": "FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis. Raman Dutt · Ondrej Bohdal · Sotirios Tsaftaris · Timothy ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/poster/19237", "full_title": "FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis", "abstract": "Training models with robust group fairness properties is crucial in ethically sensitive application areas such as medical diagnosis. Despite the growing body of work aiming to minimise demographic bias in AI, this problem remains challenging. A key reason for this challenge is the fairness generalisation gap: High-capacity deep learning models can fit all training data nearly perfectly, and thus also exhibit perfect fairness during training. In this case, bias emerges only during testing when generalisation performance differs across sub-groups. This motivates us to take a bi-level optimisation perspective on fair learning: Optimising the learning strategy based on validation fairness. Specifically, we consider the highly effective workflow of adapting pre-trained models to downstream medical imaging tasks using parameter-efficient fine-tuning (PEFT) techniques. There is a trade-off between updating more parameters, enabling a better fit to the task of interest vs. fewer parameters, potentially reducing the generalisation gap. To manage this tradeoff, we propose FairTune, a framework to optimise the choice of PEFT parameters with respect to fairness. We demonstrate empirically that FairTune leads to improved fairness on a range of medical imaging datasets. The code is available at https://github.com/Raman1121/FairTune.", "summary_cn": "FairTune框架通过双层优化调整参数高效微调，以减少医学影像分析中的群体公平性泛化差距，提升模型公平性。", "keywords": ["公平性", "医学影像分析", "参数高效微调", "双层优化", "泛化差距", "群体偏见"], "triple": {"method": "双层优化调整PEFT参数", "result": "提升多数据集公平性", "contribution": "提出FairTune框架"}}
{"venue": "ICLR", "search_title": "ICLR Poster MEDFAIR: Benchmarking Fairness forMedicalImaging", "url": "https://iclr.cc/virtual/2023/poster/11452", "year": 2023, "abstract_snippet": "A multitude of work has shown that machine learning-based medical diagnosis systems can be biased against certain subgroups of people. This has motivated a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster MEDFAIR: Benchmarking Fairness forMedicalImaging", "abstract": null}
{"venue": "ICLR", "search_title": "A Large-ScaleMedicalImage Segmentation Dataset for Fairness ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/bfdd520867b56af18dc9e80a8235b887-Abstract-Conference.html", "year": 2024, "abstract_snippet": "... research. Existing medical fairness datasets are all for classification tasks, and no fairness datasets are available for medical segmentation, while medical ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/bfdd520867b56af18dc9e80a8235b887-Abstract-Conference.html", "full_title": "FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling", "abstract": "Fairness in artificial intelligence models has gained significantly more attention in recent years, especially in the area of medicine, as fairness in medical models is critical to people's well-being and lives. High-quality medical fairness datasets are needed to promote fairness learning research. Existing medical fairness datasets are all for classification tasks, and no fairness datasets are available for medical segmentation, while medical segmentation is an equally important clinical task as classifications, which can provide detailed spatial information on organ abnormalities ready to be assessed by clinicians. In this paper, we propose the first fairness dataset for medical segmentation named Harvard-FairSeg with 10,000 subject samples. In addition, we propose a fair error-bound scaling approach to reweight the loss function with the upper error-bound in each identity group, using the segment anything model (SAM). We anticipate that the segmentation performance equity can be improved by explicitly tackling the hard cases with high training errors in each identity group. To facilitate fair comparisons, we utilize a novel equity-scaled segmentation performance metric to compare segmentation metrics in the context of fairness, such as the equity-scaled Dice coefficient. Through comprehensive experiments, we demonstrate that our fair error-bound scaling approach either has superior or comparable fairness performance to the state-of-the-art fairness learning models. The dataset and code are publicly accessible via https://ophai.hms.harvard.edu/datasets/harvard-fairseg10k.", "summary_cn": "提出首个医学分割公平性数据集Harvard-FairSeg及公平误差边界缩放方法，利用SAM模型提升分割性能公平性，优于现有方法。", "keywords": ["医学图像分割", "公平性学习", "Segment Anything Model", "误差边界缩放", "数据集", "性能公平性"], "triple": {"method": "公平误差边界缩放与SAM模型", "result": "分割公平性优于或媲美现有方法", "contribution": "首个医学分割公平数据集与公平性提升框架"}}
{"venue": "ICLR", "search_title": "ICLR Towards Clinically ApplicableMedicalAI Systems in Open ...", "url": "https://iclr.cc/virtual/2023/14465", "year": 2023, "abstract_snippet": "Client Talk by Lequan Yu in Workshop: What do we need for successful domain generalization? Towards Clinically Applicable Medical AI Systems in Open Clinical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Towards Clinically ApplicableMedicalAI Systems in Open ...", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Unlocking the Potential of Differential Privacy inMedicalImaging", "url": "https://iclr.cc/virtual/2023/14619", "year": 2023, "abstract_snippet": "Unlocking the Potential of Differential Privacy in Medical Imaging: Enabling Data Analysis while Protecting Patient Privacy. [ Abstract ]. 2023 Invited Talk", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Unlocking the Potential of Differential Privacy inMedicalImaging", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster Small Models are LLM Knowledge Triggers forMedical...", "url": "https://iclr.cc/virtual/2025/poster/29343", "year": 2025, "abstract_snippet": "The ICLR Logo above may be used on presentations. Right-click and choose download. It is a vector graphic and may be used at any scale.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/29343", "full_title": "Small Models are LLM Knowledge Triggers for Medical Tabular Prediction", "abstract": "Recent development in large language models (LLMs) has demonstrated impressive domain proficiency on unstructured textual or multi-modal tasks. However, despite with intrinsic world knowledge, their application on structured tabular data prediction still lags behind, primarily due to the numerical insensitivity and modality discrepancy that brings a gap between LLM reasoning and statistical tabular learning. Unlike textual or vision data (e.g., electronic clinical notes or medical imaging data), tabular data is often presented in heterogeneous numerical values (e.g., CBC reports). This ubiquitous data format requires intensive expert annotation, and its numerical nature limits LLMs' capability to effectively transfer untapped domain expertise. In this paper, we propose SERSAL, a general self-prompting method by synergy learning with small models to enhance LLM tabular prediction in an unsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as original soft noisy annotations, which are dynamically leveraged to teach a better small student model. Reversely, the outcomes from the trained small model are used to teach the LLM to further refine its real capability. This process can be repeatedly applied to gradually distill refined knowledge for continuous progress. Comprehensive experiments on widely used medical domain tabular datasets show that, without access to gold labels, applying SERSAL to OpenAI GPT reasoning process attains substantial improvement compared to linguistic prompting methods, which serves as an orthogonal direction for tabular LLM, and increasing prompting bonus is observed as more powerful LLMs appear. Codes are available at https://github.com/jyansir/sersal.", "summary_cn": "提出SERSAL方法，通过小模型与LLM协同学习，无监督提升LLM在医疗表格数据预测中的性能，实验显示显著优于语言提示方法。", "keywords": ["SERSAL", "LLM", "表格数据预测", "无监督学习", "协同学习", "医疗数据"], "triple": {"method": "小模型与LLM协同自提示学习", "result": "显著提升LLM表格预测性能", "contribution": "提供无监督表格LLM新方向"}}
{"venue": "ICLR", "search_title": "How Well Do Supervised 3D Models Transfer toMedicalImaging ...", "url": "https://iclr.cc/virtual/2024/oral/19781", "year": 2024, "abstract_snippet": "Oral. How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks? Wenxuan Li · Alan Yuille · Zongwei Zhou. [ Abstract ] [ Visit Oral 3D ].", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "How Well Do Supervised 3D Models Transfer toMedicalImaging ...", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster MediConfusion: Can you trust your AI radiologist ...", "url": "https://iclr.cc/virtual/2025/poster/30242", "year": 2025, "abstract_snippet": "Probing the reliability of multimodal medical foundation models. Mohammad Shahab Sepehri · Zalan Fabian · Maryam Soltanolkotabi · Mahdi Soltanolkotabi. 2025 ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/30242", "full_title": "MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models", "abstract": "Multimodal Large Language Models (MLLMs) have tremendous potential to improve the accuracy, availability, and cost-effectiveness of healthcare by providing automated solutions or serving as aids to medical professionals. Despite promising first steps in developing medical MLLMs in the past few years, their capabilities and limitations are not well understood. Recently, many benchmark datasets have been proposed that test the general medical knowledge of such models across a variety of medical areas. However, the systematic failure modes and vulnerabilities of such models are severely underexplored with most medical benchmarks failing to expose the shortcomings of existing models in this safety-critical domain. In this paper, we introduce MediConfusion, a challenging medical Visual Question Answering (VQA) benchmark dataset, that probes the failure modes of medical MLLMs from a vision perspective. We reveal that state-of-the-art models are easily confused by image pairs that are otherwise visually dissimilar and clearly distinct for medical experts. Strikingly, all available models (open-source or proprietary) achieve performance below random guessing on MediConfusion, raising serious concerns about the reliability of existing medical MLLMs for healthcare deployment. We also extract common patterns of model failure that may help the design of a new generation of more trustworthy and reliable MLLMs in healthcare.", "summary_cn": "提出MediConfusion医学VQA基准，揭示多模态大模型在视觉相似但医学不同的图像对上表现差，性能低于随机猜测，暴露其可靠性问题。", "keywords": ["多模态大语言模型", "医学视觉问答", "基准数据集", "模型可靠性", "失败模式", "医疗AI"], "triple": {"method": "构建MediConfusion医学VQA基准数据集", "result": "所有模型性能低于随机猜测，易被视觉相似医学不同的图像混淆", "contribution": "揭示医疗MLLMs可靠性缺陷，为设计更可信模型提供见解"}}
{"venue": "ICLR", "search_title": "Trustworthy Machine Learning inMedicalImaging - ICLR 2026", "url": "https://iclr.cc/virtual/2023/14780", "year": 2023, "abstract_snippet": "Intelligent medical systems capable of capturing and interpreting sensor data and providing context-aware assistance promise to revolutionize interventional ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Trustworthy Machine Learning inMedicalImaging - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster Clairvoyance: A Pipeline Toolkit forMedicalTime Series", "url": "https://iclr.cc/virtual/2021/poster/2791", "year": 2021, "abstract_snippet": "Poster. Clairvoyance: A Pipeline Toolkit for Medical Time Series. Daniel Jarrett · Jinsung Yoon · Ioana Bica · Zhaozhi Qian · Ari Ercole · Mihaela van der ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster Clairvoyance: A Pipeline Toolkit forMedicalTime Series", "abstract": null}
{"venue": "ICLR", "search_title": "Conformal Prediction Masks: Visualizing Uncertainty inMedical...", "url": "https://iclr.cc/virtual/2023/14351", "year": 2023, "abstract_snippet": "In this paper, we introduce a new approach for uncertainty quantification and visualization, based on masking. The proposed technique produces interpretable ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Conformal Prediction Masks: Visualizing Uncertainty inMedical...", "abstract": null}
{"venue": "ICLR", "search_title": "Interpretable Bilingual Multimodal Large Language Model for ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/414fd191b3246a19a55741b938380136-Abstract-Conference.html", "year": 2025, "abstract_snippet": "Authors. Lehan Wang, Haonan Wang, Honglong Yang, Jiaji Mao, Zehong Yang, Jun Shen, Xiaomeng Li. Abstract. Several medical Multimodal Large Languange Models ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/414fd191b3246a19a55741b938380136-Abstract-Conference.html", "full_title": "Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks", "abstract": "Several medical Multimodal Large Languange Models (MLLMs) have been developed to address tasks involving visual images with textual instructions across various medical modalities, achieving impressive results. Most current medical generalist models are region-agnostic, treating the entire image as a holistic representation. However, they struggle to identify which specific regions they are focusing on when generating a sentence.To mimic the behavior of doctors, who typically begin by reviewing the entire image before concentrating on specific regions for a thorough evaluation, we aim to enhance the capability of medical MLLMs in understanding anatomical regions within entire medical scans.To achieve it, we first formulate \\textbf{Region-Centric tasks} and construct a \\textbf{large-scale dataset, MedRegInstruct,} to incorporate regional information into training. Combining our collected dataset with other medical multimodal corpora for training, we propose a \\textbf{Region-Aware medical MLLM, MedRegA}, which is the first bilingual generalist medical AI system to simultaneously handle image-level and region-level medical vision-language tasks across a broad range of modalities. Our MedRegA not only enables three region-centric tasks, but also achieves the best performance for visual question answering, report generation and medical image classification over 8 modalities, showcasing significant versatility. Experiments demonstrate that our model can not only accomplish powerful performance across various medical vision-language tasks in bilingual settings, but also recognize and detect structures in multimodal medical scans, boosting the interpretability and user interactivity of medical MLLMs. The codes and model will be made publicly available.", "summary_cn": "提出首个双语区域感知医学多模态大模型MedRegA，通过MedRegInstruct数据集增强区域理解，在多种医学视觉语言任务中表现优异，提升模型可解释性与交互性。", "keywords": ["医学多模态大模型", "区域感知", "双语处理", "可解释性", "MedRegInstruct数据集", "视觉语言任务"], "triple": {"method": "构建MedRegInstruct数据集并训练区域感知模型", "result": "在8种模态的视觉问答、报告生成和分类任务中取得最佳性能", "contribution": "提升医学MLLMs的区域理解能力与可解释性"}}
{"venue": "ICLR", "search_title": "ENHANCING SMALLMEDICALLEARNERS WITH PRIVACY ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/79322f3668888f8f7fc99bbd98fbbaed-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "(b) The generated contexts are used as additional input to enhance SLM medical decision-making capacity. Keywords. LLM. Question. + Candidate answers. Context.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ENHANCING SMALLMEDICALLEARNERS WITH PRIVACY ...", "abstract": null}
{"venue": "ICLR", "search_title": "KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA", "url": "https://iclr.cc/virtual/2025/poster/32054", "year": 2025, "abstract_snippet": "Evaluations on medical QA benchmarks show that KGARevion improves accuracy by over 5.2% over 15 models in handling complex medical queries. To further ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/32054", "full_title": "KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA", "abstract": "Biomedical reasoning integrates structured, codified knowledge with tacit, experience-driven insights. Depending on the context, quantity, and nature of available evidence, researchers and clinicians use diverse strategies, including rule-based, prototype-based, and case-based reasoning. Effective medical AI models must handle this complexity while ensuring reliability and adaptability. We introduce KGARevion, a knowledge graph-based agent that answers knowledge-intensive questions. Upon receiving a query, KGARevion generates relevant triplets by leveraging the latent knowledge embedded in a large language model. It then verifies these triplets against a grounded knowledge graph, filtering out errors and retaining only accurate, contextually relevant information for the final answer. This multi-step process strengthens reasoning, adapts to different models of medical inference, and outperforms retrieval-augmented generation-based approaches that lack effective verification mechanisms. Evaluations on medical QA benchmarks show that KGARevion improves accuracy by over 5.2% over 15 models in handling complex medical queries. To further assess its effectiveness, we curated three new medical QA datasets with varying levels of semantic complexity, where KGARevion improved accuracy by 10.4%. The agent integrates with different LLMs and biomedical knowledge graphs for broad applicability across knowledge-intensive tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused on African healthcare, demonstrating its strong zero-shot generalization to underrepresented medical contexts.", "summary_cn": "KGARevion是基于知识图谱的AI代理，通过生成并验证三元组来回答生物医学问题，提升复杂查询的准确性和推理能力。", "keywords": ["知识图谱", "生物医学问答", "AI代理", "三元组验证", "推理增强", "零样本泛化"], "triple": {"method": "生成并验证三元组", "result": "准确率提升5.2%-10.4%", "contribution": "增强推理与泛化能力"}}
{"venue": "ICLR", "search_title": "Hallucination Benchmark inMedicalVisual Question Answering", "url": "https://iclr.cc/virtual/2024/20859", "year": 2024, "abstract_snippet": "The recent success of large language and vision models on vision question answering (VQA), particularly their applications in medicine (Med-VQA), has shown a ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/20859", "full_title": "Hallucination Benchmark in Medical Visual Question Answering", "abstract": "The recent success of large language and vision models on vision question answering (VQA), particularly their applications in medicine (Med-VQA), has shown a great potential of realizing effective visual assistants for healthcare. However, these models are not extensively tested on the hallucination phenomenon in clinical settings. Here, we created a hallucination benchmark of medical images paired with question-answer sets and conducted a comprehensive evaluation of the state-of-the-art models. The study provides an in-depth analysis of current models' limitations and reveals the effectiveness of various prompting strategies.", "summary_cn": "研究构建了医学视觉问答的幻觉基准，评估了前沿模型在临床环境中的局限性，并分析了不同提示策略的效果。", "keywords": ["医学视觉问答", "幻觉基准", "模型评估", "提示策略", "临床应用", "大型模型"], "triple": {"method": "构建幻觉基准并评估模型", "result": "揭示模型局限性及提示策略效果", "contribution": "提供医学VQA幻觉分析基准"}}
{"venue": "ICLR", "search_title": "ICLR Poster Efficiently DemocratizingMedicalLLMs for 50 ...", "url": "https://iclr.cc/virtual/2025/poster/30111", "year": 2025, "abstract_snippet": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts. Guorui Zheng · Xidong Wang · Juhao Liang · Nuo Chen · 余平 ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/30111", "full_title": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts", "abstract": "Adapting medical Large  Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensure its quality. In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE routing method that employs language-specific experts and cross-lingual routing. Inspired by circuit theory, our routing analysis revealed a \\textit{ Spread Out in the End } information flow mechanism: while earlier layers concentrate cross-lingual information flow, the later layers exhibit language-specific divergence. This insight directly led to the development of the Post-MoE architecture, which applies sparse routing only in the later layers while maintaining dense others. Experimental results demonstrate that this approach enhances the generalization of multilingual models to other languages while preserving interpretability. Finally, to efficiently scale the model to 50 languages, we introduce the concept of \\textit{language family} experts, drawing on linguistic priors, which enables scaling the number of languages without adding additional parameters.", "summary_cn": "提出基于语言家族专家的MoE路由方法，构建高质量医疗数据集，实现50种语言的高效多语言医疗LLM，提升泛化能力并保持可解释性。", "keywords": ["多语言医疗LLM", "混合专家", "语言家族专家", "路由分析", "泛化能力", "可解释性"], "triple": {"method": "基于语言家族专家的MoE路由与Post-MoE架构", "result": "增强多语言模型泛化至50种语言，保持可解释性", "contribution": "高效民主化医疗LLM，解决低资源语言数据稀缺问题"}}
{"venue": "ICLR", "search_title": "ICLR Poster Scale-Aware Contrastive Reverse Distillation for ...", "url": "https://iclr.cc/virtual/2025/poster/30228", "year": 2025, "abstract_snippet": "Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/30228", "full_title": "Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection", "abstract": "Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging where labeled anomalous data are scarce. While earlier approaches leverage generative models like autoencoders and generative adversarial networks (GANs), they often fall short due to overgeneralization. Recent methods explore various strategies, including memory banks, normalizing flows, self-supervised learning, and knowledge distillation, to enhance discrimination. Among these, knowledge distillation, particularly reverse distillation, has shown promise. Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations. Specifically, we introduce a contrastive student-teacher learning approach to derive more discriminative representations by generating and exploring out-of-normal distributions. Further, we design a scale adaptation mechanism to softly weight contrastive distillation losses at different scales to account for the scale variation issue. Extensive experiments on benchmark datasets demonstrate state-of-the-art performance, validating the efficacy of the proposed method. The code will be made publicly available.", "summary_cn": "提出一种尺度感知对比反向蒸馏模型，通过对比师生学习和尺度适应机制，提升无监督医学异常检测性能，在基准数据集上达到最优效果。", "keywords": ["无监督异常检测", "反向蒸馏", "对比学习", "尺度适应", "医学影像", "知识蒸馏"], "triple": {"method": "尺度感知对比反向蒸馏", "result": "在基准数据集上实现最优性能", "contribution": "提升特征判别力并处理异常尺度变化"}}
{"venue": "ICLR", "search_title": "Small Models are LLM Knowledge Triggers forMedicalTabular ...", "url": "https://iclr.cc/media/iclr-2025/Slides/29343.pdf", "year": null, "abstract_snippet": "Main experiment: medical diagnosis. AUC score comparison of ChatGPT on 10 binary medical diagnosis datasets using different prompting schemes. Page 8. Other ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Small Models are LLM Knowledge Triggers forMedicalTabular ...", "abstract": null}
{"venue": "ICLR", "search_title": "Uncertainty of VisionMedicalFoundation Models - ICLR 2026", "url": "https://iclr.cc/virtual/2025/32883", "year": 2025, "abstract_snippet": "Accurate uncertainty estimation is essential for machine learning systems deployed in high-stakes domains such as medicine. Traditional approaches primarily ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32883", "full_title": "Uncertainty of Vision Medical Foundation Models", "abstract": "Accurate uncertainty estimation is essential for machine learning systems deployed in high-stakes domains such as medicine. Traditional approaches primarily rely on probability outputs from trained models (point predictions), which provide no formal guarantees on prediction coverage and often require additional calibration techniques to improve reliability. In contrast, conformal prediction (region prediction) offers a principled alternative by generating prediction sets with finite-sample validity guarantees, ensuring that the ground truth is contained within the set at a specified confidence level.In this study, we explore the impact of pre-training approach, dataset scale and domain on both point and region-level uncertainty quantification, by studying domain-specific vision medical foundation models vs. general domain vision foundation models. We conduct a comprehensive evaluation across foundation models trained on retinal, histopathological, and magnetic resonance imaging (MRI) data, applying various calibration techniques. Our results demonstrate that (1) pre-training on larger, higher-quality datasets along with self-supervised learning leads to better-calibrated point predictions, irrespective of whether the data source is domain-specific, (2) better point prediction calibration does not directly translate to improved region prediction performance, (3) standard re-calibration methods alone cannot fully mitigate uncertainty discrepancies across models trained on different data sources.These findings highlight the importance of careful model selection and the integration of both point and region prediction strategies to enhance the reliability and trustworthiness of medical AI systems. Our work underscores the need for a holistic approach to uncertainty quantification in recent development of medical vision foundation model, ensuring robust and interpretable AI-driven decision-making.", "summary_cn": "研究探索预训练方法、数据规模和领域对医学视觉基础模型不确定性估计的影响，发现更大高质量数据集和自监督学习能改善点预测校准，但需结合点与区域预测策略提升AI可靠性。", "keywords": ["不确定性估计", "医学视觉基础模型", "保形预测", "校准技术", "自监督学习", "区域预测"], "triple": {"method": "评估不同预训练模型与校准技术", "result": "点预测校准不直接改善区域预测，标准方法无法完全消除不确定性差异", "contribution": "强调结合点与区域预测策略，提升医学AI系统可靠性"}}
{"venue": "ICLR", "search_title": "ICLR GroundingMedicalLLMs in Clinical Narratives: Scalable and ...", "url": "https://iclr.cc/virtual/2025/10000027", "year": 2025, "abstract_snippet": "Grounding Medical LLMs in Clinical Narratives: Scalable and Participatory Synthesis of Plausible Patient Data (Invited talk: Mary-Anne Hartley). Mary-Anne ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/10000027", "full_title": "Grounding Medical LLMs in Clinical Narratives: Scalable and Participatory Synthesis of Plausible Patient Data (Invited talk: Mary-Anne Hartley)", "abstract": null, "llm_error": "abstract_not_found"}
{"venue": "ICLR", "search_title": "MedAgents: Large Language Models as Collaborators for Zero-shot ...", "url": "https://iclr.cc/virtual/2024/22218", "year": 2024, "abstract_snippet": "To address these issues, we propose a novel Multi-disciplinary Collaboration (MC) framework for the medical domain that leverages role-playing LLM-based ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/22218", "full_title": "MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning", "abstract": "Large Language Models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose a novel Multi-disciplinary Collaboration (MC) framework for the medical domain that leverages role-playing LLM-based agents who participate in a collaborative multi-round discussion, thereby enhancing LLM proficiency and reasoning capabilities. This training-free and interpretable framework encompasses five critical steps: gathering domain experts, proposing individual analyses, summarising these analyses into a report, iterating over discussions until a consensus is reached, and ultimately making a decision. Our work focuses on the zero-shot setting, which is applicable in real-world scenarios. Experimental results on nine datasets (MedQA, MedMCQA, PubMedQA, and six subtasks from MMLU) establish that our proposed MC framework excels at mining and harnessing the medical expertise within LLMs, as well as extending its reasoning abilities.", "summary_cn": "提出多学科协作框架，利用角色扮演LLM代理进行多轮讨论，提升零样本医学推理能力，在九个数据集上验证有效性。", "keywords": ["大型语言模型", "医学推理", "零样本学习", "多学科协作", "角色扮演代理", "框架设计"], "triple": {"method": "多学科协作框架与角色扮演代理", "result": "在九个医学数据集上提升性能", "contribution": "增强LLM医学专业知识挖掘与推理能力"}}
{"venue": "ICLR", "search_title": "Interpretable AI forMedicalImaging - ICLR 2026", "url": "https://iclr.cc/virtual/2022/8653", "year": 2022, "abstract_snippet": "Main Navigation · Interpretable AI for Medical Imaging. Lei Xing. 2022 Invited Talk in. Workshop: PAIR^2Struct: Privacy, Accountability, Interpretability, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Interpretable AI forMedicalImaging - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "how well do supervised 3d models transfer - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/47360925c45a166c96f652589265dee9-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In addition, we released a suite of supervised pre-trained models (SuPreM) to benefit 3D medical imaging tasks. 3.1 EXTENSIVE DATASET: ABDOMENATLAS 1.1.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "how well do supervised 3d models transfer - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "FairSeg: A Large-ScaleMedicalImage Segmentation Dataset for ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/bfdd520867b56af18dc9e80a8235b887-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "High- quality medical fairness datasets are needed to promote fairness learning research. Existing medical fairness datasets are all for classification tasks,.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FairSeg: A Large-ScaleMedicalImage Segmentation Dataset for ...", "abstract": null}
{"venue": "ICLR", "search_title": "Avoiding Catastrophic Referral Failures InMedicalImages Under ...", "url": "https://iclr.cc/virtual/2023/14467", "year": 2023, "abstract_snippet": "Workshop: What do we need for successful domain generalization? Abstract: Developing robust approaches for domain generalization is critical for the real world ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Avoiding Catastrophic Referral Failures InMedicalImages Under ...", "abstract": null}
{"venue": "ICLR", "search_title": "The Effect of Intrinsic Dataset Properties on Generalization", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/5ef6b140c8b6cc2904854e30c6db78eb-Abstract-Conference.html", "year": 2024, "abstract_snippet": "... medical images. Recent works have found that the generalization error of a ... Yet, the steepness of this relationship varies significantly between medical ( ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/5ef6b140c8b6cc2904854e30c6db78eb-Abstract-Conference.html", "full_title": "The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images", "abstract": "This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic ``label sharpness'' ($K_\\mathcal{F}$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring the label sharpness of a training set: it is negatively correlated with the trained model's adversarial robustness, which notably leads to models for medical images having a substantially higher vulnerability to adversarial attack. Finally, we extend our $d_{data}$ formalism to the related metric of learned representation intrinsic dimension ($d_{repr}$), derive a generalization scaling law with respect to $d_{repr}$, and show that $d_{data}$ serves as an upper bound for $d_{repr}$. Our theoretical results are supported by thorough experiments with six models and eleven natural and medical imaging datasets over a range of training set sizes. Our findings offer insights into the influence of intrinsic dataset properties on generalization, representation learning, and robustness in deep neural networks. *Code link: https://github.com/mazurowski-lab/intrinsic-properties*", "summary_cn": "研究神经网络在自然与医学图像学习中的差异，提出标签锐度解释泛化差距，并揭示医学图像对抗脆弱性更高。", "keywords": ["泛化误差", "内在维度", "标签锐度", "对抗鲁棒性", "医学图像", "神经网络"], "triple": {"method": "提出标签锐度度量与泛化缩放定律", "result": "医学图像标签锐度高导致泛化差距大且对抗脆弱性强", "contribution": "揭示数据集内在属性对泛化与鲁棒性的影响"}}
{"venue": "ICLR", "search_title": "ICLR Poster Large-scale and Fine-grained Vision-language Pre ...", "url": "https://iclr.cc/virtual/2025/poster/28403", "year": 2025, "abstract_snippet": "... medical settings. Recent studies leverage radiology reports as a naturally high-quality supervision for medical images, using contrastive language-image pre ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/28403", "full_title": "Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding", "abstract": "Artificial intelligence (AI) shows great potential in assisting radiologists to improve the efficiency and accuracy of medical image interpretation and diagnosis. However, a versatile AI model requires large-scale data and comprehensive annotations, which are often impractical in medical settings. Recent studies leverage radiology reports as a naturally high-quality supervision for medical images, using contrastive language-image pre-training (CLIP) to develop language-informed models for radiological image interpretation. Nonetheless, these approaches typically contrast entire images with reports, neglecting the local associations between imaging regions and report sentences, which may undermine model performance and interoperability. In this paper, we propose a fine-grained vision-language model (fVLM) for anatomy-level CT image interpretation. Specifically, we explicitly match anatomical regions of CT images with corresponding descriptions in radiology reports and perform contrastive pre-training for each anatomy individually. Fine-grained alignment, however, faces considerable false-negative challenges, mainly from the abundance of anatomy-level healthy samples and similarly diseased abnormalities, leading to ambiguous patient-level pairings. To tackle this issue, we propose identifying false negatives of both normal and abnormal samples and calibrating contrastive learning from patient-level to disease-aware pairing. We curated the largest CT dataset to date, comprising imaging and report data from 69,086 patients, and conducted a comprehensive evaluation of 54 major and important disease (including several most deadly cancers) diagnosis tasks across 15 main anatomies. Experimental results demonstrate the substantial potential of fVLM in versatile medical image interpretation. In the zero-shot classification task, we achieved an average AUC of 81.3% on 54 diagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%, respectively. Additionally, on the publicly available CT-RATE and Rad-ChestCT benchmarks, our fVLM outperformed the current state-of-the-art methods with absolute AUC gains of 7.4% and 4.8%, respectively.", "summary_cn": "提出细粒度视觉语言模型fVLM，通过解剖区域与报告句子对齐及假阴性校准，在大型CT数据集上实现零样本诊断性能显著提升。", "keywords": ["细粒度视觉语言模型", "CT图像理解", "对比学习", "解剖区域对齐", "零样本诊断", "假阴性校准"], "triple": {"method": "解剖区域与报告句子对齐的对比预训练", "result": "零样本诊断AUC达81.3%，超越CLIP及监督方法", "contribution": "提升CT图像理解的细粒度对齐与泛化能力"}}
{"venue": "ICLR", "search_title": "RELIABLE AND DIVERSE EVALUATION OF LLM MEDI", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/91a5bb5e5939cb075f5f2464d7b8bbf0-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Mastering medical knowledge is crucial for medical -specific LLMs. However, despite the existence of medical benchmarks like MedQA, a unified framework that ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "RELIABLE AND DIVERSE EVALUATION OF LLM MEDI", "abstract": null}
{"venue": "ICLR", "search_title": "MMED-RAG: VERSATILE MULTIMODAL RAG SYS", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/a559a5a8aa5ae6682ced009ad97cdb16-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Medical Large Vision Language Models. Med-LVLMs bridge LLMs with medical visual mod- ules, allowing the model to take medical image xv and clinical query xt as ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MMED-RAG: VERSATILE MULTIMODAL RAG SYS", "abstract": null}
{"venue": "ICLR", "search_title": "TrustworthyMedicalAI in the Loop of Algorithm and Clinic - ICLR 2026", "url": "https://iclr.cc/virtual/2023/14357", "year": 2023, "abstract_snippet": "Client Invited Talk in Workshop: Trustworthy Machine Learning for Healthcare. Trustworthy Medical AI in the Loop of Algorithm and Clinic.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "TrustworthyMedicalAI in the Loop of Algorithm and Clinic - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster 3D UX-Net: A Large Kernel Volumetric ConvNet ...", "url": "https://iclr.cc/virtual/2023/poster/11340", "year": 2023, "abstract_snippet": "The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art performances on several 3D volumetric data benchmarks, including 3D medical image ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster 3D UX-Net: A Large Kernel Volumetric ConvNet ...", "abstract": null}
{"venue": "ICLR", "search_title": "Prompt as Knowledge Bank: Boost Vision-language model via ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/59a9cc95f046e9125d8816ef971873e7-Abstract-Conference.html", "year": 2025, "abstract_snippet": "Authors. Yuguang Yang, Tongfei Chen, Haoyu Huang, Linlin Yang, Chunyu Xie, Dawei Leng, Xianbin Cao, Baochang Zhang. Abstract. Zero-shot medical ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/59a9cc95f046e9125d8816ef971873e7-Abstract-Conference.html", "full_title": "Prompt as Knowledge Bank: Boost Vision-language model via Structural Representation for  zero-shot medical detection", "abstract": "Zero-shot medical detection can further improve detection performance without relying on annotated medical images even upon the fine-tuned model, showing great clinical value. Recent studies leverage grounded vision-language models (GLIP) to achieve this by using detailed disease descriptions as prompts for the target disease name during the inference phase.  However, these methods typically treat prompts as equivalent context to the target name, making it difficult to assign specific disease knowledge based on visual information, leading to a coarse alignment between images and target descriptions. In this paper, we propose StructuralGLIP, which introduces an auxiliary branch to encode prompts into a latent knowledge bank layer-by-layer, enabling more context-aware and fine-grained alignment. Specifically, in each layer, we select highly similar features from both the image representation and the knowledge bank, forming structural representations that capture nuanced relationships between image patches and target descriptions. These features are then fused across modalities to further enhance detection performance.Extensive experiments demonstrate that StructuralGLIP achieves a +4.1\\% AP improvement over prior state-of-the-art methods across seven zero-shot medical detection benchmarks, and consistently improves fine-tuned models by +3.2\\% AP on endoscopy image datasets.", "summary_cn": "提出StructuralGLIP，通过分层编码提示构建知识库，实现图像与疾病描述的细粒度对齐，提升零样本医学检测性能。", "keywords": ["零样本医学检测", "视觉语言模型", "细粒度对齐", "知识库", "结构表示", "GLIP"], "triple": {"method": "分层编码提示构建知识库，选择高相似特征形成结构表示", "result": "在七个基准上AP提升4.1%，内窥镜数据集上微调模型AP提升3.2%", "contribution": "增强图像与疾病描述的细粒度对齐，提升零样本检测性能"}}
{"venue": "ICLR", "search_title": "Instruction-Finetuned LLM for CXR Image Understanding and ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/7f70331dbe58ad59d83941dfa7d975aa-Abstract-Conference.html", "year": 2024, "abstract_snippet": "This direction of research is particularly relevant to medical imaging because accurate medical image analysis and generation consist of a combination of ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/7f70331dbe58ad59d83941dfa7d975aa-Abstract-Conference.html", "full_title": "LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation", "abstract": "Following the impressive development of LLMs, vision-language alignment in LLMs is actively being researched to enable multimodal reasoning and visual input/output. This direction of research is particularly relevant to medical imaging because accurate medical image analysis and generation consist of a combination of reasoning based on visual features and prior knowledge. Many recent works have focused on training adapter networks that serve as an information bridge between image processing (encoding or generating) networks and LLMs; but presumably, in order to achieve maximum reasoning potential of LLMs on visual information as well, visual and language features should be allowed to interact more freely. This is especially important in the medical domain because understanding and generating medical images such as chest X-rays (CXR) require not only accurate visual and language-based reasoning but also a more intimate mapping between the two modalities. Thus, taking inspiration from previous work on the transformer and VQ-GAN combination for bidirectional image and text generation, we build upon this approach and develop a method for instruction-tuning an LLM pre-trained only on text to gain vision-language capabilities for medical images. Specifically, we leverage a pretrained LLM’s existing question-answering and instruction-following abilities to teach it to understand visual inputs by instructing it to answer questions about image inputs and, symmetrically, output both text and image responses appropriate to a given query by tuning the LLM with diverse tasks that encompass image-based text-generation and text-based image-generation. We show that our LLM-CXR trained in this approach shows better image-text alignment in both CXR understanding and generation tasks while being smaller in size compared to previously developed models that perform a narrower range of tasks.", "summary_cn": "本研究开发了LLM-CXR模型，通过指令微调使文本预训练大语言模型具备医学影像理解与生成能力，在胸部X光任务中实现更好的图文对齐。", "keywords": ["大语言模型", "医学影像", "指令微调", "胸部X光", "多模态学习", "图像生成"], "triple": {"method": "指令微调预训练LLM", "result": "提升CXR图文对齐能力", "contribution": "开发轻量多功能医学多模态模型"}}
{"venue": "ICLR", "search_title": "mediconfusion: can you trust your ai - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/b37c2e26b75ee02fcabd65a2a0367136-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "pretrained on the largest dataset of medical image-caption data among publicly available CLIP-style biomedical vision-language models. We measure visual ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "mediconfusion: can you trust your ai - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "Dynamic Modeling of Patients, Modalities and Tasks via Multi-modal ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/e3b82f4c7ba93a88025cf97dca9edc83-Abstract-Conference.html", "year": 2025, "abstract_snippet": "However, medical imaging domains introduce two key challenges: dynamic modality fusion and modality-task dependence. The quality and amount of task-related ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/e3b82f4c7ba93a88025cf97dca9edc83-Abstract-Conference.html", "full_title": "Dynamic Modeling of Patients, Modalities and Tasks via Multi-modal Multi-task Mixture of Experts", "abstract": "Multi-modal multi-task learning holds significant promise in tackling complex diagnostic tasks and many significant medical imaging problems. It fulfills the needs in real-world diagnosis protocol to leverage information from different data sources and simultaneously perform mutually informative tasks. However, medical imaging domains introduce two key challenges: dynamic modality fusion and modality-task dependence. The quality and amount of task-related information from different modalities could vary significantly across patient samples, due to biological and demographic factors. Traditional fusion methods apply fixed combination strategies that fail to capture this dynamic relationship, potentially underutilizing modalities that carry stronger diagnostic signals for specific patients. Additionally, different clinical tasks may require dynamic feature selection and combination from various modalities, a phenomenon we term “modality-task dependence.” To address these issues, we propose M4oE, a novel Multi-modal Multi-task Mixture of Experts framework for precise Medical diagnosis. M4oE comprises Modality-Specific (MSoE) modules and a Modality-shared Modality-Task MoE (MToE) module. With collaboration from both modules, our model dynamically decomposes and learns distinct and shared information from different modalities and achieves dynamic fusion. MToE provides a joint probability model of modalities and tasks by using experts as a link and encourages experts to learn modality-task dependence via conditional mutual information loss. By doing so, M4oE offers sample and population-level interpretability of modality contributions. We evaluate M4oE on four public multi-modal medical benchmark datasets for solving two important medical diagnostic problems including breast cancer screening and retinal disease diagnosis. Results demonstrate our method's superiority over state-of-the-art methods under different metrics of classification and segmentation tasks like Accuracy, AUROC, AUPRC, and DICE.", "summary_cn": "提出M4oE框架，通过多模态多任务混合专家模型动态融合模态与任务信息，提升乳腺癌筛查和视网膜疾病诊断的准确性。", "keywords": ["多模态学习", "多任务学习", "混合专家模型", "动态融合", "医学诊断", "模态任务依赖"], "triple": {"method": "多模态多任务混合专家框架（M4oE）", "result": "在分类和分割任务中超越现有方法", "contribution": "实现动态模态融合与模态任务依赖建模"}}
{"venue": "ICLR", "search_title": "The Impact of Poisoned MRI Image on U-Net Brain Tumor ...", "url": "https://iclr.cc/virtual/2025/32191", "year": 2025, "abstract_snippet": "Deep learning-based medical image segmentation models, such as U-Net, rely on high-quality annotated datasets to achieve accurate predictions.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32191", "full_title": "Synthetic Poisoning Attacks: The Impact of Poisoned MRI Image on U-Net Brain Tumor Segmentation", "abstract": "Deep learning-based medical image segmentation models, such as U-Net, rely on high-quality annotated datasets to achieve accurate predictions. However, the increasing use of generative models for synthetic data augmentation introduces potential risks, particularly in the absence of rigorous quality control. In this paper, we investigate the impact of synthetic MRI data on the robustness and segmentation accuracy of U-Net models for brain tumor segmentation. Specifically, we generate synthetic T1-contrast-enhanced (T1-Ce) MRI scans using a GAN-based model with a shared encoding-decoding framework and shortest-path regularization. To quantify the effect of synthetic data contamination, we train U-Net models on progressively ``poisoned'' datasets, where synthetic data proportions range from 16.67\\% to 83.33\\%. Experimental results on a real MRI validation set reveal a significant performance degradation as synthetic data increases, with Dice coefficients dropping from 0.8937 (33.33\\% synthetic) to 0.7474 (83.33\\% synthetic). Accuracy and sensitivity exhibit similar downward trends, demonstrating the detrimental effect of synthetic data on segmentation robustness. These findings underscore the importance of quality control in synthetic data integration and highlight the risks of unregulated synthetic augmentation in medical image analysis. Our study provides critical insights for the development of more reliable and trustworthy AI-driven medical imaging systems.", "summary_cn": "研究合成MRI数据对U-Net脑肿瘤分割模型的影响，发现合成数据比例增加会导致分割性能显著下降，强调合成数据集成中质量控制的重要性。", "keywords": ["合成数据攻击", "U-Net分割", "脑肿瘤分割", "MRI图像", "生成对抗网络", "数据污染"], "triple": {"method": "使用GAN生成合成MRI数据，逐步污染训练集", "result": "合成数据比例增加导致Dice系数从0.8937降至0.7474", "contribution": "揭示合成数据对分割模型的负面影响，强调质量控制"}}
{"venue": "ICLR", "search_title": "ICLR Analog In-Memory Computing with Uncertainty Quantification ...", "url": "https://iclr.cc/virtual/2024/20891", "year": 2024, "abstract_snippet": "Analog In-Memory Computing with Uncertainty Quantification for Efficient Edge-based Medical Imaging Segmentation. Imane Hamzaoui · Hadjer Benmeziane · Zayneb ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/20891", "full_title": "Analog In-Memory Computing with Uncertainty Quantification for Efficient Edge-based Medical Imaging Segmentation", "abstract": "This work investigates the role of the emerging Analog In-memory computing (AIMC) paradigm in enabling Medical AI analysis and improving the certainty of these models at the edge. It contrasts AIMC's efficiency with traditional digital computing's limitations in power, speed, and scalability. Our comprehensive evaluation focuses on brain tumor analysis, spleen segmentation, and nuclei detection. The study highlights the superior robustness of isotropic architectures, which exhibit a minimal accuracy drop (0.04) in analog-aware training, compared to significant drops (up to 0.15) in pyramidal structures. Additionally, the paper emphasizes IMC's effective data pipelining, reducing latency and increasing throughput as well as the exploitation of inherent noise within AIMC, strategically harnessed to augment model certainty.", "summary_cn": "研究模拟内存计算在边缘医疗影像分割中的应用，通过各向同性架构提升模型鲁棒性，利用固有噪声增强不确定性量化，实现高效低延迟分析。", "keywords": ["模拟内存计算", "边缘计算", "医疗影像分割", "不确定性量化", "各向同性架构", "模型鲁棒性"], "triple": {"method": "模拟内存计算与各向同性架构", "result": "精度下降最小（0.04），延迟降低，吞吐量增加", "contribution": "提升边缘医疗AI效率与确定性"}}
{"venue": "ICLR", "search_title": "CanMedicalVision-Language Pre-training Succeed with Purely ...", "url": "https://iclr.cc/virtual/2025/32770", "year": 2025, "abstract_snippet": "Poster in. Workshop: Workshop on Reasoning and Planning for Large Language Models. Can Medical Vision-Language Pre-training Succeed with Purely Synthetic ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32770", "full_title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?", "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress in enabling zero-shot tasks for medical image understanding. However, training MedVLP models typically requires large-scale datasets with paired, high-quality image-text data, which are scarce in the medical domain. Recent advancements in Large Language Models (LLMs) and diffusion models have made it possible to generate large-scale synthetic image-text pairs. This raises the question: Can MedVLP succeed using purely synthetic data? To address this, we use off-the-shelf generative models to create synthetic radiology reports and paired Chest X-ray (CXR) images, and propose an automated pipeline to build a diverse, high-quality synthetic dataset, enabling a rigorous study that isolates model and training settings, focusing entirely from the data perspective.Our results show that MedVLP models trained exclusively on synthetic data outperform those trained on real data by 3.8% in averaged AUC on zero-shot classification. Moreover, using a combination of synthetic and real data leads to a further improvement of 9.07% . Additionally, MedVLP models trained on synthetic or mixed data consistently outperform those trained on real data in zero-shot grounding, as well as in fine-tuned classification and segmentation tasks.Our analysis suggests MedVLP trained on well-designed synthetic data can outperform models trained on real datasets, which may be limited by low-quality samples and long-tailed distributions.", "summary_cn": "研究探讨仅用合成数据训练医学视觉语言预训练模型的可行性。结果显示，纯合成数据训练的模型在零样本分类上优于真实数据模型，混合数据进一步提升性能。", "keywords": ["医学视觉语言预训练", "合成数据", "零样本分类", "胸部X光", "生成模型", "数据增强"], "triple": {"method": "使用生成模型创建合成胸部X光图像与报告对", "result": "纯合成数据训练模型在零样本分类AUC上优于真实数据3.8%，混合数据提升9.07%", "contribution": "证明高质量合成数据可克服真实数据限制，提升医学视觉语言模型性能"}}
{"venue": "ICLR", "search_title": "UNRAVELING LEARNING DIFFER - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/5ef6b140c8b6cc2904854e30c6db78eb-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "2Here we take “ medical ” images to refer to radiology images (e.g., x-ray, MRI), the most common type. 1. Page 2. Published as a conference paper at ICLR 2024.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "UNRAVELING LEARNING DIFFER - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "Reasoning-Enhanced Healthcare Predictions with Knowledge ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/cb5a3b4589c1a16f14740396625cbfc8-Abstract-Conference.html", "year": 2025, "abstract_snippet": "Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/cb5a3b4589c1a16f14740396625cbfc8-Abstract-Conference.html", "full_title": "Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval", "abstract": "Large language models (LLMs) have demonstrated significant potential in clinical decision support. Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical diagnosis. Traditional retrieval-augmented generation (RAG) methods attempt to address these limitations but frequently retrieve sparse or irrelevant information, undermining prediction accuracy. We introduce KARE, a novel framework that integrates knowledge graph (KG) community-level retrieval with LLM reasoning to enhance healthcare predictions. KARE constructs a comprehensive multi-source KG by integrating biomedical databases, clinical literature, and LLM-generated insights, and organizes it using hierarchical graph community detection and summarization for precise and contextually relevant information retrieval. Our key innovations include: (1) a dense medical knowledge structuring approach enabling accurate retrieval of relevant information; (2) a dynamic knowledge retrieval mechanism that enriches patient contexts with focused, multi-faceted medical insights; and (3) a reasoning-enhanced prediction framework that leverages these enriched contexts to produce both accurate and interpretable clinical predictions. Extensive experiments demonstrate that KARE outperforms leading models by up to 10.8-15.0\\% on MIMIC-III and 12.6-12.7\\% on MIMIC-IV for mortality and readmission predictions. In addition to its impressive prediction accuracy, our framework leverages the reasoning capabilities of LLMs, enhancing the trustworthiness of clinical predictions.", "summary_cn": "提出KARE框架，结合知识图谱社区检索与LLM推理，提升医疗预测准确性，在MIMIC数据集上表现优异。", "keywords": ["知识图谱", "检索增强生成", "临床预测", "大语言模型", "社区检测", "医疗推理"], "triple": {"method": "知识图谱社区检索与LLM推理结合", "result": "预测准确率提升10.8-15.0%", "contribution": "增强临床预测准确性与可解释性"}}
{"venue": "ICLR", "search_title": "FAIRTUNE: OPTIMIZING PARAMETER EFFICIENT FINE TUNING ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/da409884a933ecbc4af03338111bf6aa-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Our empirical findings consistently demonstrate that FairTune outperforms Empirical Risk. Minimization (ERM) in terms of fairness across various medical imaging ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FAIRTUNE: OPTIMIZING PARAMETER EFFICIENT FINE TUNING ...", "abstract": null}
{"venue": "ICLR", "search_title": "PROMPT AS KNOWLEDGE BANK: BOOST VISION", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/59a9cc95f046e9125d8816ef971873e7-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Zero-shot medical detection enhances existing models without relying on an- notated medical images, offering significant clinical value. By using grounded.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PROMPT AS KNOWLEDGE BANK: BOOST VISION", "abstract": null}
{"venue": "ICLR", "search_title": "MMed-RAG: Versatile Multimodal RAG System forMedicalVision ...", "url": "https://iclr.cc/media/iclr-2025/Slides/28145.pdf", "year": null, "abstract_snippet": "Cares: A comprehensive benchmark of trustworthiness in medical vision language models.. NeurIPS 2024. Xia P, Zhu K, Li H, et al. Rule: Reliable multimodal ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MMed-RAG: Versatile Multimodal RAG System forMedicalVision ...", "abstract": null}
{"venue": "ICLR", "search_title": "BoneMet: An Open Large-Scale Multi-Modal Murine Dataset for ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/25dbf5a09fbf2553739a04645d3dfb2c-Abstract-Conference.html", "year": 2025, "abstract_snippet": "... medical resource, which is derived from a well-accepted murine BCBM model. ... medical records and bone quantitative analysis), collected from more than ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/25dbf5a09fbf2553739a04645d3dfb2c-Abstract-Conference.html", "full_title": "BoneMet: An Open Large-Scale Multi-Modal Murine Dataset for Breast Cancer Bone Metastasis Diagnosis and Prognosis", "abstract": "Breast cancer bone metastasis (BCBM) affects women’s health globally, calling for the development of effective diagnosis and prognosis solutions. While deep learning has exhibited impressive capacities across various healthcare domains, its applicability in BCBM diseases is consistently hindered by the lack of an open, large-scale, deep learning-ready dataset. As such, we introduce the Bone Metastasis (BoneMet) dataset, the first large-scale, publicly available, high-resolution medical resource, which is derived from a well-accepted murine BCBM model. The unique advantage of BoneMet over existing human datasets is repeated sequential scans per subject over the entire disease development phases. The dataset consists of over 67 terabytes of multi-modal medical data, including 2D X-ray images, 3D CT scans, and detailed biological data (e.g., medical records and bone quantitative analysis), collected from more than five hundreds mice spanning from 2019 to 2024. Our BoneMet dataset is well-organized into six components, i.e., RotationX-Ray, Recon-CT, Seg-CT, Regist-CT, RoI-CT, and MiceMediRec. We further show that BoneMet can be readily adopted to build versatile, large-scale AI models for managing BCBM diseases in terms of diagnosis using 2D or 3D images, prognosis of bone deterioration, and sparse-angle 3D reconstruction for safe long-term disease monitoring. Our preliminary results demonstrate that BoneMet has the potentials to jump-start the development and fine-tuning of AI-driven solutions prior to their applications to human patients. To facilitate its easy access and wide dissemination, we have created the BoneMet package, providing three APIs that enable researchers to (i) flexibly process and download the BoneMet data filtered by specific time frames; and (ii) develop and train large-scale AI models for precise BCBM diagnosis and prognosis. The BoneMet dataset is officially available on Hugging Face Datasets at https://huggingface.co/datasets/BoneMet/BoneMet. The BoneMet package is available on the Python Package Index (PyPI) at https://pypi.org/project/BoneMet. Code and tutorials are available at https://github.com/Tiankuo528/BoneMet.", "summary_cn": "BoneMet是首个公开的大规模多模态小鼠乳腺癌骨转移数据集，包含超67TB影像与生物数据，支持AI模型开发用于诊断、预后与安全监测。", "keywords": ["乳腺癌骨转移", "多模态数据集", "小鼠模型", "AI诊断", "医学影像", "预后分析"], "triple": {"method": "构建大规模多模态小鼠数据集", "result": "提供超67TB数据，支持AI模型开发", "contribution": "填补公开数据集空白，促进AI在BCBM的应用"}}
{"venue": "ICLR", "search_title": "ICLR Poster MedTrinity-25M: A Large-scale Multimodal Dataset with ...", "url": "https://iclr.cc/virtual/2025/poster/30141", "year": 2025, "abstract_snippet": "... medical AI models, contributing to the development of future foundation models in the medical domain. We will make our dataset available. The dataset is ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/30141", "full_title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine", "abstract": "This paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal dataset for medicine, covering over 25 million images across 10 modalities with multigranular annotations for more than 65 diseases. These multigranular annotations encompass both global information, such as modality and organ detection, and local information like ROI analysis, lesion texture, and region-wise correlations. Unlike the existing multimodal datasets, which are limited by the availability of image-text pairs, we have developed the first automated pipeline that scales up multimodal data by generating multigranular visual and textual annotations in the form of image-ROI-description triplets without the need for any paired text descriptions. Specifically, data from over 30 different sources have been collected, preprocessed, and grounded using domain-specific expert models to identify ROIs related to abnormal regions. We then build a comprehensive knowledge base and prompt multimodal large language models to perform retrieval-augmented generation with the identified ROIs as guidance, resulting in multigranular textual descriptions. Compared to existing datasets, MedTrinity-25M provides the most enriched annotations, supporting a comprehensive range of multimodal tasks such as captioning and report generation, as well as vision-centric tasks like classification and segmentation. We propose LLaVA-Tri by pretraining LLaVA on MedTrinity-25M, achieving state-of-the-art performance on VQA-RAD, SLAKE, and PathVQA, surpassing representative SOTA multimodal large language models. Furthermore, MedTrinity-25M can also be utilized to support large-scale pre-training of multimodal medical AI models, contributing to the development of future foundation models in the medical domain. We will make our dataset available. The dataset is publicly available at https://yunfeixie233.github.io/MedTrinity-25M/.", "summary_cn": "提出MedTrinity-25M大规模医学多模态数据集，含2500万图像及多粒度标注，通过自动化流程生成图像-ROI-描述三元组，支持多种AI任务，并基于此预训练LLaVA-Tri模型取得SOTA性能。", "keywords": ["多模态数据集", "医学图像", "多粒度标注", "自动化标注", "大语言模型", "预训练"], "triple": {"method": "自动化流程生成图像-ROI-描述三元组", "result": "LLaVA-Tri在多个VQA基准上达到SOTA", "contribution": "提供大规模医学多模态数据集支持AI模型开发"}}
{"venue": "ICLR", "search_title": "Large-scale Training of Foundation Models for Wearable Biosignals", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/0d99a8c048befb6dd6e17d7684adacac-Abstract-Conference.html", "year": 2024, "abstract_snippet": "... medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/0d99a8c048befb6dd6e17d7684adacac-Abstract-Conference.html", "full_title": "Large-scale Training of Foundation Models for Wearable Biosignals", "abstract": "Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch. We curated PPG and ECG datasets from AHMS that include data from ${\\sim} 141$K participants spanning ${\\sim} 3$ years. Our self-supervised learning framework includes participant level positive pair selection, stochastic augmentation module and a regularized contrastive loss optimized with momentum training, and generalizes well to both PPG and ECG modalities. We show that the pre-trained foundation models readily encode information regarding participants' demographics and health conditions. To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices $\\textendash$ prior works have commonly used smaller-size datasets collected in clinical and experimental settings. We believe PPG and ECG foundation models can enhance future wearable devices by reducing the reliance on labeled data and hold the potential to help the users improve their health.", "summary_cn": "本研究利用苹果心脏与运动研究的大规模未标记PPG和ECG数据，通过自监督学习训练基础模型，有效编码用户人口统计和健康状况信息，减少对标注数据的依赖。", "keywords": ["可穿戴生物信号", "自监督学习", "基础模型", "光电容积描记", "心电图", "健康监测"], "triple": {"method": "自监督学习框架，包括参与者级正对选择、随机增强和正则化对比损失", "result": "基础模型能编码参与者人口统计和健康状况信息", "contribution": "首次利用大规模可穿戴设备数据构建PPG和ECG基础模型，减少标注数据依赖"}}
{"venue": "ICLR", "search_title": "Graph Transformers on EHRs: Better Representation Improves ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/a71c1931d3fb8ba564f7458d0657d0b1-Abstract-Conference.html", "year": 2024, "abstract_snippet": "This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2024/hash/a71c1931d3fb8ba564f7458d0657d0b1-Abstract-Conference.html", "full_title": "Graph Transformers on EHRs: Better Representation Improves Downstream Performance", "abstract": "Following the success of transformer-based methods across various machine learning applications, their adoption for healthcare predictive tasks using electronic health records (EHRs)  has also expanded extensively. Similarly, graph-based methods have been shown to be very effective in capturing inherent graph-type relationships in EHRs, leading to improved downstream performance. Although integrating these two families of approaches seems like a natural next step, in practice, creating such a design is challenging and has not been done. This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In this study, we propose GT-BEHRT, a new approach that leverages temporal visit embeddings extracted from a graph transformer and uses a BERT-based model to obtain more robust patient representations, especially on longer EHR sequences. The graph-based approach allows GT-BEHRT to implicitly capture the intrinsic graphical relationships between medical observations, while the BERT model extracts the temporal relationships between visits, loosely mimicking the clinicians' decision-making process. As part of our method, we also present a two-step pre-training strategy for learning better graphical and temporal representations. Our proposed method achieves state-of-the-art performance in a variety of standard medical predictive tasks, demonstrating the versatility of our approach.", "summary_cn": "本研究提出GT-BEHRT方法，结合图变换器和BERT模型，通过两步预训练策略提升电子健康记录的表征能力，在多项医疗预测任务中达到最优性能。", "keywords": ["图变换器", "电子健康记录", "BERT模型", "预训练策略", "医疗预测", "表征学习"], "triple": {"method": "结合图变换器与BERT的两步预训练", "result": "在多项医疗预测任务中达到最优性能", "contribution": "提出GT-BEHRT方法，提升EHR表征与下游任务表现"}}
{"venue": "ICLR", "search_title": "Time-to-Event Pretraining for 3DMedicalImaging", "url": "https://iclr.cc/media/iclr-2025/Slides/27661.pdf", "year": null, "abstract_snippet": "- Medical vision foundation models (VFMs) should help to better clinical decision making. - In medicine, prognosis can help long-term treatment planning, in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Time-to-Event Pretraining for 3DMedicalImaging", "abstract": null}
{"venue": "ICLR", "search_title": "MEDTRINITY-25M: A LARGE-SCALE - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/11c483499c285f30daf832c17dc752bd-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "However,. 1. Page 2. Published as a conference paper at ICLR 2025 current medical datasets have several limitations. Firstly, these datasets lack multigranular ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MEDTRINITY-25M: A LARGE-SCALE - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "Trustworthy Machine Learning for Healthcare - ICLR 2026", "url": "https://iclr.cc/virtual/2023/workshop/12822", "year": 2023, "abstract_snippet": "... medical data. However, ML techniques are still far from being widely applied in practice. Real-world scenarios are far more complex, and ML is often faced ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Trustworthy Machine Learning for Healthcare - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR TINY: Semantic-based Uncertainty Quantification in LLMS", "url": "https://iclr.cc/virtual/2025/32888", "year": 2025, "abstract_snippet": "TINY: Semantic-based Uncertainty Quantification in LLMS: A Case Study on Medical Explanation Generation Task. Nicholas Kian Boon Tan · Mehul Motani. Keywords ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32888", "full_title": "TINY: Semantic-based Uncertainty Quantification in LLMS: A Case Study on Medical Explanation Generation Task.", "abstract": "Given the often sensible and sometimes nonsensical outputs that modern Large Language Models (LLMs) generate, how should we interpret confident claims such as \"Strawberry has two 'r's\"? One tool that can be applied to such overconfident and hallucinatory claims is uncertainty quantification. In particular, this paper investigates the recently proposed semantic density framework to quantify uncertainty in LLM-generated medical explanations. Semantic density makes use of semantic similarity comparisons instead of lexical matching, and delivers per-response estimates of uncertainty. The results demonstrate that the semantic density framework remains performant when applied in specialized domains, and raises additional considerations around the utility of the ROUGE metric for semantic evaluations.", "summary_cn": "本文研究语义密度框架在大型语言模型生成医学解释任务中的不确定性量化，结果表明该框架在专业领域仍有效，并质疑ROUGE指标在语义评估中的实用性。", "keywords": ["不确定性量化", "语义密度", "大型语言模型", "医学解释生成", "ROUGE指标", "语义相似性"], "triple": {"method": "应用语义密度框架", "result": "框架在医学领域有效，ROUGE指标适用性存疑", "contribution": "验证语义不确定性量化在专业任务中的性能"}}
{"venue": "ICLR", "search_title": "Ho Hin Lee, PhD Candidate 3D UX-Net: A Large Kernel Volumetric ...", "url": "https://iclr.cc/media/iclr-2023/Slides/11340.pdf", "year": null, "abstract_snippet": "\"Unetr: Transformers for 3d medical image segmentation.”, WACV 2022. Page 3. Hierarchical Transformer. ○ With Swin Transformer as the generic backbone, we ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Ho Hin Lee, PhD Candidate 3D UX-Net: A Large Kernel Volumetric ...", "abstract": null}
{"venue": "ICLR", "search_title": "Track: Oral 3D - ICLR 2026", "url": "https://iclr.cc/virtual/2024/session/15083", "year": 2024, "abstract_snippet": "How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks? ... The pre-training and fine-tuning paradigm has become prominent in transfer learning. For ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Track: Oral 3D - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "TION VIA MASK-ATTRIBUTE ALIGNMENT - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/6111371a868af8dcfba0f96ad9e25ae3-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Recent advancements in medical vision-language pre-training models have driven signifi- cant progress in zero-shot disease recognition.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "TION VIA MASK-ATTRIBUTE ALIGNMENT - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Rough Transformers for Continuous and Efficient Time-Series ...", "url": "https://iclr.cc/virtual/2024/23551", "year": 2024, "abstract_snippet": "Time-series data in real-world medical settings typically exhibit long-range dependencies and are observed at non-uniform intervals.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/23551", "full_title": "Rough Transformers for Continuous and Efficient Time-Series Modelling", "abstract": "Time-series data in real-world medical settings typically exhibit long-range dependencies and are observed at non-uniform intervals. In such contents, traditional sequence-based recurrent models struggle. To overcome this, researchers replace recurrent architectures with Neural ODE-based models to model irregularly sampled data and use Transformer-based architectures to account for long-range dependencies. Despite the success of these two approaches, both incur very high computational costs for input sequences of moderate lengths and greater. To mitigate this, we introduce the Rough Transformer, a variation of the Transformer model which operates on continuous-time representations of input sequences and incurs significantly reduced computational costs, critical for addressing long-range dependencies common in medical contexts. In particular, we propose multi-view signature attention, which uses path signatures to augment vanilla attention and to capture both local and global dependencies in input data, while remaining robust to changes in the sequence length and sampling frequency. We find that Rough Transformers consistently outperform their vanilla attention counterparts while obtaining the benefits of Neural ODE-based models using a fraction of the computational time and memory resources on synthetic and real-world time-series tasks.", "summary_cn": "提出Rough Transformer，结合路径签名增强注意力，高效处理医疗时间序列的长程依赖和非均匀采样，计算成本显著降低。", "keywords": ["Rough Transformer", "时间序列建模", "路径签名", "长程依赖", "计算效率", "医疗数据"], "triple": {"method": "多视图签名注意力", "result": "性能优于传统注意力，计算资源大幅减少", "contribution": "高效连续时间序列建模方法"}}
{"venue": "ICLR", "search_title": "Learning Group Importance Using the Differentiable Hypergeometric ...", "url": "https://iclr.cc/media/iclr-2023/Slides/10707.pdf", "year": null, "abstract_snippet": "May 1, 2023 ... Medical Data Science. Learning Group Importance Using the. Differentiable Hypergeometric Distribution. Thomas M. Sutter, Laura Manduchi, Alain ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Learning Group Importance Using the Differentiable Hypergeometric ...", "abstract": null}
{"venue": "ICLR", "search_title": "Learning Causal Alignment for Reliable Disease Diagnosis", "url": "https://iclr.cc/virtual/2025/poster/28327", "year": 2025, "abstract_snippet": "We demonstrate the effectiveness of our method on two medical diagnosis applications, showcasing faithful alignment to radiologists. Show more. Video. Chat is ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/28327", "full_title": "Learning Causal Alignment for Reliable Disease Diagnosis", "abstract": "Aligning the decision-making process of machine learning algorithms with that of experienced radiologists is crucial for reliable diagnosis. While existing methods have attempted to align their prediction behaviors to those of radiologists reflected in the training data, this alignment is primarily associational rather than causal, resulting in pseudo-correlations that may not transfer well. In this paper, we propose a causality-based alignment framework towards aligning the model's decision process with that of experts. Specifically, we first employ counterfactual generation to identify the causal chain of model decisions. To align this causal chain with that of experts, we propose a causal alignment loss that enforces the model to focus on causal factors underlying each decision step in the whole causal chain. To optimize this loss that involves the counterfactual generator as an implicit function of the model's parameters, we employ the implicit function theorem equipped with the conjugate gradient method for efficient estimation. We demonstrate the effectiveness of our method on two medical diagnosis applications, showcasing faithful alignment to radiologists.", "summary_cn": "提出基于因果关系的对齐框架，通过反事实生成和因果对齐损失，使模型决策过程与放射科专家对齐，提升诊断可靠性。", "keywords": ["因果对齐", "反事实生成", "医学诊断", "机器学习", "放射科专家", "决策过程"], "triple": {"method": "反事实生成与因果对齐损失", "result": "模型决策与专家因果链对齐", "contribution": "提升诊断可靠性与可迁移性"}}
{"venue": "ICLR", "search_title": "ICLR TIMER: Temporal Instruction Modeling and Evaluation for ...", "url": "https://iclr.cc/virtual/2025/32173", "year": 2025, "abstract_snippet": "Large language models (LLMs) have emerged as promising tools for assisting in medical tasks, yet processing Electronic Health Records (EHRs) presents unique ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/32173", "full_title": "TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records", "abstract": "Large language models (LLMs) have emerged as promising tools for assisting in medical tasks, yet processing Electronic Health Records (EHRs) presents unique challenges due to their longitudinal nature. While LLMs' capabilities to perform medical tasks continue to improve, their ability to reason over temporal dependencies across multiple patient visits and time frames remains unexplored. We introduce TIMER ( T emporal I nstruction M odeling and E valuation for Longitudinal Clinical R ecords), a synthetic data generation framework that incorporates temporal distribution of instructions as a critical dimension in both instruction evaluation and tuning for longitudinal clinical records. We develop TIMER-Bench, the first time-aware benchmark that evaluates temporal reasoning capabilities over longitudinal EHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to learn reasoning over time. We demonstrate that models fine-tuned with TIMER-Instruct improve performance by 7.3% on human-generated benchmarks and 9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model performance for reasoning over EHR. Our code is available at TIMER .", "summary_cn": "TIMER框架通过生成合成数据和指令调优，提升大语言模型在纵向电子健康记录中的时序推理能力，性能显著提升。", "keywords": ["大语言模型", "电子健康记录", "时序推理", "指令调优", "基准评估", "合成数据"], "triple": {"method": "合成数据生成与指令调优", "result": "模型性能提升7.3%-9.2%", "contribution": "提出首个时序感知基准与调优方法"}}
{"venue": "ICLR", "search_title": "A General Framework for Off-Policy Learning with Partially ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/098491b37deebbe6c007e69815729e09-Abstract-Conference.html", "year": 2025, "abstract_snippet": "... medical problems. One possible solution to deal with such partial rewards is to use secondary rewards, such as dwelling time, clicks, and medical indicators ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/098491b37deebbe6c007e69815729e09-Abstract-Conference.html", "full_title": "A General Framework for Off-Policy Learning with Partially-Observed Reward", "abstract": "Off-policy learning (OPL) in contextual bandits aims to learn a decision-making policy that maximizes the target rewards by using only historical interaction data collected under previously developed policies. Unfortunately, when rewards are only partially observed, the effectiveness of OPL degrades severely. Well-known examples of such partial rewards include explicit ratings in content recommendations, conversion signals on e-commerce platforms that are partial due to delay, and the issue of censoring in medical problems. One possible solution to deal with such partial rewards is to use secondary rewards, such as dwelling time, clicks, and medical indicators, which are more densely observed. However, relying solely on such secondary rewards can also lead to poor policy learning since they may not align with the target reward. Thus, this work studies a new and general problem of OPL where the goal is to learn a policy that maximizes the expected target reward by leveraging densely observed secondary rewards as supplemental data. We then propose a new method called Hybrid Policy Optimization for Partially-Observed Reward (HyPeR), which effectively uses the secondary rewards in addition to the partially observed target reward to achieve effective OPL despite the challenging scenario. We also discuss a case where we aim to optimize not only the expected target reward but also the expected secondary rewards to some extent; counter-intuitively, we will show that leveraging the two objectives is in fact advantageous also for the optimization of only the target reward. Along with statistical analysis of our proposed methods, empirical evaluations on both synthetic and real-world data show that HyPeR outperforms existing methods in various scenarios.", "summary_cn": "提出HyPeR方法，利用密集观测的次级奖励辅助部分观测的目标奖励，提升离线策略学习效果，在合成和真实数据中表现优异。", "keywords": ["离线策略学习", "部分观测奖励", "次级奖励", "HyPeR方法", "上下文赌博机", "优化目标"], "triple": {"method": "HyPeR方法结合目标与次级奖励", "result": "在合成和真实数据中优于现有方法", "contribution": "提升部分观测奖励下的离线策略学习效果"}}
{"venue": "ICLR", "search_title": "ICLR Poster Learning General-purpose Biomedical Volume ...", "url": "https://iclr.cc/virtual/2025/poster/27787", "year": 2025, "abstract_snippet": "Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/27787", "full_title": "Learning General-purpose Biomedical Volume Representations using Randomized Synthesis", "abstract": "Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that would enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.", "summary_cn": "提出一种通过随机合成数据训练通用3D生物医学体积表示的方法，无需真实图像数据集，在配准和分割任务中实现新标准。", "keywords": ["生物医学体积表示", "随机合成", "对比学习", "3D网络", "泛化能力", "少样本分割"], "triple": {"method": "使用数据引擎合成变量样本，结合对比学习预训练", "result": "在配准和少样本分割任务中达到新标准", "contribution": "提出无需真实数据集的通用3D生物医学表示学习方法"}}
{"venue": "ICLR", "search_title": "A Semantic Metric for Evaluating Large Vision Models Using Large ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/fc07feae9af49dd3f1a1e049b77f4e17-Abstract-Conference.html", "year": 2025, "abstract_snippet": "... medical images using the encoding space of Large Language Models (LLMs) from medical reports. Through extensive experimentation on 32 datasets from The ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/fc07feae9af49dd3f1a1e049b77f4e17-Abstract-Conference.html", "full_title": "Boltzmann Semantic Score: A Semantic Metric for Evaluating Large Vision Models Using Large Language Models", "abstract": "Do Large Vision Models (LVMs) extract medically and semantically relevant features similar to those identified by human experts? Currently, only biased, qualitative approaches with limited, small-scale expert evaluations are available to answer this question. In this study, we propose the Boltzmann Semantic Score (BSS), a novel method inspired by state space modeling, to evaluate the encoding space of LVMs from medical images using the encoding space of Large Language Models (LLMs) from medical reports. Through extensive experimentation on 32 datasets from The Cancer Genome Atlas collection using five state-of-the-art LLMs, we first establish a baseline of LLMs' performance in digital pathology and show that LLMs' encoding can be linked to patient outcomes. Then, we compared seven LVMs with BSS and showed that LVMs suffer from poor semantic capability when compared with encoded expert knowledge from pathology reports.We also found statistically significant correlations between BSS (as a measure of structural similarity) and performance in two downstream tasks: information retrieval and survival prediction tasks. Our study also investigates the consensus among LLMs in evaluating LVMs using BSS, indicating that LLMs generally reach substantial consensus in rating LVMs, with some variation dependant on the cancer type. We believe the BSS metric proposed here holds significant potential for application in other domains with similar contexts. Data and code can be found in \\footnotesize \\url{ https://github.com/AIMLab-UBC/Boltzmann}", "summary_cn": "提出Boltzmann语义评分（BSS），利用大语言模型评估大视觉模型在医学图像中的语义特征提取能力，发现其与专家知识存在差距，并与下游任务性能相关。", "keywords": ["Boltzmann语义评分", "大视觉模型", "大语言模型", "医学图像分析", "语义评估", "癌症基因组图谱"], "triple": {"method": "基于状态空间建模，比较LVMs与LLMs的编码空间", "result": "LVMs语义能力不足，BSS与下游任务性能显著相关", "contribution": "提出BSS量化评估指标，促进跨模型语义对齐"}}
{"venue": "ICLR", "search_title": "Prompting Diverse Experts Together Wins More in Visual Adaptation", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/c54a5c64fd929d05547dba74db0e7e8c-Abstract-Conference.html", "year": 2025, "abstract_snippet": "Typically, prompt tuning techniques have harnessed knowledge from a single pre-trained model, whether from a general or a specialized medical domain.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://proceedings.iclr.cc/paper_files/paper/2025/hash/c54a5c64fd929d05547dba74db0e7e8c-Abstract-Conference.html", "full_title": "pMoE: Prompting Diverse Experts Together Wins More in Visual Adaptation", "abstract": "Parameter-efficient fine-tuning has demonstrated promising results across various visual adaptation tasks, such as classification and segmentation. Typically, prompt tuning techniques have harnessed knowledge from a single pre-trained model, whether from a general or a specialized medical domain. However, this approach typically overlooks the potential synergies that could arise from integrating diverse domain knowledge within the same tuning process. In this work, we propose a novel Mixture-of-Experts prompt tuning method called pMoE, which leverages the strengths of multiple expert domains through expert-specialized prompt tokens and the learnable dispatcher, effectively combining their expertise in a unified model framework. Our pMoE introduces expert-specific prompt tokens and utilizes a dynamic token dispatching mechanism at various prompt layers to optimize the contribution of each domain expert during the adaptation phase. By incorporating both domain knowledge from diverse experts, the proposed pMoE significantly enhances the model's versatility and applicability to a broad spectrum of tasks. We conduct extensive experiments across 47 adaptation tasks, including both classification and segmentation in general and medical domains. The results demonstrate that our pMoE not only achieves superior performance with a large margin of improvements but also offers an optimal trade-off between computational efficiency and adaptation effectiveness compared to existing methods.", "summary_cn": "提出pMoE方法，通过专家专用提示令牌和动态调度器整合多领域知识，在47个视觉适应任务中显著提升性能与效率。", "keywords": ["pMoE", "视觉适应", "提示调优", "专家混合", "参数高效", "多领域知识"], "triple": {"method": "专家专用提示令牌与动态调度器", "result": "在47个任务中性能大幅提升，平衡效率与效果", "contribution": "提出统一框架整合多领域专家知识"}}
{"venue": "ICLR", "search_title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees", "url": "https://iclr.cc/virtual/2022/poster/7015", "year": 2022, "abstract_snippet": "... medical history. Fully-differentiable tree architectures are grown incrementally during optimization to adapt their complexity to the modelling task, and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees", "abstract": null}
{"venue": "ICLR", "search_title": "Advancing Radiograph Representation Learning with Masked ...", "url": "https://iclr.cc/virtual/2023/poster/11871", "year": 2023, "abstract_snippet": "... medical expertise, while the complementarity between them is barely noticed. To explore this, we formulate the self- and report-completion as two ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Advancing Radiograph Representation Learning with Masked ...", "abstract": null}
{"venue": "ICLR", "search_title": "Compositional Training for End-to-End Deep AUC Maximization", "url": "https://iclr.cc/virtual/2022/poster/6071", "year": 2022, "abstract_snippet": "Recently, deep AUC maximization (DAM) has achieved great success in different domains (e.g., medical image classification). However, the end-to-end training ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Compositional Training for End-to-End Deep AUC Maximization", "abstract": null}
{"venue": "ICLR", "search_title": "Uncertainty-Aware Planning Enhances Information Seeking in Large ...", "url": "https://iclr.cc/virtual/2024/22184", "year": 2024, "abstract_snippet": "In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/22184", "full_title": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models", "abstract": "In the face of uncertainty, the ability to seek information is of fundamental importance. In many practical applications, such as medical diagnosis and troubleshooting, the information needed to solve the task is not initially given, and has to be actively sought by asking follow-up questions (for example, a doctor asking a patient for more details about their symptoms). In this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to augment large language models with the ability to actively seek information by asking effective questions. UoT combines 1) an uncertainty-aware simulation approach which enables the model to simulate possible future scenarios and how likely they are to occur, 2) uncertainty-based rewards motivated by information gain which incentivizes the model to seek information, and 3) a reward propagation scheme to select the optimal question to ask in a way that maximizes the expected reward. In experiments on medical diagnosis, troubleshooting and the `20 Questions' game, UoT achieves an average performance improvement of 57.8% in the rate of successful task completion across multiple LLMs compared with direct prompting, and also improves efficiency (i.e., the number of questions needed to complete the task).", "summary_cn": "提出UoT算法，通过不确定性感知模拟、信息增益奖励和奖励传播，增强大语言模型主动提问以寻求信息的能力，在医疗诊断等任务中显著提升成功率与效率。", "keywords": ["不确定性感知", "信息寻求", "大语言模型", "主动提问", "医疗诊断", "奖励机制"], "triple": {"method": "不确定性感知模拟与奖励传播", "result": "任务成功率平均提升57.8%，效率提高", "contribution": "增强LLM主动信息寻求能力"}}
{"venue": "ICLR", "search_title": "EHRAgent: Code Empowers Large Language Models for Few-shot ...", "url": "https://iclr.cc/virtual/2024/22183", "year": 2024, "abstract_snippet": "... medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for complex clinical ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/22183", "full_title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for complex clinical tasks within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.60%. EHRAgent leverages the emerging few-shot learning capabilities of LLMs, enabling autonomous code generation and execution to tackle complex clinical tasks. Our implementation of EHRAgent is available at https://anonymous.4open.science/r/EHRAgent24-95C0.", "summary_cn": "EHRAgent 是一个基于大语言模型的智能体，通过代码接口自主生成和执行代码，以解决电子健康记录中的复杂临床任务，在少样本学习下性能显著提升。", "keywords": ["电子健康记录", "大语言模型", "代码生成", "少样本学习", "临床推理", "自主代理"], "triple": {"method": "代码接口与长时记忆增强", "result": "在三个真实 EHR 数据集上性能提升达 29.60%", "contribution": "实现少样本复杂临床任务自主推理"}}
{"venue": "ICLR", "search_title": "ICLR 2025 Papers", "url": "https://iclr.cc/virtual/2025/papers.html", "year": 2025, "abstract_snippet": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts ... medical detection · How do we interpret the outputs of a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR 2025 Papers", "abstract": null}
{"venue": "ICLR", "search_title": "GraphCare: Enhancing Healthcare Predictions with Personalized ...", "url": "https://iclr.cc/virtual/2024/poster/17612", "year": 2024, "abstract_snippet": "Clinical predictive models often rely on patients' electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/poster/17612", "full_title": "GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs", "abstract": "Clinical predictive models often rely on patients’ electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledgegraphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GraphCare, an open-world framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patient-specific KGs, which are then used to train our proposed Bi-attention AugmenTed(BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GraphCare surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GraphCare demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GraphCare in generating personalized KGs for promoting personalized medicine.", "summary_cn": "GraphCare框架利用外部知识图谱和LLM构建个性化知识图谱，结合BAT图神经网络提升医疗预测性能，在MIMIC数据集上显著优于基线模型。", "keywords": ["个性化知识图谱", "图神经网络", "医疗预测", "电子健康记录", "大语言模型", "数据增强"], "triple": {"method": "基于外部知识图谱和LLM构建个性化知识图谱，采用BAT图神经网络", "result": "在MIMIC数据集上，死亡率预测AUROC提升17.6%，再入院预测提升6.6%", "contribution": "提出开放世界框架GraphCare，增强医疗预测的个性化和准确性"}}
{"venue": "ICLR", "search_title": "ICLR Closing The Modality Gap Enables Novel Multimodal Learning ...", "url": "https://iclr.cc/virtual/2025/36848", "year": 2025, "abstract_snippet": "In medical multimodal learning, our method enhances alignment between radiology images and clinical text, improving cross-modal retrieval and image captioning.", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/36848", "full_title": "Closing The Modality Gap Enables Novel Multimodal Learning Applications", "abstract": "In multimodal learning, CLIP has emerged as the de facto approach for mapping different modalities into a shared latent space by bringing semantically similar representations closer while pushing apart dissimilar ones. However, CLIP-based contrastive losses exhibit unintended behaviors that negatively impact true semantic alignment, leading to sparse and fragmented latent spaces. This phenomenon, known as the modality gap, has been partially mitigated for standard text and image pairs, but remains unresolved in more complex multimodal settings, especially when integrating three or more modalities.In this work, we propose a modality-agnostic framework that definitively closes the modality gap across multiple modalities, ensuring that semantically related representations are perfectly aligned, regardless of their source modality. Beyond theoretical improvements, we demonstrate that closing the modality gap has profound implications for real-world applications. In semantic communication, our approach enables the transmission of a single compact representation per semantic concept, drastically reducing bandwidth requirements while preserving multimodal reconstruction quality. In medical multimodal learning, our method enhances alignment between radiology images and clinical text, improving cross-modal retrieval and image captioning. We show that our approach not only closes the modality gap permanently but also unlocks new capabilities in downstream applications that were previously limited by poor cross-modal alignment.", "summary_cn": "提出一种模态无关框架，彻底消除多模态学习中的模态鸿沟，实现语义表示的完美对齐，显著提升语义通信和医学多模态应用性能。", "keywords": ["模态鸿沟", "多模态学习", "语义对齐", "对比学习", "医学应用", "语义通信"], "triple": {"method": "模态无关框架", "result": "消除模态鸿沟，提升跨模态检索与图像描述", "contribution": "解锁新应用能力"}}
{"venue": "ICLR", "search_title": "BOLTZMANN SEMANTIC SCORE - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/fc07feae9af49dd3f1a1e049b77f4e17-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "In standard medical practice, imaging data is typically analyzed by a single specialist, except in rare cases that require a collective assessment. In the field ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "BOLTZMANN SEMANTIC SCORE - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster Label super-resolution networks", "url": "https://iclr.cc/virtual/2019/poster/673", "year": 2019, "abstract_snippet": "We also test our approach on a medical imaging problem, resolving low-resolution probability maps into high-resolution segmentation of lymphocytes with ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster Label super-resolution networks", "abstract": null}
{"venue": "ICLR", "search_title": "Quasi-optimal Reinforcement Learning with Continuous Actions", "url": "https://iclr.cc/virtual/2023/poster/11527", "year": 2023, "abstract_snippet": "... medical treatment regimes. One challenge in adapting existing RL algorithms to medical applications, however, is that the popular infinite support ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Quasi-optimal Reinforcement Learning with Continuous Actions", "abstract": null}
{"venue": "ICLR", "search_title": "Supplementary Materials - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/5ef6b140c8b6cc2904854e30c6db78eb-Supplementary-Conference.pdf", "year": 2024, "abstract_snippet": "natural and medical images with respect to intrinsic dataset dimension ddata (Fig. ... (orange) and medical (blue) image datasets which we analyze (Sec. 4), with ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Supplementary Materials - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "GraphCare: Enhancing Healthcare Predictions With Personalized ...", "url": "https://iclr.cc/media/iclr-2024/Slides/17612.pdf", "year": null, "abstract_snippet": "How to improve time-series clinical (EHR) predictions with those KGs? - We construct medical concept-specific KGs. - We treat personalized knowledge graphs as ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "GraphCare: Enhancing Healthcare Predictions With Personalized ...", "abstract": null}
{"venue": "ICLR", "search_title": "Yet Another ICU Benchmark (YAIB)", "url": "https://iclr.cc/media/iclr-2024/Slides/17800.pdf", "year": null, "abstract_snippet": "Medical concepts of interest (e.g., sepsis) are not directly recorded but need to be retrospectively derived from these events. Exclamation-Triangle ICU ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Yet Another ICU Benchmark (YAIB)", "abstract": null}
{"venue": "ICLR", "search_title": "LEARNING GENERAL-PURPOSE BIOMEDICAL VOLUME ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/4f693c15f189efd888b6782a5f4eccb1-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Medical image analysis, 87:102792, 2023. 11. Page 12. Published as a conference paper at ICLR 2025. Liang Chen, Paul ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LEARNING GENERAL-PURPOSE BIOMEDICAL VOLUME ...", "abstract": null}
{"venue": "ICLR", "search_title": "Quantify Uncertainty and Hallucination in Foundation Models", "url": "https://iclr.cc/virtual/2025/workshop/23965", "year": 2025, "abstract_snippet": "TINY: Semantic-based Uncertainty Quantification in LLMS: A Case Study on Medical Explanation Generation Task. Nicholas Kian Boon Tan · Mehul Motani. Link.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Quantify Uncertainty and Hallucination in Foundation Models", "abstract": null}
{"venue": "ICLR", "search_title": "Anyprefer: An Agentic Framework for Preference Data Synthesis", "url": "https://iclr.cc/virtual/2025/poster/29342", "year": 2025, "abstract_snippet": "... medical image analysis datasets, and 16.00% in four visuo-motor control tasks. Chat is not available. Successful Page Load. ICLR uses cookies for essential ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2025/poster/29342", "full_title": "Anyprefer: An Agentic Framework for Preference Data Synthesis", "abstract": "High-quality preference data is essential for aligning foundation models with human values through preference learning. However, manual annotation of such data is often time-consuming and costly. Recent methods often adopt a self-rewarding approach, where the target model generates and annotates its own preference data, but this can lead to inaccuracies since the reward model shares weights with the target model, thereby amplifying inherent biases. To address these issues, we propose Anyprefer, a framework designed to synthesize high-quality preference data for aligning the target model. Anyprefer frames the data synthesis process as a cooperative two-player Markov Game, where the target model and the judge model collaborate together. Here, a series of external tools are introduced to assist the judge model in accurately rewarding the target model’s responses, mitigating biases in the rewarding process. In addition, a feedback mechanism is introduced to optimize prompts for both models, enhancing collaboration and improving data quality. The synthesized data is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K high-quality preference pairs. Extensive experiments show that Anyprefer significantly improves model alignment performance across four main applications, covering 21 datasets, achieving average improvements of 18.55% in five natural language generation datasets, 3.66% in nine vision-language understanding datasets, 30.05% in three medical image analysis datasets, and 16.00% in four visuo-motor control tasks.", "summary_cn": "提出Anyprefer框架，通过双智能体协作与外部工具辅助，合成高质量偏好数据，提升基础模型对齐性能。", "keywords": ["偏好数据合成", "模型对齐", "双智能体协作", "外部工具", "反馈机制", "Anyprefer-V1数据集"], "triple": {"method": "双智能体协作与外部工具辅助", "result": "合成58K高质量偏好对，提升多领域模型性能", "contribution": "提出Anyprefer框架，缓解偏好数据合成偏差"}}
{"venue": "ICLR", "search_title": "KNOWLEDGE GRAPH FINETUNING ENHANCES KNOWL", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/e44337573fcac83f219c8effa4ebf90d-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "However, applying. LLMs to low-data and knowledge-intensive domains (e.g., a specific medical field (Nori et al., 2023) or private data with niche protocols ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "KNOWLEDGE GRAPH FINETUNING ENHANCES KNOWL", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster Adversarial Feature Map Pruning for Backdoor", "url": "https://iclr.cc/virtual/2024/poster/18966", "year": 2024, "abstract_snippet": "... medical diagnosis. However, their security is threatened by backdoor attacks, which are achieved by adding artificial patterns to specific training data ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/poster/18966", "full_title": "Adversarial Feature Map Pruning for Backdoor", "abstract": "Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is threatened by backdoor attacks, which are achieved by adding artificial patterns to specific training data. Existing defense strategies primarily focus on using reverse engineering to reproduce the backdoor trigger generated by attackers and subsequently repair the DNN model by adding the trigger into inputs and fine-tuning the model with ground truth labels. However, once the trigger generated by the attackers is complex and invisible, the defender cannot reproduce the trigger successfully then the DNN model will not be repaired, as the trigger is not effectively removed. In this work, we propose Adversarial Feature Map Pruning for Backdoor (FMP) to mitigate backdoor from the DNN. Unlike existing defense strategies, which focus on reproducing backdoor triggers, FMP attempts to prune backdoor feature maps, which are trained to extract backdoor information from inputs. After pruning these backdoor feature maps, FMP will fine-tune the model with a secure subset of training data. Our experiments demonstrate that, compared to existing defense strategies, FMP can effectively reduce the Attack Success Rate (ASR) even against the most complex and invisible attack triggers (e.g., FMP decreases the ASR to 2.86% in CIFAR10, which is 19.2% to 65.41% lower than baselines). Second, unlike conventional defense methods that tend to exhibit low robust accuracy (that is, the accuracy of the model on poisoned data), FMP achieves a higher RA, indicating its superiority in maintaining model performance while mitigating the effects of backdoor attacks (e.g., FMP obtains 87.40% RA in CIFAR10). Our code is publicly available at: https://github.com/hku-systems/FMP.", "summary_cn": "提出对抗性特征图剪枝方法，通过剪枝后门特征图并微调，有效降低复杂隐形后门攻击成功率，同时保持模型性能。", "keywords": ["后门攻击防御", "特征图剪枝", "深度学习安全", "对抗性训练", "模型微调", "攻击成功率"], "triple": {"method": "剪枝后门特征图并微调", "result": "攻击成功率降至2.86%，鲁棒准确率达87.40%", "contribution": "高效防御复杂隐形后门攻击"}}
{"venue": "ICLR", "search_title": "DELPHIC OFFLINE REINFORCEMENT LEARNING - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/0b9ff9baa226af39f86045ecdc173672-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Alternatively, in the medical context, unrecorded patient state information such as socio-economic factors or visual appearance may have been taken into account ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DELPHIC OFFLINE REINFORCEMENT LEARNING - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "Non-asymptotic Confidence Intervals of Off-policy Evaluation: Primal ...", "url": "https://iclr.cc/virtual/2021/poster/2875", "year": 2021, "abstract_snippet": "... medical treatment, where interactive data collection is expensive or even unsafe. As the observed data tends to be noisy and limited, it is essential to ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Non-asymptotic Confidence Intervals of Off-policy Evaluation: Primal ...", "abstract": null}
{"venue": "ICLR", "search_title": "beyond fine-tuning: lora modules boost near - ICLR 2026", "url": "https://iclr.cc/virtual/2024/23846", "year": 2024, "abstract_snippet": "... medical domain as a fine-tuning task. Our results motivate the use of LoRA modules even after deployment, since they provide strong features for OOD ...", "is_main_conference": true, "abstract_source_venue": "ICLR", "abstract_source_url": "https://iclr.cc/virtual/2024/23846", "full_title": "BEYOND FINE-TUNING: LORA MODULES BOOST NEAR- OOD DETECTION AND LLM SECURITY", "abstract": "Under resource constraints, LLMs are usually fine-tuned with additional knowl- edge using Parameter Efficient Fine-Tuning (PEFT), using Low-Rank Adaptation (LoRA) modules. In fact, LoRA injects a new set of small trainable matrices to adapt an LLM to a new task, while keeping the latter frozen. At deployment, LoRA weights are subsequently merged with the LLM weights to speed up inference. In this work, we show how to exploit the unmerged LoRA’s embedding to boost the performance of Out-Of-Distribution (OOD) detectors, especially in the more challenging near-OOD scenarios. Accordingly, we demonstrate how improving OOD detection also helps in characterizing wrong predictions in downstream tasks, a fundamental aspect to improve the reliability of LLMs. Moreover, we will present a use-case in which the sensitivity of LoRA modules and OOD detection are em- ployed together to alert stakeholders about new model updates. This scenario is particularly important when LLMs are out-sourced. Indeed, test functions should be applied as soon as the model changes the version in order to adapt prompts in the downstream applications. In order to validate our method, we performed tests on Multiple Choice Question Answering datasets, by focusing on the medical domain as a fine-tuning task. Our results motivate the use of LoRA modules even after deployment, since they provide strong features for OOD detection for fine-tuning tasks and can be employed to improve the security of LLMs.", "summary_cn": "研究利用未合并的LoRA模块提升大语言模型的分布外检测性能，尤其在近分布外场景，增强模型可靠性和安全性。", "keywords": ["LoRA模块", "分布外检测", "大语言模型安全", "参数高效微调", "近分布外", "模型可靠性"], "triple": {"method": "利用未合并LoRA模块特征", "result": "提升近分布外检测性能，改善错误预测表征", "contribution": "增强LLM可靠性与安全更新"}}
{"venue": "ICLR", "search_title": "recognize any surgical object: unleashing - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/53d3f45797970d323bd8a0d379c525aa-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Isinet: an instance-based approach for surgical instrument segmentation. In International Conference on Medical Image Computing and Computer-Assisted ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "recognize any surgical object: unleashing - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "SAFLEX: SELF-ADAPTIVE AUGMENTATION VIA FEA - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a264726ebd222124514a32bf0143b83d-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "As a versatile module, SAFLEX excels across diverse datasets, including natural, medical images, and tabular data, showcasing its prowess in few-shot learning ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SAFLEX: SELF-ADAPTIVE AUGMENTATION VIA FEA - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "ORACLE EFFICIENT ALGORITHMS FOR GROUPWISE RE- GRET", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/1c9ee8c9e1a0c7de49e15720c4ce6f78-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Here medical costs have been scaled to lie in [0, 1] and so the absolute numbers are not meaningful; it is relative comparisons that are important. What we see ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ORACLE EFFICIENT ALGORITHMS FOR GROUPWISE RE- GRET", "abstract": null}
{"venue": "ICLR", "search_title": "MAKING PRE-TRAINED LANGUAGE MODELS GREAT - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/668563ef18fbfef0b66af491ea334d5f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Tabular data, a common data form, is pivotal in various fields such as medical trial predictions (Has- san et al., 2020) and financial risk detection (Aziz ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MAKING PRE-TRAINED LANGUAGE MODELS GREAT - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "FICTITIOUS SYNTHETIC DATA CAN IMPROVE LLM FACTUALITY ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/98ecdc722006c2959babbdbdeb22eb75-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "This. 16. Page 17. Published as a conference paper at ICLR 2025. Table 5: Statistics of the synthetic datasets for PREREQ-TUNE. Persons Medical Entities PopQA ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FICTITIOUS SYNTHETIC DATA CAN IMPROVE LLM FACTUALITY ...", "abstract": null}
{"venue": "ICLR", "search_title": "SAMER: A SCENARIO-AWARE MULTI-DIMENSIONAL ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/646ca7b994bc46afe33d680dbe7ed67a-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Timeliness: The advice should be current, reflecting the latest medical guidelines and research. 14. Page 15. Published as a conference paper at ICLR 2025.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SAMER: A SCENARIO-AWARE MULTI-DIMENSIONAL ...", "abstract": null}
{"venue": "ICLR", "search_title": "Downloads 2025 - ICLR 2026", "url": "https://iclr.cc/Downloads/2025", "year": null, "abstract_snippet": "Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts · Efficiently Learning at Test-Time: Active Fine-Tuning of ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Downloads 2025 - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "Hierarchical Uncertainty Estimation for Learning-based Registration ...", "url": "https://iclr.cc/media/iclr-2025/Slides/27869.pdf", "year": null, "abstract_snippet": "Mar 31, 2025 ... Xiaoling Hu. Athinoula A. Martinos Center for Biomedical Imaging. MGH/Harvard Medical School https://huxiaoling.github.io/.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Hierarchical Uncertainty Estimation for Learning-based Registration ...", "abstract": null}
{"venue": "ICLR", "search_title": "Most discriminative stimuli for functional cell type clustering", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/61370b118cd3dcf949f0803ae2d649e0-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Medical Informatics, Tübingen University, Germany, 7 Hertie Institute for AI in Brain Health, University of. Tübingen, Germany, 8 Department of Neuroscience ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Most discriminative stimuli for functional cell type clustering", "abstract": null}
{"venue": "ICLR", "search_title": "PARAM∆ FOR DIRECT WEIGHT MIXING: POST-TRAIN LARGE ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/78bca5cc621a0846cb1f8265e1927a2a-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "1-inst models, or a medical -specific model Bio- Medical -. Llama-3-8B (Con, 2024) 1; 2) There is a notable similarity between the parameter differences of the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PARAM∆ FOR DIRECT WEIGHT MIXING: POST-TRAIN LARGE ...", "abstract": null}
{"venue": "ICLR", "search_title": "The Effectiveness of Random Forgetting for Robust Generalization", "url": "https://iclr.cc/media/iclr-2024/Slides/18836.pdf", "year": null, "abstract_snippet": "medical diagnosis. ○ Adversarial Training (AT) enhances DNN robustness by training with adversarial examples. ○ Adversarial Training is essential for ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "The Effectiveness of Random Forgetting for Robust Generalization", "abstract": null}
{"venue": "ICLR", "search_title": "UNPAIRED IMAGE-TO-IMAGE TRANSLATION VIA NEURAL ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/5491280797f3192b895bce84eb83df8d-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In particular, UNSB may be used in areas with beneficial impacts, such as medical image restoration. However, UNSB may also be used to create malicious ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "UNPAIRED IMAGE-TO-IMAGE TRANSLATION VIA NEURAL ...", "abstract": null}
{"venue": "ICLR", "search_title": "Published as a conference paper at ICLR 2024 A METHOD AND ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a264726ebd222124514a32bf0143b83d-Supplementary-Conference.pdf", "year": 2024, "abstract_snippet": "Data augmentation is greedily learned in our formulation, in sync with the ongoing training dynamics. Medical image classification MedMNIST (Yang et al., 2023; ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Published as a conference paper at ICLR 2024 A METHOD AND ...", "abstract": null}
{"venue": "ICLR", "search_title": "PowerPoint 演示文稿", "url": "https://iclr.cc/media/iclr-2025/Slides/32087.pdf", "year": null, "abstract_snippet": "medical data collection, there is an increasing demand for zero-shot models capable of handling unseen diseases in an open-set setting. Challenges: • The ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PowerPoint 演示文稿", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR Poster SOM-VAE: Interpretable Discrete Representation ...", "url": "https://iclr.cc/virtual/2019/poster/729", "year": 2019, "abstract_snippet": "... medical time series application on the eICU data set. Our learned representations compare favorably with competitor methods and facilitate downstream tasks ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR Poster SOM-VAE: Interpretable Discrete Representation ...", "abstract": null}
{"venue": "ICLR", "search_title": "Self-supervised representation learning from random data projectors", "url": "https://iclr.cc/media/iclr-2024/Slides/19089.pdf", "year": null, "abstract_snippet": "More results available in the paper. Linear evaluation performance on downstream tasks. Domain- agnostic baselines. Domain- specific baselines. Medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Self-supervised representation learning from random data projectors", "abstract": null}
{"venue": "ICLR", "search_title": "DOMAIN CONSTRAINTS IMPROVE RISK PREDICTION", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/3a91841d2bcc0b13a3d0d5d60c9f0581-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "We propose two constraints informed by the medical domain to improve model estimation: a prevalence constraint, where disease prevalence is known, and an ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DOMAIN CONSTRAINTS IMPROVE RISK PREDICTION", "abstract": null}
{"venue": "ICLR", "search_title": "A LINEAR ALGEBRAIC FRAMEWORK FOR COUNTERFACTUAL ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/939a6f1fb25e0048db9b65902da10d5b-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "enhancing the precision and personalization of medical care. By tailoring treatments to patients' individual characteristics and conditions, healthcare ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A LINEAR ALGEBRAIC FRAMEWORK FOR COUNTERFACTUAL ...", "abstract": null}
{"venue": "ICLR", "search_title": "A MUTUAL INFORMATION PERSPECTIVE ON FEDERATED ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/ba8d1b46292c5e82cbfb3b3dc3b968af-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "medical images. In Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A MUTUAL INFORMATION PERSPECTIVE ON FEDERATED ...", "abstract": null}
{"venue": "ICLR", "search_title": "Identifying nonlinear dynamical systems with multiple time scales ...", "url": "https://www.iclr.cc/media/iclr-2021/Slides/3338.pdf", "year": null, "abstract_snippet": "Central Institute of Mental Health/ Medical Faculty Mannheim, Heidelberg University. Ninth International Conference on Learning Representations (ICLR 2021) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Identifying nonlinear dynamical systems with multiple time scales ...", "abstract": null}
{"venue": "ICLR", "search_title": "International Conference on Learning Representations 2025 (ICLR ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025", "year": null, "abstract_snippet": "... medical detection Yuguang Yang, Tongfei Chen, Haoyu Huang, Linlin Yang, Chunyu Xie, Dawei Leng, Xianbin Cao, Baochang Zhang; A Theoretically-Principled ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "International Conference on Learning Representations 2025 (ICLR ...", "abstract": null}
{"venue": "ICLR", "search_title": "GENERATIVE CLASSIFIERS AVOID SHORTCUT SOLUTIONS", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/28a80012e6f564c0cc8e7661e1db83fe-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Medical image analysis,. 58:101544, 2019. 13. Page 14. Published as a conference paper at ICLR 2025. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "GENERATIVE CLASSIFIERS AVOID SHORTCUT SOLUTIONS", "abstract": null}
{"venue": "ICLR", "search_title": "what's new in my data? novelty exploration - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/e2c39f96da9ec114e0b5fbd639139035-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Oct 1, 2013 ... tuning on patient records enhances a model's grasp of medical terminology and procedures (Yang et al., 2022; Thirunavukarasu et al., 2023) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "what's new in my data? novelty exploration - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "ON THE LIMITATIONS OF TEMPERATURE SCALING FOR ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a2440e23f6a8c037eff1dc4f1156aa35-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "However, as these models begin to be applied to critical applications such as predicting credit risk (Clements et al., 2020), diagnosing medical conditions ( ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ON THE LIMITATIONS OF TEMPERATURE SCALING FOR ...", "abstract": null}
{"venue": "ICLR", "search_title": "SELF-SUPERVISED REPRESENTATION LEARNING FROM ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/1b115b1feab2198dd0881c57b869ddb7-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "as medical images, time series, and tabular data, LFR had ... comparison on two medical datasets: Kvasir for medical images and MIMIC-III for medical time.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SELF-SUPERVISED REPRESENTATION LEARNING FROM ...", "abstract": null}
{"venue": "ICLR", "search_title": "ENSEMBLES OF LOW-RANK EXPERT ADAPTERS - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/e8711daef520be07cb9852390c673de8-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "tasks across fields such as medical diagnostics (Singhal et al., ... When MOE meets llms: Parameter efficient fine-tuning for multi-task medical applications.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ENSEMBLES OF LOW-RANK EXPERT ADAPTERS - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "UniversalNER: TARGETED DISTILLATION FROM - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/34678d08b36076de986df95c5bbba92f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "We find that the generated data contain entity types from various domains, ranging from the general domain (e.g., PERSON) to the clinical domain. (e.g., MEDICAL ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "UniversalNER: TARGETED DISTILLATION FROM - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "LEVERAGING OPTIMIZATION FOR ADAPTIVE ATTACKS ON ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/33ae99f57181554090fb6a9071a512a9-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "While deepfakes can serve many beneficial purposes if used ethically, for example, in medical imaging (Akrout et al., 2023) or education (Peres et al., 2023) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LEVERAGING OPTIMIZATION FOR ADAPTIVE ATTACKS ON ...", "abstract": null}
{"venue": "ICLR", "search_title": "CONVERGENCE OF SCORE-BASED DISCRETE DIFFU", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/560b4a3ad23137d641258d8807de13e9-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Medical . Image Analysis, 80:102479, 2022. Evann Courdier, Angelos Katharopoulos, and François Fleuret. Segmenting the unknown: Discrete diffusion models for non ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CONVERGENCE OF SCORE-BASED DISCRETE DIFFU", "abstract": null}
{"venue": "ICLR", "search_title": "FIRST-PERSON FAIRNESS IN CHATBOTS - ICLR Proceedings", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/92af0c8c2664429de2bb44c2692d84ae-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "... medical condition, Explain medical proce- dure, Explain medication effects, Identify medical symptoms, Provide medical advice;. 7. Legal: Draft a contract ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FIRST-PERSON FAIRNESS IN CHATBOTS - ICLR Proceedings", "abstract": null}
{"venue": "ICLR", "search_title": "LEARNING TO DESIGN PROTEIN–PROTEIN INTERAC", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/5b4263be85820683d78675cc18d2efc7-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "of protein-based therapeutics in addressing other medical conditions, such as stroke, which stands as a leading cause of disability and mortality worldwide ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LEARNING TO DESIGN PROTEIN–PROTEIN INTERAC", "abstract": null}
{"venue": "ICLR", "search_title": "MULTIMODAL LEGO: MODEL MERGING AND FUSION ACROSS ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/8064e4ebbcbe594628887b420956d8c3-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "We evaluate MM-Lego (LegoMerge and LegoFuse) and its components (LegoBlock) on seven multimodal medical datasets from three separate studies: The Cancer Genome ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MULTIMODAL LEGO: MODEL MERGING AND FUSION ACROSS ...", "abstract": null}
{"venue": "ICLR", "search_title": "HYBRID SHARING FOR MULTI-LABEL IMAGE CLASSI - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a80ebbb4ec9e9b39789318a0a61e2e43-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "(2017) use convolutional networks on an attention map to op- timize ResNet prediction. Rajpurkar et al. (2017) solve the medical multi-label problem by using.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "HYBRID SHARING FOR MULTI-LABEL IMAGE CLASSI - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "Functional Bayesian Tucker Decomposition - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/2e8d556babbff23c871b51b2cea8aad0-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "For example, medical service records can be summarized by a four-mode tensor. (patients, doctor, clinics, time) and the entry values can be the visit count ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Functional Bayesian Tucker Decomposition - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "STREAMLINING PREDICTION IN BAYESIAN DEEP LEARNING", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/8d492b8a6201d83d1015af9e264f0bf2-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "in machine-assisted medical decision making. Nature Machine Intelligence, 1(1):20–23, 2019. 1. David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "STREAMLINING PREDICTION IN BAYESIAN DEEP LEARNING", "abstract": null}
{"venue": "ICLR", "search_title": "RECONCILING MODEL MULTIPLICITY FOR DOWN - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/948552777302d3abf92415b1d7e9de70-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "... medical trials, a ... At each run, we draw a fresh loss function created based on the loss function motivated by medical domain knowledge in Zhao et al.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "RECONCILING MODEL MULTIPLICITY FOR DOWN - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "Opti- mal and Efficient Algorithms for MNL Assortment - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/b9a4d7b88a41652c63962ebcc21701b7-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "community, especially the active learning literature which has applications in Medical surveys,. AI tutoring systems, Multi-player sports/games, or any real ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Opti- mal and Efficient Algorithms for MNL Assortment - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "OPTIMAL LEARNING OF KERNEL LOGISTIC REGRES", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/854ff06c87a2204204be0b0efe1b175a-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "medical diagnoses and financial forecasting. In real-world scenarios, classification is often compli- cated by various challenges, like imbalanced label ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "OPTIMAL LEARNING OF KERNEL LOGISTIC REGRES", "abstract": null}
{"venue": "ICLR", "search_title": "task-adaptive pretrained language models - David Grangier", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/688006b3d1df8be5bb2a2a31a407180c-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "We study this setting across different specialization tasks including domain-specific language mod- eling ( medical , encyclopedic domains) and end-tasks (scholar ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "task-adaptive pretrained language models - David Grangier", "abstract": null}
{"venue": "ICLR", "search_title": "VARIATIONAL BAYES WITH STEIN MIXTURE INFERENCE", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/d390199c28b467315b454789b6584f19-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "in critical applications such as autonomous vehicles and medical diagnosis. Even in problems considered solved, such as protein structure prediction, better ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "VARIATIONAL BAYES WITH STEIN MIXTURE INFERENCE", "abstract": null}
{"venue": "ICLR", "search_title": "ROTATION HAS TWO SIDES: EVALUATING DATA AUG", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a5321f64005b0d4a94d0b18e84e19f48-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "... medical diagnosis (Schlegl et al., 2017). Generative models (Sabokrou et al., 2018; Zaheer et al., 2020; Perera et al., 2019) strive to model the training ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ROTATION HAS TWO SIDES: EVALUATING DATA AUG", "abstract": null}
{"venue": "ICLR", "search_title": "ADVERSARIAL FEATURE MAP PRUNING FOR BACK - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/4b8afc47273c746662a96dfdf562f87f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ADVERSARIAL FEATURE MAP PRUNING FOR BACK - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "EFFICIENT AUTOMATED CIRCUIT DISCOVERY IN ... - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/916ee60e315531d6b3954af8a8dc3437-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Transformers in medical image analysis. Intelligent Medicine, 3(1):. 59–78, 2023. ISSN 2667-1026. doi: https://doi.org/10.1016/j.imed.2022.07.002. URL https ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EFFICIENT AUTOMATED CIRCUIT DISCOVERY IN ... - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "provably reliable conformal prediction sets - Yan Scholten", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/8c4d21a4b33361c40c2142db9511c126-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Conformal prediction in clinical medical sciences. J. Heal. Informatics Res., 6(3):241–252, 2022. Vladimir Vovk. Conditional validity of inductive conformal ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "provably reliable conformal prediction sets - Yan Scholten", "abstract": null}
{"venue": "ICLR", "search_title": "CAUSAL MODELLING AGENTS: CAUSAL GRAPH DIS", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/fe90657b12193c7b52a3418bdc351807-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "IEEE transactions on medical imaging, 29(6):1310–1320, 6 2010. ISSN 1558-254X. Tinu Varghese, R Sheelakumari, Jija S James, and Pavagada S Mathuranath. A ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CAUSAL MODELLING AGENTS: CAUSAL GRAPH DIS", "abstract": null}
{"venue": "ICLR", "search_title": "Pseudocode for converting action sequences to masked inputs Input", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/0ee633a6ade45eab4276352b3ee79c7a-Supplementary-Conference.pdf", "year": 2024, "abstract_snippet": "His medical team staffed the hospital from 6 p.m. until about 10 p.m.. Friday. But no one came Friday night and there wasnt even a security team at the site ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Pseudocode for converting action sequences to masked inputs Input", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR 2021 Wednesday 05/5", "url": "https://iclr.cc/virtual/2021/day/5/5", "year": 2021, "abstract_snippet": "A medical classifier could fail on data from a new sensor or hospital. The good news is, we can fight dataset bias with techniques from domain adaptation ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR 2021 Wednesday 05/5", "abstract": null}
{"venue": "ICLR", "search_title": "VISION TRANSFORMERS NEED REGISTERS", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/0b408293619f725fd30162af057e531a-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "medical data, or remote sensing) or the cost at scale. Today, it is common to pretrain a model for a task for which plenty of data is available and extract ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "VISION TRANSFORMERS NEED REGISTERS", "abstract": null}
{"venue": "ICLR", "search_title": "EFFICIENT SHARPNESS-AWARE MINIMIZATION FOR ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/c309eecf4c217e01fc7120cce8db6524-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "2Institute for Medical Engineering & Science, Massachusetts Institute of Technology, USA. 3School of Computing, University of Georgia, USA. 4College of ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EFFICIENT SHARPNESS-AWARE MINIMIZATION FOR ...", "abstract": null}
{"venue": "ICLR", "search_title": "RETASA: A NONPARAMETRIC FUNCTIONAL ESTIMA - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/cc621611576a326ae3b48ff28a42d20f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "large medical facilities with advanced medical equipment and highly skilled staff. Consequently, the distribution of SOFA scores among patients differs ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "RETASA: A NONPARAMETRIC FUNCTIONAL ESTIMA - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "Published as a conference paper at ICLR 2024 - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/93b4d708976a1d9b1250c400e7fda811-Supplementary-Conference.pdf", "year": 2024, "abstract_snippet": "The Medical Expenditure Panel Survey (MEPS) (Blewett et al., 2021) dataset consists of large-scale surveys of families and individuals across the United ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Published as a conference paper at ICLR 2024 - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "SCOPE: A SELF-SUPERVISED FRAMEWORK FOR IM - HAL", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/05d6b5b6901fb57d2c287e1d3ce6d63c-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Table 1: An example of faithful and factful combinations in LLM for data-to-text generation in a medical context. Unfaithful spans are highlighted in red. While ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SCOPE: A SELF-SUPERVISED FRAMEWORK FOR IM - HAL", "abstract": null}
{"venue": "ICLR", "search_title": "CAN GENERATIVE AI SOLVE YOUR IN-CONTEXT LEARNING ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/d90268f01ef06a55630b0588227adf4f-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Figures 1d to 1f gives an example from the medical questions pairs (MQP) prediction task for which Llama-2. 7B yields random answers on average. As we ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CAN GENERATIVE AI SOLVE YOUR IN-CONTEXT LEARNING ...", "abstract": null}
{"venue": "ICLR", "search_title": "UNPROCESSING SEVEN YEARS OF ALGORITHMIC FAIRNESS", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/93b4d708976a1d9b1250c400e7fda811-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "additional experiments on the Medical Expenditure Panel Survey (MEPS) ... The Medical Expenditure Panel Survey (MEPS) (Blewett et al., 2021) dataset ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "UNPROCESSING SEVEN YEARS OF ALGORITHMIC FAIRNESS", "abstract": null}
{"venue": "ICLR", "search_title": "PROMPTAGENT: STRATEGIC PLANNING WITH LARGE ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/686a3f32067838c8dbb68da6e9e3cf69-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "a large-scale open domain question answering dataset from medical exams. Applied Sciences, 11(14):6421, 2021. Ana Jojic, Zhen Wang, and Nebojsa Jojic. Gpt is ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PROMPTAGENT: STRATEGIC PLANNING WITH LARGE ...", "abstract": null}
{"venue": "ICLR", "search_title": "ROBUST TRAINING OF FEDERATED MODELS WITH EXTREMELY ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/69b6de0de842bfedbc40ed6e162b4233-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Federated semi-supervised learning for covid region segmentation in chest ct using multi-national data from china, italy, japan. Medical image analysis, 70: ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ROBUST TRAINING OF FEDERATED MODELS WITH EXTREMELY ...", "abstract": null}
{"venue": "ICLR", "search_title": "PROGRESSIVE PARAMETER EFFICIENT TRANSFER LEARNING ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/86c070ce724102ee876d1935590e111a-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Medical sam adapter: Adapting segment anything model for medical image segmentation. arXiv preprint. arXiv:2304.12620, 2023. Tete Xiao, Yingcheng Liu, Bolei ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PROGRESSIVE PARAMETER EFFICIENT TRANSFER LEARNING ...", "abstract": null}
{"venue": "ICLR", "search_title": "Oral Session 2 - ICLR 2026", "url": "https://iclr.cc/virtual/2021/session/4323", "year": 2021, "abstract_snippet": "... medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Oral Session 2 - ICLR 2026", "abstract": null}
{"venue": "ICLR", "search_title": "MUSE: MACHINE UNLEARNING SIX-WAY EVALU - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/4556f5398bd2c61bd7500e306b4e560a-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "No verbatim memorization When a model has unlearned a medical record, it should not output its contents verbatim. We quantify the verbatim memorization VerbMem ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MUSE: MACHINE UNLEARNING SIX-WAY EVALU - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "3D-MOLM: TOWARDS 3D MOLECULE-TEXT INTER - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/4af24e6ce753c181e703f3f0be3b5e20-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Notably, LMs excel at text-based molecule understanding tasks, such as question-answering (QA) in the chemical and medical domains (Taylor et al., 2022), by ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "3D-MOLM: TOWARDS 3D MOLECULE-TEXT INTER - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "MUHBOOST: MULTI-LABEL BOOSTING FOR PRACTI - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/ca2963d1cfb25e93362e86fb427a9524-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "At the same time, research on integrating LLMs in health applications (e.g., generic medical question answering (Singhal et al.,. 2023) and mental health ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MUHBOOST: MULTI-LABEL BOOSTING FOR PRACTI - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "A CHARACTERIZATION THEOREM FOR EQUIVARIANT ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a5cd34c68805fee3ba9becde388c3d47-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Roto-. Translation Covariant Convolutional Networks for Medical Image Analysis, 1st Conference on. Medical Imaging with Deep Learning (MIDL 2018), Amsterdam, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A CHARACTERIZATION THEOREM FOR EQUIVARIANT ...", "abstract": null}
{"venue": "ICLR", "search_title": "PROMPTING FAIRNESS: INTEGRATING CAUSALITY TO DEBIAS ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/9f26a2d143a227376dff99a279f93f99-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Consider an example in the context of medical care: as illustrated in Figure 2, the observed variables (X1,X2) denote diseases and. (Y1,Y2) represent ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PROMPTING FAIRNESS: INTEGRATING CAUSALITY TO DEBIAS ...", "abstract": null}
{"venue": "ICLR", "search_title": "generalization through variance: how noise - John J. Vastola", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/564ccf9de3a2a959d3d338889bad9d88-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Harvard Medical School. Boston, MA 02115, USA john vastola ... Investigating data memorization in 3d latent diffusion models for medical image synthesis.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "generalization through variance: how noise - John J. Vastola", "abstract": null}
{"venue": "ICLR", "search_title": "COMMUNICATION-EFFICIENT FEDERATED NON - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a397986e0f34d4b1f0b640686ceaeff7-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Federated bandit optimization offers a principled way for different medical institutions to jointly solve optimization problems for smart healthcare ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "COMMUNICATION-EFFICIENT FEDERATED NON - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "muirbench: acomprehensive benchmark", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/9cf6139382f98623d08cc595622f3fb1-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "... medical images, drone/satellite ... New data address certain tasks (e.g. geographic understanding), image relations (e.g. multiview), and types (e.g. medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "muirbench: acomprehensive benchmark", "abstract": null}
{"venue": "ICLR", "search_title": "JAILBREAKING AS A REWARD MISSPECIFICATION PROBLEM", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/cf00c2fdf92882989b1fc0e3094a2abf-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "medical claims by exaggerating or inventing medical conditions or treatments. This can include submitting claims for procedures or treatments that were ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "JAILBREAKING AS A REWARD MISSPECIFICATION PROBLEM", "abstract": null}
{"venue": "ICLR", "search_title": "FUSING MODELS WITH COMPLEMENTARY EXPERTISE", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/c5169260ef32d1bd3597c14d8c89b034-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Specifically, we removed five categories (i.e., high school european history, business ethics, clinical knowledge, medical genetics, and high. 21. Page 22 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FUSING MODELS WITH COMPLEMENTARY EXPERTISE", "abstract": null}
{"venue": "ICLR", "search_title": "EXPLAINING TIME SERIES VIA CONTRASTIVE AND LOCALLY ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/bd9b0b6ffab928b68c2b126d50f26381-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "A survey on explainable artificial intelligence (xai): Toward medical xai. IEEE Transactions on Neural Networks and Learning Systems, 32(11):4793–4813, 2020.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EXPLAINING TIME SERIES VIA CONTRASTIVE AND LOCALLY ...", "abstract": null}
{"venue": "ICLR", "search_title": "A BENCHMARK FOR SEMANTIC SENSITIVE INFORMA - TITLE", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/994a53df880f1ec64fd5cbf1bba4a8af-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "(El Emam, 2011) addresses the sensitive information in medical data while protecting patient privacy. (Acquisti & Gross, 2009) investigates the risks associated ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A BENCHMARK FOR SEMANTIC SENSITIVE INFORMA - TITLE", "abstract": null}
{"venue": "ICLR", "search_title": "uc-nerf: neural radiance field for under- calibrated multi-view cameras", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/611252d40f23c8b57a8bc9ffb577419b-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Atlasnet: Multi-atlas non-linear deep networks for medical image segmentation. In Medical Image Computing and Computer Assisted Intervention–MICCAI 2018:.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "uc-nerf: neural radiance field for under- calibrated multi-view cameras", "abstract": null}
{"venue": "ICLR", "search_title": "SENSITIVITY VERIFICATION FOR ADDITIVE DECISION TREE ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/92f79f493ca2d6c0ba04c3af76bb3368-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Antonio Criminisi and Jamie Shotton. Decision forests for computer vision and medical image analysis. Springer Science & Business Media, 2013. Leonardo de Moura ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SENSITIVITY VERIFICATION FOR ADDITIVE DECISION TREE ...", "abstract": null}
{"venue": "ICLR", "search_title": "posterior sampling based on gradient flows - UCL Discovery", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a402493de088886740b5939f666a6e56-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Maass. Conditional invertible neural networks for medical imaging. Journal of Imaging, 7(11):243, 2021. C. Du, T.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "posterior sampling based on gradient flows - UCL Discovery", "abstract": null}
{"venue": "ICLR", "search_title": "LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/4990dad2c1696224de42573d0222554a-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Med-flamingo: a multimodal medical few-shot learner. In. Machine Learning for ... Therefore, John must have a medical degree. Is this argument valid or ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS", "abstract": null}
{"venue": "ICLR", "search_title": "IDENTIFIABLE EXCHANGEABLE MECHANISMS FOR CAUSAL ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/9b91ee0da3bcd61905fcd89e770168fc-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "We illustrate the practical differences between cause and mechanism variability in the medical example of learning representations from fMRI data (Hyvarinen & ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "IDENTIFIABLE EXCHANGEABLE MECHANISMS FOR CAUSAL ...", "abstract": null}
{"venue": "ICLR", "search_title": "TIGHT RATES IN SUPERVISED OUTLIER TRANSFER LEARNING", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a8b879590adff2b1874f97db59b65518-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In Medical Imaging 2011: Image Processing, volume 7962, pp. 489–500. Spie, 2011. 11. Page 12. Published as a conference paper at ICLR 2024. A APPENDIX A ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "TIGHT RATES IN SUPERVISED OUTLIER TRANSFER LEARNING", "abstract": null}
{"venue": "ICLR", "search_title": "LOCAL GRAPH CLUSTERING WITH NOISY LABELS - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a4d991d581accd2955a1e1928f4e6965-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "The dataset categorizes medical publications into one of 3 classes and comprises 19,717 nodes and 44,338 edges. Node features are TF/IDF encodings from a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LOCAL GRAPH CLUSTERING WITH NOISY LABELS - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "DEFINING EXPERTISE: APPLICATIONS TO TREATMENT EFFECT ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/5adff4d5402703418f7210a4004e1314-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "1This terminology is inspired by the medical literature; predictive biomarkers are informative of the treatment ... et al., “Closing the loop in medical decision ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DEFINING EXPERTISE: APPLICATIONS TO TREATMENT EFFECT ...", "abstract": null}
{"venue": "ICLR", "search_title": "DECISION TREE INDUCTION THROUGH LLMS VIA ... - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/08857467641ad82f635023d530605b4c-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "American Medical . Informatics Association, 1988. Farhad Soleimanian, Peyman Mohammadi, and Parvin Hakimi. Application of decision tree algorithm for data mining ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DECISION TREE INDUCTION THROUGH LLMS VIA ... - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "MANY LOSSES ARE MINIMAL FOR THE WRONG DAG - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/2858e880333b3cd64f8192f13ddcca2f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Medical Example. To highlight the importance of identifying the correct DAG given data, we provide the following example: Assume a dis- tribution pGt which ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MANY LOSSES ARE MINIMAL FOR THE WRONG DAG - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "MASTERING TASK ARITHMETIC: τJP AS - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/47fee9cd8a252161dec7cb48ec0ca2f2-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "... medical knowledge with one specialized in legal knowledge, it would be pos- sible to develop a model capable of solving tasks related to medical litigation.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MASTERING TASK ARITHMETIC: τJP AS - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "CONTEXT-AWARE META-LEARNING - Stanford Computer Science", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/dc594b8712f5d3ea1904092d74739d25-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "as in-painting. Other approaches explore in-context learning for applications like scene understanding (Balazevic et al., 2024), medical image segmentation ( ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CONTEXT-AWARE META-LEARNING - Stanford Computer Science", "abstract": null}
{"venue": "ICLR", "search_title": "efficient cross-silo federated learning on heterogeneous client ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/a9f3457fa97f106f1756885237787789-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In Medical Image Comput- ing and Computer-Assisted Intervention–MICCAI 2016 ... medical images in deep learning. Computer Methods and Programs in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "efficient cross-silo federated learning on heterogeneous client ...", "abstract": null}
{"venue": "ICLR", "search_title": "DYNAMIC SPARSE TRAINING VERSUS DENSE TRAIN- ING", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/92abec9d3f278c648dfe99c8b8f35954-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "E2enet: Dynamic sparse feature fusion for accurate and efficient 3d medical ... This holds significant implications across various domains, including medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DYNAMIC SPARSE TRAINING VERSUS DENSE TRAIN- ING", "abstract": null}
{"venue": "ICLR", "search_title": "LEAVE-ONE-OUT STABLE CONFORMAL PREDICTION", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/297fe652867e4897e9f1fe1cd715de19-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "Conformal prediction in clinical medical sciences. Journal of. Healthcare Informatics Research, 6(3):241–252, 2022. Vladimir Vovk. Cross-conformal predictors ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LEAVE-ONE-OUT STABLE CONFORMAL PREDICTION", "abstract": null}
{"venue": "ICLR", "search_title": "generalization in diffusion models arises from", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/cbaf319a4712385b5ba8a414808b5713-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Investigating data memorization in 3d latent diffusion models for medical image synthesis. ... In Int'l Conf Medical Image Computing and Computer-assisted ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "generalization in diffusion models arises from", "abstract": null}
{"venue": "ICLR", "search_title": "SCALING SPEECH-TEXT PRE-TRAINING WITH SYN - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2025/file/7b5ae891000049b91b3b62de596b1560-Paper-Conference.pdf", "year": 2025, "abstract_snippet": "towns, at the cordoba medical cns of faculty, and, <|end of audio|>. Medical Sciences Faculty of the Rosario National University , in 2010 and 2011, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SCALING SPEECH-TEXT PRE-TRAINING WITH SYN - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "DROPOUT-BASED RASHOMON SET EXPLORATION FOR ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/8cd1ce03ea58b3d7dfd809e4d42f08ea-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "domains, including financial analytics, medical prediction, large-scale images classification, and human detection. Exploring models in Rashomon sets with ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DROPOUT-BASED RASHOMON SET EXPLORATION FOR ...", "abstract": null}
{"venue": "ICLR", "search_title": "FAITHFUL EXPLANATIONS OF BLACK-BOX NLP MOD - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/d5ee23c149efa1b7fb8d96a3be9908d9-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "On model selection and model misspeci- fication in causal inference. Statistical methods in medical research, 21(1):7–30, 2012. Christina Viehmann, Tilman Beck, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FAITHFUL EXPLANATIONS OF BLACK-BOX NLP MOD - OpenReview", "abstract": null}
{"venue": "ICLR", "search_title": "PRINCIPLED FEDERATED DOMAIN ADAPTATION: GRADIENT ...", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/d649dd586dba64672a96beff24178125-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Medical Image Analysis, 65:101765, 2020. Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? Source hypothesis transfer for ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PRINCIPLED FEDERATED DOMAIN ADAPTATION: GRADIENT ...", "abstract": null}
{"venue": "ICLR", "search_title": "EMPIRICAL LIKELIHOOD FOR FAIR CLASSIFICATION", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/39fac857b4467e3ef4f358186bb07d81-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Statistical Methods in Medical Research, 31(1):87–104, 2022. Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, and Meisam Razaviyayn. Rényi fair inference. In ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EMPIRICAL LIKELIHOOD FOR FAIR CLASSIFICATION", "abstract": null}
{"venue": "ICLR", "search_title": "ICLR 2024 Tuesday 05/7", "url": "https://iclr.cc/virtual/2024/day/5/7", "year": 2024, "abstract_snippet": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting. xinlu zhang · Shiyang Li · Xianjun Yang · Chenxin Tian · Yao Qin · Linda ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICLR 2024 Tuesday 05/7", "abstract": null}
{"venue": "ICLR", "search_title": "INSTANCE LEVEL VERSUS BAG LEVEL LOSS FUNCTIONS", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/06297213eca57fa6eadf8d87caa21b3c-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "example, in a medical test, the demographic features of patients may be far less private than the re- sponses ( medical test results). We recall the formal ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "INSTANCE LEVEL VERSUS BAG LEVEL LOSS FUNCTIONS", "abstract": null}
{"venue": "ICLR", "search_title": "EVALUATING LARGE LANGUAGE MODELS AT ... - OpenReview", "url": "https://proceedings.iclr.cc/paper_files/paper/2024/file/afc8b034823271816d14f7c1aefe1dff-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Output 1: An ophthalmologist is a medical doctor who specializes in the di- agnosis and treatment of eye diseases and conditions. They conduct eye exams ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EVALUATING LARGE LANGUAGE MODELS AT ... - OpenReview", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster MultimodalMedicalCode Tokenizer", "url": "https://icml.cc/virtual/2025/poster/45110", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45110", "full_title": "Multimodal Medical Code Tokenizer", "abstract": "Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning.  We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information.  We integrate MedTok into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using MedTok tokenizer with medical QA systems. Our results demonstrate the potential of MedTok as a unified tokenizer for medical codes, improving tokenization for medical foundation models.", "summary_cn": "MedTok多模态医学代码分词器结合文本描述与关系结构，提升电子健康记录模型性能，在临床任务中表现优异。", "keywords": ["多模态分词器", "医学代码", "电子健康记录", "图编码", "临床任务", "性能提升"], "triple": {"method": "结合文本与图编码量化", "result": "AUPRC提升4.10%-11.32%", "contribution": "统一医学代码分词器"}}
{"venue": "ICML", "search_title": "Evaluating Multimodal Approaches toMedicalReport Generation ...", "url": "https://icml.cc/virtual/2025/50690", "year": 2025, "abstract_snippet": "Evaluating multimodal approaches to medical report generation and introducing a better metric for generated medical reports.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/50690", "full_title": "Evaluating Multimodal Approaches to Medical Report Generation and Introducing a Better Metric for Generated Medical Reports", "abstract": "As a result of recent advancements in foundation models, including large vision-language models, several researchers have explored methods of combining multiple modalities of data as inputs for visual question answering. One key application of visual question answering in the context of the healthcare domain is automated medical report generation, where X-ray images and text-based symptom data for a patient might be provided as inputs, with the intention of generating a relevant medical report as an output. However, very few studies analyze the performance of these models alongside unimodal fine-tuned LLMs, and even fewer compare the performance of these multimodal models depending on whether they are provided symptom information as an input. In this paper, we compare the performance of a variety of approaches for generating medical reports on a dataset of Chest X-Ray medical reports, including a unimodal fine-tuned medical LLM, a multimodal model without symptom data, and a multimodal model with symptom data. Second, we introduce a new metric for evaluating the similarity between generated and reference medical reports, which we call \"sentence pairs\". Our results show that multimodal approaches to medical report generation far outperform unimodal approaches, and providing symptom data slightly improves accuracy for generated medical reports. We also find that our \"sentence pairs\" evaluation metric more closely measures similarity between generated and reference medical reports than standard techniques.", "summary_cn": "本研究比较了单模态与多模态方法在胸部X光报告生成中的表现，发现多模态方法显著更优，症状数据可轻微提升准确性，并提出了更优的评估指标“句子对”。", "keywords": ["医学报告生成", "多模态模型", "症状数据", "评估指标", "胸部X光", "视觉问答"], "triple": {"method": "比较单模态与多模态模型，引入新评估指标", "result": "多模态方法优于单模态，症状数据提升准确性，新指标更有效", "contribution": "验证多模态优势，提出改进评估方法"}}
{"venue": "ICML", "search_title": "HealthGPT: AMedicalLarge Vision-Language Model for Unifying ...", "url": "https://icml.cc/virtual/2025/poster/45007", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... We present HealthGPT, a powerful Medical Large Vision-Language Model (Med-LVLM) that integrates medical visual comprehension and generation ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45007", "full_title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation", "abstract": "We present HealthGPT , a powerful Medical Large Vision-Language Model (Med-LVLM) that integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm. Our bootstrapping philosophy is to progressively adapt heterogeneous comprehension and generation knowledge to pre-trained Large Language Models (LLMs). This is achieved through a novel heterogeneous low-rank adaptation (H-LoRA) technique, which is complemented by a tailored hierarchical visual perception (HVP) approach and a three-stage learning strategy (TLS) . To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health . Experimental results demonstrate exceptional performance and scalability of HealthGPT in medical visual unified tasks. Our project can be accessed at https://github.com/DCDmllm/HealthGPT.", "summary_cn": "HealthGPT是医疗视觉语言模型，通过异构知识适应统一理解与生成，在医学视觉任务中表现卓越。", "keywords": ["HealthGPT", "医疗视觉语言模型", "异构知识适应", "H-LoRA", "VL-Health数据集", "统一任务"], "triple": {"method": "异构低秩适应(H-LoRA)与三阶段学习", "result": "在医学视觉统一任务中实现卓越性能", "contribution": "提出首个统一医学视觉理解与生成的模型"}}
{"venue": "ICML", "search_title": "Raptor: Scalable Train-Free Embeddings for 3DMedicalVolumes ...", "url": "https://icml.cc/virtual/2025/poster/46452", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Current challenges in developing foundational models for volumetric imaging data, such as magnetic resonance imaging (MRI), stem from the ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46452", "full_title": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models", "abstract": "Current challenges in developing foundational models for volumetric imaging data, such as magnetic resonance imaging (MRI), stem from the computational complexity of state-of-the-art architectures in high dimensions and curating sufficiently large datasets of volumes.To address these challenges, we introduce Raptor (Random Planar Tensor Reduction), a train-free method for generating semantically rich embeddings for volumetric data. Raptor leverages a frozen 2D foundation model, pretrained on natural images, to extract visual tokens from individual cross-sections of medical volumes. These tokens are then spatially compressed using random projections, significantly reducing computational complexity while retaining rich semantic information. Extensive experiments on 10 diverse medical volume tasks verify the superior performance of Raptor over state-of-the-art methods, including those pretrained exclusively on medical volumes (+3 SuPreM, +6 MISFM, +10 Merlin, +13 VoCo, and +14 SLIViT), while entirely bypassing the need for costly training. Our results highlight Raptor's effectiveness and versatility as a foundation for advancing deep learning-based methods for medical volumes (code: github.com/sriramlab/raptor).", "summary_cn": "Raptor提出一种无需训练的3D医学影像嵌入方法，利用预训练2D模型提取切片特征并通过随机投影压缩，在10个任务中超越现有方法，避免昂贵训练。", "keywords": ["3D医学影像", "无需训练嵌入", "随机投影", "预训练2D模型", "语义特征提取", "计算效率"], "triple": {"method": "利用预训练2D模型提取切片特征，结合随机投影压缩", "result": "在10个医学任务中性能超越现有方法，无需额外训练", "contribution": "提供高效、可扩展的3D医学影像基础嵌入方案"}}
{"venue": "ICML", "search_title": "ICML Poster Position:MedicalLarge Language Model Benchmarks ...", "url": "https://icml.cc/virtual/2025/poster/40129", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Medical large language models (LLMs) research often makes bold claims, from encoding clinical knowledge to reasoning like a physician.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/40129", "full_title": "Position: Medical Large Language Model Benchmarks Should Prioritize Construct Validity", "abstract": "Medical large language models (LLMs) research often makes bold claims, from encoding clinical knowledge to reasoning like a physician. These claims are usually backed by evaluation on competitive benchmarks—a tradition inherited from mainstream machine learning. But how do we separate real progress from a leaderboard flex? Medical LLM benchmarks, much like those in other fields, are arbitrarily constructed using medical licensing exam questions. For these benchmarks to truly measure progress, they must accurately capture the real-world tasks they aim to represent. In this position paper, we argue that medical LLM benchmarks should—and indeed can—be empirically evaluated for their construct validity. In the psychological testing literature, “construct validity” refers to the ability of a test to measure an underlying “construct”, that is the actual conceptual target of evaluation. By drawing an analogy between LLM benchmarks and psychological tests, we explain how frameworks from this field can provide empirical foundations for validating benchmarks. To put these ideas into practice, we use real-world clinical data in proof-of-concept experiments to evaluate popular medical LLM benchmarks and report significant gaps in their construct validity. Finally, we outline a vision for a new ecosystem of medical LLM evaluation centered around the creation of valid benchmarks.", "summary_cn": "本文主张医学大语言模型基准应优先考虑结构效度，通过心理学测试框架评估现有基准，发现其与现实临床任务存在显著差距，并展望构建有效基准的新评估生态。", "keywords": ["医学大语言模型", "基准评估", "结构效度", "临床数据", "心理学测试", "模型验证"], "triple": {"method": "类比心理学测试框架评估基准", "result": "发现现有基准与现实临床任务存在显著差距", "contribution": "提出以结构效度为中心的医学LLM评估新生态"}}
{"venue": "ICML", "search_title": "ICML Poster MedRAX:MedicalReasoning Agent for Chest X-ray", "url": "https://icml.cc/virtual/2025/poster/45678", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45678", "full_title": "MedRAX: Medical Reasoning Agent for Chest X-ray", "abstract": "Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care. While recent innovations have led to specialized models for various CXR interpretation tasks, these solutions often operate in isolation, limiting their practical utility in clinical practice. We present MedRAX, the first versatile AI agent that seamlessly integrates state-of-the-art  CXR analysis tools and multimodal large language models into a unified framework. MedRAX dynamically leverages these models to address complex medical queries without requiring additional training. To rigorously evaluate its capabilities, we introduce ChestAgentBench, a comprehensive benchmark containing 2,500 complex medical queries across 7 diverse categories. Our experiments demonstrate that MedRAX achieves state-of-the-art performance compared to both open-source and proprietary models, representing a significant step toward the practical deployment of automated CXR interpretation systems. Data and code have been publicly available at https://github.com/bowang-lab/MedRAX", "summary_cn": "MedRAX是首个整合先进CXR分析工具与多模态大语言模型的AI代理，无需额外训练即可处理复杂医疗查询，在综合基准测试中表现优异。", "keywords": ["MedRAX", "胸部X光", "AI代理", "多模态大语言模型", "医疗推理", "ChestAgentBench"], "triple": {"method": "整合CXR分析工具与多模态大语言模型", "result": "在ChestAgentBench基准上达到最优性能", "contribution": "推动自动化CXR解读系统实际部署"}}
{"venue": "ICML", "search_title": "BoxLM: Unifying Structures and Semantics ofMedicalConcepts for ...", "url": "https://icml.cc/virtual/2025/poster/44310", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Language Models (LMs) have advanced diagnosis prediction by leveraging the semantic understanding of medical concepts in Electronic Health ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44310", "full_title": "BoxLM: Unifying Structures and Semantics of Medical Concepts for Diagnosis Prediction in Healthcare", "abstract": "Language Models (LMs) have advanced diagnosis prediction by leveraging the semantic understanding of medical concepts in Electronic Health Records (EHRs). Despite these advancements, existing LM-based methods often fail to capture the structures of medical concepts (e.g., hierarchy structure from domain knowledge). In this paper, we propose BoxLM, a novel framework that unifies the structures and semantics of medical concepts for diagnosis prediction. Specifically, we propose a structure-semantic fusion mechanism via box embeddings, which integrates both ontology-driven and EHR-driven hierarchical structures with LM-based semantic embeddings, enabling interpretable medical concept representations.Furthermore, in the box-aware diagnosis prediction module, an evolve-and-memorize patient box learning mechanism is proposed to model the temporal dynamics of patient visits, and a volume-based similarity measurement is proposed to enable accurate diagnosis prediction. Extensive experiments demonstrate that BoxLM consistently outperforms state-of-the-art baselines, especially achieving strong performance in few-shot learning scenarios, showcasing its practical utility in real-world clinical settings.", "summary_cn": "BoxLM框架通过盒嵌入统一医学概念的结构与语义，结合本体和电子病历层次结构，提升诊断预测性能，尤其在少样本学习中表现优异。", "keywords": ["BoxLM", "诊断预测", "盒嵌入", "结构语义融合", "少样本学习", "电子病历"], "triple": {"method": "盒嵌入融合结构与语义", "result": "超越现有基线，少样本学习表现强", "contribution": "提出统一框架提升诊断预测"}}
{"venue": "ICML", "search_title": "ICML Modeling Cognitive and Implicit Biases in Multi-AgentMedical...", "url": "https://icml.cc/virtual/2025/49339", "year": 2025, "abstract_snippet": "Biases in large language models threaten diagnostic equity and patient safety, and their downstream effects on multi-agent medical systems have only ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/49339", "full_title": "Modeling Cognitive and Implicit Biases in Multi-Agent Medical Systems for Clinical Diagnoses", "abstract": "Biases in large language models threaten diagnostic equity and patient safety, and their downstream effects on multi-agent medical systems have only recently been explored. Using a multi-agent framework that mirrored patient-physician conversations, we simulated implicit  and cognitive biases within approximately 1,700 MedQA and NEJM encounters and measured downstream effects on diagnostic accuracy, ancillary test utilization, and diagnostic breadth. We found that implicit and cognitive biases could lower diagnostic accuracy by up to 24% and 32%, respectively, with variable effects on test ordering behavior and diagnostic considerations. Our findings expand on current notions of how cognitive and implicit biases may adversely affect multi-agent medical systems, draw parallels between biases in multi-agent systems and real-world clinical contexts, and highlight the need for equitable safeguards in the development of medical agents for clinical decision-making.", "summary_cn": "研究模拟多智能体医疗系统中认知与隐性偏见，发现其显著降低诊断准确性，并影响测试使用与诊断广度，强调需开发公平保障措施。", "keywords": ["多智能体系统", "认知偏见", "隐性偏见", "诊断准确性", "医疗公平", "临床决策"], "triple": {"method": "多智能体框架模拟医患对话", "result": "偏见降低诊断准确性达24%-32%", "contribution": "揭示偏见对医疗系统影响，呼吁公平保障"}}
{"venue": "ICML", "search_title": "EnhancingMedicalMulti-modal Learning through Adaptive Modality ...", "url": "https://icml.cc/virtual/2025/poster/45524", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Lay Summary. Motivation: Medical research and care often rely on combining different modalities (like medical images, genetic information, and ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45524", "full_title": "Modalities Contribute Unequally: Enhancing Medical Multi-modal Learning through Adaptive Modality Token Re-balancing", "abstract": "Motivation: Medical research and care often rely on combining different modalities (like medical images, genetic information, and patient records). However, these “multimodal” datasets face a critical challenge: data quality varies widely between different types of data and between patients. Traditional methods struggle to handle these inconsistencies, especially in complex medical scenarios where data types (like genes and pathology scans) are very different and their relevance can change. Key Insight: Not all data types (“modalities”) are equally useful for every patient or task. Some modalities might be highly informative for a specific case, while others are unreliable or irrelevant. Instead of treating all modalities the same, we need to dynamically weigh their importance and focus on the most trustworthy information. Our Solution: We propose a new approach called AMC to address these challenges. 1. Assess Modality Importance (“Top” Step): First, the model evaluates how useful each type of data (e.g., MRI scans vs. blood test results) is for the specific task, like cancer diagnosis. It does this by identifying which data types contain the clearest, most relevant information for the patient or condition at hand.2. Replace Unreliable Data with Useful Insights (“Down” Step): For each data type, the model then filters out uninformative or noisy parts and replaces them with insights from more reliable data types. For example, if a patient’s genetic data is of poor quality, the model might rely more on their imaging data instead. This “re-balancing” ensures the model focuses on the most trustworthy information from all available sources.3. Smart Fusion with a Customized Model: We design a flexible, efficient model (similar to those used in language apps like chatbots) to combine the re-balanced data. This model includes features to improve accuracy and interpretability, making it suitable for medical use where trust and clarity are essential. Impact: Tests on real-world medical datasets showed that AMC performs better than traditional methods when data quality varies. Key benefits include: More Reliable Diagnoses and Predictions: By focusing on high-quality data, the model makes more accurate decisions, which is critical for treatments and personalized care. Flexibility Across Medical Fields: AMC works well for diverse tasks, from Alzheimer’s research to cancer subtype analysis, showing its broad utility in healthcare. Interpretability: The model’s ability to quantify which data types are most important helps doctors and researchers understand why it makes certain decisions, building trust in AI-driven medical tools.This approach could pave the way for more robust, adaptable AI in healthcare, improving how we use diverse data to better understand and treat diseases.", "summary_cn": "提出AMC方法，通过自适应模态令牌重平衡动态评估并融合多模态医疗数据，提升数据质量不均时的诊断准确性与可解释性。", "keywords": ["多模态学习", "自适应重平衡", "医疗AI", "数据质量不均", "模态重要性评估", "可解释性"], "triple": {"method": "自适应模态令牌重平衡（AMC）", "result": "在真实医疗数据上优于传统方法，提升诊断准确性", "contribution": "增强多模态医疗AI的鲁棒性与可解释性"}}
{"venue": "ICML", "search_title": "Position: Retrieval-augmented systems can be dangerousmedical...", "url": "https://icml.cc/virtual/2025/poster/40149", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Patients have long sought health information online, and increasingly, they are turning to generative AI to answer their health-related ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/40149", "full_title": "Position: Retrieval-augmented systems can be dangerous medical communicators", "abstract": "Patients have long sought health information online, and increasingly, they are turning to generative AI to answer their health-related queries. Given the high stakes of the medical domain, techniques like retrieval-augmented generation and citation grounding have been widely promoted as methods to reduce hallucinations and improve the accuracy of AI-generated responses and have been widely adopted into search engines. However, we argue that even when these methods produce literally accurate content drawn from source documents sans hallucinations, they can still be highly misleading. Patients may derive significantly different interpretations from AI-generated outputs than they would from reading the original source material, let alone consulting a knowledgeable clinician. Through a large-scale query analysis on topics including disputed diagnoses and procedure safety, we support our argument with quantitative and qualitative evidence of the suboptimal answers resulting from current systems. In particular, we highlight how these models tend to decontextualize facts, omit critical relevant sources, and reinforce patient misconceptions or biases. We propose a series of recommendations---such as the incorporation of communication pragmatics and enhanced comprehension of source documents---that could help mitigate these issues and extend beyond the medical domain.", "summary_cn": "检索增强系统在医疗沟通中可能误导患者，即使内容准确，也可能因去语境化、遗漏关键信息而强化误解。", "keywords": ["检索增强生成", "医疗沟通", "误导风险", "去语境化", "患者误解", "准确性"], "triple": {"method": "大规模查询分析", "result": "系统产生次优答案，去语境化事实并遗漏关键来源", "contribution": "揭示检索增强系统在医疗领域的潜在危险，提出改进建议"}}
{"venue": "ICML", "search_title": "Unlocking the Power of Spatial and Temporal Information inMedical...", "url": "https://icml.cc/virtual/2024/poster/34857", "year": 2024, "abstract_snippet": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/34857", "full_title": "Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training", "abstract": "Medical vision-language pre-training methods mainly leverage the correspondence between paired medical images and radiological reports. Although multi-view spatial images and temporal sequences of image-report pairs are available in off-the-shelf multi-modal medical datasets, most existing methods have not thoroughly tapped into such extensive supervision signals. In this paper, we introduce the Med-ST framework for fine-grained spatial and temporal modeling to exploit information from multiple spatial views of chest radiographs and temporal historical records. For spatial modeling, Med-ST employs the Mixture of View Expert (MoVE) architecture to integrate different visual features from both frontal and lateral views. To achieve a more comprehensive alignment, Med-ST not only establishes the global alignment between whole images and texts but also introduces modality-weighted local alignment between text tokens and spatial regions of images. For temporal modeling, we propose a novel cross-modal bidirectional cycle consistency objective by forward mapping classification (FMC) and reverse mapping regression (RMR). By perceiving temporal information from simple to complex, Med-ST can learn temporal semantics. Experimental results across four distinct tasks demonstrate the effectiveness of Med-ST, especially in temporal classification tasks. Our code and model are available at https://github.com/SVT-Yang/MedST.", "summary_cn": "提出Med-ST框架，通过多视图空间建模和跨模态时序一致性目标，利用医学多模态数据中的空间和时间信息，提升医学视觉-语言预训练性能。", "keywords": ["医学多模态预训练", "空间建模", "时序建模", "视图专家混合", "跨模态对齐", "循环一致性"], "triple": {"method": "多视图空间建模与跨模态时序一致性目标", "result": "在四项任务中有效，尤其在时序分类任务表现突出", "contribution": "开发Med-ST框架，充分利用医学数据的空间和时间信息"}}
{"venue": "ICML", "search_title": "ICML Poster GraphCL: Graph-based Clustering for Semi-Supervised ...", "url": "https://icml.cc/virtual/2025/poster/45355", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Semi-supervised learning (SSL) has made notable advancements in medical image segmentation (MIS), particularly in scenarios with limited ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45355", "full_title": "GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation", "abstract": "Semi-supervised learning (SSL) has made notable advancements in medical image segmentation (MIS), particularly in scenarios with limited labeled data and significantly enhancing data utilization efficiency. Previous methods primarily focus on complex training strategies to utilize unlabeled data but neglect the importance of graph structural information. Different from existing methods, we propose a graph-based clustering for semi-supervised medical image segmentation (GraphCL) by jointly modeling graph data structure in a unified deep model. The proposed GraphCL model enjoys several advantages. Firstly, to the best of our knowledge, this is the first work to model the data structure information for semi-supervised medical image segmentation (SSMIS). Secondly, to get the clustered features across different graphs, we integrate both pairwise affinities between local image features and raw features as inputs. Extensive experimental results on three standard benchmarks show that the proposed GraphCL algorithm outperforms state-of-the-art semi-supervised medical image segmentation methods.", "summary_cn": "提出GraphCL模型，首次在图结构中建模数据信息，用于半监督医学图像分割，通过整合局部特征亲和度与原始特征提升性能，在三个基准测试中优于现有方法。", "keywords": ["半监督学习", "医学图像分割", "图聚类", "数据建模", "特征亲和度", "深度学习"], "triple": {"method": "图聚类建模数据结构", "result": "在三个基准测试中优于现有方法", "contribution": "首次将图结构信息引入半监督医学图像分割"}}
{"venue": "ICML", "search_title": "iDPA: Instance Decoupled Prompt Attention for IncrementalMedical...", "url": "https://icml.cc/virtual/2025/poster/44405", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... In this paper, our contributions are summarized in threefold: • We propose a novel prompt-based framework iDPA to effectively address ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44405", "full_title": "iDPA: Instance Decoupled Prompt Attention for Incremental Medical Object Detection", "abstract": "Existing prompt-based approaches have demonstrated impressive performance in continual learning, leveraging pre-trained large-scale models for classification tasks; however, the tight coupling between foreground-background information and the coupled attention between prompts and image-text tokens present significant challenges in incremental medical object detection tasks, due to the conceptual gap between medical and natural domains. To overcome these challenges, we introduce the iDPA framework, which comprises two main components: 1) Instance-level Prompt Generation (IPG), which decouples fine-grained instance-level knowledge from images and generates prompts that focus on dense predictions, and 2) Decoupled Prompt Attention (DPA), which decouples the original prompt attention, enabling a more direct and efficient transfer of prompt information while reducing memory usage and mitigating catastrophic forgetting. We collect 13 clinical, cross-modal, multi-organ, and multi-category datasets, referred to as ODinM-13, and experiments demonstrate that iDPA outperforms existing SOTA methods, with FAP improvements of f 5.44%, 4.83%, 12.88%, and 4.59% in full data, 1-shot, 10-shot, and 50-shot settings, respectively.", "summary_cn": "提出iDPA框架，通过实例级提示生成与解耦提示注意力，解决增量医学目标检测中信息耦合与灾难性遗忘问题，在ODinM-13数据集上性能优于现有方法。", "keywords": ["增量学习", "医学目标检测", "提示学习", "灾难性遗忘", "实例解耦", "多模态数据"], "triple": {"method": "实例级提示生成与解耦提示注意力", "result": "在ODinM-13数据集上FAP指标提升显著", "contribution": "提升增量医学目标检测性能并减少遗忘"}}
{"venue": "ICML", "search_title": "ClinicalFMamba: Mamba-based MultimodalMedicalImage Fusion ...", "url": "https://icml.cc/virtual/2025/50490", "year": 2025, "abstract_snippet": "Multimodal medical image fusion integrates complementary information from different imaging modalities to enhance diagnostic accuracy and treatment planning ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/50490", "full_title": "ClinicalFMamba: Mamba-based Multimodal Medical Image Fusion for Enhanced Clinical Diagnosis", "abstract": "The ICML Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "提出ClinicalFMamba模型，基于Mamba架构融合多模态医学图像，提升临床诊断效果。", "keywords": ["医学图像融合", "Mamba架构", "多模态", "临床诊断", "深度学习"], "triple": {"method": "基于Mamba的多模态融合", "result": "增强诊断效果", "contribution": "提出新融合模型"}}
{"venue": "ICML", "search_title": "MMedPO: AligningMedicalVision-Language Models with Clinical ...", "url": "https://icml.cc/virtual/2025/poster/44599", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44599", "full_title": "MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization", "abstract": "The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter factuality challenges due to modality misalignment, where the models prioritize textual knowledge over visual input, leading to hallucinations that contradict information in medical images. Previous attempts to enhance modality alignment in Med-LVLMs through preference optimization have inadequately addressed clinical relevance in preference data, making these samples easily distinguishable and reducing alignment effectiveness. In response, we propose MMedPO, a novel multimodal medical preference optimization approach that considers the clinical relevance of preference samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference data by introducing two types of dispreference: (1) plausible hallucinations injected through target Med-LVLMs or GPT-4o to produce medically inaccurate responses, and (2) lesion region neglect achieved through local lesion-noising, disrupting visual understanding of critical areas. We then calculate clinical relevance for each sample based on scores from multiple Med-LLMs and visual tools, enabling effective alignment. Our experiments demonstrate that MMedPO significantly enhances factual accuracy in Med-LVLMs, achieving substantial improvements over existing preference optimization methods by 14.2% and 51.7% on the Med-VQA and report generation tasks, respectively. Our code are available in https://github.com/aiming-lab/MMedPO}{https://github.com/aiming-lab/MMedPO.", "summary_cn": "提出MMedPO方法，通过引入临床相关性的多模态偏好优化，提升医学视觉语言模型的事实准确性，减少幻觉。", "keywords": ["医学视觉语言模型", "多模态偏好优化", "临床相关性", "事实准确性", "幻觉减少", "模态对齐"], "triple": {"method": "引入临床相关性的多模态偏好数据优化", "result": "在Med-VQA和报告生成任务上分别提升14.2%和51.7%", "contribution": "增强医学模型模态对齐与事实准确性"}}
{"venue": "ICML", "search_title": "MedXpertQA: Benchmarking Expert-LevelMedicalReasoning and ...", "url": "https://icml.cc/virtual/2025/poster/45718", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... MedXpertQA encompasses diverse medical specialties, body systems, and clinical tasks. It addresses critical gaps in current benchmarks, ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45718", "full_title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding", "abstract": "We introduce MedXpertQA, a highly challenging and comprehensive benchmark to evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA includes 4,460 questions spanning 17 specialties and 11 body systems. It includes two subsets, Text for text evaluation and MM for multimodal evaluation. Notably, MM introduces expert-level exam questions with diverse images and rich clinical information, including patient records and examination results, setting it apart from traditional medical multimodal benchmarks with simple QA pairs generated from image captions. MedXpertQA applies rigorous filtering and augmentation to address the insufficient difficulty of existing benchmarks like MedQA, and incorporates specialty board questions to improve clinical relevance and comprehensiveness. We perform data synthesis to mitigate data leakage risk and conduct multiple rounds of expert reviews to ensure accuracy and reliability. We evaluate 18 leading models on MedXpertQA. Moreover, medicine is deeply connected to real-world decision-making, providing a rich and representative setting for assessing reasoning abilities beyond mathematics and code. To this end, we develop a reasoning-oriented subset to facilitate the assessment of o1-like models.", "summary_cn": "MedXpertQA是一个评估专家级医学知识与推理的基准，包含4,460个问题，涵盖17个专科和11个身体系统，分为文本和多模态子集，通过严格过滤和专家审核确保质量。", "keywords": ["医学基准", "专家级推理", "多模态评估", "临床相关性", "数据合成", "模型评估"], "triple": {"method": "数据合成与专家审核", "result": "构建包含文本和多模态子集的基准", "contribution": "提升医学AI评估的难度与可靠性"}}
{"venue": "ICML", "search_title": "ICML Poster Evaluating LLMs Across Multi-Cognitive Levels", "url": "https://icml.cc/virtual/2025/poster/43822", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... The framework integrates existing medical datasets and introduces tasks targeting three cognitive levels: preliminary knowledge grasp, ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43822", "full_title": "Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving", "abstract": "Large language models (LLMs) have demonstrated remarkable performance on various medical benchmarks, but their capabilities across different cognitive levels remain underexplored. Inspired by Bloom's Taxonomy, we propose a multi-cognitive-level evaluation framework for assessing LLMs in the medical domain in this study. The framework integrates existing medical datasets and introduces tasks targeting three cognitive levels: preliminary knowledge grasp, comprehensive knowledge application, and scenario-based problem solving. Using this framework, we systematically evaluate state-of-the-art general and medical LLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek. Our findings reveal a significant performance decline as cognitive complexity increases across evaluated models, with model size playing a more critical role in performance at higher cognitive levels. Our study highlights the need to enhance LLMs' medical capabilities at higher cognitive levels and provides insights for developing LLMs suited to real-world medical applications.", "summary_cn": "研究基于布鲁姆分类法提出多认知层次评估框架，系统评估主流大语言模型在医学领域的表现，发现模型性能随认知复杂度增加而下降，模型规模在高认知层次中更为关键。", "keywords": ["大语言模型", "医学评估", "认知层次", "布鲁姆分类法", "模型性能", "场景问题解决"], "triple": {"method": "多认知层次评估框架", "result": "模型性能随认知复杂度增加而下降", "contribution": "揭示模型规模在高认知层次的关键作用"}}
{"venue": "ICML", "search_title": "SecuringMedicalData from Unauthorized Traning via Sparsity ...", "url": "https://icml.cc/virtual/2024/37554", "year": 2024, "abstract_snippet": "... medical data generation and storage, boosting medical AI development. However, fears of unauthorized use, like training commercial AI models, hinder ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/37554", "full_title": "Medical Unlearnable Examples: Securing Medical Data from Unauthorized Traning via Sparsity-Aware Local Masking", "abstract": "The rapid expansion of AI in healthcare has led to a surge in medical data generation and storage, boosting medical AI development. However, fears of unauthorized use, like training commercial AI models, hinder researchers from sharing their valuable datasets. To encourage data sharing, one promising solution is to introduce imperceptible noise into the data. This method aims to safeguard the data against unauthorized training by inducing degradation in the generalization ability of the trained model. However, they are not effective and efficient when applied to medical data, mainly due to the ignorance of the sparse nature of medical images. To address this problem, we propose the Sparsity-Aware Local Masking (SALM) method, a novel approach that selectively perturbs significant pixel regions rather than the entire image as previously. This simple yet effective approach, by focusing on local areas, significantly narrows down the search space for disturbances and fully leverages the characteristics of sparsity. Our extensive experiments across various datasets and model architectures demonstrate that SALM effectively prevents unauthorized training of different models and outperforms previous SoTA data protection methods.", "summary_cn": "提出SALM方法，通过稀疏感知局部掩蔽在医学图像中引入噪声，防止未经授权的AI模型训练，提升数据保护效果。", "keywords": ["医学数据安全", "不可学习示例", "稀疏感知", "局部掩蔽", "AI模型保护", "数据共享"], "triple": {"method": "稀疏感知局部掩蔽(SALM)", "result": "有效阻止不同模型未经授权训练，优于现有方法", "contribution": "提升医学数据保护效率与效果"}}
{"venue": "ICML", "search_title": "ICML Multi-ModalMedicalImage Augmentation for Controlled ...", "url": "https://icml.cc/virtual/2025/50903", "year": 2025, "abstract_snippet": "Limited data in medical imaging exacerbate class imbalance and fairness gaps, undermining deep-learning across diverse patient subgroups.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/50903", "full_title": "Multi-Modal Medical Image Augmentation for Controlled Heterogeneity and Fair Outcomes", "abstract": "Limited data in medical imaging exacerbate class imbalance and fairness gaps, undermining deep-learning across diverse patient subgroups. GAN- and diffusion-based augmenters can expand datasets but often lack precise control over multiple clinical attributes and fail to cover the full range of real-world variability. We introduce a four-step augmentation pipeline. First, an automated scoring function identifies which classes or regions most urgently need synthetic examples. Second, we construct sketch–image–text triplets from real scans, embedding age, sex, and disease labels. Third, we fine-tune a sketch-conditioned diffusion network for reliable sketch-to-image synthesis and boost variability by generating multiple, similarity-penalized sketches per case. Fourth, we propose a novel diversity metric that simultaneously measures semantic feature-space coverage and pixel-level dispersion—unlike FID or IS, it captures intra-class spread and boundary sharpness without human annotations. Experiments on chest X-rays show our pipeline delivers high-fidelity, diverse images aligned with user-specified conditions, substantially improving fairness and generalizability.", "summary_cn": "提出四步医学图像增强流程，通过自动评分、多模态嵌入、扩散网络和多样性度量，生成可控合成图像，提升公平性和泛化能力。", "keywords": ["医学图像增强", "扩散模型", "公平性", "多样性度量", "多模态嵌入", "合成数据"], "triple": {"method": "四步增强流程（评分、嵌入、扩散合成、多样性度量）", "result": "生成高保真、多样化的合成图像，改善公平性和泛化性", "contribution": "提出可控多模态增强方法，提升数据覆盖和模型公平性"}}
{"venue": "ICML", "search_title": "ICML Poster Distribution-aware Fairness Learning inMedicalImage ...", "url": "https://icml.cc/virtual/2025/poster/46110", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46110", "full_title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective", "abstract": "Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic attributes (e.g., age, sex, race) and clinical factors (e.g., disease severity). To address these challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired by optimal control theory. We provide a comprehensive analysis of its underlying mechanisms and clarify dMoE's role in adapting to heterogeneous distributions in medical image segmentation. Furthermore, we integrate dMoE into multiple network architectures, demonstrating its broad applicability across diverse medical image analysis tasks. By incorporating demographic and clinical factors, dMoE achieves state-of-the-art performance on two 2D benchmark datasets and a 3D in-house dataset. Our results highlight the effectiveness of dMoE in mitigating biases from imbalanced distributions, offering a promising approach to bridging control theory and medical image segmentation within fairness learning paradigms. The source code is available at https://github.com/tvseg/dMoE.", "summary_cn": "提出分布感知专家混合模型（dMoE），基于最优控制理论解决医学图像分割中的公平性问题，有效缓解数据不平衡带来的偏见，在多个数据集上实现先进性能。", "keywords": ["医学图像分割", "公平性学习", "分布感知", "专家混合模型", "最优控制理论", "数据不平衡"], "triple": {"method": "分布感知专家混合模型（dMoE）", "result": "在2D基准和3D内部数据集上实现先进性能", "contribution": "结合控制理论缓解医学图像分割中的分布偏见"}}
{"venue": "ICML", "search_title": "ACAT: Adversarial Counterfactual Attention for Classification and ...", "url": "https://icml.cc/virtual/2023/poster/24472", "year": 2023, "abstract_snippet": "In some medical imaging tasks and other settings where only small parts of the image are informative for the classification task, traditional CNNs can ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ACAT: Adversarial Counterfactual Attention for Classification and ...", "abstract": null}
{"venue": "ICML", "search_title": "Modeling and InterpretingMedicalDecisions with Adaptive Imitation ...", "url": "https://icml.cc/virtual/2024/poster/33778", "year": 2024, "abstract_snippet": "We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on predicting antibiotic prescription in intensive care units ( ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/33778", "full_title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning", "abstract": "The ICML Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "提出情境化策略恢复方法，通过自适应模仿学习建模和解释医疗决策，提升决策可解释性。", "keywords": ["情境化策略恢复", "自适应模仿学习", "医疗决策建模", "决策解释", "机器学习", "医疗人工智能"], "triple": {"method": "自适应模仿学习", "result": "建模和解释医疗决策", "contribution": "提升决策可解释性"}}
{"venue": "ICML", "search_title": "ICML Poster ImprovingMedicalPredictions by Irregular Multimodal ...", "url": "https://icml.cc/virtual/2023/poster/24359", "year": 2023, "abstract_snippet": "To the best of our knowledge, this is the first work to thoroughly model irregularity in multimodalities for improving medical predictions. Our proposed methods ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster ImprovingMedicalPredictions by Irregular Multimodal ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML RethinkingMedicalReport Generation: Disease Revealing ...", "url": "https://icml.cc/virtual/2023/27743", "year": 2023, "abstract_snippet": "Knowledge graph (KG) is an important component in medical report generation because it can reveal the relations among diseases and thus is often utilized during ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML RethinkingMedicalReport Generation: Disease Revealing ...", "abstract": null}
{"venue": "ICML", "search_title": "Conditional Diffusion Replay for Continual Learning in ... - ICML 2026", "url": "https://icml.cc/virtual/2023/28915", "year": 2023, "abstract_snippet": "Conditional Diffusion Replay for Continual Learning in Medical Settings. Yewon Byun · Saurabh Garg · Sanket Vaibhav Mehta · Praveer Singh · Jayashree ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Conditional Diffusion Replay for Continual Learning in ... - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "Visual and Domain Knowledge for Professional-level Graph-of ...", "url": "https://icml.cc/virtual/2025/poster/43761", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Medical Visual Question Answering (MVQA) requires AI models to answer questions related to medical images, offering significant potential to ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43761", "full_title": "Visual and Domain Knowledge for Professional-level Graph-of-Thought Medical Reasoning", "abstract": "Medical Visual Question Answering (MVQA) requires AI models to answer questions related to medical images, offering significant potential to assist medical professionals in evaluating and diagnosing diseases, thereby improving early interventions. However, existing MVQA datasets primarily focus on basic questions regarding visual perception and pattern recognition, without addressing the more complex questions that are critical in clinical diagnosis and decision-making. This paper introduces a new benchmark designed for professional-level medical reasoning, simulating the decision-making process. We achieve this by collecting MRI and clinical data related to Hypoxic-Ischemic Encephalopathy, enriched with expert annotations and insights. Building on this data, we generate clinical question-answer pairs and MRI interpretations to enable comprehensive diagnosis, interpretation, and prediction of neurocognitive outcomes. Our evaluation of current large vision-language models (LVLMs) shows limited performance on this benchmark, highlighting both the challenges of the task and the importance of this benchmark for advancing medical AI. Furthermore, we propose a novel ``Clinical Graph of Thoughts\" model, which integrates domain-specific medical knowledge and clinical reasoning processes with the interpretive abilities of LVLMs. The model demonstrates promising results, achieving around 15\\% absolute gain on the most important neurocognitive outcome task, while the benchmark still reveals substantial opportunities for further research innovation.", "summary_cn": "本文提出专业级医学推理新基准，针对缺氧缺血性脑病，结合MRI与临床数据生成问答对。现有大视觉语言模型表现有限，而新提出的临床思维图模型集成领域知识，在神经认知结果任务上提升约15%。", "keywords": ["医学视觉问答", "专业级推理", "缺氧缺血性脑病", "大视觉语言模型", "临床思维图", "神经认知预测"], "triple": {"method": "构建基准与临床思维图模型", "result": "新模型在关键任务上提升约15%", "contribution": "推动医学AI专业推理发展"}}
{"venue": "ICML", "search_title": "Transformers Make Strong Encoders forMedicalImage Segmentation", "url": "https://icml.cc/virtual/2021/12728", "year": 2021, "abstract_snippet": "Medical image segmentation is an essential prerequisite for developing healthcare systems, especially for disease diagnosis and treatment planning.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Transformers Make Strong Encoders forMedicalImage Segmentation", "abstract": null}
{"venue": "ICML", "search_title": "ICML Explanation-guided dynamic feature selection formedicalrisk ...", "url": "https://icml.cc/virtual/2023/27742", "year": 2023, "abstract_snippet": "Poster in. Workshop: 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH). Explanation-guided dynamic feature selection for medical risk ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Explanation-guided dynamic feature selection formedicalrisk ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML LOOD: Localization-based Uncertainty Estimation forMedical...", "url": "https://icml.cc/virtual/2021/11215", "year": 2021, "abstract_snippet": "Our key idea is to estimate the OOD score from a localized feature region that is highly indicative of the disease label, as opposed to averaging signals from ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML LOOD: Localization-based Uncertainty Estimation forMedical...", "abstract": null}
{"venue": "ICML", "search_title": "Towards Privacy-preserving Explanations inMedicalImage Analysis", "url": "https://icml.cc/virtual/2021/12736", "year": 2021, "abstract_snippet": "Towards Privacy-preserving Explanations in Medical Image Analysis. Helena Montenegro · Wilson Silva · Jaime S. Cardoso. [ Abstract ]. [ Visit Poster at Spot B6 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Privacy-preserving Explanations inMedicalImage Analysis", "abstract": null}
{"venue": "ICML", "search_title": "Evidential Interactive Learning forMedicalImage Captioning", "url": "https://icml.cc/virtual/2023/poster/24068", "year": 2023, "abstract_snippet": "Medical image captioning alleviates the burden of physicians and possibly reduces medical errors by automatically generating text descriptions to describe image ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Evidential Interactive Learning forMedicalImage Captioning", "abstract": null}
{"venue": "ICML", "search_title": "TinyMIG: Transferring Generalization from Vision Foundation ...", "url": "https://icml.cc/virtual/2025/poster/45472", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Medical imaging faces significant challenges in single-domain generalization (SDG) due to the diversity of imaging devices and the ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45472", "full_title": "TinyMIG: Transferring Generalization from Vision Foundation Models to Single-Domain Medical Imaging", "abstract": "Medical imaging faces significant challenges in single-domain generalization (SDG) due to the diversity of imaging devices and the variability among data collection centers. To address these challenges, we propose \\textbf{TinyMIG}, a framework designed to transfer generalization capabilities from vision foundation models to medical imaging SDG. TinyMIG aims to enable lightweight specialized models to mimic the strong generalization capabilities of foundation models in terms of both global feature distribution and local fine-grained details during training. Specifically, for global feature distribution, we propose a Global Distribution Consistency Learning strategy that mimics the prior distributions of the foundation model layer by layer. For local fine-grained details, we further design a Localized Representation Alignment method, which promotes semantic alignment and generalization distillation between the specialized model and the foundation model. These mechanisms collectively enable the specialized model to achieve robust performance in diverse medical imaging scenarios. Extensive experiments on large-scale benchmarks demonstrate that TinyMIG, with extremely low computational cost, significantly outperforms state-of-the-art models, showcasing its superior SDG capabilities. All the code and model weights will be publicly available.", "summary_cn": "TinyMIG框架将视觉基础模型的泛化能力迁移至医学影像单域泛化，通过全局分布一致性和局部表示对齐，以极低计算成本显著提升性能。", "keywords": ["单域泛化", "医学影像", "基础模型", "迁移学习", "轻量模型", "泛化能力"], "triple": {"method": "全局分布一致性学习与局部表示对齐", "result": "在基准测试中显著超越现有模型", "contribution": "实现轻量模型高效单域泛化"}}
{"venue": "ICML", "search_title": "Diagnostically Lossless Compression ofMedicalImages - ICML 2026", "url": "https://icml.cc/virtual/2023/28401", "year": 2023, "abstract_snippet": "In this work, we address the challenge of compressing medical images while preserving fine-grained features needed for diagnosis, a property known as diagnostic ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Diagnostically Lossless Compression ofMedicalImages - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "LangDAug: Langevin Data Augmentation for Multi-Source Domain ...", "url": "https://icml.cc/virtual/2025/poster/45607", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Medical image segmentation models often struggle to generalize across different domains due to various reasons. Domain Generalization (DG) ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45607", "full_title": "LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation", "abstract": "Medical image segmentation models often struggle to generalize across different domains due to various reasons. Domain Generalization (DG) methods overcome this either through representation learning or data augmentation (DA). While representation learning methods seek domain-invariant features, they often rely on ad-hoc techniques and lack formal guarantees. DA methods, which enrich model representations through synthetic samples, have shown comparable or superior performance to representation learning approaches. We propose LangDAug, a novel Lang evin D ata Aug mentation for multi-source domain generalization in 2D medical image segmentation. LangDAug leverages Energy-Based Models (EBMs) trained via contrastive divergence to traverse between source domains, generating intermediate samples through Langevin dynamics. Theoretical analysis shows that LangDAug induces a regularization effect, and for GLMs, it upper-bounds the Rademacher complexity by the intrinsic dimensionality of the data manifold. Through extensive experiments on Fundus segmentation and 2D MRI prostate segmentation benchmarks, we show that LangDAug outperforms state-of-the-art domain generalization methods and effectively complements existing domain-randomization approaches. The codebase for our method is available at https://github.com/backpropagator/LangDAug.", "summary_cn": "提出LangDAug方法，利用基于能量的模型和Langevin动力学生成中间样本，增强医学图像分割的跨域泛化能力，在眼底和MRI前列腺分割基准测试中表现优异。", "keywords": ["医学图像分割", "域泛化", "数据增强", "基于能量的模型", "Langevin动力学", "多源域"], "triple": {"method": "基于能量的模型与Langevin动力学生成中间样本", "result": "在眼底和MRI前列腺分割基准上超越现有域泛化方法", "contribution": "提出理论正则化框架并补充现有域随机化方法"}}
{"venue": "ICML", "search_title": "MH-pFLID: Model Heterogeneous personalized Federated Learning ...", "url": "https://icml.cc/virtual/2024/poster/34360", "year": 2024, "abstract_snippet": "Federated learning is widely used in medical applications for training global models without needing local data access, but varying computational ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/34360", "full_title": "MH-pFLID: Model Heterogeneous personalized Federated Learning via Injection and Distillation for Medical Data Analysis", "abstract": "Federated learning is widely used in medical applications for training global models without needing local data access, but varying computational capabilities and network architectures (system heterogeneity) across clients pose significant challenges in effectively aggregating information from non-independently and identically distributed (non-IID) data (statistic heterogeneity). Current federated learning methods using knowledge distillation require public datasets, raising privacy and data collection issues. Additionally, these datasets require additional local computing and storage resources, which is a burden for medical institutions with limited hardware conditions. In this paper, we introduce a novel federated learning paradigm, named Model Heterogeneous personalized Federated Learning via Injection and Distillation (MH-pFLID). Our framework leverages a lightweight messenger model, eliminating the need for public datasets and reducing the training cost for each client. We also develops receiver and transmitter modules for each client to separate local biases from generalizable information, reducing biased data collection and mitigating client drift. Our experiments on various medical tasks including image classification, image segmentation, and time-series classification, show MH-pFLID outperforms state-of-the-art methods in all these areas and has good generalizability.", "summary_cn": "提出MH-pFLID框架，通过注入与蒸馏实现模型异构的个性化联邦学习，无需公共数据集，降低客户端负担，在多项医疗任务中表现优异。", "keywords": ["联邦学习", "模型异构", "知识蒸馏", "医疗数据分析", "个性化学习", "隐私保护"], "triple": {"method": "轻量信使模型与收发模块", "result": "多项医疗任务性能超越现有方法", "contribution": "无需公共数据集，降低计算负担，提升泛化能力"}}
{"venue": "ICML", "search_title": "Assessing Bias inMedicalAI - ICML 2026", "url": "https://icml.cc/virtual/2021/12751", "year": 2021, "abstract_snippet": "Machine learning and artificial intelligence are increasingly deployed in critical societal functions such as finance, media and healthcare.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Assessing Bias inMedicalAI - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "Efficient Graph Neural Architecture Search forMedicalImaging in ...", "url": "https://icml.cc/virtual/2025/50548", "year": 2025, "abstract_snippet": "Deploying deep learning in clinical settings requires balancing accuracy with limited computational resources. This is especially challenging in multitask ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/50548", "full_title": "Efficient Graph Neural Architecture Search for Medical Imaging in Real-World Clinical Settings", "abstract": "Deploying deep learning in clinical settings requires balancing accuracy with limited computational resources. This is especially challenging in multitask medical imaging, where shared encoders reduce redundancy but task-specific heads remain memory-intensive. We propose Efficient Graph Neural Architecture Search (EGNAS), a gradient-based method that explores a graph-structured space to find compact, task-specific predictors. EGNAS jointly optimizes accuracy and model size using a Pareto-efficient strategy. Evaluated on six MedNIST tasks, it reduces head size by 2.1x on average without performance loss. We further validate EGNAS in a real-world deployment on a low-resource clinical laptop in Algeria, demonstrating its practical utility for resource-constrained healthcare.", "summary_cn": "提出EGNAS方法，通过图结构搜索优化多任务医学影像模型，在保持精度的同时平均减少2.1倍头部尺寸，适用于资源受限的临床环境。", "keywords": ["图神经架构搜索", "多任务医学影像", "资源受限部署", "梯度优化", "临床实用性", "模型压缩"], "triple": {"method": "基于梯度的图神经架构搜索", "result": "头部尺寸减少2.1倍且性能无损", "contribution": "实现资源受限临床环境的高效部署"}}
{"venue": "ICML", "search_title": "A ChatGPT Aided Explainable Framework for Zero-ShotMedical...", "url": "https://icml.cc/virtual/2023/27737", "year": 2023, "abstract_snippet": "Poster in. Workshop: 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH). A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A ChatGPT Aided Explainable Framework for Zero-ShotMedical...", "abstract": null}
{"venue": "ICML", "search_title": "Temporally-Extended Prompts Optimization for SAM in ... - ICML 2026", "url": "https://icml.cc/virtual/2023/29819", "year": 2023, "abstract_snippet": "Poster in. Workshop: Interactive Learning with Implicit Human Feedback. Temporally-Extended Prompts Optimization for SAM in Interactive Medical Image ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Temporally-Extended Prompts Optimization for SAM in ... - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "An Agent-Search Strategy for Contrast Enhancement in ... - ICML 2026", "url": "https://icml.cc/virtual/2023/28346", "year": 2023, "abstract_snippet": "Poster in. Affinity Workshop: LatinX in AI (LXAI) Workshop. An Agent-Search Strategy for Contrast Enhancement in Medical Images. Nayeli Areli Perez Padilla.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "An Agent-Search Strategy for Contrast Enhancement in ... - ICML 2026", "abstract": null}
{"venue": "NeurIPS", "search_title": "CARES: A Comprehensive Benchmark of Trustworthiness ... - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/fde7f40f8ced5735006810534dc66b33-Abstract-Datasets_and_Benchmarks_Track.html", "year": 2024, "abstract_snippet": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models. Peng Xia, Ze Chen, Juanxi Tian, Yangrui Gong, Ruibo Hou, Yue Xu, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/fde7f40f8ced5735006810534dc66b33-Abstract-Datasets_and_Benchmarks_Track.html", "full_title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models", "abstract": "Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare. However, the trustworthiness of Med-LVLMs remains unverified, posing significant risks for future model deployment. In this paper, we introduce CARES and aim to comprehensively evaluate the Trustworthiness of Med-LVLMs across the medical domain. We assess the trustworthiness of Med-LVLMs across five dimensions, including trustfulness, fairness, safety, privacy, and robustness. CARES comprises about 41K question-answer pairs in both closed and open-ended formats, covering 16 medical image modalities and 27 anatomical regions. Our analysis reveals that the models consistently exhibit concerns regarding trustworthiness, often displaying factual inaccuracies and failing to maintain fairness across different demographic groups. Furthermore, they are vulnerable to attacks and demonstrate a lack of privacy awareness. We publicly release our benchmark and code in https://github.com/richard-peng-xia/CARES.", "summary_cn": "CARES基准全面评估医疗视觉语言模型的可信度，涵盖五个维度，揭示模型存在事实错误、公平性不足、易受攻击及隐私意识缺乏等问题。", "keywords": ["医疗视觉语言模型", "可信度评估", "基准测试", "公平性", "安全性", "隐私保护"], "triple": {"method": "构建多维度基准CARES", "result": "模型存在可信度问题", "contribution": "提供公开评估工具"}}
{"venue": "ICML", "search_title": "Reinforcement Learning for Sampling on TemporalMedicalImaging ...", "url": "https://icml.cc/virtual/2023/29347", "year": 2023, "abstract_snippet": "Abstract. Accelerated magnetic resonance imaging resorts to either Fourier-domain subsampling or better reconstruction algorithms to deal with fewer ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Reinforcement Learning for Sampling on TemporalMedicalImaging ...", "abstract": null}
{"venue": "ICML", "search_title": "Towards Safe Large Language Models for Medicine - ICML 2026", "url": "https://icml.cc/virtual/2024/37543", "year": 2024, "abstract_snippet": "... medical LLMs. We find that 1) current medical LLMs do not meet standards of general or medical safety, as they readily comply with harmful requests and that ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/37543", "full_title": "Towards Safe Large Language Models for Medicine", "abstract": "As large language models (LLMs) develop ever-improving capabilities and are applied in real-world settings, it is important to understand their safety. While initial steps have been taken to evaluate the safety of general-knowledge LLMs, exposing some weaknesses, the safety of medical LLMs has not been sufficiently evaluated despite their high risks to personal health and safety, public health and safety, patient rights, and human rights. To address this gap, we conduct, to our knowledge, the first study of its kind to evaluate and improve the safety of medical LLMs. We find that 1) current medical LLMs do not meet standards of general or medical safety, as they readily comply with harmful requests and that 2) fine-tuning medical LLMs on safety demonstrations significantly improves their safety. Along the way, we also present a definition of medical safety for LLMs and develop a benchmark dataset to evaluate and train for medical safety in LLMs. At the intersection of research on machine learning safety and medical machine learning, this work casts light on the status quo of the safety of medical LLMs and motivates future work in this area, mitigating the risks of harm of LLMs in medicine.", "summary_cn": "本研究首次评估并提升医疗大语言模型的安全性，发现现有模型存在安全隐患，但通过安全演示微调可显著改善。", "keywords": ["医疗大语言模型", "安全性评估", "微调", "基准数据集", "医学机器学习", "风险缓解"], "triple": {"method": "安全演示微调", "result": "模型安全性显著提升", "contribution": "定义医疗安全并创建评估基准"}}
{"venue": "ICML", "search_title": "ICML Towards Dynamic Feature Acquisition onMedicalTime Series ...", "url": "https://icml.cc/virtual/2024/36140", "year": 2024, "abstract_snippet": "Inspired by the maximization of conditional mutual information, we propose an approach to train acquirers end-to-end using only the downstream loss. We show ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/36140", "full_title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information", "abstract": "Knowing which features of a multivariate time series to measure and when is a key task in medicine, wearables, and robotics. Better acquisition policies can reduce costs while maintaining or even improving the performance of downstream predictors. Inspired by the maximization of conditional mutual information, we propose an approach to train acquirers end-to-end using only the downstream loss. We show that our method outperforms random acquisition policy, matches a model with an unrestrained budget, but does not yet overtake a static acquisition strategy. We highlight the assumptions and outline avenues for future work.", "summary_cn": "本文提出一种基于条件互信息最大化的动态特征获取方法，用于医学时间序列，旨在降低成本并保持预测性能。", "keywords": ["动态特征获取", "条件互信息", "医学时间序列", "端到端训练", "成本降低", "预测性能"], "triple": {"method": "条件互信息最大化", "result": "优于随机策略，匹配无限制预算模型", "contribution": "提出端到端动态获取方法"}}
{"venue": "ICML", "search_title": "Direct Uncertainty Prediction forMedicalSecond Opinions", "url": "https://icml.cc/media/icml-2019/Slides/4911.pdf", "year": null, "abstract_snippet": "Diagnostic Concordance Amongst Pathologists Interpreting. Breast Biopsy Specimens, UW School of Medicine, JAMA,. 2015. ○ Agreement between individual.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Direct Uncertainty Prediction forMedicalSecond Opinions", "abstract": null}
{"venue": "ICML", "search_title": "Handling the long tail inmedicalimaging - ICML 2026", "url": "https://icml.cc/virtual/2021/11102", "year": 2021, "abstract_snippet": "The ICML Logo above may be used on presentations. Right-click and choose download. It is a vector graphic and may be used at any scale.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Handling the long tail inmedicalimaging - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "ICML Enabling risk-aware Reinforcement Learning formedical...", "url": "https://icml.cc/virtual/2021/12752", "year": 2021, "abstract_snippet": "Enabling risk-aware Reinforcement Learning for medical interventions through uncertainty decomposition. Paul Festor · Giulia Luise · Matthieu Komorowski ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Enabling risk-aware Reinforcement Learning formedical...", "abstract": null}
{"venue": "ICML", "search_title": "A Data-Centric Approach to Synthetic Data forMedicalTasks", "url": "https://icml.cc/virtual/2025/poster/45228", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Breaking the Barrier of Hard Samples: A Data-Centric Approach to Synthetic Data for Medical Tasks. Maynara de Souza · Cleber Zanchettin.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45228", "full_title": "Breaking the Barrier of Hard Samples: A Data-Centric Approach to Synthetic Data for Medical Tasks", "abstract": "Data scarcity and quality issues remain significant barriers to developing robust predictive models in medical research. Traditional reliance on real-world data often leads to biased models with poor generalizability across diverse patient populations. Synthetic data generation has emerged as a promising solution, yet challenges related to these sample's representativeness and effective utilization persist. This paper introduces Profile2Gen, a novel data-centric framework designed to guide the generation and refinement of synthetic data, focusing on addressing hard-to-learn samples in regression tasks. We conducted approximately 18,000 experiments to validate its effectiveness across six medical datasets, utilizing seven state-of-the-art generative models. Results demonstrate that refined synthetic samples can reduce predictive errors and enhance model reliability. Additionally, we generalize the DataIQ framework to support regression tasks, enabling its application in broader contexts. Statistical analyses confirm that our approach achieves equal or superior performance compared to models trained exclusively on real data.", "summary_cn": "本文提出Profile2Gen框架，通过生成和优化合成数据解决医学回归任务中难样本问题，在六个数据集上验证其能降低预测误差并提升模型可靠性。", "keywords": ["合成数据", "医学回归", "难样本", "数据生成", "模型可靠性", "Profile2Gen"], "triple": {"method": "Profile2Gen框架与DataIQ扩展", "result": "合成数据降低预测误差，性能等同或优于纯真实数据", "contribution": "提出数据中心方法优化合成数据，提升模型泛化能力"}}
{"venue": "ICML", "search_title": "A Statistical Approach to Texture Description ofMedicalImages", "url": "https://icml.cc/Conferences/2002/workshops/MLCV02/MLCV02-Bevk.pdf", "year": null, "abstract_snippet": "This study is a pre- liminary preparation for application of these methods on medical images. 1. Introduction. Texture is a very commonly used term in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Statistical Approach to Texture Description ofMedicalImages", "abstract": null}
{"venue": "ICML", "search_title": "Multi-ModalMedicalImage Augmentation for Controlled ...", "url": "https://icml.cc/media/icml-2025/Slides/50903.pdf", "year": null, "abstract_snippet": "Multi-Modal Medical Image Augmentation for Controlled. Heterogeneity and Fair Outcomes. ○ In medical domain, data imbalance among different patient group is ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Multi-ModalMedicalImage Augmentation for Controlled ...", "abstract": null}
{"venue": "ICML", "search_title": "A Quantitative Comparison of TotalSegmentator and MOOSE ...", "url": "https://icml.cc/virtual/2025/50452", "year": 2025, "abstract_snippet": "The Boundary versus The Core: A Quantitative Comparison of TotalSegmentator and MOOSE Performance in Medical Image Segmentation. Qifan Chen · Yifei Shi · Jin ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/50452", "full_title": "The Boundary versus The Core: A Quantitative Comparison of TotalSegmentator and MOOSE Performance in Medical Image Segmentation", "abstract": "The rise of total-body PET/CT imaging necessitates robust automated segmentation tools, fueling a debate between using general-purpose \"foundation\" models and domain-specific \"specialised\" models. This paper presents a rigorous, quantitative comparison between TotalSegmentator, a foundation model trained on over 1,200 CT scans, and MOOSE, a specialised tool designed for PET/CT analysis. We evaluated both models on public datasets for spleen and vertebrae segmentation, using a comprehensive suite of metrics covering both volumetric overlap (Dice, Jaccard) and boundary precision (Hausdorff Distance). Our results reveal a critical trade-off: TotalSegmentator delivers significantly superior boundary accuracy for all tested structures, making it the premier choice for precision-critical tasks, such as radiotherapy planning. Conversely, MOOSE achieves higher volumetric overlap for vertebrae, suggesting better performance in capturing the core anatomical volume. However, this comes at the cost of severe and frequent boundary errors. We conclude that TotalSegmentator has better performance in Total-body PET/CT images segmentation. The optimal choice is application-dependent, requiring a careful balance between the need for precise surface delineation and accurate core volume assessment. Our findings provide evidence-based guidance for researchers and clinicians in selecting the appropriate AI tool for their specific quantitative imaging needs.", "summary_cn": "本研究对比了通用模型TotalSegmentator与专用模型MOOSE在医学图像分割中的表现。TotalSegmentator在边界精度上更优，适合放疗规划；MOOSE在椎体体积重叠上更好，但边界误差严重。选择取决于具体应用需求。", "keywords": ["医学图像分割", "TotalSegmentator", "MOOSE", "边界精度", "体积重叠", "PET/CT"], "triple": {"method": "使用Dice、Jaccard和Hausdorff距离等指标对比模型", "result": "TotalSegmentator边界精度更高，MOOSE体积重叠更好但边界误差大", "contribution": "为临床选择AI工具提供基于证据的指导"}}
{"venue": "ICML", "search_title": "ICML Contributed Talk 4: A Benchmark ofMedicalOut of Distribution ...", "url": "https://icml.cc/virtual/2020/6914", "year": 2020, "abstract_snippet": "Contributed Talk 4: A Benchmark of Medical Out of Distribution Detection. Joseph Paul Cohen. 2020 Presentation in. Workshop: Uncertainty and Robustness in Deep ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Contributed Talk 4: A Benchmark ofMedicalOut of Distribution ...", "abstract": null}
{"venue": "ICML", "search_title": "Interpretable Machine Learning in Healthcare - ICML 2026", "url": "https://icml.cc/virtual/2021/workshop/8358", "year": 2021, "abstract_snippet": "Such methodologies would make medical decisions more trustworthy and reliable for physicians, which could facilitate the deployment ultimately. On the other ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Interpretable Machine Learning in Healthcare - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Introducing 3D Representation for Dense Volume-to ...", "url": "https://icml.cc/virtual/2025/poster/45130", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... In volume-to-volume translations in medical images, existing models often struggle to capture the inherent volumetric distribution using 3D ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45130", "full_title": "Introducing 3D Representation for Dense Volume-to-Volume Translation via Score Fusion", "abstract": "In volume-to-volume translations in medical images, existing models often struggle to capture the inherent volumetric distribution using 3D voxel-space representations, due to high computational dataset demands. We present Score-Fusion, a novel volumetric translation model that effectively learns 3D representations by ensembling perpendicularly trained 2D diffusion models in score function space. By carefully initializing our model to start with an average of 2D models as in existing models, we reduce 3D training to a fine-tuning process, mitigating computational and data demands. Furthermore, we explicitly design the 3D model's hierarchical layers to learn ensembles of 2D features, further enhancing efficiency and performance. Moreover, Score-Fusion naturally extends to multi-modality settings by fusing diffusion models conditioned on different inputs for flexible, accurate integration. We demonstrate that 3D representation is essential for better performance in downstream recognition tasks, such as tumor segmentation, where most segmentation models are based on 3D representation. Extensive experiments demonstrate that Score-Fusion achieves superior accuracy and volumetric fidelity in 3D medical image super-resolution and modality translation. Additionally, we extend Score-Fusion to video super-resolution by integrating 2D diffusion models on time-space slices with a spatial-temporal video diffusion backbone, highlighting its potential for general-purpose volume translation and providing broader insight into learning-based approaches for score function fusion.", "summary_cn": "提出Score-Fusion模型，通过融合垂直训练的2D扩散模型学习3D表示，降低计算需求，提升医学图像超分辨率和模态转换的精度与体积保真度。", "keywords": ["3D表示", "体积转换", "扩散模型", "分数融合", "医学图像", "超分辨率"], "triple": {"method": "融合2D扩散模型分数函数", "result": "提升3D图像转换精度与效率", "contribution": "降低3D训练计算需求并扩展至多模态"}}
{"venue": "ICML", "search_title": "ICML 2025 Position:MedicalLarge Language Model Benchmarks ...", "url": "https://icml.cc/virtual/2025/oral/40130", "year": 2025, "abstract_snippet": "Main Navigation · Position: Medical Large Language Model Benchmarks Should Prioritize Construct Validity. Ahmed Alaa · Thomas Hartvigsen · Niloufar Golchini · ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2025 Position:MedicalLarge Language Model Benchmarks ...", "abstract": null}
{"venue": "ICML", "search_title": "Effective Multi-center Dataset Pruning forMedicalImage Segmentation", "url": "https://icml.cc/virtual/2023/27766", "year": 2023, "abstract_snippet": "To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Effective Multi-center Dataset Pruning forMedicalImage Segmentation", "abstract": null}
{"venue": "ICML", "search_title": "Prior Image-Constrained Reconstruction using Style", "url": "https://icml.cc/media/icml-2021/Slides/9541.pdf", "year": null, "abstract_snippet": "Medical imaging. Page 3. Bioengineering. 4. Images from Incomplete Measurements. Image credits (L to R):. Canon Global. Povic, et al., Nat. Astronomy '18.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Prior Image-Constrained Reconstruction using Style", "abstract": null}
{"venue": "ICML", "search_title": "Guiding the Generation of Synthetic Data forMedicalTasks with ...", "url": "https://icml.cc/virtual/2025/46748", "year": 2025, "abstract_snippet": "Breaking Barriers in Hard Samples: Guiding the Generation of Synthetic Data for Medical Tasks with Data-centric Approach", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/46748", "full_title": "Breaking Barriers in Hard Samples: Guiding the Generation of Synthetic Data for Medical Tasks with Data-centric Approach", "abstract": "Data scarcity and quality issues remain significant barriers to developing robust predictive models in medical research. Traditional reliance on real-world data often leads to biased models with poor generalizability across diverse patient populations. Synthetic data generation has emerged as a promising solution, yet challenges related to these sample's representativeness and effective utilization persist. This paper introduces Profile2Gen, a novel data-centric framework designed to guide the generation and refinement of synthetic data, focusing on addressing hard-to-learn samples in regression tasks. We conducted approximately 18,000 experiments to validate its effectiveness across six medical datasets, utilizing seven state-of-the-art generative models. Results demonstrate that refined synthetic samples can reduce predictive errors and enhance model reliability. Additionally, we generalize the DataIQ framework to support regression tasks, enabling its application in broader contexts. Statistical analyses confirm that our approach achieves equal or superior performance compared to models trained exclusively on real data.", "summary_cn": "本文提出Profile2Gen框架，通过数据驱动方法指导合成数据生成，针对医学回归任务中的难样本，提升模型预测精度与可靠性。", "keywords": ["合成数据生成", "数据驱动方法", "医学回归任务", "难样本处理", "模型可靠性", "Profile2Gen框架"], "triple": {"method": "Profile2Gen框架指导合成数据生成与精炼", "result": "减少预测误差，性能等同或优于仅用真实数据训练的模型", "contribution": "推广DataIQ至回归任务，提升模型在医学数据中的泛化能力"}}
{"venue": "ICML", "search_title": "Raptor: Scalable Train-free Embeddings for 3DMedicalVolumes ...", "url": "https://icml.cc/media/icml-2025/Slides/46452.pdf", "year": null, "abstract_snippet": "3D medical imaging models are computationally expensive and require large labeled datasets, which are often unavailable in medical domains. Training state ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Raptor: Scalable Train-free Embeddings for 3DMedicalVolumes ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Direct Uncertainty Prediction forMedicalSecond ...", "url": "https://icml.cc/virtual/2019/poster/3695", "year": 2019, "abstract_snippet": "Direct Uncertainty Prediction for Medical Second Opinions. Maithra Raghu · Katy Blumer · Rory sayres · Ziad Obermeyer · Bobby Kleinberg · Sendhil ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster Direct Uncertainty Prediction forMedicalSecond ...", "abstract": null}
{"venue": "ICML", "search_title": "3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)", "url": "https://icml.cc/virtual/2023/workshop/21486", "year": 2023, "abstract_snippet": "To enhance the interpretability of medical intelligence, it becomes critical to develop methodologies to explain predictions as these systems are pervasively ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)", "abstract": null}
{"venue": "ICML", "search_title": "From Post Hoc Explanations to Inherently Interpretable Models for ...", "url": "https://icml.cc/virtual/2023/27753", "year": 2023, "abstract_snippet": "Bridging the Gap: From Post Hoc Explanations to Inherently Interpretable Models for Medical Imaging. Shantanu Ghosh · Ke Yu · Forough Arabshahi · Kayhan ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "From Post Hoc Explanations to Inherently Interpretable Models for ...", "abstract": null}
{"venue": "ICML", "search_title": "Evaluating Saliency Map Explanation on Multi-ModalMedicalImages", "url": "https://icml.cc/virtual/2021/13103", "year": 2021, "abstract_snippet": "Being able to explain the prediction to clinical end-users is a necessity to leverage the power of AI models for clinical decision support. For medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Evaluating Saliency Map Explanation on Multi-ModalMedicalImages", "abstract": null}
{"venue": "ICML", "search_title": "Learning 3D Image Prior through Position-aware Diffusion Score ...", "url": "https://icml.cc/virtual/2024/37056", "year": 2024, "abstract_snippet": "Diffusion models face significant challenges when employed for real world large-scale medical image reconstruction problems such as 3D Computed Tomography ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/37056", "full_title": "DiffusionBlend: Learning 3D Image Prior through Position-aware Diffusion Score Blending for 3D Computed Tomography Reconstruction", "abstract": "The ICML Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "提出DiffusionBlend方法，通过位置感知扩散分数融合学习3D图像先验，用于3D CT重建，提升重建质量。", "keywords": ["3D CT重建", "扩散模型", "图像先验", "位置感知", "分数融合", "深度学习"], "triple": {"method": "位置感知扩散分数融合", "result": "提升3D CT重建质量", "contribution": "学习3D图像先验"}}
{"venue": "ICML", "search_title": "ICML Poster CLIMB: Data Foundations for Large Scale Multimodal ...", "url": "https://icml.cc/virtual/2025/poster/45167", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... This research demonstrates that AI systems trained on diverse medical data can better generalize to new clinical challenges and provides a ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45167", "full_title": "CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models", "abstract": "Recent advances in clinical AI have enabled remarkable progress across many clinical domains. However, existing benchmarks and models are primarily limited to a small set of modalities and tasks, which hinders the development of large-scale multimodal methods that can make holistic assessments of patient health and well-being. To bridge this gap, we introduce Clinical Large-scale Integrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark unifying diverse clinical data across imaging, language, temporal, and graph modalities. CLIMB comprises 4.51 million patient samples totaling 19.01 terabytes distributed across 2D imaging, 3D video, time series, graphs, and multimodal data. Through extensive empirical evaluation, we demonstrate that multitask pretraining significantly improves performance on understudied domains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis over single-task learning. Pretraining on CLIMB also effectively improves models' generalization capability to new tasks, and strong unimodal encoder performance translates well to multimodal performance when paired with task-appropriate fusion strategies. Our findings provide a foundation for new architecture designs and pretraining strategies to adavance clinical AI research. Code is released at https://github.com/DDVD233/climb.", "summary_cn": "CLIMB是一个大规模多模态临床基准数据集，整合了影像、语言、时序和图数据，包含451万患者样本。研究表明，多任务预训练显著提升超声和心电图分析性能，并增强模型泛化能力。", "keywords": ["多模态基准", "临床AI", "预训练", "泛化能力", "数据整合", "医学影像"], "triple": {"method": "构建CLIMB多模态临床基准数据集并进行多任务预训练", "result": "超声和心电图分析性能提升达29%和23%，模型泛化能力增强", "contribution": "为临床AI研究提供大规模数据基础和架构设计指导"}}
{"venue": "ICML", "search_title": "ICML Poster Dual Decomposition of Convex Optimization Layers for ...", "url": "https://icml.cc/virtual/2022/poster/17537", "year": 2022, "abstract_snippet": "Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images. Tom Ron · Tamir Hazan. Keywords: [ DL: Attention Mechanisms ].", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster Dual Decomposition of Convex Optimization Layers for ...", "abstract": null}
{"venue": "ICML", "search_title": "Training-free Design of Augmentations with Data-centric Principles", "url": "https://icml.cc/virtual/2024/36733", "year": 2024, "abstract_snippet": "Our results demonstrate consistent improvements over existing state-of-the-art segmentation methods across various medical imaging datasets.We attach our ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/36733", "full_title": "Training-free Design of Augmentations with Data-centric Principles", "abstract": "The remarkable advancements in Artificial Intelligence (AI) and Deep Learning owe significantly to the evolution of informative datasets. With the emerging concept of ``Data-centric AI'', there has been a shift in focus from developing deep neural networks (DNNs) to crafting high-quality training datasets. However, current data-centric approaches predominantly rely on empirics or heavy DNN training costs, lacking established design principles. Our work concentrates on data augmentation, a key technique for enhancing data quality. Grounded by the recent development of deep learning theory, we discover principled metrics that effectively gauge both data quality and its interaction with DNNs. Crucially, these principles can be calculated without the need for extensive DNN training, enabling training-free augmentation design with minimal computation costs. Comprehensive experiments validate that our principles are strongly aligned with optimal choices of augmentations used in practice. Our method is particularly beneficial in domain-specific fields like medical image analysis, where the optimal augmentation strategy and the data's inductive bias are often unclear. Our results demonstrate consistent improvements over existing state-of-the-art segmentation methods across various medical imaging datasets.We attach our code at: https://anonymous.4open.science/r/240523 anonymous repo-C828/.", "summary_cn": "本研究提出无需训练的数据增强设计原则，通过理论推导的指标评估数据质量与模型交互，在医学图像分割中验证了其有效性。", "keywords": ["数据增强", "数据为中心AI", "无训练设计", "医学图像分析", "深度学习理论", "数据质量评估"], "triple": {"method": "基于深度学习理论推导原则性指标", "result": "增强策略与最优选择高度一致，提升医学图像分割性能", "contribution": "实现低计算成本的无训练数据增强设计"}}
{"venue": "ICML", "search_title": "Machine Learning for Multimodal Healthcare Data - ICML 2026", "url": "https://icml.cc/virtual/2023/workshop/21474", "year": 2023, "abstract_snippet": "Topics of interest include, but are not limited to: Multimodal fusion and learning in medical imaging, digital pathology, computational biology, genetics ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Machine Learning for Multimodal Healthcare Data - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "OrthoGraphRAG: Enhancing Clinical Decision Making with Multi ...", "url": "https://icml.cc/virtual/2025/51234", "year": 2025, "abstract_snippet": "Large Language Models (LLMs) face accuracy and complex reasoning challenges in specialized medical domains like orthopedics. We introduce OrthoGraphRAG, a ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/51234", "full_title": "OrthoGraphRAG: Enhancing Clinical Decision Making with Multi-Level Knowledge Graphs", "abstract": "Large Language Models (LLMs) face accuracy and complex reasoning challenges in specialized medical domains like orthopedics. We introduce OrthoGraphRAG, a multi-level Graph Retrieval-Augmented Generation (GraphRAG) framework, to address these issues. OrthoGraphRAG constructs a novel multi-level knowledge graph linking private clinical knowledge with public UMLS data, building on recent medical GraphRAG advancements. The framework retrieves query-entity-based subgraphs, augments them with clinical note text, allowing an LLM to synthesize informed responses from combined graph and textual evidence. Evaluated on real-world orthopedic clinic letters with diverse query complexities, OrthoGraphRAG demonstrated effectiveness, particularly in contextual reasoning integrating private patient data with broader medical knowledge. This multi-level GraphRAG approach offers a promising path to safer, more capable, and contextually aware LLMs for specialized clinical applications. Our code is released at: https://github.com/venkateshtata/OrthoGraphRAG.", "summary_cn": "OrthoGraphRAG提出多级知识图谱增强生成框架，结合私有临床数据与公共UMLS知识，提升骨科领域LLM的准确性和复杂推理能力。", "keywords": ["GraphRAG", "知识图谱", "临床决策", "骨科", "LLM增强", "多级检索"], "triple": {"method": "多级知识图谱构建与检索增强生成", "result": "在骨科临床信件评估中有效提升上下文推理能力", "contribution": "为专业医疗应用提供更安全、上下文感知的LLM框架"}}
{"venue": "ICML", "search_title": "ICML Poster Adaptively Weighted Data Augmentation Consistency ...", "url": "https://icml.cc/virtual/2023/poster/23766", "year": 2023, "abstract_snippet": "Concept shift is a prevailing problem in natural tasks like medical image segmentation where samples usually come from different subpopulations with variant ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster Adaptively Weighted Data Augmentation Consistency ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Exploiting Negative Samples: A Catalyst for Cohort ...", "url": "https://icml.cc/virtual/2024/poster/33276", "year": 2024, "abstract_snippet": "... medical interest via density-based clustering. We empirically evaluate the effectiveness of our approach on the real-world electronic medical records from ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/33276", "full_title": "Exploiting Negative Samples: A Catalyst for Cohort Discovery in Healthcare Analytics", "abstract": "In healthcare analytics, addressing binary diagnosis or prognosis tasks presents unique challenges due to the inherent asymmetry between positive and negative samples. While positive samples, indicating patients with a disease, are defined based on stringent medical criteria, negative samples are defined in an open-ended manner and remain underexplored in prior research. To bridge this gap, we propose an innovative approach to facilitate cohort discovery within negative samples, leveraging a Shapley-based exploration of interrelationships between these samples, which holds promise for uncovering valuable insights concerning the studied disease, and related comorbidity and complications. We quantify each sample’s contribution using data Shapley values, subsequently constructing the Negative Sample Shapley Field to model the distribution of all negative samples. Next, we transform this field through manifold learning, preserving the essential data structure information while imposing an isotropy constraint in data Shapley values. Within this transformed space, we pinpoint cohorts of medical interest via density-based clustering. We empirically evaluate the effectiveness of our approach on the real-world electronic medical records from National University Hospital in Singapore, yielding clinically valuable insights aligned with existing knowledge, and benefiting medical research and clinical decision-making.", "summary_cn": "本研究提出一种利用Shapley值和流形学习分析医疗负样本的方法，通过密度聚类发现临床相关队列，在新加坡国立大学医院电子病历上验证有效，为疾病研究提供新见解。", "keywords": ["负样本分析", "Shapley值", "流形学习", "密度聚类", "队列发现", "医疗分析"], "triple": {"method": "Shapley值结合流形学习与密度聚类", "result": "从负样本中识别出临床相关队列，验证与现有知识一致", "contribution": "为医疗分析提供负样本探索新方法，辅助临床决策"}}
{"venue": "ICML", "search_title": "2nd Workshop on Interpretable Machine Learning in Healthcare ...", "url": "https://icml.cc/virtual/2022/workshop/13449", "year": 2022, "abstract_snippet": "To enhance the interpretability of medical intelligence, it becomes critical to develop methodologies to explain predictions as these systems are pervasively ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "2nd Workshop on Interpretable Machine Learning in Healthcare ...", "abstract": null}
{"venue": "ICML", "search_title": "machinelearning.org - Proceedings ICML 2004", "url": "https://icml.cc/Conferences/2004/proceedings.html", "year": null, "abstract_snippet": "Jan 3, 2006 ... Glenn Fung - CAD, Siemens Medical Solutions USA Murat Dundar - CAD, Siemens Medical Solutions USA Jinbo Bi - CAD, Siemens Medical Solutions USA", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "machinelearning.org - Proceedings ICML 2004", "abstract": null}
{"venue": "ICML", "search_title": "Unsupervised Domain Adaptation for Anatomical Structure ...", "url": "https://icml.cc/virtual/2024/poster/33163", "year": 2024, "abstract_snippet": "The TKT leverages prior knowledge of the medical anatomy of fetal as topological information, reconstructing and aligning anatomy features across source and ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/33163", "full_title": "Unsupervised Domain Adaptation for Anatomical Structure Detection in Ultrasound Images", "abstract": "The ICML Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "该研究提出一种无监督域自适应方法，用于超声图像中的解剖结构检测，旨在解决跨域数据分布差异问题，提升模型在目标域上的检测性能。", "keywords": ["无监督域自适应", "超声图像", "解剖结构检测", "跨域学习", "医学影像分析"], "triple": {"method": "无监督域自适应方法", "result": "提升目标域检测性能", "contribution": "解决跨域数据差异问题"}}
{"venue": "ICML", "search_title": "A Text-to-Image Approach for Continual Learning inMedicalSettings", "url": "https://icml.cc/virtual/2023/27928", "year": 2023, "abstract_snippet": "In this work, we introduce two novel healthcare benchmarks for domain incremental continual learning: diabetic retinopathy severity classification and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Text-to-Image Approach for Continual Learning inMedicalSettings", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Detecting Any instruction-to-answer interaction ...", "url": "https://icml.cc/virtual/2024/poster/35018", "year": 2024, "abstract_snippet": "Medical Visual Question Answering (Med-VQA) interprets complex medical imagery using user instructions for precise diagnostics, yet faces challenges due to ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/35018", "full_title": "Detecting Any instruction-to-answer interaction relationship:Universal Instruction-to-Answer Navigator for Med-VQA", "abstract": "Medical Visual Question Answering (Med-VQA) interprets complex medical imagery using user instructions for precise diagnostics, yet faces challenges due to diverse, inadequately annotated images. In this paper, we introduce the Universal Instruction-Vision Navigator (Uni-Med) framework for extracting instruction-to-answer relationships, facilitating the understanding of visual evidence behind responses. Specifically, we design the Instruct-to-Answer Clues Interpreter (IAI) to generate visual explanations based on the answers and mark the core part of instructions with \"real intent\" labels. The IAI-Med VQA dataset, produced using IAI, is now publicly available to advance Med-VQA research. Additionally, our Token-Level Cut-Mix module dynamically aligns visual explanations with image patches, ensuring answers are traceable and learnable. We also implement intention-guided attention to minimize non-core instruction interference, sharpening focus on 'real intent'. Extensive experiments on SLAKE datasets show Uni-Med’s superior accuracies (87.52% closed, 86.12% overall), outperforming MedVInT-PMC-VQA by 1.22% and 0.92%. Code and dataset are available at: https://github.com/zhongzee/Uni-Med-master.", "summary_cn": "提出Uni-Med框架，通过指令-答案线索解释器和Token-Level Cut-Mix模块，提升医学视觉问答的准确性与可解释性，在SLAKE数据集上达到87.52%的封闭准确率。", "keywords": ["医学视觉问答", "指令-答案关系", "视觉解释", "可解释性", "数据集", "注意力机制"], "triple": {"method": "指令-答案线索解释器与Token-Level Cut-Mix模块", "result": "SLAKE数据集上封闭准确率87.52%，超越基准模型", "contribution": "提升Med-VQA准确性与可解释性，公开数据集IAI-Med VQA"}}
{"venue": "ICML", "search_title": "Track: Oral 4B Positions: Generative AI Evaluation - ICML 2026", "url": "https://icml.cc/virtual/2025/session/46910", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Medical LLM benchmarks, much like those in other fields, are arbitrarily constructed using medical licensing exam questions. For these ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Track: Oral 4B Positions: Generative AI Evaluation - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "The 1st Workshop on Healthcare AI and COVID-19 - ICML 2026", "url": "https://icml.cc/virtual/2022/workshop/13469", "year": 2022, "abstract_snippet": "... medical imaging diagnosis. With the development of the epidemic, the virus ... The goal of this workshop is to bring together perspectives from multiple ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "The 1st Workshop on Healthcare AI and COVID-19 - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "A Multi-Graph Neural Framework for Generalized Multimodal Fusion ...", "url": "https://icml.cc/virtual/2023/27925", "year": 2023, "abstract_snippet": "MaxCorrMGNN: A Multi-Graph Neural Framework for Generalized Multimodal Fusion of Medical Data for Outcome Prediction. Niharika D'Souza · Hongzhi Wang ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Multi-Graph Neural Framework for Generalized Multimodal Fusion ...", "abstract": null}
{"venue": "ICML", "search_title": "Generalizing Orthogonalization for Models with Non-Linearities", "url": "https://icml.cc/virtual/2024/poster/33057", "year": 2024, "abstract_snippet": "... medical experts. If this fact is not known to the medical expert, automatic decision-making based on this algorithm could lead to prescribing a treatment ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/33057", "full_title": "Generalizing Orthogonalization for Models with Non-Linearities", "abstract": "The complexity of black-box algorithms can lead to various challenges, including the introduction of biases. These biases present immediate risks in the algorithms’ application. It was, for instance, shown that neural networks can deduce racial information solely from a patient's X-ray scan, a task beyond the capability of medical experts. If this fact is not known to the medical expert, automatic decision-making based on this algorithm could lead to prescribing a treatment (purely) based on racial information. While current methodologies allow for the \"orthogonalization\" or \"normalization\" of neural networks with respect to such information, existing approaches are grounded in linear models. Our paper advances the discourse by introducing corrections for non-linearities such as ReLU activations. Our approach also encompasses scalar and tensor-valued predictions, facilitating its integration into neural network architectures. Through extensive experiments, we validate our method's effectiveness in safeguarding sensitive data in generalized linear models, normalizing convolutional neural networks for metadata, and rectifying pre-existing embeddings for undesired attributes.", "summary_cn": "本文提出一种非线性正交化方法，用于消除神经网络中的敏感信息偏差，如从X射线推断种族，通过实验验证其在保护隐私和纠正嵌入方面的有效性。", "keywords": ["正交化", "非线性模型", "神经网络", "偏差消除", "敏感数据保护", "元数据归一化"], "triple": {"method": "引入非线性正交化校正", "result": "有效保护敏感数据并纠正嵌入属性", "contribution": "扩展正交化方法至非线性模型"}}
{"venue": "ICML", "search_title": "TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking ...", "url": "https://icml.cc/virtual/2025/poster/43507", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Lay Summary. When computers partition similar data into groups (like categorizing customer profiles or medical images), current methods can spot ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43507", "full_title": "TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization", "abstract": "Density-based mode-seeking methods generate a density-ascending dependency from low-density points towards higher-density neighbors.Current mode-seeking methods identify modes by breaking some dependency connections, but relying heavily on local data characteristics, requiring case-by-case threshold settings or human intervention to be effective for different datasets. To address this issue, we introduce a novel concept called typicality, by exploring the locally defined dependency from a global perspective, to quantify how confident a point would be a mode. We devise an algorithm that effectively and efficiently identifies modes with the help of the global-view typicality. To implement and validate our idea, we design a clustering method called TANGO, which not only leverages typicality to detect modes, but also utilizes graph-cut with an improved path-based similarity to aggregate data into the final clusters. Moreover, this paper also provides some theoretical analysis on the proposed algorithm. Experimental results on several synthetic and extensive real-world datasets demonstrate the effectiveness and superiority of TANGO. The code is available at https://github.com/SWJTU-ML/TANGO_code.", "summary_cn": "TANGO提出典型性概念，从全局视角改进密度模式搜索，结合图割优化实现高效聚类，在合成和真实数据集上表现优异。", "keywords": ["典型性", "模式搜索", "图割", "聚类", "全局视角", "密度估计"], "triple": {"method": "典型性感知非局部模式搜索与图割优化", "result": "在合成和真实数据集上表现有效且优越", "contribution": "提出典型性概念，改进模式检测与聚类方法"}}
{"venue": "ICML", "search_title": "Automated Active Learning with Differentiable Query Strategy Search", "url": "https://icml.cc/virtual/2025/poster/45158", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Our tests on both everyday and medical images show that AutoAL consistently beats using single strategy alone. This makes it much easier and ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45158", "full_title": "AutoAL: Automated Active Learning with Differentiable Query Strategy Search", "abstract": "As deep learning continues to evolve, the need for data efficiency becomes increasingly important. Considering labeling large datasets is both time-consuming and expensive, active learning (AL) provides a promising solution to this challenge by iteratively selecting the most informative subsets of examples to train deep neural networks, thereby reducing the labeling cost. However, the effectiveness of different AL algorithms can vary significantly across data scenarios, and determining which AL algorithm best fits a given task remains a challenging problem. This work presents the first differentiable AL strategy search method, named AutoAL, which is designed on top of existing AL sampling strategies. AutoAL consists of two neural nets, named SearchNet and FitNet, which are optimized concurrently under a differentiable bi-level optimization framework. For any given task, SearchNet and FitNet are iteratively co-optimized using the labeled data, learning how well a set of candidate AL algorithms perform on that task. With the optimal AL strategies identified, SearchNet selects a small subset from the unlabeled pool for querying their annotations, enabling efficient training of the task model. Experimental results demonstrate that AutoAL consistently achieves superior accuracy compared to all candidate AL algorithms and other selective AL approaches, showcasing its potential for adapting and integrating multiple existing AL methods across diverse tasks and domains.", "summary_cn": "AutoAL提出首个可微分的主动学习策略搜索方法，通过SearchNet和FitNet协同优化，自动选择最优策略，在多种任务中实现更高准确率，降低标注成本。", "keywords": ["主动学习", "可微分搜索", "策略优化", "数据效率", "深度学习", "标注成本"], "triple": {"method": "可微分双层优化框架", "result": "优于所有候选AL算法", "contribution": "自适应集成多种AL方法"}}
{"venue": "ICML", "search_title": "Interpretable Alzheimer's Disease Classification Via a Contrastive ...", "url": "https://icml.cc/virtual/2023/27770", "year": 2023, "abstract_snippet": "Therefore, this work stands as a contribution to the pertinent development of accurate and interpretable deep learning within medical imaging. Show more ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Interpretable Alzheimer's Disease Classification Via a Contrastive ...", "abstract": null}
{"venue": "ICML", "search_title": "Data-Driven Subgroup Identification for Linear Regression", "url": "https://icml.cc/virtual/2023/poster/24479", "year": 2023, "abstract_snippet": "Medical studies frequently require to extract the relationship between each covariate and the outcome with statistical confidence measures. To do this ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Data-Driven Subgroup Identification for Linear Regression", "abstract": null}
{"venue": "ICML", "search_title": "On the Vulnerability of Applying Retrieval-Augmented Generation ...", "url": "https://icml.cc/virtual/2025/poster/45226", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... ... medical Q&A. In such attacks, adversaries generate poisoned documents containing a broad spectrum of targeted information, such as ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45226", "full_title": "On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains", "abstract": "Retrieval-Augmented Generation (RAG) has been empirically shown to enhance the performance of large language models (LLMs) in knowledge-intensive domains such as healthcare, finance, and legal contexts. Given a query, RAG retrieves relevant documents from a corpus and integrates them into the LLMs’ generation process. In this study, we investigate the adversarial robustness of RAG, focusing specifically on examining the retrieval system. First, across 225 different setup combinations of corpus, retriever, query, and targeted information, we show that retrieval systems are vulnerable to universal poisoning attacks in medical Q&A. In such attacks, adversaries generate poisoned documents containing a broad spectrum of targeted information, such as personally identifiable information. When these poisoned documents are inserted into a corpus, they can be accurately retrieved by any users, as long as attacker-specified queries are used. To understand this vulnerability, we discovered that the deviation from the query’s embedding to that of the poisoned document tends to follow a pattern in which the high similarity between the poisoned document and the query is retained, thereby enabling precise retrieval. Based on these findings, we develop a new detection-based defense to ensure the safe use of RAG. Through extensive experiments spanning various Q&A domains, we observed that our proposed method consistently achieves excellent detection rates in nearly all cases.", "summary_cn": "研究发现检索增强生成（RAG）在医疗问答等领域易受通用投毒攻击，攻击者通过插入含目标信息的文档影响检索结果。基于此，提出了一种检测防御方法，实验证明其有效性。", "keywords": ["检索增强生成", "投毒攻击", "医疗问答", "对抗鲁棒性", "检测防御", "知识密集型领域"], "triple": {"method": "实验分析投毒攻击模式", "result": "RAG检索系统易受攻击，新防御方法检测率高", "contribution": "揭示RAG脆弱性并提出有效防御策略"}}
{"venue": "ICML", "search_title": "ICML Poster Inverse Contextual Bandits: Learning How Behavior ...", "url": "https://icml.cc/virtual/2022/poster/16317", "year": 2022, "abstract_snippet": "... Medical practice is constantly evolving as clinical professionals fine-tune their knowledge over time. For instance, as the medical community's ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster Inverse Contextual Bandits: Learning How Behavior ...", "abstract": null}
{"venue": "ICML", "search_title": "BLO-SAM: Bi-level Optimization Based Finetuning of the Segment ...", "url": "https://icml.cc/virtual/2024/poster/32990", "year": 2024, "abstract_snippet": "... medical imaging. To overcome these limitations, we introduce BLO-SAM, which finetunes SAM based on bi-level optimization (BLO). Our approach allows for ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/32990", "full_title": "BLO-SAM: Bi-level Optimization Based Finetuning of the Segment Anything Model for Overfitting-Preventing Semantic Segmentation", "abstract": "The Segment Anything Model (SAM), a foundation model pretrained on millions of images and segmentation masks, has significantly advanced semantic segmentation, a fundamental task in computer vision. Despite its strengths, SAM encounters two major challenges. Firstly, it struggles with segmenting specific objects autonomously, as it relies on users to manually input prompts like points or bounding boxes to identify targeted objects. Secondly, SAM faces challenges in excelling at specific downstream tasks, like medical imaging, due to a disparity between the distribution of its pretraining data, which predominantly consists of general-domain images, and the data used in downstream tasks. Current solutions to these problems, which involve finetuning SAM, often lead to overfitting, a notable issue in scenarios with very limited data, like in medical imaging. To overcome these limitations, we introduce BLO-SAM, which finetunes SAM based on bi-level optimization (BLO). Our approach allows for automatic image segmentation without the need for manual prompts, by optimizing a learnable prompt embedding. Furthermore, it significantly reduces the risk of overfitting by training the model's weight parameters and the prompt embedding on two separate subsets of the training dataset, each at a different level of optimization. We apply BLO-SAM to diverse semantic segmentation tasks in general and medical domains. The results demonstrate BLO-SAM's superior performance over various state-of-the-art image semantic segmentation methods. The code of BLO-SAM is available at https://github.com/importZL/BLO-SAM.", "summary_cn": "BLO-SAM通过双层优化微调SAM模型，实现无手动提示的自动图像分割，有效防止过拟合，在通用和医学图像分割任务中表现优异。", "keywords": ["双层优化", "SAM模型", "语义分割", "过拟合预防", "医学图像", "自动分割"], "triple": {"method": "双层优化微调SAM", "result": "性能优于现有方法", "contribution": "实现无提示自动分割并防过拟合"}}
{"venue": "ICML", "search_title": "\"Why Is There a Tumor?\": Tell Me the Reason, Show Me the Evidence", "url": "https://icml.cc/virtual/2025/poster/43910", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Medical AI models excel at tumor detection and segmentation. However, their latent representations often lack explicit ties to clinical ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43910", "full_title": "\"Why Is There a Tumor?\": Tell Me the Reason, Show Me the Evidence", "abstract": "Medical AI models excel at tumor detection and segmentation. However, their latent representations often lack explicit ties to clinical semantics, producing outputs less trusted in clinical practice. Most of the existing models generate either segmentation masks/labels (localizing where without why) or textual justifications (explaining why without where), failing to ground clinical concepts in spatially localized evidence. To bridge this gap, we propose to develop models that can justify the segmentation or detection using clinically relevant terms and point to visual evidence. We address two core challenges: First, we curate a rationale dataset to tackle the lack of paired images, annotations, and textual rationales for training. The dataset includes 180K image-mask-rationale triples with quality evaluated by expert radiologists. Second, we design rationale-informed optimization that disentangles and localizes fine-grained clinical concepts in a self-supervised manner without requiring pixel-level concept annotations. Experiments across medical benchmarks show our model demonstrates superior performance in segmentation, detection, and beyond. The anonymous link to our code.", "summary_cn": "提出一种医学AI模型，结合分割与文本解释，用临床术语定位肿瘤并提供视觉证据，提升临床可信度。", "keywords": ["医学AI", "肿瘤分割", "临床解释", "视觉证据", "自监督学习", "数据集构建"], "triple": {"method": "自监督优化与数据集构建", "result": "在分割与检测任务中表现优异", "contribution": "实现临床概念的空间定位与解释"}}
{"venue": "ICML", "search_title": "CLIMB: Data Foundations for Large Scale Multimodal Clinical ...", "url": "https://icml.cc/media/icml-2025/Slides/45167.pdf", "year": null, "abstract_snippet": "Few‐shot performance of models across different pretraining (PT) datasets. Below describes our preprint. QoQ- Med : Building Multimodal Clinical Foundation Models.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CLIMB: Data Foundations for Large Scale Multimodal Clinical ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML How Does Adaptive Optimization Impact Local Neural Network ...", "url": "https://icml.cc/virtual/2023/25871", "year": 2023, "abstract_snippet": "Instead, we advocate for a local trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce R med OPT ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML How Does Adaptive Optimization Impact Local Neural Network ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Variational Open-Domain Question Answering", "url": "https://icml.cc/virtual/2023/poster/24576", "year": 2023, "abstract_snippet": "On the MedMCQA dataset, we outperform the domain-tuned Med -PaLM by +5.3% despite using 2.500 × fewer parameters. Our retrieval-augmented BioLinkBERT model ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML Poster Variational Open-Domain Question Answering", "abstract": null}
{"venue": "ICML", "search_title": "Co-EM Support Vector Learning", "url": "https://icml.cc/Conferences/2004/proceedings/papers/96.pdf", "year": null, "abstract_snippet": "Multi-view algorithms, such as co-training and co-EM, utilize unlabeled data when the available attributes can be split into inde-.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Co-EM Support Vector Learning", "abstract": null}
{"venue": "ICML", "search_title": "Infinite SVM: a Dirichlet Process Mixture of Large-margin Kernel ...", "url": "https://icml.cc/Conferences/2011/papers/374_icmlpaper.pdf", "year": null, "abstract_snippet": "We begin with a brief introduction of the MED large- margin machines and DP mixtures; followed by the. iSVM which builds on these two lines of thoughts. 2.1.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Infinite SVM: a Dirichlet Process Mixture of Large-margin Kernel ...", "abstract": null}
{"venue": "ICML", "search_title": "Causal Conceptions of Fairness and their Consequences", "url": "https://icml.cc/media/icml-2022/Slides/17122_eHjIkLG.pdf", "year": null, "abstract_snippet": "D(T = Med ., Race = Majority). D(T = High, Race = Majority). 43. D(T = Low, Race = Minority). D(T = Med ., Race = Minority). D(T = High, Race = Minority). Page 44 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Causal Conceptions of Fairness and their Consequences", "abstract": null}
{"venue": "ICML", "search_title": "Multi-Task Learning for HIV Therapy Screening", "url": "https://icml.cc/Conferences/2008/papers/520.pdf", "year": null, "abstract_snippet": "Given this set of identified mutations together with the patient's med -.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Multi-Task Learning for HIV Therapy Screening", "abstract": null}
{"venue": "ICML", "search_title": "Max-Margin Nonparametric Latent Feature Models for Link Prediction", "url": "https://icml.cc/2012/papers/374.pdf", "year": null, "abstract_snippet": "MED subsumes SVM as a special case and has been extended to incorporate latent variables (Jebara, 2002; Zhu et al., 2009) and to perform structured output ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Max-Margin Nonparametric Latent Feature Models for Link Prediction", "abstract": null}
{"venue": "ICML", "search_title": "A Conditional Normalizing Flow for Accelerated Multi-Coil MR Imaging", "url": "https://icml.cc/media/icml-2023/Slides/23820.pdf", "year": null, "abstract_snippet": "Med . Image Comput. Comput. Assist. Intervent., pp. 234–241, 2015. Conditioning. Network, g! Zero-Filled. Estimate, y. True Image. {x i }#$%. &. Nu llsp ace. Pro.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Conditional Normalizing Flow for Accelerated Multi-Coil MR Imaging", "abstract": null}
{"venue": "ICML", "search_title": "Open-Det: An Efficient Learning Framework for Open-Ended Detection", "url": "https://icml.cc/virtual/2025/poster/45000", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... The source codes are available at: https://github.com/ Med -Process/Open-Det. Show more. Lay Summary. How to detect novel objects in open-world ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45000", "full_title": "Open-Det: An Efficient Learning Framework for Open-Ended Detection", "abstract": "Open-Ended object Detection (OED) is a novel and challenging task that detects objects and generates their category names in a free-form manner, without requiring additional vocabularies during inference. However, the existing OED models, such as GenerateU, require large-scale datasets for training, suffer from slow convergence, and exhibit limited performance. To address these issues, we present a novel and efficient Open-Det framework, consisting of four collaborative parts. Specifically, Open-Det accelerates model training in both the bounding box and object name generation process by reconstructing the Object Detector and the Object Name Generator. To bridge the semantic gap between Vision and Language modalities, we propose a Vision-Language Aligner with V-to-L and L-to-V alignment mechanisms, incorporating with the Prompts Distiller to transfer knowledge from the VLM into VL-prompts, enabling accurate object name generation for the LLM. In addition, we design a Masked Alignment Loss to eliminate contradictory supervision and introduce a Joint Loss to enhance classification, resulting in more efficient training. Compared to GenerateU, Open-Det, using only 1.5% of the training data (0.077M vs. 5.077M), 20.8% of the training epochs (31 vs. 149), and fewer GPU resources (4 V100 vs. 16 A100), achieves even higher performance (+1.0% in APr). The source codes are available at: https://github.com/Med-Process/Open-Det.", "summary_cn": "提出Open-Det框架，通过重构检测器和名称生成器，结合视觉-语言对齐与提示蒸馏，显著提升开放目标检测的训练效率和性能。", "keywords": ["开放目标检测", "视觉-语言对齐", "提示蒸馏", "高效训练", "多模态学习", "目标名称生成"], "triple": {"method": "重构检测器与生成器，结合视觉-语言对齐与提示蒸馏", "result": "使用更少数据和资源，性能超越GenerateU（APr提升1.0%）", "contribution": "提出高效开放检测框架，解决训练慢、数据需求大的问题"}}
{"venue": "ICML", "search_title": "ICML 2024 Papers", "url": "https://icml.cc/virtual/2024/papers.html", "year": 2024, "abstract_snippet": "... Med -VQA · Unraveling the Impact of Heterophilic Structures on Graph Positive-Unlabeled Learning · Mitigating Label Noise on Graphs via Topological Sample ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2024 Papers", "abstract": null}
{"venue": "ICML", "search_title": "Stein Point Markov Chain Monte Carlo", "url": "https://icml.cc/media/Slides/icml/2019/101(11-11-00)-11-12-00-4703-stein_point_mar.pdf", "year": null, "abstract_snippet": "Jun 11, 2019 ... MED . SP. SP-MALA LAST. SP-MALA INFL. SP-RWM LAST. SP-RWM INFL. SP-MCMC methods are compared against the original SP (Chen et al., 2018), MED ( ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Stein Point Markov Chain Monte Carlo", "abstract": null}
{"venue": "ICML", "search_title": "Uncertainty Sampling and Transductive Experimental Design for ...", "url": "https://icml.cc/Conferences/2009/papers/582.pdf", "year": null, "abstract_snippet": "ibm-mac (1937 examples, 9822 fea- tures), baseball-hockey (1988 examples, 12148 fea- tures) and med -space (1972 examples, 17084 features) datasets are drawn ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Uncertainty Sampling and Transductive Experimental Design for ...", "abstract": null}
{"venue": "ICML", "search_title": "Deep Supervised t-Distributed Embedding", "url": "https://icml.cc/Conferences/2010/papers/149.pdf", "year": null, "abstract_snippet": "of Med . Research, University of Toronto, 160 College St, Toronto ON, M5S 3E1 CANADA. Abstract. Deep learning has been successfully applied to perform non ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Deep Supervised t-Distributed Embedding", "abstract": null}
{"venue": "ICML", "search_title": "ICML 2021 Organizers", "url": "https://icml.cc/virtual/2021/organizers", "year": 2021, "abstract_snippet": "She holds an MSc in mathematics, a BSc in biology, and an MEd in high school mathematics education from the University of Zurich. She obtained her PhD in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2021 Organizers", "abstract": null}
{"venue": "ICML", "search_title": "Incorporating Domain Knowledge in Matching Problems via ...", "url": "https://icml.cc/2012/papers/639.pdf", "year": null, "abstract_snippet": "of Biostatistics & Med . Informatics, University of Wisconsin Madison. §Dept. of Computer Science and Dept. of Statistics, University of Chicago. {pachauri ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Incorporating Domain Knowledge in Matching Problems via ...", "abstract": null}
{"venue": "ICML", "search_title": "A Hierarchical Dirichlet Process Model with Multiple Levels of ...", "url": "https://icml.cc/2012/papers/49.pdf", "year": null, "abstract_snippet": "littb@mail. med .upenn.edu. Depts. of Neurology and Bioengineering, University of Pennsylvania, Philadelphia, PA USA. Abstract. Driven by the multi-level ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Hierarchical Dirichlet Process Model with Multiple Levels of ...", "abstract": null}
{"venue": "ICML", "search_title": "Hierarchical Maximum Entropy Density Estimation - Robert Schapire", "url": "https://icml.cc/imls/conferences/2007/proceedings/papers/448.pdf", "year": null, "abstract_snippet": "( med . 90). 10 species. ( med . 19). Figure 1. The hierarchy of species in the ... ( med . 35). 4 species. ( med . 107). 1 species. (96) rainforest trees (26). 4 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Hierarchical Maximum Entropy Density Estimation - Robert Schapire", "abstract": null}
{"venue": "ICML", "search_title": "P assport", "url": "https://media.icml.cc/Conferences/ICML2019/PASSPORT.pdf", "year": null, "abstract_snippet": "Med Ctr. NORTH. Promenade. Promenade. © 2/19 LBT. Metro Blue Line. Downtown Long Beach. Station. 710. Long. Beach. A. B F. D. C. E. Free circulator bus serving ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "P assport", "abstract": null}
{"venue": "ICML", "search_title": "Sample of the ACORD CERTIFICATE OF LIABILITY INSURANCE", "url": "https://media.icml.cc/Conferences/ICML2024/ICML2024_EAC_Sample_COI.pdf", "year": null, "abstract_snippet": "MED EXP (Any one person). $. PERSONAL & ADV INJURY. $. GENERAL AGGREGATE. $. PRODUCTS - COMP/OP AGG. $. $. RETENTION. DED. CLAIMS-MADE. OCCUR. $. AGGREGATE. $.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Sample of the ACORD CERTIFICATE OF LIABILITY INSURANCE", "abstract": null}
{"venue": "ICML", "search_title": "Influenza forecasting framework based on Gaussian processes", "url": "https://icml.cc/media/icml-2020/Slides/5959.pdf", "year": null, "abstract_snippet": "Med .). 15. | Christoph Zimmer | 2020-06-15. Robert Bosch GmbH 2020. All rights reserved, also regarding any disposal, exploitation, reproduction, editing ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Influenza forecasting framework based on Gaussian processes", "abstract": null}
{"venue": "ICML", "search_title": "Optimal Assignment Kernels For Attributed Molecular Graphs", "url": "https://icml.cc/Conferences/2005/proceedings/papers/029_Optimal_FroehlichEtAl.pdf", "year": null, "abstract_snippet": "Med . Chem., 45, 1585–1597. Bonchev, D., & Rouvray, D. H. (Eds.). (1990). Chem- ical Graph Theory: Introduction and Fundamentals, vol. 1 of Mathematical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Optimal Assignment Kernels For Attributed Molecular Graphs", "abstract": null}
{"venue": "ICML", "search_title": "ICML 2020 Organizers", "url": "https://icml.cc/virtual/2020/organizers", "year": 2020, "abstract_snippet": "She holds an MSc in mathematics, a BSc in biology, and an MEd in high school mathematics education from the University of Zurich. She obtained her PhD in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2020 Organizers", "abstract": null}
{"venue": "ICML", "search_title": "Fast Global Alignment Kernels", "url": "https://icml.cc/2011/papers/489_icmlpaper.pdf", "year": null, "abstract_snippet": "Parameter grid for all considered kernels. med (f) stands for the empirical median of f evaluated on a few points of the training set, either time series if the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Fast Global Alignment Kernels", "abstract": null}
{"venue": "ICML", "search_title": "NeuronTune: Towards Self-Guided Spurious Bias Mitigation", "url": "https://icml.cc/virtual/2025/poster/43955", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Mmis = Med (¯Vyi ) and Mcor = Med (ˆVyi ). Theorem 4.2 assumes that each dimension of input embeddings consists of a linear combination of ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43955", "full_title": "NeuronTune: Towards Self-Guided Spurious Bias Mitigation", "abstract": "Deep neural networks often develop spurious bias, reliance on correlations between non-essential features and classes for predictions. For example, a model may identify objects based on frequently co-occurring backgrounds rather than intrinsic features, resulting in degraded performance on data lacking these correlations. Existing mitigation approaches typically depend on external annotations of spurious correlations, which may be difficult to obtain and are not relevant to the spurious bias in a model. In this paper, we take a step towards self-guided mitigation of spurious bias by proposing NeuronTune, a post hoc method that directly intervenes in a model's internal decision process. Our method probes in a model's latent embedding space to identify and regulate neurons that lead to spurious prediction behaviors. We theoretically justify our approach and show that it brings the model closer to an unbiased one. Unlike previous methods, NeuronTune operates without requiring spurious correlation annotations, making it a practical and effective tool for improving model robustness. Experiments across different architectures and data modalities demonstrate that our method significantly mitigates spurious bias in a self-guided way.", "summary_cn": "NeuronTune提出一种自引导后处理方法，通过干预模型内部决策过程，无需外部标注即可显著减轻虚假偏差，提升模型鲁棒性。", "keywords": ["虚假偏差", "自引导缓解", "后处理方法", "神经元调控", "模型鲁棒性", "内部决策干预"], "triple": {"method": "在潜在嵌入空间识别并调控导致虚假预测的神经元", "result": "显著减轻虚假偏差，提升模型在不同架构和数据模态上的鲁棒性", "contribution": "提出无需外部标注的自引导后处理方法，直接干预模型内部决策过程"}}
{"venue": "ICML", "search_title": "Rainprotection - International Conference on Machine Learning", "url": "https://media.icml.cc/Conferences/ICML2025/ICML2025-Rainprotection.pdf", "year": null, "abstract_snippet": "MED EXP (Any one person). $. PERSONAL & ADV INJURY. $. GENERAL AGGREGATE. $. PRODUCTS - COMP/OP AGG. $. $. RETENTION. DED. CLAIMS-MADE. OCCUR. $. AGGREGATE. $.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Rainprotection - International Conference on Machine Learning", "abstract": null}
{"venue": "ICML", "search_title": "MorphGrower: A Synchronized Layer-by-layer Growing Approach for ...", "url": "https://icml.cc/media/icml-2024/Slides/35513.pdf", "year": null, "abstract_snippet": "Jul 23, 2024 ... MED . 0.85. 0.90. 0.95. 1.00. CTT. Reference. MorphVAE. Ours. MorphGrower significantly outperforms. MorphVAE！ Page 14. CNN. Block. L inear. CNN.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MorphGrower: A Synchronized Layer-by-layer Growing Approach for ...", "abstract": null}
{"venue": "ICML", "search_title": "Neural Architecture Search in a Proxy Validation Loss Landscape", "url": "https://icml.cc/media/icml-2020/Slides/5824.pdf", "year": null, "abstract_snippet": "med in a r K = 8, le convo- separable utions, 2. ⇥ 3 max peration epresent- stacking. Model. GPUs. Time. (Days). Params. (M). Test Error. (%). ResNet-110. -. -.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Neural Architecture Search in a Proxy Validation Loss Landscape", "abstract": null}
{"venue": "ICML", "search_title": "Near-Exact Recovery for Tomographic Inverse Problems via Deep ...", "url": "https://icml.cc/media/icml-2022/Slides/16156.pdf", "year": null, "abstract_snippet": "Jul 17, 2022 ... and corrupted measurements y = Ax. 0. + e with. ‖e‖. 2. ≤ 𝜂, reconstruct the signal x. 0 . <latexit ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Near-Exact Recovery for Tomographic Inverse Problems via Deep ...", "abstract": null}
{"venue": "ICML", "search_title": "Comparing Clusterings in Space", "url": "https://icml.cc/Conferences/2010/papers/642.pdf", "year": null, "abstract_snippet": "This work was supported by the School of Medicine and Public Health, the Wisconsin Alumni Research. Foundation, the Department of Biostatistics and Med - ical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Comparing Clusterings in Space", "abstract": null}
{"venue": "ICML", "search_title": "Dirichlet Enhanced Relational Learning", "url": "https://icml.cc/Conferences/2005/proceedings/papers/127_DirichletEnhanced_XuEtAl.pdf", "year": null, "abstract_snippet": "The Figure 2 gives an example in a med - ical domain. Patient.PrimeComplaint is an attribute describing the prime complaint of the patient. Proce-. Page 4 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Dirichlet Enhanced Relational Learning", "abstract": null}
{"venue": "ICML", "search_title": "A Bayesian Approach to Protein Model Quality Assessment", "url": "https://icml.cc/Conferences/2009/papers/525.pdf", "year": null, "abstract_snippet": "Med . Chem., 49, 5895–5902. Nallapati, R. (2006). The Smoothed Dirichlet Distribu- tion: Understanding Cross-entropy Ranking in In- formation Retrieval ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Bayesian Approach to Protein Model Quality Assessment", "abstract": null}
{"venue": "ICML", "search_title": "A Model for Handling Approximate, Noisy or Incomplete Labeling in ...", "url": "https://icml.cc/Conferences/2005/proceedings/papers/086_HandlingApproximate_RamakrishanEtAl.pdf", "year": null, "abstract_snippet": "med . 0.913. 0.909. 0.858. Average. 0.803. 0.801. 0.766. Table 2. F scores, using BayesANIL in conjunction with. SVM, with rate of mislabeled positive class ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Model for Handling Approximate, Noisy or Incomplete Labeling in ...", "abstract": null}
{"venue": "ICML", "search_title": "Efficient Learning with Partially Observed Attributes", "url": "https://icml.cc/Conferences/2010/papers/319.pdf", "year": null, "abstract_snippet": "Returning to the example of med - ical applications, it is unrealistic to convince patients to participate in a medical experiment in which they need to go ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Efficient Learning with Partially Observed Attributes", "abstract": null}
{"venue": "ICML", "search_title": "Polyhedral Classifier for Target Detection A Case Study", "url": "https://icml.cc/Conferences/2008/papers/513.pdf", "year": null, "abstract_snippet": "The goal of a Computer Aided Detection (CAD) system is to detect potentially malignant tumors and lesions in med - ical images (CT scans, X-ray, MRI etc). In ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Polyhedral Classifier for Target Detection A Case Study", "abstract": null}
{"venue": "ICML", "search_title": "The Skew Spectrum of Graphs", "url": "https://icml.cc/Conferences/2008/papers/396.pdf", "year": null, "abstract_snippet": "J Med Chem, 34, 786–797. Diaconis, P. (1988). Group representation in proba- bility and statistics, vol. 11 of IMS Lecture Series. Institute of Mathematical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "The Skew Spectrum of Graphs", "abstract": null}
{"venue": "ICML", "search_title": "Robust Matrix Completion and Corrupted Columns", "url": "https://icml.cc/2011/papers/469_icmlpaper.pdf", "year": null, "abstract_snippet": "In many situations such as med - ical research (see e.g. (Cesa-Bianchi et al., 2010)), the data matrix is only partially observed, and the question is if we.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Robust Matrix Completion and Corrupted Columns", "abstract": null}
{"venue": "ICML", "search_title": "EigenTransfer: A Unified Framework for Transfer Learning", "url": "https://icml.cc/Conferences/2009/papers/141.pdf", "year": null, "abstract_snippet": "sci. med , talk.politics.mideast ccl-ohs1. Carcinoma, Pregnancy ccl-ohs2. Prognosis, Receptors ccl-ohs3. In-Vitro, Molecular-Sequence-Data ccl-ohs4. Antibodies ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "EigenTransfer: A Unified Framework for Transfer Learning", "abstract": null}
{"venue": "ICML", "search_title": "Copula Mixture Model for Dependency-seeking Clustering", "url": "https://icml.cc/2012/papers/486.pdf", "year": null, "abstract_snippet": "can serve as two sources of information about a med - ical treatment. We assume that X and Y have co- occurring samples (x1,...,xn) and (y1,...,yn) with xi ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Copula Mixture Model for Dependency-seeking Clustering", "abstract": null}
{"venue": "ICML", "search_title": "Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples", "url": "https://icml.cc/Conferences/2009/papers/422.pdf", "year": null, "abstract_snippet": "sci. med . 50.6 ± 1.9. 62.1 ± 3.9 sci.space. 54.7 ± 2.5. 75.7 ± 3.4 sci.religion.christian. 49.2 ± 3.4. 59.0 ± 4.7 talk.politics.guns. 47.7 ± 3.8. 58.5 ± 6.0 talk ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples", "abstract": null}
{"venue": "ICML", "search_title": "Group Sparse Additive Models", "url": "https://icml.cc/2012/papers/463.pdf", "year": null, "abstract_snippet": "Med .,. 347(25):1999–2009, 2002. Yuan, M. and Lin, Y. Model selection and estimation in regression with grouped variables. JRSSB, 68(1):49–67,. 2006. Appendix ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Group Sparse Additive Models", "abstract": null}
{"venue": "ICML", "search_title": "Fast Neighborhood Subgraph Pairwise Distance Kernel", "url": "https://icml.cc/Conferences/2010/papers/347.pdf", "year": null, "abstract_snippet": "Med . Chem., 48(1):312–320, 2005. Menchetti, S., Costa, F., and Frasconi, P. Weighted decomposition kernels. In Proc. ICML, pp. 585–592,. 2005. Schietgat, L ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Fast Neighborhood Subgraph Pairwise Distance Kernel", "abstract": null}
{"venue": "ICML", "search_title": "Confidence-Weighted Linear Classification", "url": "https://icml.cc/Conferences/2008/papers/322.pdf", "year": null, "abstract_snippet": "sci. med talk talk.politics.guns talk.politics.mideast. Table 1. 20 Newsgroups binary decision tasks. where diag(xi) is a diagonal matrix with the square of ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Confidence-Weighted Linear Classification", "abstract": null}
{"venue": "ICML", "search_title": "Group Lasso with Overlap and Graph", "url": "https://icml.cc/Conferences/2009/papers/471.pdf", "year": null, "abstract_snippet": "A gene-expression sig- nature as a predictor of survival in breast cancer. N. Engl. J. Med ., 347, 1999–2009. Wainwright, M. J. (2006). Sharp thresholds for high ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Group Lasso with Overlap and Graph", "abstract": null}
{"venue": "ICML", "search_title": "Step-wise Triple-Consistent Diffusion Sampling For Inverse Problems", "url": "https://icml.cc/virtual/2025/poster/46601", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... https://fastmri. med .nyu. edu/, 2019. arXiv preprint arXiv:1811.08839. Hatamizadeh, A., Song, J., Liu, G., Kautz, J., and Vahdat, A. Diffit ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46601", "full_title": "SITCOM: Step-wise Triple-Consistent Diffusion Sampling For Inverse Problems", "abstract": "Diffusion models (DMs) are a class of generative models that allow sampling from a distribution learned over a training set. When applied to solving inverse problems, the reverse sampling steps are modified to approximately sample from a measurement-conditioned distribution. However, these modifications may be unsuitable for certain settings (e.g., presence of measurement noise) and non-linear tasks, as they often struggle to correct errors from earlier steps and generally require a large number of optimization and/or sampling steps. To address these challenges, we state three conditions for achieving measurement-consistent diffusion trajectories. Building on these conditions, we propose a new optimization-based sampling method that not only enforces standard data manifold measurement consistency and forward diffusion consistency, as seen in previous studies, but also incorporates our proposed step-wise and network-regularized backward diffusion consistency that maintains a diffusion trajectory by optimizing over the input of the pre-trained model at every sampling step. By enforcing these conditions (implicitly or explicitly), our sampler requires significantly fewer reverse steps. Therefore, we refer to our method as S tep-w i se T riple- Co nsistent Sa m pling ( SITCOM ). Compared to SOTA baselines, our experiments across several linear and non-linear tasks (with natural and medical images) demonstrate that SITCOM achieves competitive or superior results in terms of standard similarity metrics and run-time.", "summary_cn": "SITCOM提出一种三步一致性扩散采样方法，用于解决逆问题，通过优化预训练模型输入，减少反向步骤，在多种任务中实现高效且性能优越的结果。", "keywords": ["扩散模型", "逆问题", "一致性采样", "优化方法", "医学图像", "非线性任务"], "triple": {"method": "三步一致性扩散采样", "result": "减少反向步骤，提升性能与运行效率", "contribution": "提出SITCOM方法，解决逆问题中的噪声和非线性挑战"}}
{"venue": "ICML", "search_title": "Trusted Multi-View Classification with Expert Knowledge Constraints", "url": "https://icml.cc/virtual/2025/poster/45140", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... , 2021) and MISC (Niknazar & Med - nick, 2024). For a detailed description of these methods, please refer to Appendix A.5. Evaluation Metrics ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45140", "full_title": "Trusted Multi-View Classification  with Expert Knowledge Constraints", "abstract": "Multi-view classification (MVC) based on the Dempster-Shafer theory has gained significant recognition for its reliability in safety-critical applications. However, existing methods predominantly focus on providing confidence levels for decision outcomes without explaining the reasoning behind these decisions. Moreover, the reliance on first-order statistical magnitudes of belief masses often inadequately capture the intrinsic uncertainty within the evidence.  To address these limitations, we propose a novel framework termed Trusted Multi-view Classification Constrained with Expert Knowledge (TMCEK). TMCEK integrates expert knowledge to enhance feature-level interpretability and introduces a distribution-aware subjective opinion mechanism to derive more reliable and realistic confidence estimates. The theoretical superiority of the proposed uncertainty measure over conventional approaches is rigorously established. Extensive experiments conducted on three multi-view datasets for sleep stage classification demonstrate that TMCEK achieves state-of-the-art performance while offering interpretability at both the feature and decision levels. These results position TMCEK as a robust and interpretable solution for MVC in safety-critical domains. The code is available at https://github.com/jie019/TMCEK_ICML2025.", "summary_cn": "提出TMCEK框架，集成专家知识和分布感知主观意见机制，提升多视图分类的可解释性与置信度估计，在睡眠分期任务中实现最优性能。", "keywords": ["多视图分类", "专家知识", "可解释性", "置信度估计", "睡眠分期", "不确定性建模"], "triple": {"method": "集成专家知识与分布感知主观意见机制", "result": "在睡眠分期任务中达到最优性能", "contribution": "提升多视图分类的可解释性与置信度估计"}}
{"venue": "ICML", "search_title": "Estimating Risk Ratios via Observational Studies - ICML 2026", "url": "https://icml.cc/virtual/2025/poster/45747", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Med ., 117(11):916–921, December 1992. Nie, X. and Wager, S. Quasi-oracle estimation of heteroge- neous treatment effects, 2020. Noma, H ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45747", "full_title": "Quantifying Treatment Effects: Estimating Risk Ratios via Observational Studies", "abstract": "The Risk Difference (RD), an absolute measure of effect, is widely used and well-studied in both randomized controlled trials (RCTs) and observational studies. Complementary to the RD, the Risk Ratio (RR), as a relative measure, is critical for a comprehensive understanding of intervention effects: RD can downplay small absolute changes, while RR can highlight them. Despite its significance, the theoretical study of RR has received less attention, particularly in observational settings. This paper addresses this gap by tackling the estimation of RR in observational data. We propose several RR estimators and establish their theoretical properties, including asymptotic normality and confidence intervals. Through analyses on simulated and real-world datasets, we evaluate the performance of these estimators in terms of bias, efficiency, and robustness to generative data models. We also examine the coverage and length of the associated confidence intervals. Due to the non-linear nature of RR, influence function theory yields two distinct efficient estimators with different convergence assumptions. Based on theoretical and empirical insights, we recommend, among all estimators, one of the two doubly-robust estimators, which, intriguingly, challenges conventional expectations.", "summary_cn": "本文针对观察性研究中风险比估计的理论不足，提出多种估计器并评估其性能，推荐一种双重稳健估计器以提升效果评估。", "keywords": ["风险比", "观察性研究", "估计器", "双重稳健", "理论性质", "置信区间"], "triple": {"method": "提出多种风险比估计器", "result": "评估性能并推荐双重稳健估计器", "contribution": "填补观察性研究中风险比估计的理论空白"}}
{"venue": "ICML", "search_title": "Demand-Driven Clustering in Relational Domains for Predicting ...", "url": "https://icml.cc/2012/papers/644.pdf", "year": null, "abstract_snippet": "Med - ical resources provide some relevant information. For example, the ICD9 diagnoses codes are a tree struc-. Page 2. Demand-Driven Clustering in Relational ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Demand-Driven Clustering in Relational Domains for Predicting ...", "abstract": null}
{"venue": "ICML", "search_title": "A Graph-based Framework for Multi-Task Multi-View Learning", "url": "https://icml.cc/2011/papers/38_icmlpaper.pdf", "year": null, "abstract_snippet": "sci. med (594) pc.hardware (587). P2T2 comp.sys.mac. sci.space (593) hardware (575). P3T1 rec.autos (592) talk.politics.mideast. (564). P3T2 rec.motorcycles talk ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Graph-based Framework for Multi-Task Multi-View Learning", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Training Flexible Models of Genetic Variant Effects from ...", "url": "https://icml.cc/virtual/2025/poster/44064", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Genome Med ., 12(1):103, December 2020. Lizio, M., Harshbarger, J., Shimoji, H., Severin, J., Ka- sukawa, T., Sahin, S., Abugessaisa, I ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44064", "full_title": "Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra", "abstract": "To understand how genetic variants in human genomes manifest in phenotypes - traits like height or diseases like asthma - geneticists have sequenced and measured hundreds of thousands of individuals. Geneticists use this data to build models that predict how a genetic variant impacts phenotype given genomic features of the variant, like DNA accessibility or the presence of nearby DNA-bound proteins. As more data and features become available, one might expect predictive models to improve. Unfortunately, training these models is bottlenecked by the need to solve expensive linear algebra problems because variants in the genome are correlated with nearby variants, requiring inversion of large matrices. Previous methods have therefore been restricted to fitting small models, and fitting simplified summary statistics, rather than the full likelihood of the statistical model. In this paper, we leverage modern fast linear algebra techniques to develop DeepWAS (Deep genome Wide Association Studies), a method to train large and flexible neural network predictive models to optimize likelihood. Surprisingly, we find that larger models only improve performance when using our full likelihood approach; when trained by fitting traditional summary statistics, larger models perform no better than small ones. We find larger models trained on more features make better predictions, potentially improving disease predictions and therapeutic target identification.", "summary_cn": "本文提出DeepWAS方法，利用快速线性代数技术训练大型神经网络模型，优化全似然函数，以预测遗传变异对表型的影响，提升疾病预测和靶点识别能力。", "keywords": ["DeepWAS", "遗传变异", "神经网络", "全似然优化", "线性代数", "疾病预测"], "triple": {"method": "利用快速线性代数训练大型神经网络", "result": "大模型在全似然方法下性能提升，预测更优", "contribution": "开发DeepWAS方法，改善疾病预测和靶点识别"}}
{"venue": "ICML", "search_title": "ICML Poster Distilling the Knowledge in Data Pruning", "url": "https://icml.cc/virtual/2025/poster/46023", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... , 2021; Feldman & Zhang, 2020; Med - ing et al., 2021; Chitta et al., 2019; Sorscher et al., 2022). In (Sorscher et al., 2022), the authors ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46023", "full_title": "Distilling the Knowledge in Data Pruning", "abstract": "With the increasing size of datasets used for training neural networks, data pruning has gained traction in recent years. However, most current data pruning algorithms are limited in their ability to preserve accuracy compared to models trained on the full data, especially in high pruning regimes. In this paper we explore the application of data pruning while incorporating knowledge distillation (KD) when training on a pruned subset. That is, rather than relying solely on ground-truth labels, we also use the soft predictions from a teacher network pre-trained on the complete data. By integrating KD into training, we demonstrate significant improvement across datasets, pruning methods, and on all pruning fractions. We first establish a theoretical motivation for employing self-distillation to improve training on pruned data. Then, we empirically make a compelling and highly practical observation: using KD, simple random pruning is comparable or superior to sophisticated pruning methods across all pruning regimes. On ImageNet for example, we achieve superior accuracy despite training on a random subset of only 50% of the data. Additionally, we demonstrate a crucial connection between the pruning factor and the optimal knowledge distillation weight. This helps mitigate the impact of samples with noisy labels and low-quality images retained by typical pruning algorithms. Finally, we make an intriguing observation: when using lower pruning fractions, larger teachers lead to accuracy degradation, while surprisingly, employing teachers with a smaller capacity than the student's may improve results. Our code will be made available.", "summary_cn": "本研究将知识蒸馏融入数据剪枝训练，显著提升模型精度，使简单随机剪枝媲美复杂方法，并探索了剪枝比例与蒸馏权重的关键联系。", "keywords": ["数据剪枝", "知识蒸馏", "随机剪枝", "模型训练", "ImageNet", "精度提升"], "triple": {"method": "结合知识蒸馏训练剪枝数据", "result": "随机剪枝精度媲美复杂方法，ImageNet上50%数据达优", "contribution": "提出高效数据剪枝框架，揭示剪枝与蒸馏权重关系"}}
{"venue": "ICML", "search_title": "Efficient Reinforcement Learning with Multiple Reward Functions for ...", "url": "https://icml.cc/Conferences/2010/papers/464.pdf", "year": null, "abstract_snippet": "Results are over 1000 randomly generated datasets using. N = 1290, |A| = 3, T = 3. Min. Med . Max. Bound. Knots in ˆQ2. 687. 790. 910. 3870. Knots in ˆQ1. 2814 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Efficient Reinforcement Learning with Multiple Reward Functions for ...", "abstract": null}
{"venue": "ICML", "search_title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co ...", "url": "https://icml.cc/virtual/2025/poster/46473", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... and Med . are the average and median values over the average docking scores for all 15 LIT-PCBA protein targets. The results for the ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46473", "full_title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co-design", "abstract": "Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features.Here, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while modeling continuous states. Our key insight is that modeling compositional state transitions can be formulated as a straightforward extension of the flow matching interpolation process.We further build upon the theoretical foundations of generative flow networks (GFlowNets), enabling reward-guided sampling of compositional structures. We apply CGFlow to synthesizable drug design by jointly designing the molecule's synthetic pathway with its 3D binding pose.Our approach achieves state-of-the-art binding affinity and synthesizability on all 15 targets from the LIT-PCBA benchmark, and 4.2x improvement in sampling efficiency compared to 2D synthesis-based baseline.To our best knowledge, our method is also the first to achieve state of-art-performance in both Vina Dock (-9.42) and AiZynth success rate (36.1\\%) on the CrossDocked2020 benchmark.", "summary_cn": "提出CGFlow框架，结合流匹配与生成流网络，实现可合成3D分子与合成路径的协同设计，在多个基准测试中取得最优性能。", "keywords": ["CGFlow", "3D分子设计", "合成路径", "流匹配", "生成流网络", "药物设计"], "triple": {"method": "流匹配扩展与生成流网络结合", "result": "在LIT-PCBA和CrossDocked2020基准上实现最优结合亲和力与合成成功率", "contribution": "首次实现可合成3D分子与路径协同设计的高效框架"}}
{"venue": "ICML", "search_title": "Nearly Optimal Sample Complexity for Learning with Label ...", "url": "https://icml.cc/virtual/2025/poster/43817", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Curran Associates, Inc., 2023. Busa-Fekete, R., Choi, H., Dick, T., Gentile, C., and Med - ina, A. M. Easy learning from label proportions.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43817", "full_title": "Nearly Optimal Sample Complexity for Learning with Label Proportions", "abstract": "We investigate Learning from Label Proportions (LLP), a partial information setting where examples in a training set are grouped into bags, and only aggregate label values in each bag are available. Despite the partial observability, the goal is still to achieve small regret at the level of individual examples. We give results on the sample complexity of LLP under square loss, showing that our sample complexity is essentially optimal. From an algorithmic viewpoint, we rely on carefully designed variants of Empirical Risk Minimization, and Stochastic Gradient Descent algorithms, combined with ad hoc variance reduction techniques. On one hand, our theoretical results improve in important ways on the existing literature on LLP, specifically in the way the sample complexity depends on the bag size. On the other hand, we validate our  algorithmic solutions on several datasets, demonstrating improved empirical performance (better accuracy for less samples)  against recent baselines.", "summary_cn": "研究标签比例学习(LLP)的样本复杂度，提出接近最优的样本复杂度，并设计基于经验风险最小化和随机梯度下降的算法，在多个数据集上验证了性能提升。", "keywords": ["标签比例学习", "样本复杂度", "经验风险最小化", "随机梯度下降", "方差减少", "最优性"], "triple": {"method": "经验风险最小化与随机梯度下降结合方差减少", "result": "样本复杂度接近最优，实验性能优于基线", "contribution": "改进LLP样本复杂度理论并提升算法效果"}}
{"venue": "ICML", "search_title": "ICML Poster \"Who experiences large model decay and why?\" A ...", "url": "https://icml.cc/virtual/2025/poster/45315", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Med ., 7(1):334, November 2024. Sugiyama, M., Nakajima, S., Kashima, H., Buenau, P., and Kawanabe, M. Direct importance estimation with model ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45315", "full_title": "\"Who experiences large model decay and why?\" A Hierarchical Framework for Diagnosing Heterogeneous Performance Drift", "abstract": "Machine learning (ML) models frequently experience performance degradation when deployed in new contexts. Such degradation is rarely uniform: some subgroups may suffer large performance decay while others may not. Understanding where and how large differences in performance arise is critical for designing targeted corrective actions that mitigate decay for the most affected subgroups while minimizing any unintended effects. Current approaches do not provide such detailed insight, as they either (i) explain how average performance shifts arise or (ii) identify adversely affected subgroups without insight into how this occurred. To this end, we introduce a S ubgroup-scanning H ierarchical I nference F ramework for performance drif T (SHIFT). SHIFT first asks \"Is there any subgroup with unacceptably large performance decay due to covariate/outcome shifts?\" ( Where? ) and, if so, dives deeper to ask \"Can we explain this using more detailed variable(subset)-specific shifts?\" ( How? ). In real-world experiments, we find that SHIFT identifies interpretable subgroups affected by performance decay, and suggests targeted actions that effectively mitigate the decay.", "summary_cn": "提出SHIFT框架，通过分层推理诊断机器学习模型性能漂移，识别受协变量或结果偏移影响的子组，并提供针对性缓解措施。", "keywords": ["性能漂移", "子组分析", "SHIFT框架", "机器学习部署", "异质性诊断", "模型衰减"], "triple": {"method": "分层推理与子组扫描", "result": "识别受性能衰减影响的子组并解释原因", "contribution": "提供针对性缓解措施框架"}}
{"venue": "ICML", "search_title": "ICML Poster Steer LLM Latents for Hallucination Detection", "url": "https://icml.cc/virtual/2025/poster/45122", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Med - halt: Medical domain hallucination test for large language models. In CoNLL, 2023. Paszke, A., Gross, S., Massa, F., Lerer, A ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/45122", "full_title": "Steer LLM Latents for Hallucination Detection", "abstract": "Hallucinations in LLMs pose a significant concern to their safe deployment in real-world applications. Recent approaches have leveraged the latent space of LLMs for hallucination detection, but their embeddings, optimized for linguistic coherence rather than factual accuracy, often fail to clearly separate truthful and hallucinated content.To this end, we propose the T ruthfulness S eparator V ector ( TSV ), a lightweight and flexible steering vector that reshapes the LLM’s representation space during inference to enhance the separation between truthful and hallucinated outputs, without altering model parameters.Our two-stage framework first trains TSV on a small set of labeled exemplars to form compact and well-separated clusters.It then augments the exemplar set with unlabeled LLM generations, employing an optimal transport-based algorithm for pseudo-labeling combined with a confidence-based filtering process.Extensive experiments demonstrate that TSV achieves state-of-the-art performance with minimal labeled data, exhibiting strong generalization across datasets and providing a practical solution for real-world LLM applications.", "summary_cn": "提出TSV向量，通过重塑LLM表示空间增强真实与幻觉输出的分离，无需修改模型参数，实现高效幻觉检测。", "keywords": ["幻觉检测", "表示空间", "轻量级向量", "最优传输", "伪标签", "泛化能力"], "triple": {"method": "训练TSV向量并优化伪标签", "result": "SOTA性能，最小标注数据，强泛化", "contribution": "提供实用LLM幻觉检测方案"}}
{"venue": "ICML", "search_title": "Eliciting Harmful Jailbreaks from LLMs with Simple Interactions", "url": "https://icml.cc/virtual/2025/poster/44478", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... Med - safetybench: Evaluating and improving the medical safety of large language models. NeurIPS, 2024. Harrosh, S. Identifying harms ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44478", "full_title": "Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions", "abstract": "Large language models (LLMs) are designed to follow safety guidelines that prevent harmful use. However, researchers have found ways to bypass these safeguards and generate dangerous content, a tactic known as \"jailbreaking.\" While previous work has focused on technical methods for carrying out such attacks, we asked two new questions: First, are these harmful responses actually useful in helping someone carry out harmful actions? Second, can such responses be triggered through simple, everyday interactions?We found that the most harmful responses are both actionable (offering clear steps to follow) and informative (providing useful details). Surprisingly, these kinds of responses can be elicited using simple, non-technical methods. To better evaluate this risk, we develop HarmScore, a tool that measures how much a model response enables harmful actions. We also introduce Speak Easy, a simple jailbreak framework that uses natural, multi-step conversations across different languages to bypass safety measures. These findings highlight a critical vulnerability: even without advanced skills, users can exploit common interaction patterns to misuse LLMs. Recognizing this risk is an important step toward building safer and more responsible AI systems.", "summary_cn": "研究发现，通过简单多语言对话即可绕过LLMs安全防护，生成有害且可操作的内容。开发了HarmScore评估工具和Speak Easy越狱框架，揭示AI系统安全漏洞。", "keywords": ["大语言模型", "越狱攻击", "安全漏洞", "多语言对话", "风险评估", "有害内容"], "triple": {"method": "自然多语言对话框架", "result": "简单交互即可触发有害响应", "contribution": "揭示LLMs安全风险并提出评估工具"}}
{"venue": "ICML", "search_title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification", "url": "https://icml.cc/virtual/2025/poster/46130", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Med - former: A multi-granularity patching transformer for medical time-series classification. In The Thirty-eighth Annual Conference on ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46130", "full_title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification", "abstract": "Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.", "summary_cn": "提出SoftShape模型，通过软形状稀疏化和学习模块，高效保留所有子序列信息并学习时序模式，提升时间序列分类性能与可解释性。", "keywords": ["时间序列分类", "形状稀疏化", "软表示", "模式学习", "可解释性", "高效分类"], "triple": {"method": "软形状稀疏化与学习模块", "result": "优于现有方法，生成可解释结果", "contribution": "提升分类效率与性能"}}
{"venue": "ICML", "search_title": "Proceedings of the Workshop on Prior Knowledge for Text and ...", "url": "https://icml.cc/Conferences/2008/workshops/Prior_knowledge_for_Text_and_Language_Processing_Workshop_2008_Proceedings.pdf", "year": null, "abstract_snippet": "Jul 9, 2008 ... J Am Med Inform Assoc, 15(2),. 150–157. Tjong Kim Sang, E. F., & De Meulder, F. (2003). In- troduction to the conll-2003 shared task ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Proceedings of the Workshop on Prior Knowledge for Text and ...", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Position: Trustworthy AI Agents Require the Integration ...", "url": "https://icml.cc/virtual/2025/poster/40101", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... J Med Internet Res, 26, Apr 2024. Claude, T. The claude 3 model family: Opus, sonnet, haiku. 2024. URL https://api.semanticscholar. org ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/40101", "full_title": "Position: Trustworthy AI Agents Require the Integration of Large Language Models and Formal Methods", "abstract": "Large Language Models (LLMs) have emerged as a transformative AI paradigm, profoundly influencing broad aspects of daily life. Despite their remarkable performance, LLMs exhibit a fundamental limitation: hallucination—the tendency to produce misleading outputs that appear plausible. This inherent unreliability poses significant risks, particularly in high-stakes domains where trustworthiness is essential.On the other hand, Formal Methods (FMs), which share foundations with symbolic AI, provide mathematically rigorous techniques for modeling, specifying, reasoning, and verifying the correctness of systems. These methods have been widely employed in mission-critical domains such as aerospace, defense, and cybersecurity. However, the broader adoption of FMs remains constrained by significant challenges, including steep learning curves, limited scalability, and difficulties in adapting to the dynamic requirements of daily applications.To build trustworthy AI agents, we argue that the integration of LLMs and FMs is necessary to overcome the limitations of both paradigms. LLMs offer adaptability and human-like reasoning but lack formal guarantees of correctness and reliability. FMs provide rigor but need enhanced accessibility and automation to support broader adoption from LLMs.", "summary_cn": "本文主张结合大语言模型与形式化方法，以构建可信AI代理。前者灵活但易产生幻觉，后者严谨但应用受限，整合可互补优势。", "keywords": ["大语言模型", "形式化方法", "可信AI", "幻觉", "系统验证", "AI集成"], "triple": {"method": "整合LLMs与FMs", "result": "互补灵活性与严谨性", "contribution": "提出可信AI代理构建路径"}}
{"venue": "ICML", "search_title": "Context-Aware Visual Explanations for Document Question Answering", "url": "https://icml.cc/virtual/2025/poster/43613", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Llava- med : Training a large language-and-vision assistant for biomedicine in one day. Advances in Neural Information Processing Systems, 36 ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/43613", "full_title": "DocVXQA: Context-Aware Visual Explanations for Document Question Answering", "abstract": "We propose DocVXQA , a novel framework for visually self-explainable document question answering, where the goal is not only to produce accurate answers to questions but also to learn visual heatmaps that highlight critical regions, offering interpretable justifications for the model decision. To integrate explanations into the learning process, we quantitatively formulate explainability principles as explicit learning criteria.Unlike conventional relevance map methods that solely emphasize regions relevant to the answer, our context-aware DocVXQA delivers explanations that are contextually sufficient yet representation-efficient. This fosters user trust while achieving a balance between predictive performance and interpretability in document visual question answering applications. Extensive experiments, including human evaluation, provide strong evidence supporting the effectiveness of our method.", "summary_cn": "DocVXQA框架通过上下文感知视觉热图，在文档问答中实现自解释，平衡预测性能与可解释性。", "keywords": ["文档问答", "视觉解释", "上下文感知", "可解释性", "热图", "自解释模型"], "triple": {"method": "上下文感知视觉热图学习", "result": "提升预测性能与解释质量", "contribution": "提出自解释文档问答框架"}}
{"venue": "ICML", "search_title": "Private Outsourced Bayesian Optimization - ICML Proceedings", "url": "https://proceedings.icml.cc/static/paper_files/icml/2020/6298-Paper.pdf", "year": null, "abstract_snippet": "(a) A hospital is trying to find out which patients are likely to be readmitted soon based on the result of an expensive med - ical test (Yu et al., 2013) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Private Outsourced Bayesian Optimization - ICML Proceedings", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Doubly Robust Conformalized Survival Analysis with ...", "url": "https://icml.cc/virtual/2025/poster/46585", "year": 2025, "abstract_snippet": "Jul 15, 2025 ... BMC Med . Res. Methodol., 18: 1–12, 2018. Lei, J. and Wasserman, L. Distribution-free prediction bands for non-parametric regression. J. R. ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/46585", "full_title": "Doubly Robust Conformalized Survival Analysis with Right-Censored Data", "abstract": "We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, and then analyzes the imputed data using a survival model calibrated via weighted conformal inference. This approach is theoretically supported by an asymptotic double robustness property. Empirical studies on simulated and real data demonstrate that our method leads to relatively informative predictive inferences and is especially robust in challenging settings where the survival model may be inaccurate.", "summary_cn": "提出一种双重鲁棒的保形推理方法，用于右删失生存数据的预测区间构建，通过机器学习模型插补未观测的删失时间，并利用加权保形推理校准生存模型，在生存模型不准确时仍保持稳健性。", "keywords": ["保形推理", "生存分析", "右删失数据", "双重鲁棒性", "机器学习", "预测区间"], "triple": {"method": "机器学习插补与加权保形推理", "result": "构建信息丰富的预测区间，在模型不准确时保持稳健", "contribution": "扩展保形推理至右删失数据，提供理论双重鲁棒保证"}}
{"venue": "ICML", "search_title": "ICML Poster Parrot: Multilingual Visual Instruction Tuning", "url": "https://icml.cc/virtual/2025/poster/44886", "year": 2025, "abstract_snippet": "Jul 16, 2025 ... Llava- med : Training a large language-and-vision assistant for biomedicine in one day. arXiv:2306.00890, 2023a. Li, J., Li, D., Savarese, S ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44886", "full_title": "Parrot: Multilingual Visual Instruction Tuning", "abstract": "The rapid development of Multimodal Large Language Models (MLLMs), such as GPT-4, marks a significant step toward artificial general intelligence. Existing methods typically align vision encoders with LLMs via supervised fine-tuning (SFT), but this often deteriorates their ability to handle multiple languages as training progresses. We empirically observe that imbalanced SFT datasets, largely English-centric, degrade performance on non-English languages due to the failure in multilingual token alignment. To address this, we propose Parrot, a novel approach that leverages textual guidance for visual token alignment at the language level. Parrot conditions visual tokens on diverse language inputs and uses Mixture-of-Experts (MoE) to align multilingual tokens. By computing cross-attention between initial visual features and textual embeddings, we select the most relevant experts, converting visual tokens into language-specific representations. Additionally, we introduce the Massive Multilingual Multimodal Benchmark (MMMB), a new benchmark comprising 6 languages, 15 categories, and 12,000 questions, to assess multilingual capabilities. Parrot achieves state-of-the-art performance on both the multilingual benchmarks and a wide range of multimodal tasks. Code and dataset are available at: \\url{https://github.com/AIDC-AI/Parrot}.", "summary_cn": "Parrot提出一种基于文本引导的多语言视觉指令调优方法，通过MoE对齐多语言标记，提升多语言多模态任务性能，并引入新基准MMMB进行评估。", "keywords": ["多语言视觉指令调优", "混合专家", "多模态大语言模型", "标记对齐", "多语言基准", "跨模态学习"], "triple": {"method": "使用文本引导和MoE对齐多语言视觉标记", "result": "在多语言基准和多模态任务中达到最先进性能", "contribution": "提出Parrot方法和MMMB基准，解决多语言性能退化问题"}}
{"venue": "ICML", "search_title": "ICML Poster scSSL-Bench: Benchmarking Self-Supervised Learning ...", "url": "https://icml.cc/virtual/2025/poster/44286", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Computational data analysis was performed at Leonhard Med secure trusted research environment at ETH Zurich and at the BIFOLD Hydra cluster.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44286", "full_title": "scSSL-Bench: Benchmarking Self-Supervised Learning for Single-Cell Data", "abstract": "Self-supervised learning (SSL) has proven to be a powerful approach for extracting biologically meaningful representations from single-cell data. To advance our understanding of SSL methods applied to single-cell data, we present scSSL-Bench, a comprehensive benchmark that evaluates nineteen SSL methods. Our evaluation spans nine datasets and focuses on three common downstream tasks: batch correction, cell type annotation, and missing modality prediction. Furthermore, we systematically assess various data augmentation strategies. Our analysis reveals task-specific trade-offs: the specialized single-cell frameworks, scVI, CLAIRE, and the finetuned scGPT excel at uni-modal batch correction, while generic SSL methods, such as VICReg and SimCLR, demonstrate superior performance in cell typing and multi-modal data integration. Random masking emerges as the most effective augmentation technique across all tasks, surpassing domain-specific augmentations. Notably, our results indicate the need for a specialized single-cell multi-modal data integration framework. scSSL-Bench provides a standardized evaluation platform and concrete recommendations for applying SSL to single-cell analysis, advancing the convergence of deep learning and single-cell genomics.", "summary_cn": "scSSL-Bench基准测试评估19种自监督学习方法在单细胞数据上的表现，涵盖批量校正、细胞类型注释和多模态预测任务，发现任务特异性权衡，并推荐随机掩码作为最佳数据增强策略。", "keywords": ["自监督学习", "单细胞数据", "基准测试", "数据增强", "多模态整合", "深度学习"], "triple": {"method": "构建scSSL-Bench基准，评估19种SSL方法", "result": "揭示任务特异性权衡，随机掩码增强效果最佳", "contribution": "提供标准化平台，推动深度学习与单细胞基因组学融合"}}
{"venue": "ICML", "search_title": "ICML Poster Test-Time Learning for Large Language Models", "url": "https://icml.cc/virtual/2025/poster/44367", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... Geo., Agri., Med ., and Fin. represent the Geography, Agriculture, Medicine, and Finance, respectively. LLM refers to Llama3-8B-Instruct. NF4 ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44367", "full_title": "Test-Time Learning for Large Language Models", "abstract": "While Large Language Models (LLMs) have exhibited remarkable emergent capabilities through extensive pre-training,  they still face critical limitations in generalizing to specialized domains and handling diverse linguistic variations, known as distribution shifts. In this paper, we propose a Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically adapts LLMs to target domains using only unlabeled test data during testing. Specifically, we first provide empirical evidence and theoretical insights to reveal that more accurate predictions from LLMs can be achieved by minimizing the input perplexity of the unlabeled test data. Based on this insight, we formulate the Test-Time Learning process of LLMs as input perplexity minimization, enabling self-supervised enhancement of LLM performance. Furthermore, we observe that high-perplexity samples tend to be more informative for model optimization. Accordingly, we introduce a Sample Efficient Learning Strategy that actively selects and emphasizes these high-perplexity samples for test-time updates. Lastly, to mitigate catastrophic forgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA) instead of full-parameter optimization, which allows lightweight model updates while preserving more original knowledge from the model. We introduce the AdaptEval benchmark for TTL and demonstrate through experiments that TLM improves performance by at least 20% compared to original LLMs on domain knowledge adaptation.", "summary_cn": "提出TLM方法，通过测试时学习动态适应大语言模型，利用未标注测试数据最小化困惑度，提升领域适应性能至少20%。", "keywords": ["测试时学习", "大语言模型", "领域适应", "困惑度最小化", "低秩适应", "样本选择"], "triple": {"method": "测试时学习与低秩适应", "result": "性能提升至少20%", "contribution": "实现轻量级领域适应"}}
{"venue": "ICML", "search_title": "Track: Poster Session 3 - ICML 2026", "url": "https://icml.cc/virtual/2024/session/35593", "year": 2024, "abstract_snippet": "Extensive experiments on SLAKE datasets show Uni- Med's superior accuracies (87.52% closed, 86.12% overall), outperforming MedVInT-PMC-VQA by 1.22% and 0.92%.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Track: Poster Session 3 - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "Continuously Updating Digital Twins using Large Language Models", "url": "https://icml.cc/virtual/2025/poster/44291", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... science/article/pii/S0169023X24000284. Kuang, K., Dean, F., Jedlicki, J. B., Ouyang, D., Philip- pakis, A., Sontag, D., and Alaa, A. Med ...", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2025/poster/44291", "full_title": "Continuously Updating Digital Twins using Large Language Models", "abstract": "Digital twins are models of real-world systems that can simulate their dynamics in response to potential actions. In complex settings, the state and action variables, and available data and knowledge relevant to a system can constantly change, requiring digital twins to continuously update with these changes to remain relevant. Current approaches struggle in this regard, as they require fixed, well-defined modelling environments, and they cannot adapt to novel variables without re-designs, or incorporate new information without re-training. To address this, we frame digital twinning as an in-context learning problem using large language models, enabling seamless updates to the twin at inference time. We develop CALM-DT, a Context-Adaptive Language Model-based Digital Twin that can accurately simulate across diverse state-action spaces using in-context learning alone by utilising fine-tuned encoders for sample retrieval. We empirically demonstrate CALM-DT's competitive performance with existing digital twin approaches, and its unique ability to adapt to changes in its modelling environment without parameter updates.", "summary_cn": "提出CALM-DT，一种基于大语言模型的数字孪生方法，通过上下文学习实现动态更新，无需参数调整即可适应环境变化。", "keywords": ["数字孪生", "大语言模型", "上下文学习", "自适应更新", "CALM-DT"], "triple": {"method": "基于大语言模型的上下文学习与微调编码器检索", "result": "在多样化状态-动作空间中准确模拟，无需参数更新即可适应环境变化", "contribution": "实现数字孪生的动态自适应更新，克服传统方法固定建模环境的限制"}}
{"venue": "ICML", "search_title": "Track: Poster Session 5 - ICML 2026", "url": "https://icml.cc/virtual/2024/session/35595", "year": 2024, "abstract_snippet": "In this paper, we introduce the Med -ST framework for fine-grained spatial and temporal modeling to exploit information from multiple spatial views of chest ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Track: Poster Session 5 - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "ICML 2024 Schedule", "url": "https://icml.cc/virtual/2024/calendar", "year": 2024, "abstract_snippet": "... Med -VQA · A Nearly Optimal Single Loop Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness · SqueezeLLM: Dense-and-Sparse Quantization.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2024 Schedule", "abstract": null}
{"venue": "ICML", "search_title": "TECHNICAL GUIDELINES - ESCRS 2023", "url": "https://media.icml.cc/Conferences/ICML2024/MWECC_Technical_Regulations_2022_EN.pdf", "year": null, "abstract_snippet": "sonnel through RMW to be based in the designated med - ical service rooms and who can guarantee correct first aid care. If the organiser organises the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "TECHNICAL GUIDELINES - ESCRS 2023", "abstract": null}
{"venue": "ICML", "search_title": "Freeman-exhibition-booth-kit", "url": "https://icml.cc/2016/wp-content/uploads/Freeman-exhibition-booth-kit.pdf", "year": null, "abstract_snippet": "Jun 13, 2016 ... Black Display Cylinder/ Med . 272.10. 299.30. 380.95. N75022. Black Display Cylinder/Lg.... 272.10. 299.30. 380.95. Display Cylinders. FREEMAN.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Freeman-exhibition-booth-kit", "abstract": null}
{"venue": "ICML", "search_title": "Application of Machine Learning To Epileptic Seizure Detection", "url": "https://icml.cc/Conferences/2010/papers/493.pdf", "year": null, "abstract_snippet": "Abstract. We present and evaluate a machine learn- ing approach to constructing patient-specific classifiers that detect the onset of an epileptic.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Application of Machine Learning To Epileptic Seizure Detection", "abstract": null}
{"venue": "ICML", "search_title": "ICML 2008", "url": "https://icml.cc/Conferences/2008/papers/icml2008proceedings.pdf", "year": null, "abstract_snippet": "... med - ication history, a medical practitioner needs to decide which combination of drugs to administer. The large number of genetic mutations and the wide ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2008", "abstract": null}
{"venue": "ICML", "search_title": "ICML 2024 Wednesday 07/24", "url": "https://icml.cc/virtual/2024/day/7/24", "year": 2024, "abstract_snippet": "... Med -VQA. Zhongze Wu · Hongyan Xu · Yitian Long · Shan You · Xiu Su · Jun Long · Yueyi Luo · Chang Xu. A Nearly Optimal Single Loop Algorithm for Stochastic ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ICML 2024 Wednesday 07/24", "abstract": null}
{"venue": "ICML", "search_title": "2025 Spotlight Posters - ICML 2026", "url": "https://icml.cc/virtual/2025/events/2025SpotlightPosters", "year": 2025, "abstract_snippet": "We present HealthGPT, a powerful Medical Large Vision-Language Model ( Med -LVLM) that integrates medical visual comprehension and generation capabilities within ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "2025 Spotlight Posters - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "Track: Poster Session 6 West - ICML 2026", "url": "https://icml.cc/virtual/2025/session/50262", "year": 2025, "abstract_snippet": "Jul 17, 2025 ... We present HealthGPT, a powerful Medical Large Vision-Language Model ( Med -LVLM) that integrates medical visual comprehension and generation ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Track: Poster Session 6 West - ICML 2026", "abstract": null}
{"venue": "ICML", "search_title": "CVPR 2023 (Inside Front Cover) Main Conference", "url": "https://media.icml.cc/Conferences/CVPR2023/CVPR_2023_MainConference_ProgramGuide.pdf", "year": null, "abstract_snippet": "MED -VT: Multiscale Encoder-Decoder Video Transformer With. Application to Object Segmentation, Rezaul Karim, He Zhao,. Richard P. Wildes, Mennatullah Siam. 211 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "CVPR 2023 (Inside Front Cover) Main Conference", "abstract": null}
{"venue": "ICML", "search_title": "Classification using Discriminative Restricted Boltzmann Machines", "url": "https://icml.cc/Conferences/2008/papers/601.pdf", "year": null, "abstract_snippet": "Abstract. Recently, many applications for Restricted. Boltzmann Machines (RBMs) have been de- veloped for a large variety of learning prob-.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Classification using Discriminative Restricted Boltzmann Machines", "abstract": null}
{"venue": "ICML", "search_title": "ICML Poster Re-Dock: Towards Flexible and Realistic Molecular ...", "url": "https://icml.cc/virtual/2024/poster/34081", "year": 2024, "abstract_snippet": "Accurate prediction of protein-ligand binding structures, a task known as molecular docking is crucial for drug design but remains challenging.", "is_main_conference": true, "abstract_source_venue": "ICML", "abstract_source_url": "https://icml.cc/virtual/2024/poster/34081", "full_title": "Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge", "abstract": "Accurate prediction of protein-ligand binding structures, a task known as molecular docking is crucial for drug design but remains challenging. While deep learning has shown promise, existing methods often depend on holo-protein structures (docked, and not accessible in realistic tasks) or neglect pocket sidechain conformations, leading to limited practical utility and unrealistic conformation predictions. To fill these gaps, we introduce an under-explored task, named flexible docking to predict poses of ligand and pocket sidechains simultaneously and introduce Re-Dock, a novel diffusion bridge generative model extended to geometric manifolds. Specifically, we propose energy-to-geometry mapping inspired by the Newton-Euler equation to co-model the binding energy and conformations for reflecting the energy-constrained docking generative process. Comprehensive experiments on designed benchmark datasets including apo-dock and cross-dock demonstrate our model's superior effectiveness and efficiency over current methods.", "summary_cn": "提出Re-Dock扩散桥模型，通过能量-几何映射同时预测配体和口袋侧链构象，在柔性对接任务中实现更真实高效的结合结构预测。", "keywords": ["分子对接", "扩散模型", "柔性对接", "能量几何映射", "药物设计", "构象预测"], "triple": {"method": "扩散桥生成模型与能量-几何映射", "result": "在apo-dock和cross-dock基准上超越现有方法", "contribution": "提出柔性对接任务并提升预测实用性与真实性"}}
{"venue": "ICML", "search_title": "2007 International Conference on Machine Learning", "url": "https://icml.cc/Conferences/2007/", "year": null, "abstract_snippet": "June 20-24: ICML Conference Dates ; June 20: ICML Tutorials ; June 19-21: ILP Conference ; June 21-23: ICML Technical Sessions ; June 24: ICML Workshops ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "2007 International Conference on Machine Learning", "abstract": null}
{"venue": "NeurIPS", "search_title": "Enhancing vision-language models formedicalimaging - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/b53513b83232116ae25f57a174a7c993-Abstract-Datasets_and_Benchmarks_Track.html", "year": 2024, "abstract_snippet": "Our studies represent a significant step toward integrating AI in medical imaging to enhance patient care and facilitate medical research. We hope this work ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/b53513b83232116ae25f57a174a7c993-Abstract-Datasets_and_Benchmarks_Track.html", "full_title": "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", "abstract": "Recent approaches to vision-language tasks are built on the remarkable capabilities of large vision-language models (VLMs). These models excel in zero-shot and few-shot learning, enabling them to learn new tasks without parameter updates. However, their primary challenge lies in their design, which primarily accommodates 2D input, thus limiting their effectiveness for medical images, particularly radiological images like MRI and CT, which are typically 3D. To bridge the gap between state-of-the-art 2D VLMs and 3D medical image data, we developed an innovative, one-pass, unsupervised representative slice selection method called Vote-MI, which selects representative 2D slices from 3D medical imaging. To evaluate the effectiveness of vote-MI when implemented with VLMs, we introduce BrainMD, a robust, multimodal dataset comprising 2,453 annotated 3D MRI brain scans with corresponding textual radiology reports and electronic health records. Based on BrainMD, we further develop two benchmarks, BrainMD-select (including the most representative 2D slice of 3D image) and BrainBench (including various vision-language downstream tasks). Extensive experiments on the BrainMD dataset and its two corresponding benchmarks demonstrate that our representative selection method significantly improves performance in zero-shot and few-shot learning tasks. On average, Vote-MI achieves a 14.6\\% and 16.6\\% absolute gain for zero-shot and few-shot learning, respectively, compared to randomly selecting examples. Our studies represent a significant step toward integrating AI in medical imaging to enhance patient care and facilitate medical research. We hope this work will serve as a foundation for data selection as vision-language models are increasingly applied to new tasks.", "summary_cn": "提出Vote-MI方法，从3D医学影像中无监督选择代表性2D切片，结合BrainMD数据集，显著提升视觉语言模型在零样本和少样本学习中的性能。", "keywords": ["视觉语言模型", "3D医学影像", "切片选择", "零样本学习", "BrainMD数据集", "无监督学习"], "triple": {"method": "Vote-MI无监督切片选择", "result": "零样本和少样本学习性能分别提升14.6%和16.6%", "contribution": "弥合2D视觉语言模型与3D医学影像间的差距"}}
{"venue": "NeurIPS", "search_title": "Breaking the Dilemma ofMedicalImage-to-image Translation", "url": "https://proceedings.neurips.cc/paper/2021/hash/0f2818101a7ac4b96ceeba38de4b934c-Abstract.html", "year": null, "abstract_snippet": "The goal is to search for the common optimal solution to both image-to-image translation and registration tasks. We incorporated RegGAN into a few state-of-the- ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Breaking the Dilemma ofMedicalImage-to-image Translation", "abstract": null}
{"venue": "NeurIPS", "search_title": "Transfusion: Understanding Transfer Learning forMedicalImaging", "url": "https://proceedings.neurips.cc/paper/8596-transfusion-understanding-transfer-learning-for-medical-imaging", "year": null, "abstract_snippet": "We isolate where useful feature reuse occurs, and outline the implications for more efficient model exploration. We also explore feature independent benefits of ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Transfusion: Understanding Transfer Learning forMedicalImaging", "abstract": null}
{"venue": "NeurIPS", "search_title": "MDAgents: An Adaptive Collaboration of LLMs forMedicalDecision ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/90d1fc07f46e31387978b88e7e057a31-Abstract-Conference.html", "year": 2024, "abstract_snippet": "We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and clinical diagnosis benchmarks, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/90d1fc07f46e31387978b88e7e057a31-Abstract-Conference.html", "full_title": "MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making", "abstract": "Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named **M**edical **D**ecision-making **Agents** (**MDAgents**) that helps to address this gap by automatically assigning a collaboration structure to a team of LLMs. The assigned solo or group collaboration structure is tailored to the medical task at hand, a simple emulation inspired by the way real-world medical decision-making processes are adapted to tasks of different complexities. We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and clinical diagnosis benchmarks, including a comparison ofLLMs’ medical complexity classification against human physicians. MDAgents achieved the **best performance in seven out of ten** benchmarks on tasks requiring an understanding of medical knowledge and multi-modal reasoning, showing a significant **improvement of up to 4.2\\%** ($p$ < 0.05) compared to previous methods' best performances. Ablation studies reveal that MDAgents effectively determines medical complexity to optimize for efficiency and accuracy across diverse medical tasks. Notably, the combination of moderator review and external medical knowledge in group collaboration resulted in an average accuracy **improvement of 11.8\\%**. Our code can be found at https://github.com/mitmedialab/MDAgents.", "summary_cn": "MDAgents提出多智能体框架，根据医疗任务复杂度自动分配LLM协作结构，在多项医学基准测试中表现最佳，准确率提升最高达4.2%。", "keywords": ["多智能体框架", "医疗决策", "大语言模型", "自适应协作", "医学基准测试", "准确率提升"], "triple": {"method": "自适应多智能体协作框架", "result": "十项基准中七项最佳，准确率提升最高4.2%", "contribution": "优化医疗任务中LLM协作效率与准确性"}}
{"venue": "NeurIPS", "search_title": "MedicalImaging meets NeurIPS", "url": "https://neurips.cc/virtual/2023/workshop/66536", "year": 2023, "abstract_snippet": "“ Medical Imaging meets NeurIPS” aims to bring researchers together from the medical imaging and machine learning communities to create a cutting-edge venue for ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MedicalImaging meets NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "AIM-FM: Advancements InMedicalFoundation Models - NeurIPS", "url": "https://neurips.cc/virtual/2024/workshop/84711", "year": 2024, "abstract_snippet": "Towards next-generation medical analysis: Unlock the potential of medical foundation models for more explainable, robust, secure diagnosis solutions.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "AIM-FM: Advancements InMedicalFoundation Models - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Universal and Interactive VolumetricMedicalImage Segmentation", "url": "https://neurips.cc/virtual/2024/poster/96893", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... Precise image segmentation provides clinical study with instructive information. Despite the remarkable progress achieved in medical image ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/96893", "full_title": "SegVol: Universal and Interactive Volumetric Medical Image Segmentation", "abstract": "Precise image segmentation provides clinical study with instructive information. Despite the remarkable progress achieved in medical image segmentation, there is still an absence of a 3D foundation segmentation model that can segment a wide range of anatomical categories with easy user interaction. In this paper, we propose a 3D foundation segmentation model, named SegVol, supporting universal and interactive volumetric medical image segmentation. By scaling up training data to 90K unlabeled Computed Tomography (CT) volumes and 6K labeled CT volumes, this foundation model supports the segmentation of over 200 anatomical categories using semantic and spatial prompts. To facilitate efficient and precise inference on volumetric images, we design a zoom-out-zoom-in mechanism. Extensive experiments on 22 anatomical segmentation tasks verify that SegVol outperforms the competitors in 19 tasks, with improvements up to 37.24\\% compared to the runner-up methods. We demonstrate the effectiveness and importance of specific designs by ablation study. We expect this foundation model can promote the development of volumetric medical image analysis. The model and code are publicly available at https://github.com/BAAI-DCAI/SegVol.", "summary_cn": "SegVol是一种通用交互式3D医学图像分割基础模型，通过大规模CT数据训练和缩放机制，支持200多个解剖类别分割，在22项任务中19项领先。", "keywords": ["3D医学图像分割", "基础模型", "交互式分割", "CT图像", "解剖类别", "缩放机制"], "triple": {"method": "大规模CT数据训练与缩放机制", "result": "22项任务中19项领先，最高提升37.24%", "contribution": "提出通用交互式3D分割基础模型"}}
{"venue": "NeurIPS", "search_title": "Uni-Med: A UnifiedMedicalGeneralist Foundation Model For Multi ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/941938d6c3c57b4ef4a518965e238a6d-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "However, building a unified MLLM for multi-task learning in the medical field remains a thorny challenge. To mitigate the tug-of-war problem of multi-modal ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Uni-Med: A UnifiedMedicalGeneralist Foundation Model For Multi ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Domain Generalization forMedicalImaging Classification ... - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2020/hash/201d7288b4c18a679e48b31c72c30ded-Abstract.html", "year": 2020, "abstract_snippet": "Recently, we have witnessed great progress in the field of medical imaging classification by adopting deep neural networks. However, the recent advanced models ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Domain Generalization forMedicalImaging Classification ... - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Multi-Granularity Cross-modal Alignment for GeneralizedMedical...", "url": "https://papers.neurips.cc/paper_files/paper/2022/file/d925bda407ada0df3190df323a212661-Paper-Conference.pdf", "year": null, "abstract_snippet": "Learning medical visual representations directly from paired radiology reports has become an emerging topic in representation learning.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Multi-Granularity Cross-modal Alignment for GeneralizedMedical...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Rethinking Semi-SupervisedMedicalImage Segmentation - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1f7e6d5c84b0ed286d0e69b7d2c79b47-Paper-Conference.pdf", "year": 2023, "abstract_snippet": "For medical image segmentation, contrastive learning is the dominant practice to improve the quality of visual representations by contrasting semantically ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Rethinking Semi-SupervisedMedicalImage Segmentation - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "An Iterative Self-Learning Framework forMedicalDomain ... - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac0035c349f3fe8af6a93fe44697b5bd-Abstract-Conference.html", "year": 2023, "abstract_snippet": "We propose SLGD, a self-learning framework that iteratively discovers decoupled domains and trains personalized classifiers for each decoupled domain.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "An Iterative Self-Learning Framework forMedicalDomain ... - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Knowledge-Empowered Dynamic Graph Network for Irregularly ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/7c04aea54c2a60a632a47bd451cd2849-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Irregularly Sampled Medical Time Series (ISMTS) are commonly found in the healthcare domain, where different variables exhibit unique temporal patterns while ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/7c04aea54c2a60a632a47bd451cd2849-Abstract-Conference.html", "full_title": "Knowledge-Empowered Dynamic Graph Network for Irregularly Sampled Medical Time Series", "abstract": "Irregularly Sampled Medical Time Series (ISMTS) are commonly found in the healthcare domain, where different variables exhibit unique temporal patterns while interrelated. However, many existing methods fail to efficiently consider the differences and correlations among medical variables together, leading to inadequate capture of fine-grained features at the variable level in ISMTS. We propose Knowledge-Empowered Dynamic Graph Network (KEDGN), a graph neural network empowered by variables' textual medical knowledge, aiming to model variable-specific temporal dependencies and inter-variable dependencies in ISMTS. Specifically, we leverage a pre-trained language model to extract semantic representations for each variable from their textual descriptions of medical properties, forming an overall semantic view among variables from a medical perspective. Based on this, we allocate variable-specific parameter spaces to capture variable-specific temporal patterns and generate a complete variable graph to measure medical correlations among variables. Additionally, we employ a density-aware mechanism to dynamically adjust the variable graph at different timestamps, adapting to the time-varying correlations among variables in ISMTS. The variable-specific parameter spaces and dynamic graphs are injected into the graph convolutional recurrent network to capture intra-variable and inter-variable dependencies in ISMTS together. Experiment results on four healthcare datasets demonstrate that KEDGN significantly outperforms existing methods.", "summary_cn": "提出KEDGN模型，利用医学知识构建动态图网络，有效捕捉不规则采样医疗时间序列中变量间及变量内的依赖关系，在四个数据集上表现优异。", "keywords": ["不规则采样医疗时间序列", "图神经网络", "医学知识", "动态图", "变量依赖", "语义表示"], "triple": {"method": "基于预训练语言模型提取变量语义，构建动态图网络", "result": "在四个医疗数据集上显著优于现有方法", "contribution": "结合医学知识建模变量特定与变量间依赖，提升不规则序列分析性能"}}
{"venue": "NeurIPS", "search_title": "3D Self-Supervised Methods forMedicalImaging - NeurIPS", "url": "https://proceedings.neurips.cc/paper/2020/hash/d2dc6368837861b42020ee72b0896182-Abstract.html", "year": null, "abstract_snippet": "Self-supervised learning methods have witnessed a recent surge of interest after proving successful in multiple application fields. In this work, we leverage ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "3D Self-Supervised Methods forMedicalImaging - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Diagnosing failures of fairness transfer across distribution shift in ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/7a969c30dc7e74d4e891c8ffb217cf79-Abstract-Conference.html", "year": 2022, "abstract_snippet": "Diagnosing failures of fairness transfer across distribution shift in real-world medical settings. Jessica Schrouff, Natalie Harris, Sanmi Koyejo, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Diagnosing failures of fairness transfer across distribution shift in ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Fairness Benchmarking forMedicalImaging Foundation Models", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/c9826b9ea5e1b49b256329934a578d83-Paper-Datasets_and_Benchmarks_Track.pdf", "year": 2024, "abstract_snippet": "Foundation Model (FM) facilitated medical image analysis is playing a pivotal role in healthcare [2,. 3]. These models, which leverage large-scale pretraining ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Fairness Benchmarking forMedicalImaging Foundation Models", "abstract": null}
{"venue": "NeurIPS", "search_title": "Learning to Zoom with Anatomical Relations forMedicalStructure ...", "url": "https://neurips.cc/virtual/2025/poster/118432", "year": 2025, "abstract_snippet": "Dec 5, 2025 ... ZR-DETR uniquely incorporates scale-sensitive zoom embeddings, anatomical relation constraints, and a Gaussian Process-based detection head.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/118432", "full_title": "Learning to Zoom with Anatomical Relations for Medical Structure Detection", "abstract": "Accurate anatomical structure detection is a critical preliminary step for diagnosing diseases characterized by structural abnormalities. In clinical practice, medical experts frequently adjust the zoom level of medical images to obtain comprehensive views for diagnosis. This common interaction results in significant variations in the apparent scale of anatomical structures across different images or fields of view. However, the information embedded in these zoom-induced scale changes is often overlooked by existing detection algorithms.  In addition, human organs possess a priori, fixed topological knowledge. To overcome this limitation, we propose ZR-DETR, a zoom-aware probabilistic framework tailored for medical object detection. ZR-DETR uniquely incorporates scale-sensitive zoom embeddings, anatomical relation constraints, and a Gaussian Process-based detection head. This architecture enables the framework to jointly model semantic context, enforce anatomical plausibility, and quantify detection uncertainty. Empirical validation across three diverse medical imaging benchmarks demonstrates that ZR-DETR consistently outperforms strong baselines in both single-domain and unsupervised domain adaptation scenarios.", "summary_cn": "提出ZR-DETR框架，结合缩放感知与解剖关系约束，提升医学结构检测精度，在多个基准测试中表现优异。", "keywords": ["医学目标检测", "缩放感知", "解剖关系", "ZR-DETR", "不确定性量化", "域适应"], "triple": {"method": "引入缩放嵌入与解剖约束的ZR-DETR框架", "result": "在单域与无监督域适应场景中超越基线", "contribution": "提升医学结构检测的准确性与鲁棒性"}}
{"venue": "NeurIPS", "search_title": "Hybrid Retrieval-Generation Reinforced Agent forMedicalImage ...", "url": "http://papers.neurips.cc/paper/7426-hybrid-retrieval-generation-reinforced-agent-for-medical-image-report-generation.pdf", "year": null, "abstract_snippet": "Generating long and coherent reports to describe medical images poses challenges to bridging visual patterns with informative human linguistic descriptions.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Hybrid Retrieval-Generation Reinforced Agent forMedicalImage ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "MedSafetyBench: Evaluating and Improving theMedicalSafety of ...", "url": "https://neurips.cc/virtual/2024/poster/97606", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... The results indicate that medical LLMs readily comply with harmful general and medical requests, and they do so more frequently than their ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/97606", "full_title": "MedSafetyBench: Evaluating and Improving the Medical Safety of Large Language Models", "abstract": "As large language models (LLMs) develop increasingly sophisticated capabilities and find applications in medical settings, it becomes important to assess their medical safety due to their far-reaching implications for personal and public health, patient safety, and human rights. However, there is little to no understanding of the notion of medical safety in the context of LLMs, let alone how to evaluate and improve it. To address this gap, we first define the notion of medical safety in LLMs based on the Principles of Medical Ethics set forth by the American Medical Association. We then leverage this understanding to introduce MedSafetyBench, the first benchmark dataset designed to measure the medical safety of LLMs. We demonstrate the utility of MedSafetyBench by using it to evaluate and improve the medical safety of LLMs. Our results show that publicly-available medical LLMs do not meet standards of medical safety and that fine-tuning them using MedSafetyBench improves their medical safety while preserving their medical performance. By introducing this new benchmark dataset, our work enables a systematic study of the state of medical safety in LLMs and motivates future work in this area, paving the way to mitigate the safety risks of LLMs in medicine. The benchmark dataset and code are available at https://github.com/AI4LIFE-GROUP/med-safety-bench.", "summary_cn": "本文提出首个评估大语言模型医疗安全性的基准数据集MedSafetyBench，基于医学伦理原则定义医疗安全，并通过微调提升模型安全性，同时保持医疗性能。", "keywords": ["大语言模型", "医疗安全", "基准数据集", "医学伦理", "微调", "评估"], "triple": {"method": "基于医学伦理原则定义医疗安全，构建MedSafetyBench基准数据集", "result": "公开医疗大语言模型未达医疗安全标准，微调后安全性提升且医疗性能保持", "contribution": "引入首个医疗安全基准数据集，推动大语言模型在医疗领域的安全性研究"}}
{"venue": "NeurIPS", "search_title": "Diversity-Optimized forMedicalSeries-Text Decoding via LLMs", "url": "https://neurips.cc/virtual/2025/poster/117266", "year": 2025, "abstract_snippet": "Dec 5, 2025 ... Medical time-series analysis differs fundamentally from general ones by requiring specialized domain knowledge to interpret complex signals ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/117266", "full_title": "From Indicators to Insights: Diversity-Optimized for Medical Series-Text Decoding via LLMs", "abstract": "Medical time-series analysis differs fundamentally from general ones by requiring specialized domain knowledge to interpret complex signals and clinical context. Large language models (LLMs) hold great promise for augmenting medical time-series analysis by complementing raw series with rich contextual knowledge drawn from biomedical literature and clinical guidelines. However, realizing this potential depends on precise and meaningful prompts that guide the LLM to key information. Yet, determining what constitutes effective prompt content remains non-trivial—especially in medical settings where signal interpretation often hinges on subtle, expert-defined decision-making indicators.  To this end, we propose InDiGO, a knowledge-aware evolutionary learning framework that integrates clinical signals and decision-making indicators through iterative optimization. Across four medical benchmarks, InDiGO consistently outperforms prior methods.  The code is available at: https://github.com/jinxyBJTU/InDiGO.", "summary_cn": "提出InDiGO框架，结合临床信号与决策指标，通过进化学习优化LLM提示，在四个医学基准测试中表现优于现有方法。", "keywords": ["医学时间序列", "大语言模型", "提示优化", "进化学习", "决策指标", "临床分析"], "triple": {"method": "知识感知进化学习框架", "result": "在四个医学基准上超越先前方法", "contribution": "提升LLM在医学时间序列分析中的性能"}}
{"venue": "NeurIPS", "search_title": "Contrastive learning of global and local features formedicalimage ...", "url": "https://proceedings.neurips.cc/paper/2020/file/949686ecef4ee20a62d16b4a2d7ccca3-Paper.pdf", "year": null, "abstract_snippet": "Supervised deep learning provides state-of-the-art medical image segmentation [47, 39, 31, 32], when large labeled datasets are available. However, assembling ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Contrastive learning of global and local features formedicalimage ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Saliency Guided LongitudinalMedicalVisual Question Answering", "url": "https://neurips.cc/virtual/2025/128766", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Longitudinal medical visual question answering (Diff-VQA) requires comparing paired studies from different time points and answering ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/128766", "full_title": "Saliency Guided Longitudinal Medical Visual Question Answering", "abstract": "Longitudinal medical visual question answering (Diff-VQA) requires comparing paired studies from different time points and answering questions about clinically meaningful changes. In this setting, the difference signal and the consistency of visual focus across time are more informative than absolute single-image findings. We propose a saliency-guided encoder–decoder for chest X-ray Diff-VQA that turns post-hoc saliency into actionable supervision. The model first performs a lightweight near-identity affine pre-alignment to reduce nuisance motion between visits. It then executes a within-epoch two-step loop: step 1 extracts a medically relevant keyword from the answer and generates keyword-conditioned Grad-CAM on both images to obtain disease-focused saliency; step 2 applies the shared saliency mask to both time points and generates the final answer. This closes the language–vision loop so that the terms that matter also guide where the model looks, enforcing spatially consistent attention on corresponding anatomy. On Medical-Diff-VQA, the approach attains competitive performance on BLEU, ROUGE-L, CIDEr, and METEOR while providing intrinsic interpretability. Notably, the backbone and decoder are general-domain pretrained without radiology-specific pretraining, highlighting practicality and transferability. These results support saliency-conditioned generation with mild pre-alignment as a principled framework for longitudinal reasoning in medical VQA.", "summary_cn": "提出显著性引导编码器-解码器模型，用于胸部X光纵向医学视觉问答。通过关键词生成Grad-CAM显著性图，引导模型关注疾病区域，实现时空一致注意力，提升性能与可解释性。", "keywords": ["纵向医学视觉问答", "显著性引导", "Grad-CAM", "胸部X光", "时空一致性", "可解释性"], "triple": {"method": "显著性引导编码器-解码器，结合轻量预对齐与关键词条件Grad-CAM", "result": "在BLEU等指标上表现竞争性，提供内在可解释性", "contribution": "建立显著性条件生成框架，支持医学VQA中的纵向推理"}}
{"venue": "NeurIPS", "search_title": "DDXPlus: A New Dataset For AutomaticMedicalDiagnosis - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/cae73a974390c0edd95ae7aeae09139c-Abstract-Datasets_and_Benchmarks.html", "year": 2022, "abstract_snippet": "There has been a rapidly growing interest in Automatic Symptom Detection (ASD) and Automatic Diagnosis (AD) systems in the machine learning research literature, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "DDXPlus: A New Dataset For AutomaticMedicalDiagnosis - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "MedicalDead-ends and Learning to Identify High-Risk States and ...", "url": "https://proceedings.neurips.cc/paper/2021/hash/26405399c51ad7b13b504e74eb7c696c-Abstract.html", "year": null, "abstract_snippet": "We introduce an inherently different approach that identifies \"dead-ends\" of a state space. We focus on patient condition in the intensive care unit, where a \" ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MedicalDead-ends and Learning to Identify High-Risk States and ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "A Benchmark forMedicalImage Sequences Grounding - NeurIPS", "url": "https://neurips.cc/virtual/2025/poster/121815", "year": 2025, "abstract_snippet": "Dec 5, 2025 ... Visual grounding is essential for precise perception and reasoning in multimodal large language models (MLLMs), especially in medical ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/121815", "full_title": "MedSG-Bench: A Benchmark for Medical Image Sequences Grounding", "abstract": "Visual grounding is essential for precise perception and reasoning in multimodal large language models (MLLMs), especially in medical imaging domains. While existing medical visual grounding benchmarks primarily focus on single-image scenarios, real-world clinical applications often involve sequential images, where accurate lesion localization across different modalities and temporal tracking of disease progression (e.g., pre- vs. post-treatment comparison) require fine-grained cross-image semantic alignment and context-aware reasoning. To remedy the underrepresentation of image sequences in existing medical visual grounding benchmarks, we propose MedSG-Bench, the first benchmark tailored for Medical Image Sequences Grounding. It comprises eight VQA-style tasks, formulated into two paradigms of the grounding tasks, including 1) Image Difference Grounding, which focuses on detecting change regions across images, and 2) Image Consistency Grounding, which emphasizes detection of consistent or shared semantics across sequential images. MedSG-Bench covers 76 public datasets, 10 medical imaging modalities, and a wide spectrum of anatomical structures and diseases, totaling 9,630 question–answer pairs. We benchmark both general-purpose MLLMs (e.g., Qwen2.5-VL) and medical-domain specialized MLLMs (e.g., HuatuoGPT-vision), observing that even the advanced models exhibit substantial limitations in medical sequential grounding tasks. To advance this field, we construct MedSG-188K, a large-scale instruction-tuning dataset tailored for sequential visual grounding, and further develop MedSeq-Grounder, an MLLM designed to facilitate future research on fine-grained understanding across medical sequential images. We release all resources on https://github.com/Yuejingkun/MedSG-Bench", "summary_cn": "提出首个医学图像序列定位基准MedSG-Bench，涵盖8个任务与9,630个问答对，揭示现有多模态大模型在序列图像定位中的局限，并构建大规模指令调优数据集以促进研究。", "keywords": ["医学图像序列", "视觉定位", "多模态大语言模型", "基准测试", "疾病进展跟踪", "跨模态对齐"], "triple": {"method": "构建包含图像差异与一致性定位任务的基准MedSG-Bench", "result": "现有先进模型在医学序列定位任务中表现显著不足", "contribution": "提供首个医学图像序列定位基准与大规模指令数据集，推动细粒度跨图像理解研究"}}
{"venue": "NeurIPS", "search_title": "Coordinating Multi-Model Domain Adaptation forMedicalImage ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/8313b1920ee9c78d846c5798c1ce48be-Paper-Conference.pdf", "year": 2022, "abstract_snippet": "In medical image analysis, often we need to build an image recognition system for a target scenario with the access to small labeled data and abundant ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Coordinating Multi-Model Domain Adaptation forMedicalImage ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Uni-Med: A UnifiedMedicalGeneralist Foundation Model For Multi ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/941938d6c3c57b4ef4a518965e238a6d-Abstract-Conference.html", "year": 2024, "abstract_snippet": "In this paper, we introduce Uni-Med, a novel medical generalist foundation model which consists of a universal visual feature extraction module, a connector ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/941938d6c3c57b4ef4a518965e238a6d-Abstract-Conference.html", "full_title": "Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE", "abstract": "Multi-modal large language models (MLLMs) have shown impressive capabilities as a general-purpose interface for various visual and linguistic tasks. However, building a unified MLLM for multi-task learning in the medical field remains a thorny challenge. To mitigate the tug-of-war problem of multi-modal multi-task optimization in MLLMs, recent advances primarily focus on improving the LLM components, while neglecting the connector that bridges the gap between modalities. In this paper, we introduce Uni-Med, a novel medical generalist foundation model which consists of a universal visual feature extraction module, a connector mixture-of-experts (CMoE) module, and an LLM. Benefiting from the proposed CMoE that leverages a well-designed router with a mixture of projection experts at the connector, Uni-Med achieves efficient solution to the tug-of-war problem and can perform six different medical tasks including question answering, visual question answering, report generation, referring expression comprehension, referring expression generation and image classification. To the best of our knowledge, Uni-Med is the first effort to tackle multi-task interference at the connector in MLLMs. Extensive ablation experiments validate the effectiveness of introducing CMoE under any configuration, with up to an average 8% performance gains. We further provide interpretation analysis of the tug-of-war problem from the perspective of gradient optimization and parameter statistics. Compared to previous state-of-the-art medical MLLMs, Uni-Med achieves competitive or superior evaluation metrics on diverse tasks. Code and resources are available at https://github.com/MSIIP/Uni-Med.", "summary_cn": "Uni-Med提出连接器混合专家模块，解决多模态多任务学习中的优化冲突，在六项医疗任务上表现优异。", "keywords": ["多模态大语言模型", "医疗任务", "混合专家", "连接器优化", "多任务学习", "视觉问答"], "triple": {"method": "引入连接器混合专家模块", "result": "平均性能提升达8%，在六项医疗任务上表现竞争或更优", "contribution": "首次在连接器层面解决多任务干扰问题"}}
{"venue": "NeurIPS", "search_title": "MedCalc-Bench: Evaluating Large Language Models forMedical...", "url": "https://neurips.cc/virtual/2024/poster/97666", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... To this end, we propose MedCalc-Bench, a first-of-its-kind dataset focused on evaluating the medical calculation capability of LLMs. MedCalc- ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/97666", "full_title": "MedCalc-Bench: Evaluating Large Language Models for Medical Calculations", "abstract": "Current benchmarks for evaluating large language models (LLMs) in medicine are primarily focused on question-answering involving domain knowledge and descriptive reasoning. While such qualitative capabilities are vital to medical diagnosis, in real-world scenarios, doctors frequently use clinical calculators that follow quantitative equations and rule-based reasoning paradigms for evidence-based decision support. To this end, we propose MedCalc-Bench, a first-of-its-kind dataset focused on evaluating the medical calculation capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000 manually reviewed instances from 55 different medical calculation tasks. Each instance in MedCalc-Bench consists of a patient note, a question requesting to compute a specific medical value, a ground truth answer, and a step-by-step explanation showing how the answer is obtained. While our evaluation results show the potential of LLMs in this area, none of them are effective enough for clinical settings. Common issues include extracting the incorrect entities, not using the correct equation or rules for a calculation task, or incorrectly performing the arithmetic for the computation. We hope our study highlights the quantitative knowledge and reasoning gaps in LLMs within medical settings, encouraging future improvements of LLMs for various clinical calculation tasks. MedCalc-Bench is publicly available at: https://github.com/ncbi-nlp/MedCalc-Bench.", "summary_cn": "提出MedCalc-Bench数据集，评估大语言模型在医学计算任务中的表现，发现现有模型在临床计算中存在不足，需改进定量推理能力。", "keywords": ["医学计算", "大语言模型", "评估基准", "临床决策", "定量推理", "数据集"], "triple": {"method": "构建包含1000多个实例的MedCalc-Bench数据集", "result": "现有模型在实体提取、方程应用和算术计算上存在错误", "contribution": "首次系统评估LLMs的医学计算能力，促进临床任务改进"}}
{"venue": "NeurIPS", "search_title": "MDAgents: An Adaptive Collaboration of LLMs forMedicalDecision ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/90d1fc07f46e31387978b88e7e057a31-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "We introduce a novel multi-agent frame- work, named Medical Decision-making Agents (MDAgents) that helps to address this gap by automatically assigning a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MDAgents: An Adaptive Collaboration of LLMs forMedicalDecision ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Med-Real2Sim: Non-InvasiveMedicalDigital Twins using Physics ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0b081a44ed0b8c0c4aa6bd886a60bea4-Abstract-Conference.html", "year": 2024, "abstract_snippet": "By constructing digital twins for disease processes, we can perform in-silico simulations that mimic patients' health conditions and counterfactual outcomes ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0b081a44ed0b8c0c4aa6bd886a60bea4-Abstract-Conference.html", "full_title": "Med-Real2Sim: Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning", "abstract": "A digital twin is a virtual replica of a real-world physical phenomena that uses mathematical modeling to characterize and simulate its defining features. By constructing digital twins for disease processes, we can perform in-silico simulations that mimic patients' health conditions and counterfactual outcomes under hypothetical interventions in a virtual setting. This eliminates the need for invasive procedures or uncertain treatment decisions. In this paper, we propose a method to identify digital twin model parameters using only noninvasive patient health data. We approach the digital twin modeling as a composite inverse problem, and observe that its structure resembles pretraining and finetuning in self-supervised learning (SSL). Leveraging this, we introduce a physics-informed SSL algorithm that initially pretrains a neural network on the pretext task of learning a differentiable simulator of a physiological process. Subsequently, the model is trained to reconstruct physiological measurements from noninvasive modalities while being constrained by the physical equations learned in pretraining. We apply our method to identify digital twins of cardiac hemodynamics using noninvasive echocardiogram videos, and demonstrate its utility in unsupervised disease detection and in-silico clinical trials.", "summary_cn": "提出Med-Real2Sim方法，利用物理信息自监督学习从无创医疗数据构建医学数字孪生，应用于心脏血流动力学模拟，支持无监督疾病检测和虚拟临床试验。", "keywords": ["医学数字孪生", "物理信息自监督学习", "无创数据", "心脏血流动力学", "虚拟临床试验", "疾病检测"], "triple": {"method": "物理信息自监督学习", "result": "从超声视频构建心脏数字孪生", "contribution": "实现无创医学模拟与疾病检测"}}
{"venue": "NeurIPS", "search_title": "Disentangling Human Error from Ground Truth in Segmentation of ...", "url": "https://proceedings.neurips.cc/paper/2020/hash/b5d17ed2b502da15aa727af0d51508d6-Abstract.html", "year": null, "abstract_snippet": "This problem is particularly pertinent in the medical image domain, where both the annotation cost and inter-observer variability are high. In a typical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Disentangling Human Error from Ground Truth in Segmentation of ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Fairness Benchmarking forMedicalImaging Foundation Models", "url": "https://neurips.cc/virtual/2024/poster/97809", "year": 2024, "abstract_snippet": "The advent of foundation models (FMs) in healthcare offers unprecedented opportunities to enhance medical diagnostics through automated classification and ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/97809", "full_title": "FairMedFM: Fairness Benchmarking for Medical Imaging Foundation Models", "abstract": "The advent of foundation models (FMs) in healthcare offers unprecedented opportunities to enhance medical diagnostics through automated classification and segmentation tasks. However, these models also raise significant concerns about their fairness, especially when applied to diverse and underrepresented populations in healthcare applications. Currently, there is a lack of comprehensive benchmarks, standardized pipelines, and easily adaptable libraries to evaluate and understand the fairness performance of FMs in medical imaging, leading to considerable challenges in formulating and implementing solutions that ensure equitable outcomes across diverse patient populations. To fill this gap, we introduce FairMedFM, a fairness benchmark for FM research in medical imaging. FairMedFM integrates with 17 popular medical imaging datasets, encompassing different modalities, dimensionalities, and sensitive attributes. It explores 20 widely used FMs, with various usages such as zero-shot learning, linear probing, parameter-efficient fine-tuning, and prompting in various downstream tasks -- classification and segmentation. Our exhaustive analysis evaluates the fairness performance over different evaluation metrics from multiple perspectives, revealing the existence of bias, varied utility-fairness trade-offs on different FMs, consistent disparities on the same datasets regardless FMs, and limited effectiveness of existing unfairness mitigation methods. Furthermore, FairMedFM provides an open-sourced codebase at https://github.com/FairMedFM/FairMedFM, supporting extendible functionalities and applications and inclusive for studies on FMs in medical imaging over the long term.", "summary_cn": "FairMedFM是医学影像基础模型的公平性基准，整合17个数据集和20个模型，揭示模型偏见、效用-公平权衡及现有缓解方法效果有限。", "keywords": ["公平性基准", "医学影像", "基础模型", "偏见评估", "开源代码库", "多模态数据"], "triple": {"method": "整合多数据集与模型进行公平性分析", "result": "发现偏见、权衡差异及缓解方法效果有限", "contribution": "提供首个医学影像基础模型公平性基准与开源工具"}}
{"venue": "NeurIPS", "search_title": "Large Language Models as ChineseMedicalAssistants for Pediatric ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/fa5b423e24b442180bcd4e13ae75a27f-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/fa5b423e24b442180bcd4e13ae75a27f-Abstract-Conference.html", "full_title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications", "abstract": "Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures.To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline.In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses. In the parameter-efficient secondary SFT phase,a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. The project and data will be released at https://github.com/ydk122024/PediatricsGPT.", "summary_cn": "本文构建了高质量儿科数据集PedCorpus，并提出首个中文儿科大语言模型助手PediatricsGPT，通过系统训练流程提升儿科诊断性能。", "keywords": ["儿科大语言模型", "PedCorpus数据集", "混合指令预训练", "监督微调", "偏好优化", "医学助手"], "triple": {"method": "构建PedCorpus数据集，采用混合指令预训练、全参数SFT和偏好优化", "result": "在多项评估中优于现有中文医学大语言模型", "contribution": "开发首个中文儿科大语言模型助手，提升儿科诊断效率"}}
{"venue": "NeurIPS", "search_title": "EnhancingMedicalVQA with Multimodal Determination Rationales", "url": "https://neurips.cc/virtual/2024/106856", "year": 2024, "abstract_snippet": "Medical Visual Question Answering (MedVQA), which offers language responses to image-based medical inquiries, represents a challenging task and significant ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106856", "full_title": "Enhancing Medical VQA with Multimodal Determination Rationales", "abstract": "Medical Visual Question Answering (MedVQA), which offers language responses to image-based medical inquiries, represents a challenging task and significant advancement in healthcare. It assists medical experts to swiftly interpret medical images, thereby enabling faster and more accurate diagnoses. However, the model interpretability and transparency of existing MedVQA solutions are often limited, posing challenges in understanding their decision-making processes. To address this issue, we devise a semi-automated annotation process to streamline data preparation and build new benchmark MedVQA datasets R-RAD, R-SLAKE and R-Path. These datasets provide intermediate medical decision-making rationales generated by multimodal large language models and human annotations for question-answering pairs in existing MedVQA datasets, i.e., VQA-RAD, SLAKE and PathVQA. Moreover, we design a novel framework, MedThink, which finetunes lightweight pretrained generative models by incorporating medical decision-making rationales. MedThink includes three distinct strategies to generate decision outcomes and corresponding rationales, thereby clearly showcasing the medical decision-making process during reasoning. Our comprehensive experiments show that our method achieves an accuracy of 83.5\\% on R-RAD, 86.3\\% on R-SLAKE and 87.2\\% on R-Path. These results significantly exceed those of existing state-of-the-art models with comparable parameters. Datasets and code will be released.", "summary_cn": "提出MedThink框架，通过半自动标注构建含决策依据的MedVQA数据集，结合多模态大模型生成医学决策依据，提升模型准确性与可解释性。", "keywords": ["医学视觉问答", "多模态大语言模型", "决策依据", "可解释性", "半自动标注", "MedThink"], "triple": {"method": "半自动标注构建数据集，MedThink框架微调轻量生成模型", "result": "在R-RAD、R-SLAKE、R-Path数据集上准确率达83.5%、86.3%、87.2%", "contribution": "提升MedVQA准确率与决策过程可解释性"}}
{"venue": "NeurIPS", "search_title": "Towards Multi-dimensional Explanation Alignment forMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/ea370419760b421ce12e3082eb2ae1a8-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Med-MICN provides interpretability alignment for various angles, including neural symbolic reasoning, concept semantics, and saliency maps, which are superior ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/ea370419760b421ce12e3082eb2ae1a8-Abstract-Conference.html", "full_title": "Towards Multi-dimensional Explanation Alignment for Medical Classification", "abstract": "The lack of interpretability in the field of medical image analysis has significant ethical and legal implications. Existing interpretable methods in this domain encounter several challenges, including dependency on specific models, difficulties in understanding and visualization, and issues related to efficiency. To address these limitations, we propose a novel framework called Med-MICN (Medical Multi-dimensional Interpretable Concept Network). Med-MICN provides interpretability alignment for various angles, including neural symbolic reasoning, concept semantics, and saliency maps, which are superior to current interpretable methods. Its advantages include high prediction accuracy, interpretability across multiple dimensions, and automation through an end-to-end concept labeling process that reduces the need for extensive human training effort when working with new datasets. To demonstrate the effectiveness and interpretability of Med-MICN, we apply it to four benchmark datasets and compare it with baselines. The results clearly demonstrate the superior performance and interpretability of our Med-MICN.", "summary_cn": "提出Med-MICN框架，通过多维度解释对齐提升医学图像分类的可解释性，在多个基准数据集上验证了其优越性能。", "keywords": ["医学图像分析", "可解释性", "多维度对齐", "Med-MICN", "概念网络", "神经符号推理"], "triple": {"method": "Med-MICN框架", "result": "在四个基准数据集上表现优于基线", "contribution": "实现多维度解释对齐，提升可解释性与自动化"}}
{"venue": "NeurIPS", "search_title": "Medformer: A Multi-Granularity Patching Transformer for ... - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/3fe2a777282299ecb4f9e7ebb531f0ab-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Abstract. Medical time series (MedTS) data, such as Electroencephalography (EEG) and Electrocardiography (ECG), play a crucial role in healthcare, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/3fe2a777282299ecb4f9e7ebb531f0ab-Abstract-Conference.html", "full_title": "Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification", "abstract": "Medical time series (MedTS) data, such as Electroencephalography (EEG) and Electrocardiography (ECG), play a crucial role in healthcare, such as diagnosing brain and heart diseases. Existing methods for MedTS classification primarily rely on handcrafted biomarkers extraction and CNN-based models, with limited exploration of transformer-based models. In this paper, we introduce Medformer, a multi-granularity patching transformer tailored specifically for MedTS classification. Our method incorporates three novel mechanisms to leverage the unique characteristics of MedTS: cross-channel patching to leverage inter-channel correlations, multi-granularity embedding for capturing features at different scales, and two-stage (intra- and inter-granularity) multi-granularity self-attention for learning features and correlations within and among granularities. We conduct extensive experiments on five public datasets under both subject-dependent and challenging subject-independent setups. Results demonstrate Medformer's superiority over 10 baselines, achieving top averaged ranking across five datasets on all six evaluation metrics. These findings underscore the significant impact of our method on healthcare applications, such as diagnosing Myocardial Infarction, Alzheimer's, and Parkinson's disease. We release the source code at https://github.com/DL4mHealth/Medformer.", "summary_cn": "Medformer是一种多粒度分块Transformer，专为医疗时间序列分类设计，通过跨通道分块和多粒度自注意力机制，在五个公开数据集上超越10个基线模型，提升疾病诊断性能。", "keywords": ["医疗时间序列", "Transformer", "多粒度分块", "跨通道相关", "疾病诊断", "自注意力"], "triple": {"method": "多粒度分块Transformer", "result": "在五个数据集上超越10个基线模型", "contribution": "提升医疗时间序列分类性能"}}
{"venue": "NeurIPS", "search_title": "Benchmarking Large Language Models on CMExam - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/a48ad12d588c597f4725a8b84af647b5-Abstract-Datasets_and_Benchmarks.html", "year": 2023, "abstract_snippet": "Benchmarking Large Language Models on CMExam - A comprehensive Chinese Medical Exam Dataset. Junling Liu, Peilin Zhou, Yining Hua, Dading Chong, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Benchmarking Large Language Models on CMExam - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "SMMILE: An expert-driven benchmark for multimodalmedicalin ...", "url": "https://neurips.cc/virtual/2025/poster/121577", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... We introduce SMMILE, the first expert-driven multimodal ICL benchmark for medical tasks. Eleven medical experts curated problems, each including ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/121577", "full_title": "SMMILE: An expert-driven benchmark for multimodal medical in-context learning", "abstract": "Multimodal in-context learning (ICL) remains underexplored despite significant potential for domains such as medicine. Clinicians routinely encounter diverse, specialized tasks requiring adaptation from limited examples, such as drawing insights from a few relevant prior cases or considering a constrained set of differential diagnoses. While multimodal large language models (MLLMs) have shown advances in medical visual question answering (VQA), their ability to learn multimodal tasks from context is largely unknown. We introduce SMMILE, the first expert-driven multimodal ICL benchmark for medical tasks. Eleven medical experts curated problems, each including a multimodal query and multimodal in-context examples as task demonstrations. SMMILE encompasses 111 problems (517 question-image-answer triplets) covering 6 medical specialties and 13 imaging modalities. We further introduce SMMILE++, an augmented variant with 1038 permuted problems. A comprehensive evaluation of 15 MLLMs demonstrates that most models exhibit moderate to poor multimodal ICL ability in medical tasks. In open-ended evaluations, ICL contributes only an 8% average improvement over zero-shot on SMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant in-context examples: even a single noisy or irrelevant example can degrade performance by up to 9.5%. Moreover, we observe that MLLMs are affected by a recency bias, where placing the most relevant example last can lead to substantial performance improvements of up to 71%. Our findings highlight critical limitations and biases in current MLLMs when learning multimodal medical tasks from context. SMMILE is available at https://smmile-benchmark.github.io.", "summary_cn": "SMMILE是首个专家驱动的医学多模态上下文学习基准，涵盖111个问题。评估15个MLLM发现其医学多模态上下文学习能力有限，易受无关示例和近因偏差影响。", "keywords": ["多模态上下文学习", "医学基准", "专家驱动", "大语言模型", "视觉问答", "性能评估"], "triple": {"method": "构建专家驱动的多模态医学基准SMMILE，评估15个MLLM", "result": "MLLM医学多模态上下文学习能力有限，易受无关示例和近因偏差影响", "contribution": "揭示当前MLLM在医学多模态上下文学习中的关键局限与偏差"}}
{"venue": "NeurIPS", "search_title": "Offline Guarded Safe Reinforcement Learning forMedicalTreatment ...", "url": "https://neurips.cc/virtual/2025/poster/119943", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... To safely improve policy beyond clinician recommendations while ensuring that state-action trajectories remain in-distribution, we propose \\ ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/119943", "full_title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies", "abstract": "The NeurIPS Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "本研究提出一种离线安全强化学习方法，用于优化医疗治疗策略，确保在数据驱动决策中的安全性和有效性。", "keywords": ["离线强化学习", "医疗优化", "安全策略", "数据驱动", "治疗策略", "安全约束"], "triple": {"method": "离线安全强化学习", "result": "优化医疗治疗策略", "contribution": "确保决策安全有效"}}
{"venue": "NeurIPS", "search_title": "GMAI-MMBench: A Comprehensive Multimodal Evaluation ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/ab7e02fd60e47e2a379d567f6b54f04e-Abstract-Datasets_and_Benchmarks_Track.html", "year": 2024, "abstract_snippet": "GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI. Pengcheng Chen, Jin Ye, Guoan Wang, Yanjun Li, Zhongying Deng, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/ab7e02fd60e47e2a379d567f6b54f04e-Abstract-Datasets_and_Benchmarks_Track.html", "full_title": "GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI", "abstract": "Large Vision-Language Models (LVLMs) are capable of handling diverse data types such as imaging, text, and physiological signals, and can be applied in various fields. In the medical field, LVLMs have a high potential to offer substantial assistance for diagnosis and treatment. Before that, it is crucial to develop benchmarks to evaluate LVLMs' effectiveness in various medical applications. Current benchmarks are often built upon specific academic literature, mainly focusing on a single domain, and lacking varying perceptual granularities. Thus, they face specific challenges, including limited clinical relevance, incomplete evaluations, and insufficient guidance for interactive LVLMs. To address these limitations, we developed the GMAI-MMBench, the most comprehensive general medical AI benchmark with well-categorized data structure and multi-perceptual granularity to date. It is constructed from 284 datasets across 38 medical image modalities, 18 clinical-related tasks, 18 departments, and 4 perceptual granularities in a Visual Question Answering (VQA) format. Additionally, we implemented a lexical tree structure that allows users to customize evaluation tasks, accommodating various assessment needs and substantially supporting medical AI research and applications. We evaluated 50 LVLMs, and the results show that even the advanced GPT-4o only achieves an accuracy of 53.96\\%, indicating significant room for improvement. Moreover, we identified five key insufficiencies in current cutting-edge LVLMs that need to be addressed to advance the development of better medical applications. We believe that GMAI-MMBench will stimulate the community to build the next generation of LVLMs toward GMAI.", "summary_cn": "本文提出GMAI-MMBench，一个全面的通用医疗AI多模态评估基准，涵盖多种医学图像模态、临床任务和感知粒度，以评估大型视觉语言模型在医疗领域的性能。", "keywords": ["医疗AI", "多模态评估", "大型视觉语言模型", "视觉问答", "基准测试", "医学图像"], "triple": {"method": "构建多模态医疗基准GMAI-MMBench，涵盖284个数据集、38种图像模态、18项任务和4种感知粒度，采用VQA格式和词汇树结构", "result": "评估50个LVLMs，GPT-4o准确率仅53.96%，揭示模型在医疗领域存在显著不足", "contribution": "提供全面、可定制的医疗AI评估基准，促进下一代通用医疗AI发展"}}
{"venue": "NeurIPS", "search_title": "A Hierarchical Contrastive Framework forMedicalTime-Series", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/ae7d9c77b5ff9e3b7833a68523b880f2-Abstract-Conference.html", "year": 2023, "abstract_snippet": "We present COMET, an innovative hierarchical framework that leverages data consistencies at all inherent levels in medical time series.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Hierarchical Contrastive Framework forMedicalTime-Series", "abstract": null}
{"venue": "NeurIPS", "search_title": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/58cc11cda2a2679e8af5c6317aed0af8-Abstract-Conference.html", "year": 2023, "abstract_snippet": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical Imaging via Second-order Graph Matching. Duy M. H. Nguyen, Hoang Nguyen, Nghiem Diep ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Curriculum Fine-tuning of Vision Foundation Model forMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/2093ed77c549eda95bd6f7212b735b43-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Noisy labels are a critical issue in medical datasets and can significantly degrade model performance. Previous clean sample selection methods have not utilized ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/2093ed77c549eda95bd6f7212b735b43-Abstract-Conference.html", "full_title": "Curriculum Fine-tuning of Vision Foundation Model for Medical Image Classification Under Label Noise", "abstract": "Deep neural networks have demonstrated remarkable performance in various vision tasks, but their success heavily depends on the quality of the training data. Noisy labels are a critical issue in medical datasets and can significantly degrade model performance. Previous clean sample selection methods have not utilized the well pre-trained features of vision foundation models (VFMs) and assumed that training begins from scratch. In this paper, we propose CUFIT, a curriculum fine-tuning paradigm of VFMs for medical image classification under label noise. Our method is motivated by the fact that linear probing of VFMs is relatively unaffected by noisy samples, as it does not update the feature extractor of the VFM, thus robustly classifying the training samples. Subsequently, curriculum fine-tuning of two adapters is conducted, starting with clean sample selection from the linear probing phase. Our experimental results demonstrate that CUFIT outperforms previous methods across various medical image benchmarks. Specifically, our method surpasses previous baselines by 5.0\\%, 2.1\\%, 4.6\\%, and 5.8\\% at a 40\\% noise rate on the HAM10000, APTOS-2019, BloodMnist, and OrgancMnist datasets, respectively. Furthermore, we provide extensive analyses to demonstrate the impact of our method on noisy label detection. For instance, our method shows higher label precision and recall compared to previous approaches. Our work highlights the potential of leveraging VFMs in medical image classification under challenging conditions of noisy labels.", "summary_cn": "提出CUFIT方法，通过线性探测和课程微调适配器，利用视觉基础模型处理医学图像分类中的标签噪声，在多个数据集上性能优于基线。", "keywords": ["医学图像分类", "标签噪声", "视觉基础模型", "课程微调", "线性探测", "CUFIT"], "triple": {"method": "线性探测与课程微调适配器", "result": "在多个数据集上性能提升2.1%-5.8%", "contribution": "利用视觉基础模型提升噪声标签下的分类鲁棒性"}}
{"venue": "NeurIPS", "search_title": "Representation Learning of Structured Data forMedicalFoundation ...", "url": "https://neurips.cc/virtual/2024/102673", "year": 2024, "abstract_snippet": "Our approach is validated through model pre-training on both an extensive internal medical database and a public repository of structured medical records.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/102673", "full_title": "Representation Learning of Structured Data for Medical Foundation Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across various domains, including healthcare. However, their ability to effectively represent structured non-textual data, such as the alphanumeric medical codes used in records like ICD-10 or SNOMED-CT, is limited and has been particularly exposed in recent research. This paper examines the challenges LLMs face in processing medical codes due to the shortcomings of current tokenization methods. As a result, we introduce the UniStruct architecture to design a multimodal medical foundation model of unstructured text and structured data, which addresses these challenges by adapting subword tokenization techniques specifically for the structured medical codes. Our approach is validated through model pre-training on both an extensive internal medical database and a public repository of structured medical records. Trained on over 1 billion tokens on the internal medical database, the proposed model achieves up to a 23% improvement in evaluation metrics, with around 2% gain attributed to our proposed tokenization. Additionally, when evaluated on the EHRSHOT public benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model improves performance on over 42% of the downstream tasks. Our approach not only enhances the representation and generalization capabilities of patient-centric models but also bridges a critical gap in representation learning models’ ability to handle complex structured medical data, alongside unstructured text.", "summary_cn": "本文提出UniStruct架构，通过改进子词分词技术处理结构化医疗代码，提升多模态医学基础模型性能，在评估指标上实现高达23%的改进。", "keywords": ["UniStruct架构", "结构化医疗数据", "子词分词", "多模态基础模型", "表示学习", "医疗代码"], "triple": {"method": "改进子词分词技术处理医疗代码", "result": "评估指标提升23%，下游任务性能改善超42%", "contribution": "增强患者中心模型表示与泛化能力，弥合结构化数据处理差距"}}
{"venue": "NeurIPS", "search_title": "Unleash the Potential of Test-Time Scaling forMedicalReasoning in ...", "url": "https://neurips.cc/virtual/2025/124931", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124931", "full_title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning in Large Language Models", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the reasoning capabilities of large language models (LLMs). However, its effectiveness in medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in terms of knowledge representation and decision-making processes. In this paper, we provide the first comprehensive investigation of test-time scaling for medical reasoning and present \\textbf{m1}, a simple yet effective approach that increases a model’s medical reasoning capability at inference. Through extensive experiments on open-source LLMs (Qwen2.5, 7B and 32B), we demonstrate that increasing the ``thinking'' token budget consistently improves accuracy without additional model training. Our evaluation across diverse medical tasks demonstrates that test-time scaling significantly enhances medical reasoning, enabling lightweight fine-tuned models to achieve performance comparable to computationally intensive counterparts (e.g., our 32B model matches previous 70B-scale medical LLMs). We identify an optimal reasoning token budget of approximately 4K, beyond which performance may degrade due to overthinking. Budget forcing, which controls test-time computation by extending reasoning through iterative prompts (e.g., appending \"Wait\"), helps models double-check answers but does not necessarily improve overall medical QA performance and, in some cases, introduces errors into previously correct responses. Critically, our analysis highlights insufficient medical knowledge as a primary failure mode, a limitation unresolvable through increased reasoning alone, underscoring the necessity of incorporating medical knowledge. Furthermore, increasing data scale, enhancing data quality, or expanding model capacity consistently improves medical knowledge grounding and thus boosts performance, particularly on challenging medical benchmarks where smaller models reach performance saturation. These findings reveal fundamental differences between medical and mathematical reasoning capabilities in LLMs. All data, code, and models will be publicly available to encourage future exploration in optimizing inference strategies in clinical AI applications.", "summary_cn": "研究提出m1方法，通过增加推理时token预算提升大语言模型的医学推理能力，无需额外训练，使轻量模型达到大型模型性能，并揭示医学与数学推理的根本差异。", "keywords": ["医学推理", "大语言模型", "测试时缩放", "推理优化", "知识表示", "临床AI"], "triple": {"method": "增加推理时token预算", "result": "提升医学推理准确率，轻量模型匹配大型模型性能", "contribution": "揭示医学推理特性，优化临床AI推理策略"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster MedicalNarratives: ConnectingMedicalVision and ...", "url": "https://neurips.cc/virtual/2025/poster/121849", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... Multi-modal models are data hungry. While datasets with natural images are abundant, medical image datasets can not afford the same luxury.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/121849", "full_title": "MedicalNarratives: Connecting Medical Vision and Language with Localized Narratives", "abstract": "Multi-modal models are data hungry. While datasets with natural images are abundant, medical image datasets can not afford the same luxury. To enable representation learning for medical images at scale, we turn to YouTube, a platform with a large reservoir of open-source medical pedagogical videos. We curate MedicalNarratives, a dataset 4.7M medical image-text pairs, with 1M samples containing dense annotations in the form of traces spatial traces (and bounding boxes), and 118K videos centered on the trace event (with aligned text), enabling spatiotemporal grounding beyond single frames. Similar to think-aloud studies where instructors speak while hovering their mouse cursor movements over relevant image regions, 1M images in MedicalNarratives contains localized mouse traces in image pixels, creating a spatial association between the text and pixels. To evaluate the utility of MedicalNarratives, we train GenMedClip with a CLIP-like objective using our dataset spanning 12 medical domains. GenMedClip outperforms previous state-of-the-art models on all 12 domains on a newly constructed medical imaging benchmark. Data, demo, code, and models will be made available.", "summary_cn": "从YouTube医学教学视频中构建MedicalNarratives数据集，含470万图像-文本对，其中100万带空间轨迹标注。基于此训练的GenMedClip模型在12个医学领域超越现有最佳模型。", "keywords": ["医学多模态", "数据集构建", "空间轨迹标注", "CLIP模型", "医学图像理解", "视频分析"], "triple": {"method": "利用YouTube医学视频构建带空间轨迹标注的数据集", "result": "GenMedClip在12个医学领域超越现有最佳模型", "contribution": "提供大规模医学多模态数据集并提升模型性能"}}
{"venue": "NeurIPS", "search_title": "NeurIPS SCRIBE: A Fine-Tuned Transformer Embedding Model for ...", "url": "https://neurips.cc/virtual/2025/133812", "year": 2025, "abstract_snippet": "Personal statements are a crucial part of the medical school application process, offering applicants the opportunity to showcase their personality, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133812", "full_title": "SCRIBE: A Fine-Tuned Transformer Embedding Model for Evaluating Medical School Personal Statements", "abstract": "Personal statements are a crucial part of the medical school application process, offering applicants the opportunity to showcase their personality, experiences, and motivation for pursuing a career in medicine. However, many students struggle to draft and revise these essays while juggling pre-med commitments. To address this, we present the Semantic and Contextual Rubric-Based Intelligence for Biomedical Essays (SCRIBE), a novel offline tool for the automated evaluation of medical school personal statements, which fine-tunes the state-of-the-art e5-large-v2. SCRIBE provides automatic, structured feedback, lowering barriers for students who may lack access to mentoring or editing support. Our tool segments essays into semantically coherent sections, classifies each into rubric categories (Spark, Healthcare Experience, Showing Doctor Qualities, Spin), and assigns a score from 1 to 4. The SCRIBE tool was trained on manually annotated text by subject experts. The novel contributions of our research work include: (1) Development of an automated tool named SCRIBE for practical evaluation of medical personal statements by fine-tuning the state-of-the-art e5-large-v2 model, which is publicly available.", "summary_cn": "SCRIBE是基于e5-large-v2微调的Transformer模型，用于自动评估医学院个人陈述，提供结构化反馈和评分。", "keywords": ["SCRIBE", "医学院个人陈述", "自动评估", "Transformer微调", "结构化反馈", "e5-large-v2"], "triple": {"method": "微调e5-large-v2模型", "result": "实现个人陈述自动分段、分类和评分", "contribution": "开发公开可用的自动化评估工具"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster GauSAM: Contour‑Guided 2D Gaussian Fields for ...", "url": "https://neurips.cc/virtual/2025/poster/119713", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... Effective multiscale medical image segmentation requires simultaneously preserving smooth spatial continuity and accurately delineating ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/119713", "full_title": "GauSAM: Contour‑Guided 2D Gaussian Fields for Multi‑Scale Medical Image Segmentation with Segment Anything", "abstract": "Effective multiscale medical image segmentation requires simultaneously preserving smooth spatial continuity and accurately delineating high-frequency boundaries, yet pixel-wise decoders often fail to maintain this balance consistently across varying resolutions. We introduce GauSAM, which seamlessly integrates contour‑guided 2D Gaussian probability fields into the Segment Anything Model to address these challenges. In our framework, segmentation masks are parameterized as continuous probability fields of learnable 2D Gaussian primitives, enforcing spatially smooth and structurally consistent. Contourlet transforms extract rich multidirectional frequency information, notably edges and fine textures, which dynamically guide the spatial distribution of Gaussian primitives to substantially improve boundary fidelity in complex structures. The incorporation of these high-frequency contour priors also enriches the expressive capacity of the SAM image encoder. Extensive experiments on diverse 2D medical segmentation tasks confirm that GauSAM consistently delivers robust generalization and state-of-the-art performance with only 1.2M trainable parameters. The official implementation of GauSAM is publicly available at https://github.com/Quinten-Wu504/GauSAM.", "summary_cn": "GauSAM将轮廓引导的2D高斯概率场集成到Segment Anything模型中，通过轮廓波变换提取高频边界信息指导高斯原语分布，提升了多尺度医学图像分割的边界精度和泛化性能。", "keywords": ["医学图像分割", "高斯概率场", "轮廓波变换", "多尺度分割", "边界精度", "Segment Anything"], "triple": {"method": "集成轮廓引导2D高斯场与SAM", "result": "在多种2D医学分割任务中实现SOTA性能", "contribution": "提升边界精度与模型泛化能力"}}
{"venue": "NeurIPS", "search_title": "FEDMEKI: A Benchmark for ScalingMedicalFoundation Models via ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0235cbb8cd6425d0b55daefce388fc0b-Abstract-Datasets_and_Benchmarks_Track.html", "year": 2024, "abstract_snippet": "The platform is meticulously designed to handle multi-site, multi-modal, and multi-task medical data, which includes 7 medical modalities, including images, ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0235cbb8cd6425d0b55daefce388fc0b-Abstract-Datasets_and_Benchmarks_Track.html", "full_title": "FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection", "abstract": "This study introduces the Federated Medical Knowledge Injection (FedMEKI) platform, a new benchmark designed to address the unique challenges of integrating medical knowledge into foundation models under privacy constraints. By leveraging a cross-silo federated learning approach, FedMEKI circumvents the issues associated with centralized data collection, which is often prohibited under health regulations like the Health Insurance Portability and Accountability Act (HIPAA) in the USA. The platform is meticulously designed to handle multi-site, multi-modal, and multi-task medical data, which includes 7 medical modalities, including images, signals, texts, laboratory test results, vital signs, input variables, and output variables. The curated dataset to validate FedMEKI covers 8 medical tasks, including 6 classification tasks (lung opacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal detection, mortality prediction, sepsis protection, and enlarged cardiomediastinum detection) and 2 generation tasks (medical visual question answering (MedVQA) and ECG noise clarification). This comprehensive dataset is partitioned across several clients to facilitate the decentralized training process under 16 benchmark approaches. FedMEKI not only preserves data privacy but also enhances the capability of medical foundation models by allowing them to learn from a broader spectrum of medical knowledge without direct data exposure, thereby setting a new benchmark in the application of foundation models within the healthcare sector.", "summary_cn": "FedMEKI平台通过联邦学习整合多模态医疗数据，在保护隐私下提升基础模型能力，涵盖8项医疗任务，为医疗AI设立新基准。", "keywords": ["联邦学习", "医疗基础模型", "隐私保护", "多模态数据", "基准测试", "知识注入"], "triple": {"method": "跨孤岛联邦学习", "result": "提升模型性能并保护数据隐私", "contribution": "建立医疗基础模型联邦知识注入基准"}}
{"venue": "NeurIPS", "search_title": "Sm: enhanced localization in Multiple Instance Learning formedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/8db9279f593652ee9bb2223b4a2c43fa-Abstract-Conference.html", "year": 2024, "abstract_snippet": "Multiple Instance Learning (MIL) is widely used in medical imaging classification to reduce the labeling effort. While only bag labels are available for ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/8db9279f593652ee9bb2223b4a2c43fa-Abstract-Conference.html", "full_title": "Sm: enhanced localization in Multiple Instance Learning for medical imaging classification", "abstract": "Multiple Instance Learning (MIL) is widely used in medical imaging classification to reduce the labeling effort. While only bag labels are available for training, one typically seeks predictions at both bag and instance levels (classification and localization tasks, respectively). Early MIL methods treated the instances in a bag independently. Recent methods account for global and local dependencies among instances. Although they have yielded excellent results in classification, their performance in terms of localization is comparatively limited. We argue that these models have been designed to target the classification task, while implications at the instance level have not been deeply investigated. Motivated by a simple observation -- that neighboring instances are likely to have the same label -- we propose a novel, principled, and flexible mechanism to model local dependencies. It can be used alone or combined with any mechanism to model global dependencies (e.g., transformers). A thorough empirical validation shows that our module leads to state-of-the-art performance in localization while being competitive or superior in classification. Our code is at https://github.com/Franblueee/SmMIL.", "summary_cn": "提出Sm模块增强多示例学习中的局部依赖建模，提升医学影像分类的定位性能，同时保持分类竞争力。", "keywords": ["多示例学习", "医学影像分类", "局部依赖", "定位性能", "深度学习"], "triple": {"method": "引入局部依赖建模机制", "result": "定位性能达最优，分类表现优异", "contribution": "提升医学影像定位准确性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster The Boundaries of Fair AI inMedicalImage Prognosis", "url": "https://neurips.cc/virtual/2025/poster/118323", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... As machine learning (ML) algorithms are increasingly used in medical image analysis, concerns have emerged about their potential biases ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/118323", "full_title": "The Boundaries of Fair AI in Medical Image Prognosis: A Causal Perspective", "abstract": "As machine learning (ML) algorithms are increasingly used in medical image analysis, concerns have emerged about their potential biases against certain social groups. Although many approaches have been proposed to ensure the fairness of ML models, most existing works focus only on medical image diagnosis tasks, such as image classification and segmentation, and overlooked prognosis scenarios, which involve predicting the likely outcome or progression of a medical condition over time. To address this gap, we introduce FairTTE, the first comprehensive framework for assessing fairness in time-to-event (TTE) prediction in medical imaging. FairTTE encompasses a diverse range of imaging modalities and TTE outcomes, integrating cutting-edge TTE prediction and fairness algorithms to enable systematic and fine-grained analysis of fairness in medical image prognosis. Leveraging causal analysis techniques, FairTTE uncovers and quantifies distinct sources of bias embedded within medical imaging datasets. Our large-scale evaluation reveals that bias is pervasive across different imaging modalities and that current fairness methods offer limited mitigation. We further demonstrate a strong association between underlying bias sources and model disparities, emphasizing the need for holistic approaches that target all forms of bias. Notably, we find that fairness becomes increasingly difficult to maintain under distribution shifts, underscoring the limitations of existing solutions and the pressing need for more robust, equitable prognostic models.", "summary_cn": "本文提出FairTTE框架，首次从因果视角评估医学影像预后中的公平性，揭示普遍偏见并指出现有方法在分布偏移下效果有限。", "keywords": ["医学影像预后", "公平性评估", "因果分析", "时间到事件预测", "偏见来源", "分布偏移"], "triple": {"method": "开发FairTTE框架，整合TTE预测与公平算法", "result": "发现偏见普遍存在，现有方法缓解有限，分布偏移下公平性更难维持", "contribution": "首次系统评估医学影像预后公平性，强调需针对所有偏见来源的整体方法"}}
{"venue": "NeurIPS", "search_title": "Enhancing vision-language models formedicalimaging - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/b53513b83232116ae25f57a174a7c993-Paper-Datasets_and_Benchmarks_Track.pdf", "year": 2024, "abstract_snippet": "To bridge the gap between state-of-the-art 2D VLMs and 3D medical image data, we developed an innovative, one-pass, unsupervised representative slice selection ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Enhancing vision-language models formedicalimaging - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "DAAC: Discrepancy-Aware Adaptive Contrastive Learning ... - NeurIPS", "url": "https://neurips.cc/virtual/2025/poster/115757", "year": 2025, "abstract_snippet": "Dec 4, 2025 ... Medical time-series data play a vital role in disease diagnosis but suffer from limited labeled samples and single-center bias, which hinder ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/115757", "full_title": "DAAC: Discrepancy-Aware Adaptive Contrastive Learning for Medical Time series", "abstract": "Medical time-series data play a vital role in disease diagnosis but suffer from limited labeled samples and single-center bias, which hinder model generalization and lead to overfitting. To address these challenges, we propose DAAC (Discrepancy-Aware Adaptive Contrastive learning), a learnable multi-view contrastive framework that integrates external normal samples and enhances feature learning through adaptive contrastive strategies. DAAC consists of two key modules: (1) a Discrepancy Estimator, built upon a GAN-enhanced encoder-decoder architecture, captures the distribution of normal data and computes reconstruction errors as indicators of abnormality. These discrepancy features augment the target dataset to mitigate overfitting. (2) an Adaptive Contrastive Learner uses multi-head attention to extract discriminative representations by contrasting embeddings across multiple views and data granularities (subject, trial, epoch, and temporal levels), eliminating the need for handcrafted positive-negative sample pairs. Extensive experiments on three clinical datasets—covering Alzheimer’s disease, Parkinson’s disease, and myocardial infarction—demonstrate that DAAC significantly outperforms existing methods, even when only 10\\% of labeled data is available, showing strong generalization and diagnostic performance. Our code is available at https://github.com/CUHKSZ-MED-BioE/DAAC.", "summary_cn": "提出DAAC框架，通过差异感知和自适应对比学习，利用外部正常样本增强医学时间序列特征，有效缓解过拟合，在阿尔茨海默病等数据集上显著提升诊断性能。", "keywords": ["医学时间序列", "对比学习", "过拟合缓解", "多视图学习", "异常检测", "自适应策略"], "triple": {"method": "差异感知自适应对比学习框架", "result": "在三个临床数据集上显著优于现有方法", "contribution": "提升小样本下的泛化与诊断性能"}}
{"venue": "NeurIPS", "search_title": "A Textbook Remedy for Domain Shifts: Knowledge Priors ... - NeurIPS", "url": "https://neurips.cc/virtual/2024/poster/95098", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis. Yue Yang · Mona Gandhi · Yufei Wang · Yifan Wu · Michael Yao · ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/95098", "full_title": "A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis", "abstract": "While deep networks have achieved broad success in analyzing natural images, when applied to medical scans, they often fail in unexcepted situations. We investigate this challenge and focus on model sensitivity to domain shifts, such as data sampled from different hospitals or data confounded by demographic variables such as sex, race, etc, in the context of chest X-rays and skin lesion images. A key finding we show empirically is that existing visual backbones lack an appropriate prior from the architecture for reliable generalization in these settings. Taking inspiration from medical training, we propose giving deep networks a prior grounded in explicit medical knowledge communicated in natural language. To this end, we introduce Knowledge-enhanced Bottlenecks (KnoBo), a class of concept bottleneck models that incorporates knowledge priors that constrain it to reason with clinically relevant factors found in medical textbooks or PubMed. KnoBo uses retrieval-augmented language models to design an appropriate concept space paired with an automatic training procedure for recognizing the concept. We evaluate different resources of knowledge and recognition architectures on a broad range of domain shifts across 20 datasets. In our comprehensive evaluation with two imaging modalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4% on average. Finally, evaluations reveal that PubMed is a promising resource for making medical models less sensitive to domain shift, outperforming other resources on both diversity of information and final prediction performance.", "summary_cn": "针对医学图像分析中的域偏移问题，提出知识增强瓶颈模型，通过整合医学教科书和PubMed知识，提升模型在跨域数据集上的泛化性能。", "keywords": ["域偏移", "医学图像分析", "知识先验", "概念瓶颈模型", "PubMed", "泛化性能"], "triple": {"method": "知识增强瓶颈模型整合医学知识", "result": "在20个数据集上平均提升32.4%性能", "contribution": "提升模型对域偏移的鲁棒性"}}
{"venue": "NeurIPS", "search_title": "Image-aware Evaluation of GeneratedMedicalReports - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0fbbc5129cafcee8530223b8565561ac-Abstract-Conference.html", "year": 2024, "abstract_snippet": "We demonstrate the benefit of our metric through evaluation on a dataset where radiologists marked errors in pairs of reports, showing notable alignment with ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/0fbbc5129cafcee8530223b8565561ac-Abstract-Conference.html", "full_title": "Image-aware Evaluation of Generated Medical Reports", "abstract": "The paper proposes a novel evaluation metric for automatic medical report generation from X-ray images, VLScore. It aims to overcome the limitations of existing evaluation methods, which either focus solely on textual similarities, ignoring clinical aspects, or concentrate only on a single clinical aspect, the pathology, neglecting all other factors. The key idea of our metric is to measure the similarity between radiology reports while considering the corresponding image. We demonstrate the benefit of our metric through evaluation on a dataset where radiologists marked errors in pairs of reports, showing notable alignment with radiologists' judgments. In addition, we provide a new dataset for evaluating metrics. This dataset includes well-designed perturbations that distinguish between significant modifications (e.g., removal of a diagnosis) and insignificant ones. It highlights the weaknesses in current evaluation metrics and provides a clear framework for analysis.", "summary_cn": "提出VLScore新指标，结合图像评估X光报告生成质量，优于现有方法，与放射科医生判断一致，并提供新数据集验证。", "keywords": ["医学报告生成", "评估指标", "图像感知", "放射学", "VLScore", "数据集"], "triple": {"method": "提出VLScore指标，结合图像与文本相似度", "result": "与放射科医生判断一致，优于现有评估方法", "contribution": "提供新评估指标和数据集，提升医学报告生成评估质量"}}
{"venue": "NeurIPS", "search_title": "A Benchmark for Long-FormMedicalQuestion Answering - NeurIPS", "url": "https://neurips.cc/virtual/2024/103919", "year": 2024, "abstract_snippet": "Most existing benchmarks for medical QA evaluation focus on automatic metrics and multiple-choice questions. While valuable, these benchmarks do not fully ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103919", "full_title": "A Benchmark for Long-Form Medical Question Answering", "abstract": "There is a lack of benchmarks for evaluating large language models (LLMs) in long-form medical question answering (QA). Most existing benchmarks for medical QA evaluation focus on automatic metrics and multiple-choice questions. While valuable, these benchmarks do not fully capture or assess the complexities of real-world clinical applications where LLMs are being deployed. Furthermore, the limited studies on long-form answer generation in medical QA are primarily closed-source, with no access to human medical expert annotations, making it difficult to reproduce results and improve baselines. In this work, we introduce a new publicly available benchmark featuring real-world consumer medical questions with long-form answer evaluations annotated by medical doctors. We conduct pairwise comparisons of responses from various open and closed medical and general-purpose LLMs based on criteria such as correctness, helpfulness, harmfulness, and bias. Additionally, we perform a comprehensive LLM-as-a-judge analysis to study the alignment between human judgments and LLMs. Our preliminary results highlight the strong potential of open LLMs in medical QA compared to leading closed models.", "summary_cn": "本文提出一个公开的长篇医学问答基准，包含医生标注的真实问题与答案，用于评估大语言模型在临床应用中的表现。", "keywords": ["医学问答", "基准测试", "大语言模型", "长篇答案", "医生标注", "模型评估"], "triple": {"method": "构建公开基准并进行模型比较", "result": "开源模型在医学问答中表现潜力强", "contribution": "填补长篇医学问答评估空白"}}
{"venue": "NeurIPS", "search_title": "MedSat: A Public Health Dataset for England FeaturingMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/f4fdf676c3b21f20f8c391d929188386-Abstract-Datasets_and_Benchmarks.html", "year": 2023, "abstract_snippet": "Abstract. As extreme weather events become more frequent, understanding their impact on human health becomes increasingly crucial.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MedSat: A Public Health Dataset for England FeaturingMedical...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Auto-Encoding Knowledge Graph for UnsupervisedMedicalReport ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/876e1c59023b1a0e95808168e1a8ff89-Abstract.html", "year": 2021, "abstract_snippet": "Medical report generation, which aims to automatically generate a long and coherent report of a given medical image, has been receiving growing research ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Auto-Encoding Knowledge Graph for UnsupervisedMedicalReport ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Domain Generalization forMedicalImaging Classification with ...", "url": "https://proceedings.neurips.cc/paper/2020/file/201d7288b4c18a679e48b31c72c30ded-Paper.pdf", "year": null, "abstract_snippet": "Due to the breakthrough in machine learning and deep learning, recent years have witnessed numerous significant successes in various medical imaging tasks.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Domain Generalization forMedicalImaging Classification with ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "The Adaptive Neuron Network Expansion forMedicalImage ...", "url": "https://neurips.cc/virtual/2025/131937", "year": 2025, "abstract_snippet": "... medical image segmentation). In this work, we introduce ANNE: The Adaptive Neuron Network Expansion for 2D Medical Image Segmentation. ANNE is an efficient ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/131937", "full_title": "The Adaptive Neuron Network Expansion for Medical  Image Segmentation", "abstract": "Many deep learning architectures struggle to combine the benefits of local feature extraction and global contextual awareness, limiting their effectiveness in complex segmentation tasks (i.e., medical image segmentation). In this work, we introduce ANNE: The Adaptive Neuron Network Expansion for 2D Medical Image Segmentation. ANNE is an efficient yet computationally effective deep learning architecture, inspired by the Remez and Progressive Expansion Neurons algorithms, designed to approximate complex functions with fewer trainable parameters. Our model utilizes Mamba and Adaptable Progressive Expansion Neurons-based techniques to better leverage the combined benefits of local and global features. Experimental results demonstrate competitive performance in various medical image segmentation tasks, including retinal, polyp, and skin lesion segmentation, while achieving a significantly reduced number of trainable parameters compared to existing deep learning models.", "summary_cn": "提出ANNE模型，结合Mamba与自适应扩展神经元，以较少参数实现医学图像分割，在视网膜、息肉等任务中表现优异。", "keywords": ["医学图像分割", "自适应扩展神经元", "Mamba", "参数效率", "深度学习", "局部与全局特征"], "triple": {"method": "结合Mamba与自适应扩展神经元", "result": "分割性能优异且参数显著减少", "contribution": "提出高效轻量分割模型ANNE"}}
{"venue": "NeurIPS", "search_title": "A case for reframing automatedmedicalimage classification ... - NIPS", "url": "https://papers.neurips.cc/paper_files/paper/2023/file/ad6a3bd12095fdca71c306871bdec400-Paper-Conference.pdf", "year": null, "abstract_snippet": "Figure 1: Illustration of three medical image analysis problems that can be framed using either classification or segmentation. trained networks are coming ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A case for reframing automatedmedicalimage classification ... - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report ...", "url": "https://neurips.cc/virtual/2025/poster/121676", "year": 2025, "abstract_snippet": "Dec 4, 2025 ... Most existing medical VLMs are trained on a subset of imaging modalities and focus primarily on high-resource languages, thus limiting their ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/121676", "full_title": "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation", "abstract": "Vision-Language Foundation Models (VLMs), trained on large-scale multimodal datasets, have driven significant advances in Artificial Intelligence (AI) by enabling rich cross-modal reasoning. Despite their success in general domains, applying these models to medical imaging remains challenging due to the limited availability of diverse imaging modalities and multilingual clinical data. Most existing medical VLMs are trained on a subset of imaging modalities and focus primarily on high-resource languages, thus limiting their generalizability and clinical utility. To address these limitations, we introduce a novel Vietnamese-language multimodal medical dataset consisting of 2,757 whole-body PET/CT volumes from independent patients and their corresponding full-length clinical reports. This dataset is designed to fill two pressing gaps in medical AI development: (1) the lack of PET/CT imaging data in existing VLMs training corpora, which hinders the development of models capable of handling functional imaging tasks; and (2) the underrepresentation of low-resource languages, particularly the Vietnamese language, in medical vision-language research. To the best of our knowledge, this is the first dataset to provide comprehensive PET/CT-report pairs in Vietnamese. We further introduce a training framework to enhance VLMs' learning, including data augmentation and expert-validated test sets. We conduct comprehensive experiments benchmarking state-of-the-art VLMs on downstream tasks, including medical report generation and visual question answering. The experimental results show that incorporating our dataset significantly improves the performance of existing VLMs. However, despite these advancements, the models still underperform on clinically critical criteria, particularly the diagnosis of lung cancer, indicating substantial room for future improvement. We believe this dataset and benchmark will serve as a pivotal step in advancing the development of more robust VLMs for medical imaging, particularly in low-resource languages, and improving their clinical relevance in Vietnamese healthcare.", "summary_cn": "本文构建首个越南语PET/CT影像与报告数据集，提出增强训练框架，显著提升视觉语言模型在医学报告生成等任务上的性能，但临床关键指标仍有改进空间。", "keywords": ["视觉语言模型", "PET/CT影像", "越南语数据集", "医学报告生成", "低资源语言", "多模态学习"], "triple": {"method": "构建越南语PET/CT数据集与增强训练框架", "result": "提升现有模型性能，但肺癌诊断等临床指标仍不足", "contribution": "填补PET/CT数据与低资源语言空白，推动医学AI发展"}}
{"venue": "NeurIPS", "search_title": "LoMix: Learnable Weighted Multi-Scale Logits Mixing for ... - NeurIPS", "url": "https://neurips.cc/virtual/2025/poster/119650", "year": 2025, "abstract_snippet": "Dec 4, 2025 ... LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation. Md Mostafijur Rahman · Radu Marculescu. Project Page ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/119650", "full_title": "LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation", "abstract": "The NeurIPS Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "LoMix提出可学习的加权多尺度逻辑混合方法，提升医学图像分割性能，通过自适应融合多尺度特征优化分割结果。", "keywords": ["医学图像分割", "多尺度特征融合", "可学习加权", "逻辑混合", "深度学习"], "triple": {"method": "可学习的加权多尺度逻辑混合", "result": "提升分割性能", "contribution": "优化医学图像分割结果"}}
{"venue": "NeurIPS", "search_title": "MetaTeacher: Coordinating Multi-Model Domain Adaptation for ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/8313b1920ee9c78d846c5798c1ce48be-Abstract-Conference.html", "year": 2022, "abstract_snippet": "Abstract. In medical image analysis, we often need to build an image recognition system for a target scenario with the access to small labeled data and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MetaTeacher: Coordinating Multi-Model Domain Adaptation for ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Demo: Orchestrating Large Language Model Agents and Resources ...", "url": "https://neurips.cc/virtual/2025/124871", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Demo: Orchestrating Large Language Model Agents and Resources for Medical Deep Research. Yuan Li · Claire Liu · Matthew Pan · Hengjin Zhu · ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124871", "full_title": "Demo: Orchestrating Large Language Model Agents and Resources for Medical Deep Research", "abstract": "Deep Research represents the convergence of large language models (LLMs), advanced reasoning, and information retrieval for expert-level inquiry. Existing Deep Research systems are constrained by reliability issues, limited integration with specialized resources, and inflexible output formats. In this paper, we introduce \\textbf{Medical Deep Research}, an open, agentic system designed for in-depth medical and clinical investigations. Our framework features a multi-agent research module and a resource module that integrates curated medical tools and can dynamically discover Model Context Protocols (MCPs). Through fine-grained design for planning, tool orchestration, query processing, report formatting, and MCP integration, the system supports comprehensive medical information retrieval and customizable output generation. We evaluate this system across four key aspects: resource coverage, tractability, correctness, and helpfulness. Our evaluation results demonstrate the potential of Medical Deep Research to serve as a reliable and powerful platform for medical research.", "summary_cn": "本文提出Medical Deep Research系统，结合多智能体与资源模块，支持深度医学检索与定制化报告生成，提升可靠性与灵活性。", "keywords": ["医学研究", "大语言模型", "多智能体系统", "信息检索", "资源集成", "报告生成"], "triple": {"method": "多智能体与资源模块设计", "result": "系统在资源覆盖、可追踪性、正确性和实用性方面表现良好", "contribution": "提供可靠、灵活的医学深度研究平台"}}
{"venue": "NeurIPS", "search_title": "AMedicalX-ray Attention Block for Improved Multi-Label Diagnosis", "url": "https://neurips.cc/virtual/2025/128744", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... These results demonstrate that attention modules can be overfit in a beneficial, task-aware sense to the unique structure and demands of ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/128744", "full_title": "Beyond Conventional Transformers: A Medical X-ray Attention Block for Improved Multi-Label Diagnosis", "abstract": "Transformers have reshaped visual recognition through generic self-attention, yet their application to specialized domains like medical imaging remains underexplored. In this work, we introduce the Medical X-ray Attention (MXA) block, a domain-specific attention mechanism designed specifically for multi-label chest X-ray diagnosis. Unlike conventional attention modules, MXA augments transformer backbones with inductive priors tailored to radiology, including a lightweight region-of-interest pooling and CBAM-style channel–spatial attention, both integrated in parallel with multi-head self-attention. To reduce the computational burden of traditional transformers and support deployment in clinical settings, we embed MXA within an Efficient Vision Transformer (EfficientViT) and apply knowledge distillation from a calibrated DenseNet-121 teacher. This combined approach produces a model that is both accurate and resource-efficient. Our framework achieves 0.85 mean AUC on the CheXpert benchmark, representing a +0.19 absolute improvement and approximately 233\\% relative improvement over chance-level performance (AUC = 0.5) compared to a vanilla EfficientViT baseline. These results demonstrate that attention modules can be overfit in a beneficial, task-aware sense to the unique structure and demands of clinical imaging. More broadly, we show that transformers do not need to remain generic, and that domain-specific attention can bridge the gap between expressive global modeling and real-world deployment.", "summary_cn": "提出医学X射线注意力块（MXA），结合区域池化与通道-空间注意力，集成于高效视觉Transformer，提升多标签胸片诊断性能，在CheXpert基准上达到0.85平均AUC。", "keywords": ["医学影像", "注意力机制", "多标签诊断", "高效视觉Transformer", "知识蒸馏", "CheXpert"], "triple": {"method": "设计MXA块，集成区域池化与通道-空间注意力，结合高效视觉Transformer与知识蒸馏", "result": "在CheXpert基准上平均AUC达0.85，相对基线提升显著", "contribution": "提出领域专用注意力机制，提升医学影像诊断性能与部署效率"}}
{"venue": "NeurIPS", "search_title": "Towards Generic Semi-Supervised Framework for Volumetric ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/05dc08730e32441edff52b0fa6caab5f-Abstract-Conference.html", "year": 2023, "abstract_snippet": "Towards Generic Semi-Supervised Framework for Volumetric Medical Image Segmentation ... Volume-wise labeling in 3D medical images is a time-consuming task that ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Generic Semi-Supervised Framework for Volumetric ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "SegVol: Universal and Interactive VolumetricMedicalImage ... - NIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/c7c7cf10082e454b9662a686ce6f1b6f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Despite the remarkable progress achieved in medical image segmentation, there is still an absence of a 3D foundation segmentation model that can segment a wide.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SegVol: Universal and Interactive VolumetricMedicalImage ... - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "DiversityMedQA: A Benchmark for Assessing Demographic Biases ...", "url": "https://neurips.cc/virtual/2024/103874", "year": 2024, "abstract_snippet": "... medical queries across diverse patient demographics, such as gender and ethnicity. By perturbing questions from the MedQA dataset, which comprises medical ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103874", "full_title": "DiversityMedQA: A Benchmark for Assessing Demographic Biases in Medical Diagnosis using Large Language Models", "abstract": "As large language models (LLMs) gain traction in healthcare, concerns about their susceptibility to demographic biases are growing. We introduce DiversityMedQA, a novel benchmark designed to assess LLM responses to medical queries across diverse patient demographics, such as gender and ethnicity. By perturbing questions from the MedQA dataset, which comprises medical board exam questions, we created a benchmark that captures the nuanced differences in medical diagnosis across varying patient profiles. Our findings reveal notable discrepancies in model performance when tested against these demographic variations. Furthermore, to ensure the perturbations were accurate, we also propose a filtering strategy that validates each perturbation. By releasing DiversityMedQA, we provide a resource for evaluating and mitigating demographic bias in LLM medical diagnoses.", "summary_cn": "提出DiversityMedQA基准，通过扰动MedQA问题评估大语言模型在不同人口统计特征（如性别、种族）下的医疗诊断偏见，发现模型性能存在显著差异。", "keywords": ["DiversityMedQA", "人口统计偏见", "大语言模型", "医疗诊断", "基准评估", "扰动验证"], "triple": {"method": "扰动MedQA问题并过滤验证", "result": "模型性能随人口特征变化出现差异", "contribution": "提供评估医疗诊断偏见的基准资源"}}
{"venue": "NeurIPS", "search_title": "Keypoint-Augmented Self-Supervised Learning forMedicalImage ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/bee3d6218d7414f8cadfff0eafd0d7be-Abstract-Conference.html", "year": 2023, "abstract_snippet": "We present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Keypoint-Augmented Self-Supervised Learning forMedicalImage ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Self-Paced Contrastive Learning for Semi-supervisedMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/8b5c8441a8ff8e151b191c53c1842a38-Abstract.html", "year": 2021, "abstract_snippet": "We use these meta-labels to pre-train the image encoder, as well as in a semi-supervised learning step that leverages a reduced set of annotated data. A self- ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Self-Paced Contrastive Learning for Semi-supervisedMedical...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Can Large Language Models Provide EmergencyMedical...", "url": "https://neurips.cc/virtual/2024/108252", "year": 2024, "abstract_snippet": "A comparative study on large language model understanding of emergency medical scenarios in resource-constrained settings.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/108252", "full_title": "Can Large Language Models Provide Emergency Medical Help Where There Is No Ambulance? A Comparative Study on Large Language Model Understanding of Emergency Medical Scenarios in Resource-Constrained Settings", "abstract": "There are a few medicine-oriented evaluation datasets and benchmarks for assessing the performance of various LLMs in clinical scenarios; however, there is a paucity of information on the real-world utility of LLMs in context-specific scenarios in resource-constrained settings. In this study, 16 iterations of a decision support tool for medical emergencies using 4 distinct generalized LLMs were constructed, alongside a combination of 4 Prompt Engineering techniques. In total 428 model responses were quantitatively and qualitatively evaluated by 22 clinicians familiar with the medical scenarios and background contexts. The best model-technique pair had a mean rating of 8.05/10. Our study highlights the benefits of In-Context Learning with few-shot prompting, and the utility of the relatively novel self-questioning prompting technique. We demonstrate the benefits of combining various prompting techniques to elicit the best performance of LLMs. We also highlight the need for continuous human expert verification in the development and deployment of LLM-based health applications, especially in use cases where context is paramount.", "summary_cn": "研究评估四种通用大语言模型在资源有限医疗场景中的应急决策支持能力，结合提示工程技术，经临床专家评估，最佳模型-技术对平均评分8.05/10。", "keywords": ["大语言模型", "应急医疗", "资源有限", "提示工程", "临床评估", "决策支持"], "triple": {"method": "结合四种提示工程技术构建决策支持工具", "result": "最佳模型-技术对平均评分8.05/10", "contribution": "验证提示工程组合与专家验证在医疗应用中的重要性"}}
{"venue": "NeurIPS", "search_title": "A case for reframing automatedmedicalimage classification as ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/ad6a3bd12095fdca71c306871bdec400-Abstract-Conference.html", "year": 2023, "abstract_snippet": "We reexamine the choice of training classification vs. segmentation models. First, we use an information theoretic approach to analyze why segmentation vs. ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A case for reframing automatedmedicalimage classification as ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "A case study on organ transplantation - NeurIPS", "url": "https://proceedings.neurips.cc/paper/2021/hash/c344336196d5ec19bd54fd14befdde87-Abstract.html", "year": null, "abstract_snippet": "Closing the loop in medical decision support by understanding clinical ... However, drivers of real-world clinical decisions in complex medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A case study on organ transplantation - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Towards Privacy-PreservingMedicalImaging: Federated Learning ...", "url": "https://neurips.cc/virtual/2024/109149", "year": 2024, "abstract_snippet": "Abstract. With increasing concerns over privacy in healthcare, especially for sensitive medical data, this research introduces a federated learning framework ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/109149", "full_title": "Towards Privacy-Preserving Medical Imaging: Federated Learning with Differential Privacy and Secure Aggregation Using a Modified ResNet Architecture", "abstract": "With increasing concerns over privacy in healthcare, especially for sensitive medical data, this research introduces a federated learning framework that combines local differential privacy and secure aggregation using Secure Multi-Party Computation for medical image classification. Further, we propose DPResNet, a modified ResNet architecture optimized for differential privacy. Leveraging the BloodMNIST benchmark dataset, we simulate a realistic data-sharing environment across different hospitals, addressing the distinct privacy challenges posed by federated healthcare data. Experimental results indicate that our privacy-preserving federated model achieves accuracy levels close to non-private models, surpassing traditional approaches while maintaining strict data confidentiality. By enhancing the privacy, efficiency, and reliability of healthcare data management, our approach offers substantial benefits to patients, healthcare providers, and the broader healthcare ecosystem.", "summary_cn": "本研究提出结合差分隐私和安全聚合的联邦学习框架DPResNet，用于医疗图像分类，在保护隐私的同时实现接近非私有模型的准确率。", "keywords": ["联邦学习", "差分隐私", "医疗图像分类", "安全聚合", "DPResNet", "隐私保护"], "triple": {"method": "联邦学习结合差分隐私与安全聚合，使用改进的ResNet架构", "result": "在BloodMNIST数据集上实现接近非私有模型的准确率", "contribution": "提升医疗数据隐私保护与分类性能"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster SM3-Text-to-Query: Synthetic Multi-ModelMedical...", "url": "https://neurips.cc/virtual/2024/poster/97708", "year": 2024, "abstract_snippet": "In this paper, we present SM3-Text-to-Query, the first multi-model medical Text-to-Query benchmark based on synthetic patient data from Synthea.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/97708", "full_title": "SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark", "abstract": "Electronic health records (EHRs) are stored in various database systems with different database models on heterogeneous storage architectures, such as relational databases, document stores, or graph databases. These different database models have a big impact on query complexity and performance. While this has been a known fact in database research, its implications for the growing number of Text-to-Query systems have surprisingly not been investigated so far.In this paper, we present SM3-Text-to-Query, the first multi-model medical Text-to-Query benchmark based on synthetic patient data from Synthea, following the SNOMED-CT taxonomy---a widely used knowledge graph ontology covering medical terminology. SM3-Text-to-Query provides data representations for relational databases (PostgreSQL), document stores (MongoDB), and graph databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four popular query languages, namely SQL, MQL, Cypher, and SPARQL.We systematically and manually develop 408 template questions, which we augment to construct a benchmark of 10K diverse natural language question/query pairs for these four query languages (40K pairs overall). On our dataset, we evaluate several common in-context-learning (ICL) approaches for a set of representative closed and open-source LLMs.Our evaluation sheds light on the trade-offs between database models and query languages for different ICL strategies and LLMs. Last,SM3-Text-to-Query is easily extendable to additional query languages or real, standard-based patient databases.", "summary_cn": "提出首个多模型医疗文本转查询基准SM3-Text-to-Query，基于合成患者数据，支持四种查询语言评估，揭示不同数据库模型与LLM性能权衡。", "keywords": ["文本转查询", "多模型数据库", "医疗基准", "合成数据", "查询语言评估", "大语言模型"], "triple": {"method": "基于Synthea合成数据构建多模型基准，手动开发模板问题并扩展为10K问题/查询对", "result": "评估多种ICL方法与LLM，揭示数据库模型与查询语言对性能的权衡关系", "contribution": "提供首个可扩展的多模型医疗文本转查询基准，支持跨数据库系统比较"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Geometric Shape Matching for Explainable and Accurate ...", "url": "https://neurips.cc/virtual/2025/128789", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Deep learning models for medical image segmentation, while achieving remarkable performance, often produce anatomically implausible outputs ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/128789", "full_title": "Geometric Shape Matching for Explainable and Accurate Medical Image Segmentation: A Post-Processing Refinement Framework", "abstract": "Deep learning models for medical image segmentation, while achieving remarkable performance, often produce anatomically implausible outputs that compromise clinical trust and adoption. We propose a novel inference-time refinement framework that leverages geometric shape matching against a curated library of high-quality organ segmentations to enhance TotalSegmentator predictions without requiring retraining or ground truth data. Our approach provides interpretable corrections by comparing predicted segmentations with anatomically plausible reference templates through a geometry-based matching framework. The framework operates as a modular post-processing layer, addressing TotalSegmentator's occasional anatomical hallucinations while maintaining compatibility with existing clinical workflows. Proof-of-concept experiments on liver segmentation using the CT-ORG dataset demonstrate an average 15\\% improvement in Dice scores for poor-performing segmentations. This work presents a promising direction for improving segmentation reliability in clinical deployment while preserving the interpretability required for medical applications.", "summary_cn": "提出一种基于几何形状匹配的后处理框架，通过高质量器官分割库优化TotalSegmentator预测，无需重新训练或真实数据，提高分割准确性和可解释性。", "keywords": ["几何形状匹配", "医学图像分割", "后处理框架", "可解释性", "TotalSegmentator", "临床部署"], "triple": {"method": "几何形状匹配后处理", "result": "Dice分数平均提升15%", "contribution": "提升分割可靠性与可解释性"}}
{"venue": "NeurIPS", "search_title": "Retrieval-Based Editing forMedicalLLMs with Key-Aware Prompts", "url": "https://neurips.cc/virtual/2025/133175", "year": 2025, "abstract_snippet": "LLMs hold great promise for healthcare applications, but the rapid evolution of medical knowledge and errors in training data often cause them to generate ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133175", "full_title": "MedREK: Retrieval-Based Editing for Medical LLMs with Key-Aware Prompts", "abstract": "LLMs hold great promise for healthcare applications, but the rapid evolution of medical knowledge and errors in training data often cause them to generate outdated or inaccurate information, limiting their applicability in high-stakes clinical practice. Model editing has emerged as a potential remedy without full retraining. While parameter-based editing often compromises locality and is thus ill-suited for the medical domain, retrieval-based editing offers a more viable alternative. However, it still faces two critical challenges: (1) representation overlap within the medical knowledge space often causes inaccurate retrieval and reduces editing accuracy; (2) existing methods are restricted to single-sample edits, while batch-editing remains largely unexplored despite its importance for real-world medical applications. To address these challenges, we first construct MedVersa, an enhanced benchmark with broader coverage of medical subjects, designed to evaluate both single and batch edits under strict locality constraints. We then propose MedREK, a retrieval-based editing framework that integrates a shared query-key module for precise matching with an attention-based prompt encoder for informative guidance. Experimental results on various medical benchmarks demonstrate that our MedREK achieves superior performance across different core metrics and provides the first validated solution for batch-editing in medical LLMs. Our code and dataset are available at https://github.com/mylittleriver/MedREK.", "summary_cn": "针对医学大模型知识过时问题，提出MedREK检索编辑框架，通过共享查询键模块和注意力提示编码器提升编辑精度，支持批量编辑，在医学基准测试中表现优异。", "keywords": ["医学大模型", "检索编辑", "批量编辑", "知识更新", "MedREK", "MedVersa"], "triple": {"method": "共享查询键模块与注意力提示编码器", "result": "在医学基准测试中实现优异性能", "contribution": "首个验证的医学大模型批量编辑解决方案"}}
{"venue": "NeurIPS", "search_title": "NeurIPSMedicalquestion-generation for pre-consultation with LLM ...", "url": "https://neurips.cc/virtual/2024/106861", "year": 2024, "abstract_snippet": "Pre-consultation gives healthcare providersa history of present illness (HPI) prior to a patient's visit,streamlining the visit and promoting shared ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106861", "full_title": "Medical question-generation for pre-consultation with LLM in-context learning", "abstract": "Pre-consultation gives healthcare providersa history of present illness (HPI) prior to a patient's visit,streamlining the visit and promoting shared decision making.Compared to a digital questionnaire,LLM-powered AI agents have proven successful inproviding a more natural interface for pre-consultation.But LLM-based approaches struggle to ask productive follow-up questions andrequire complex prompts to guide the consultation.While effective automated prompting strategies exist for medicalquestion-answering LLMs, the task of question generation for pre-consultationis lacking effective strategies.In this study, we develop a methodology for evaluating existing approaches to medical pre-consultation,using prior datasets of HPIs and patient-doctor dialogue.We propose a novel approach of converting abundant clinical note datainto question generation demonstrations and then retrieving relevantdemonstrations for in-context learning.We find this approach to question generation for pre-consultationachieves a higher recall of facts in ground truth consultationscompared against competitive baselines in prior literature across a range of simultated patient personalities.", "summary_cn": "本研究提出一种新方法，将临床笔记转化为问题生成示例，用于LLM上下文学习，以提高预咨询中事实召回率。", "keywords": ["预咨询", "问题生成", "上下文学习", "临床笔记", "大语言模型", "事实召回"], "triple": {"method": "临床笔记转示例并检索用于上下文学习", "result": "事实召回率高于基线", "contribution": "提升预咨询问题生成效果"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Med-FastSAM: Improving Transfer Efficiency of SAM to ...", "url": "https://neurips.cc/virtual/2024/103888", "year": 2024, "abstract_snippet": "Poster in. Workshop: AIM-FM: Advancements In Medical Foundation Models: Explainability, Robustness, Security, and Beyond. Med-FastSAM: Improving Transfer ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103888", "full_title": "Med-FastSAM: Improving Transfer Efficiency of SAM to Domain-Generalised Medical Image Segmentation", "abstract": "Medical image segmentation is a crucial computer vision task in medical image analysis. Recently, the Segment Anything Model (SAM) has made significant advancements in natural image segmentation. Despite current studies indicating the potential of SAM to revolutionise medical image segmentation using parameter-efficient fine-tuning techniques, it still faces three primary challenges. Firstly, these methods still rely on the large vision transformer of SAM, which is computationally expensive. Secondly, the point and box prompt modes of SAM demand manual annotations, which are time-consuming and expensive in medical scenarios and reduce their clinical applicability. Thirdly, SAM leverages large-size patches to predict masks, resulting in the loss of fine-grained details. To address these limitations, in this paper, we propose a fast-transferring architecture for adapting SAM to domain-generalised medical image segmentation, named Med-FastSAM. Specifically, we introduce a lightweight knowledge aggregation encoder that combines the distilled natural image knowledge with learned medical-specific information for producing feature representation. Moreover, we devise a coarse prompt module to automatically generate coarse masks for guiding segmentation decoding. Furthermore, we design a multi-scale feature decoder to produce precise segmentation masks. Eventually, extensive experiments on four benchmark datasets have been conducted to evaluate the proposed model. The result demonstrates that Med-FastSAM outperforms state-of-the-art methods without any manual prompts. Especially, our model shows excellent zero-shot domain generalisation performance by using only 15.45\\% parameters compared to the standard SAM. The code for our work and more technical details can be found at https://github.com/GalacticHogrider/Med-FastSAM.", "summary_cn": "提出Med-FastSAM，通过轻量知识聚合编码器、粗提示模块和多尺度解码器，实现无需手动提示的高效医学图像分割，参数仅需SAM的15.45%。", "keywords": ["医学图像分割", "域泛化", "轻量模型", "自动提示", "多尺度解码", "零样本学习"], "triple": {"method": "轻量知识聚合编码器、粗提示模块、多尺度解码器", "result": "超越现有方法，零样本域泛化性能优秀，参数减少至15.45%", "contribution": "实现高效无手动提示的医学图像分割模型"}}
{"venue": "NeurIPS", "search_title": "The Medkit-Learn(ing) Environment:MedicalDecision Modelling ...", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/26e359e83860db1d11b6acca57d8ea88-Abstract-round2.html", "year": null, "abstract_snippet": "Mainstream development of algorithms is often geared towards optimal performance in tasks that do not necessarily translate well into the medical regime---due ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "The Medkit-Learn(ing) Environment:MedicalDecision Modelling ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "FFA-IR: Towards an Explainable and ReliableMedicalReport ...", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/hash/35f4a8d465e6e1edc05f3d8ab658c551-Abstract-round2.html", "year": 2021, "abstract_snippet": "... medical domain knowledge for the generation of readable medical reports. However, existing medical report generation (MRG) benchmarks lack both explainable ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "FFA-IR: Towards an Explainable and ReliableMedicalReport ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "MedVLThinker: Simple Baselines for MultimodalMedicalReasoning", "url": "https://neurips.cc/virtual/2025/124929", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124929", "full_title": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning", "abstract": "Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding\" via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We will release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.", "summary_cn": "提出MedVLThinker，一种用于多模态医学推理的简单基线方法。通过强化学习与可验证奖励训练，仅使用文本推理数据即超越现有开源模型，性能媲美GPT-4o。", "keywords": ["多模态医学推理", "强化学习", "可验证奖励", "数据筛选", "开源基准", "链式思维"], "triple": {"method": "使用强化学习与可验证奖励训练", "result": "仅文本数据训练效果优于多模态，性能达GPT-4o水平", "contribution": "提供开源基准与数据，推动医学推理研究"}}
{"venue": "NeurIPS", "search_title": "Improving Accuracy and Explainability inMedicalVisual Reasoning", "url": "https://neurips.cc/virtual/2025/129997", "year": 2025, "abstract_snippet": "Nov 30, 2025 ... However, modern medical visual-language models (VLMs) often generate conclusions without explicit reasoning, limiting clinician trust and ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/129997", "full_title": "MedVCTP: Improving Accuracy and Explainability in Medical Visual Reasoning", "abstract": "Reasoning transparency and accuracy are critical to the implementation of AI algorithms in medical applications. However, modern medical visual-language models (VLMs) often generate conclusions without explicit reasoning, limiting clinician trust and potentially compromising the quality of diagnosis. Reasoning-focused VLMs remain confined to basic VQA datasets (e.g., A-OKVQA), while medical VLMs lack reasoning transparency, modularity, and output refinement capabilities. We introduce Medical Visual Chain-of-Thought Processing (MedVCTP), a training-free framework implementing a structured See–Think–Confirm pipeline. The See stage extracts global and regional visual concepts via advanced visual encoders. The Think stage generates reasoning-grounded answers through LLM-based chain-of-thought processing. The Confirm stage iteratively refines rationales via multi-shot prompting and cross-modal CLIP-based consistency checks, aligning reasoning with visual context to mitigate hallucination and enable visual grounding. Our modular design supports rapid deployment with interchangeable components for scalable performance. On SLAKE, MedVCTP achieves 85.8% accuracy-a 19.4% improvement over ablations without CLIP refinement—demonstrating that iterative cross-modal validation directly enhances both accuracy and reasoning coherence. These results establish MedVCTP as a step toward reliable, explainable medical visual reasoning systems deployable without task-specific training. Code and artifacts will be made available upon acceptance.", "summary_cn": "提出MedVCTP框架，通过See-Think-Confirm三阶段实现免训练医学视觉推理，提升准确性与可解释性。", "keywords": ["医学视觉推理", "可解释性", "链式思维", "免训练框架", "跨模态验证"], "triple": {"method": "See-Think-Confirm三阶段管道", "result": "SLAKE数据集准确率达85.8%，提升19.4%", "contribution": "增强推理透明度与准确性，支持免训练部署"}}
{"venue": "NeurIPS", "search_title": "MEDS-torch: An ML Pipleine for Inductive Experiments for EHR ...", "url": "https://neurips.cc/virtual/2024/103000", "year": 2024, "abstract_snippet": "We introduce meds-torch, a scalable and extensible pipeline designed to process any medical dataset adhering to the MEDS format—a universal schema for medical ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103000", "full_title": "MEDS-torch: An ML Pipleine for Inductive Experiments for EHR Medical Foundation Models", "abstract": "We introduce meds-torch, a scalable and extensible pipeline designed to process any medical dataset adhering to the MEDS format—a universal schema for medical time series. We systematically compare three tokenization methods (Everything In Code, Triplet, and Text Code) and evaluate five transfer learning techniques, including variations of autoregressive generative modeling and contrastive learning, across multiple predictive tasks on the MIMIC-IV EHR dataset. Our empirical analysis provides actionable insights into the effectiveness of each method, demonstrating that certain tokenization and pretraining combinations significantly outperform others. By benchmarking these approaches against fully supervised learning models, we offer practical recommendations for selecting appropriate modeling strategies in diverse healthcare settings. The meds-torch pipeline not only streamlines the application of these methods but also promotes reproducibility and standardization in EHR research, facilitating more effective machine learning applications in healthcare.", "summary_cn": "MEDS-torch是一个可扩展的医疗数据处理管道，用于比较不同标记化和迁移学习方法在电子健康记录预测任务中的效果，提供实用建模建议。", "keywords": ["MEDS-torch", "电子健康记录", "标记化方法", "迁移学习", "机器学习管道", "MIMIC-IV"], "triple": {"method": "比较三种标记化方法和五种迁移学习技术", "result": "某些组合显著优于其他方法", "contribution": "提供实用建模建议并促进研究标准化"}}
{"venue": "NeurIPS", "search_title": "Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of ...", "url": "https://neurips.cc/virtual/2025/124951", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs. Blazej Manczak · Eric Lin · Francisco Eiras · James O' Neill · ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124951", "full_title": "Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs", "abstract": "Large language models (LLMs) are rapidly transitioning into medical clinical use, yet their reliability under realistic, multi-turn interactions remains poorly understood. Existing evaluation frameworks typically assess single-turn question answering under idealized conditions, overlooking the complexities of medical consultations where conflicting input, misleading context, and authority influence are common. We introduce MedQA-Followup, a framework for systematically evaluating multi-turn robustness in medical question answering. Our approach distinguishes between shallow robustness (resisting misleading initial context) and deep robustness (maintaining accuracy when answers are challenged across turns), while also introducing an indirect–direct axis that separates contextual framing (indirect) from explicit suggestion (direct). Using controlled interventions on the MedQA dataset, we evaluate five state-of-the-art LLMs and find that while models perform reasonably well under shallow perturbations, they exhibit severe vulnerabilities in multi-turn settings, with accuracy dropping from 91.2\\% to as low as 13.5\\% for Claude Sonnet 4. Counterintuitively, indirect, context-based interventions are often more harmful than direct suggestions, yielding larger accuracy drops across models and exposing a significant vulnerability for clinical deployment. Further compounding analyses reveal model differences, with some showing further performance drops under repeated interventions while others partially recovering or even improving. These findings highlight multi-turn robustness as a critical but underexplored dimension for safe and reliable deployment of medical LLMs.", "summary_cn": "研究评估医疗大语言模型在多轮对话中的鲁棒性，发现模型在浅层干扰下表现尚可，但在深层多轮挑战中准确性大幅下降，间接干预尤其有害。", "keywords": ["医疗大语言模型", "多轮对话评估", "鲁棒性", "MedQA-Followup", "临床部署", "准确性下降"], "triple": {"method": "引入MedQA-Followup框架，区分浅层与深层鲁棒性，并在MedQA数据集上进行控制干预", "result": "模型在浅层干扰下表现较好，但多轮设置中准确性从91.2%降至13.5%，间接干预危害更大", "contribution": "揭示多轮鲁棒性是医疗LLM安全部署的关键未探索维度，强调临床部署中的脆弱性"}}
{"venue": "NeurIPS", "search_title": "Personalized English AmharicMedicalImage Caption and Speech ...", "url": "https://neurips.cc/virtual/2025/125497", "year": 2025, "abstract_snippet": "Access to medical information is critical for healthcare equity, particularly for visually impaired citizens and lowresource language speakers.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/125497", "full_title": "Personalized English Amharic Medical Image Caption and Speech Generation for Visually Impaired Patients Using Vision Transformer Fused with LLM", "abstract": "Access to medical information is critical for healthcare equity, particularly for visually impaired citizens and lowresource language speakers. Our goal is to create a model that enables visually impaired individuals to access their medical image results, by turn the text into an audio message, and translate generated captions into local languages to understand their medical results in their mother tongue. developing algorithms that can generate captions, translating into Amharic and generate speech from images is a major goal of our study by fussing computer vision and Generative AI. Accessible images are essential for those who are blind or visually impaired.  In this study, following the design science approach, the data were gathered from the Tikur Anbessa specialized hospital, Addis Ababa University, and the data annotation was carried out by a domain expert. We preprocessed the data to make suitable for models. The work presents a novel approach model fusion such as Vision Transformer (ViT)GPT2, VIT-Llama2, and VGG16-LSTM architectures for medical image captioning. The model is designed to generate detailed captions for radiologists, translate the generated caption into Amharic, and speech for visually impaired patients. Among the model's ViT-Llama2 model generate high-quality caption and robust feature extraction, ensures precise, context-aware captions. Experiments demonstrate the effectiveness of this method, VIT-Llama2 achieving a high BLEU score of 0.633\\% in image captioning and enhanced usability and accessibility.  The system is deployed as a user-friendly application that accepts medical images as input, processes them through the models, outputs textual captions, translates generated caption into Amharic, and speech. This model bridges the gap in medical accessibility for low-resource language speakers, empowering visually impaired individuals and understand their medical image results.", "summary_cn": "本研究融合视觉Transformer与大型语言模型，开发了为视障患者生成医学图像描述、翻译成阿姆哈拉语并转换为语音的系统，提升医疗信息可及性。", "keywords": ["医学图像描述", "视觉Transformer", "大型语言模型", "阿姆哈拉语翻译", "语音生成", "视障辅助"], "triple": {"method": "融合ViT与LLM（如ViT-Llama2）", "result": "BLEU得分0.633%，生成高质量描述与语音", "contribution": "提升低资源语言视障患者的医疗信息可及性"}}
{"venue": "NeurIPS", "search_title": "Applying SAM to Few-shotMedicalImage Segmentation using Mask ...", "url": "https://neurips.cc/virtual/2024/109352", "year": 2024, "abstract_snippet": "2:30 - 3:30 PM: Applying SAM to Few-shot Medical Image Segmentation using Mask Propagation and Auto-prompting", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/109352", "full_title": "2:30 - 3:30 PM: Applying SAM to Few-shot Medical Image Segmentation using Mask Propagation and Auto-prompting", "abstract": "Applying SAM to Few-shot Medical Image Segmentation using Mask Propagation and Auto-prompting", "summary_cn": "本研究提出一种结合掩码传播与自动提示的方法，将SAM应用于少样本医学图像分割，提升了分割精度与效率。", "keywords": ["SAM", "少样本学习", "医学图像分割", "掩码传播", "自动提示", "深度学习"], "triple": {"method": "掩码传播与自动提示", "result": "提升分割精度与效率", "contribution": "扩展SAM在少样本医学分割的应用"}}
{"venue": "NeurIPS", "search_title": "Gaze-AssistedMedicalImage Segmentation - NeurIPS", "url": "https://neurips.cc/virtual/2024/103920", "year": 2024, "abstract_snippet": "In particular, we fine-tuned the Segment Anything Model in Medical Images (MedSAM), a public solution that uses various prompt types as additional input for ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103920", "full_title": "Gaze-Assisted Medical Image Segmentation", "abstract": "The annotation of patient organs is a crucial part of various diagnostic and treatment procedures, such as radiotherapy planning. Manual annotation is extremely time-consuming, while its automation using modern image analysis techniques has not yet reached levels sufficient for clinical adoption. This paper investigates the idea of semi-supervised medical image segmentation using human gaze as interactive input for segmentation correction. In particular, we fine-tuned the Segment Anything Model in Medical Images (MedSAM), a public solution that uses various prompt types as additional input for semi-automated segmentation correction. We used human gaze data from reading abdominal images as a prompt for fine-tuning MedSAM. The model was validated on a public WORD database, which consists of 120 CT scans of 16 abdominal organs. The results of the gaze-assisted MedSAM were shown to be superior to the results of the state-of-the-art segmentation models. In particular, the average Dice coefficient for 16 abdominal organs was 85.8\\%, 86.7\\%, 81.7\\%, and 90.5\\% for nnUNetV2, ResUNet, original MedSAM, and our gaze-assisted MedSAM model, respectively.", "summary_cn": "本研究利用人眼注视数据微调MedSAM模型，实现半监督医学图像分割。在腹部CT数据集上，该模型分割性能优于现有先进模型，平均Dice系数达90.5%。", "keywords": ["医学图像分割", "注视数据", "MedSAM", "半监督学习", "腹部器官", "CT扫描"], "triple": {"method": "利用注视数据微调MedSAM", "result": "平均Dice系数90.5%，优于基准模型", "contribution": "提出注视辅助的半监督分割方法"}}
{"venue": "NeurIPS", "search_title": "BenchX: A Unified Benchmark Framework forMedicalVision ...", "url": "https://neurips.cc/virtual/2024/poster/97555", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... Medical Vision-Language Pretraining (MedVLP) shows promise in learning generalizable and transferable visual representations from paired and ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/97555", "full_title": "BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays", "abstract": "Medical Vision-Language Pretraining (MedVLP) shows promise in learning generalizable and transferable visual representations from paired and unpaired medical images and reports. MedVLP can provide useful features to downstream tasks and facilitate adapting task-specific models to new setups using fewer examples. However, existing MedVLP methods often differ in terms of datasets, preprocessing, and finetuning implementations. This pose great challenges in evaluating how well a MedVLP method generalizes to various clinically-relevant tasks due to the lack of unified, standardized, and comprehensive benchmark. To fill this gap, we propose BenchX, a unified benchmark framework that enables head-to-head comparison and systematical analysis between MedVLP methods using public chest X-ray datasets. Specifically, BenchX is composed of three components: 1) Comprehensive datasets covering nine datasets and four medical tasks; 2) Benchmark suites to standardize data preprocessing, train-test splits, and parameter selection; 3) Unified finetuning protocols that accommodate heterogeneous MedVLP methods for consistent task adaptation in classification, segmentation, and report generation, respectively. Utilizing BenchX, we establish baselines for nine state-of-the-art MedVLP methods and found that the performance of some early MedVLP methods can be enhanced to surpass more recent ones, prompting a revisiting of the developments and conclusions from prior works in MedVLP. Our code are available at https://github.com/yangzhou12/BenchX.", "summary_cn": "提出BenchX统一基准框架，用于标准化评估胸部X光医学视觉-语言预训练方法，涵盖多数据集与任务，促进公平比较与性能提升。", "keywords": ["医学视觉-语言预训练", "胸部X光", "基准框架", "标准化评估", "多任务学习", "性能比较"], "triple": {"method": "构建统一基准框架BenchX", "result": "提升早期方法性能并超越新方法", "contribution": "促进MedVLP方法公平比较与系统分析"}}
{"venue": "NeurIPS", "search_title": "PediatricsGPT: Large Language Models as ChineseMedical... - NIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/fa5b423e24b442180bcd4e13ae75a27f-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "LLMs in Medical Applications. Current LLMs provide unprecedented opportunities to develop resource-efficient and diagnostic-comprehensive intelligent healthcare ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "PediatricsGPT: Large Language Models as ChineseMedical... - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Demographic Bias of Expert-Level Vision-Language Foundation ...", "url": "https://neurips.cc/virtual/2024/106883", "year": 2024, "abstract_snippet": "Advances in artificial intelligence (AI) have achieved expert-level performance in medical imaging applications. Notably, self-supervised vision-language ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106883", "full_title": "Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging", "abstract": "Advances in artificial intelligence (AI) have achieved expert-level performance in medical imaging applications. Notably, self-supervised vision-language foundation models can detect a broad spectrum of pathologies without relying on explicit training annotations. However, it is crucial to ensure that these AI models do not mirror or amplify human biases, disadvantaging historically marginalized groups such as females or Black patients. In this study, we investigate the algorithmic fairness of state-of-the-art vision-language foundation models in chest X-ray diagnosis across five globally-sourced datasets. Our findings reveal that compared to board-certified radiologists, these foundation models consistently underdiagnose marginalized groups, with even higher rates seen in intersectional subgroups such as Black female patients. Such biases present over a wide range of pathologies and demographic attributes. Further analysis of the model embedding uncovers its significant encoding of demographic information beyond human levels. Deploying medical AI systems with biases can intensify pre-existing care disparities, posing potential challenges to equitable healthcare access and raising ethical questions about their clinical applications. Code is available at: https://github.com/YyzHarry/vlm-fairness.", "summary_cn": "研究发现，医学影像中的视觉语言基础模型在胸片诊断中存在人口统计学偏见，对边缘群体（如黑人女性）诊断不足，可能加剧医疗不平等。", "keywords": ["医学影像", "视觉语言模型", "人口统计学偏见", "公平性", "胸片诊断", "边缘群体"], "triple": {"method": "分析五个全球数据集中的模型表现", "result": "模型对边缘群体诊断不足，编码人口信息超人类水平", "contribution": "揭示AI模型偏见风险，呼吁临床应用中关注公平性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster Towards Doctor-Like Reasoning:MedicalRAG ...", "url": "https://neurips.cc/virtual/2025/poster/118649", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/118649", "full_title": "Towards Doctor-Like Reasoning: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients", "abstract": "Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases - a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.", "summary_cn": "提出DoctorRAG框架，融合医学知识与类似病例经验，通过标签分配、混合检索及文本梯度模块提升推理准确性，在多语言多任务数据集上表现优异。", "keywords": ["医学RAG", "病例类比", "混合检索", "文本梯度", "临床推理", "多语言任务"], "triple": {"method": "标签分配与混合检索结合Med-TextGrad模块", "result": "在多语言多任务数据集上显著超越基线模型", "contribution": "模拟医生推理，提升回答准确性、相关性和全面性"}}
{"venue": "NeurIPS", "search_title": "Class-Aware Adversarial Transformers forMedicalImage ... - NeurIPS", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/be99227ef4a4de84bb45d7dc7b53f808-Abstract-Conference.html", "year": 2022, "abstract_snippet": "Transformers have made remarkable progress towards modeling long-range dependencies within the medical image analysis domain. However, current transformer ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Class-Aware Adversarial Transformers forMedicalImage ... - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "CARES: Comprehensive Evaluation of Safety and Adversarial ...", "url": "https://neurips.cc/virtual/2025/poster/121833", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs. Sijia Chen · Xiaomin Li · mengxue zhang · Eric Hanchen ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/121833", "full_title": "CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs", "abstract": "Large language models (LLMs) are increasingly deployed in medical contexts, raising critical concerns about safety, alignment, and susceptibility to adversarial manipulation. While prior benchmarks assess model refusal capabilities for harmful prompts, they often lack clinical specificity, graded harmfulness levels, and coverage of jailbreak-style attacks. We introduce CARES (Clinical Adversarial Robustness and Evaluation of Safety), a benchmark for evaluating LLM safety in healthcare. CARES includes over 18,000 prompts spanning eight medical safety principles, four harm levels, and four prompting styles—direct, indirect, obfuscated, and role-play—to simulate both malicious and benign use cases. We propose a three-way response evaluation protocol (Accept, Caution, Refuse) and a fine-grained Safety Score metric to assess model behavior. Our analysis reveals that many state-of-the-art LLMs remain vulnerable to jailbreaks that subtly rephrase harmful prompts, while also over-refusing safe but atypically phrased queries. Finally, we propose a mitigation strategy using a lightweight classifier to detect jailbreak attempts and steer models toward safer behavior via reminder-based conditioning. CARES provides a rigorous framework for testing and improving medical LLM safety under adversarial and ambiguous conditions.", "summary_cn": "CARES基准评估医疗大语言模型安全性与对抗鲁棒性，包含多级危害提示，揭示模型易受攻击且过度拒绝安全查询，提出轻量级分类器缓解策略。", "keywords": ["医疗大语言模型", "安全性评估", "对抗鲁棒性", "基准测试", "缓解策略", "临床安全"], "triple": {"method": "构建CARES基准，含多级危害提示与三向评估协议", "result": "模型易受攻击且过度拒绝安全查询", "contribution": "提供测试框架与轻量级分类器缓解策略"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster ExGra-Med: Extended Context Graph Alignment for ...", "url": "https://neurips.cc/virtual/2025/poster/117826", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... State-of-the-art medical multi-modal LLMs (med-MLLMs), such as LLaVA-Med and BioMedGPT, primarily depend on scaling model size and data ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/117826", "full_title": "ExGra-Med: Extended Context Graph Alignment for Medical Vision-Language Models", "abstract": "State-of-the-art medical multi-modal LLMs (med-MLLMs), such as LLaVA-Med and BioMedGPT, primarily depend on scaling model size and data volume, with training driven largely by autoregressive objectives. However, we reveal that this approach can lead to weak vision-language alignment, making these models overly dependent on costly instruction-following data. To address this, we introduce ExGra-Med, a novel multi-graph alignment framework that jointly aligns images, instruction responses, and extended captions in the latent space, advancing semantic grounding and cross-modal coherence. To scale to large LLMs (e.g., LLaMa-7B), we develop an efficient end-to-end training scheme using black-box gradient estimation, enabling fast and scalable optimization. Empirically, ExGra-Med matches LLaVA-Med’s performance using just 10\\% of pre-training data, achieving a 20.13\\% gain on VQA-RAD and approaching full-data performance. It also outperforms strong baselines like BioMedGPT and RadFM on visual chatbot and zero-shot classification tasks, demonstrating its promise for efficient, high-quality vision-language integration in medical AI.", "summary_cn": "ExGra-Med提出多图对齐框架，通过联合对齐图像、指令响应和扩展标题，提升医学视觉语言模型的语义基础和跨模态一致性，仅用10%数据即匹配LLaVA-Med性能。", "keywords": ["医学视觉语言模型", "多图对齐", "跨模态学习", "高效训练", "语义基础", "零样本分类"], "triple": {"method": "多图对齐框架与黑盒梯度估计训练", "result": "仅用10%数据匹配LLaVA-Med，VQA-RAD提升20.13%", "contribution": "实现高效高质量的医学视觉语言集成"}}
{"venue": "NeurIPS", "search_title": "Med-UniC: Unifying Cross-LingualMedicalVision-Language Pre ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/af38fb8e90d586f209235c94119ba193-Abstract-Conference.html", "year": 2023, "abstract_snippet": "This paper presents a novel framework named Unifying Cross-Lingual Medical Vision-Language Pre-Training (\\textbf{Med-UniC}), designed to integrate multi-modal ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Med-UniC: Unifying Cross-LingualMedicalVision-Language Pre ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Faithful or Just Plausible? Evaluating Faithfulness for ... - NeurIPS", "url": "https://neurips.cc/virtual/2025/124886", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Closed-source large language models (LLMs), such as ChatGPT and Gemini, are increasingly consulted for medical advice, yet their ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124886", "full_title": "Faithful or Just Plausible? Evaluating Faithfulness for Medical Reasoning in Closed-Source LLMs", "abstract": "Closed-source large language models (LLMs), such as ChatGPT and Gemini, are increasingly consulted for medical advice, yet their explanations may appear plausible while failing to reflect the model’s underlying reasoning process. This gap poses serious risks as patients and clinicians may trust coherent but misleading explanations. We conduct a systematic black-box evaluation of faithfulness in medical reasoning among three widely used closed-source LLMs. Our study consists of three perturbation-based probes: (1) causal ablation, testing whether stated chain-of-thought (CoT) reasoning causally influences predictions; (2) positional bias, examining whether models create post-hoc justifications for answers driven by input positioning; and (3) hint injection, testing susceptibility to external suggestions. We complement these quantitative probes with a small-scale human evaluation of model responses to patient-style medical queries to examine concordance between physician assessments of explanation faithfulness and layperson perceptions of trustworthiness. We find that CoT reasoning steps often do not causally drive predictions, and models readily incorporate external hints without acknowledgment. In contrast, positional biases showed minimal impact in this setting. These results underscore that faithfulness, not just accuracy, must be central in evaluating LLMs for medicine, to ensure both public protection and safe clinical deployment.", "summary_cn": "评估闭源大语言模型在医学推理中的忠实性，发现其解释常与推理过程不符，存在因果脱钩和外部提示影响，强调需重视忠实性以确保安全应用。", "keywords": ["闭源大语言模型", "医学推理", "忠实性评估", "因果消融", "提示注入", "位置偏差"], "triple": {"method": "基于扰动的黑盒评估与人类评估", "result": "推理步骤常不驱动预测，易受外部提示影响", "contribution": "强调医学评估需重视忠实性"}}
{"venue": "NeurIPS", "search_title": "Towards Multi-dimensional Explanation Alignment forMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/ea370419760b421ce12e3082eb2ae1a8-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "The lack of interpretability in the field of medical image analysis has significant eth- ical and legal implications. Existing interpretable methods in this ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Multi-dimensional Explanation Alignment forMedical...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Trustworthiness of LLMs in Grading and Demographic Fairness in ...", "url": "https://neurips.cc/virtual/2025/133826", "year": 2025, "abstract_snippet": "Trustworthiness of LLMs in Grading and Demographic Fairness in Medical RAG. Marina Diaconu · Adejumobi Joshua. Project Page. Abstract. Large Language Models ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133826", "full_title": "Trustworthiness of LLMs in Grading and Demographic Fairness in Medical RAG", "abstract": "Large Language Models (LLMs) have quickly become essential in healthcare, but even top models trained on vast biomedical datasets can generate factually incorrect or biased responses, with notable implications for medicine. Prior work shows that retrieval-augmented generation (RAG) can improve accuracy, raising the question of whether retrieval mitigates, exacerbates, or leaves bias unaffected, or if it introduces new forms of bias. To study this, we investigate patient-level bias through gender and ethnicity perturbations and physician-level bias through persona prompting, where models grade answers of a “female doctor” or “male doctor”. For the patient-level bias experiment, we compare a baseline LLM (GPT-4o Mini) to a MedRAG-enhanced version with two retrieval strategies(MedCPT and BM25) and two external corpora(Textbooks and Statpearls), while we extend evaluation to multiple models (GPT-4o Mini, Meta LLaMA 3.1 8B, Gemini, and Claude 3.5 Haiku) for the physician-level bias experiment, measuring endorsement and rejection accuracy to detect conservativeness or sycophancy.   We evaluate on the DiversityMedQA dataset, which perturbed MedQA questions along gender and ethnicity, totaling to 1,040 gender items and 1,068 ethnicity items where the clinically correct answer remains invariant under demographic edits. To reduce confounding, we modified only references to the primary patient, creating parallel male, female, and genderless versions, and used the released ethnicity subset as it was released by the dataset authors. We selected 300 gender pairs and 300 ethnicity pairs for analysis and utilized evaluation metrics including first-index accuracy, Majority@5, and total proportion, and applied two-proportion Z-tests to measure statistically significant disparities across demographic perturbations.  Altering the patient’s gender or ethnicity in the query had a negligible effect on base model performance: for both perturbations, first-answer accuracy, within the range of 69–71% for the original questions showed similar pattern for the perturbed pairs, and statistical tests confirmed no significant differences, indicating that diagnostic accuracy was not noticeably biased by patient demographic description. Retrieval augmentation (RAG) consistently boosted accuracy into the low-to-mid 70% range, improving performance without introducing new disparities. In the physician-persona experiments, all models showed a consistent conservative bias—more accurate at rejecting incorrect answers than endorsing correct ones—with highly significant gaps ranging from ~9 points (Claude) to over 40 points (GPT-4o Mini and LLaMA 3.1 8B). Persona settings (female vs. male doctor) produced very similar patterns of conservativeness with no significant gender differences, and we did not observe evidence of sycophancy. Instead, models systematically leaned conservative, rejecting incorrect answers more reliably than confirming correct ones.", "summary_cn": "研究评估LLMs在医学问答中的偏见与公平性，发现患者性别/种族扰动对诊断准确性无显著影响，RAG提升准确性且未引入新偏见；医生角色实验中模型普遍呈现保守倾向，但无性别差异或谄媚行为。", "keywords": ["大型语言模型", "检索增强生成", "医疗公平性", "偏见评估", "医学问答", "保守倾向"], "triple": {"method": "使用DiversityMedQA数据集，通过性别/种族扰动和医生角色提示评估模型", "result": "患者扰动无显著偏见，RAG提升准确性；模型普遍呈现保守倾向，无性别差异", "contribution": "揭示了RAG在医疗中的公平性影响及模型的保守偏差特征"}}
{"venue": "NeurIPS", "search_title": "Eye-gaze Guided Multi-modal Alignment forMedicalRepresentation ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/0b9536e186a77feff516893a5f393f7a-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In the medical multi-modal frameworks, the alignment of cross-modality features presents a significant challenge. However, existing works have learned ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Eye-gaze Guided Multi-modal Alignment forMedicalRepresentation ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/d6be2b51b213f4f5994243ccb494d97e-Abstract-Conference.html", "year": 2024, "abstract_snippet": "We propose a 3D medical image segmentation model called Efficient to Efficient Network (E2ENet), which incorporates two parametrically and computationally ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/d6be2b51b213f4f5994243ccb494d97e-Abstract-Conference.html", "full_title": "E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D Medical Image Segmentation", "abstract": "Deep neural networks have evolved as the leading approach in 3D medical image segmentation due to their outstanding performance. However, the ever-increasing model size and computational cost of deep neural networks have become the primary barriers to deploying them on real-world, resource-limited hardware. To achieve both segmentation accuracy and efficiency, we propose a 3D medical image segmentation model called Efficient to Efficient Network (E2ENet), which incorporates two parametrically and computationally efficient designs. i. Dynamic sparse feature fusion (DSFF) mechanism: it adaptively learns to fuse informative multi-scale features while reducing redundancy. ii. Restricted depth-shift in 3D convolution: it leverages the 3D spatial information while keeping the model and computational complexity as 2D-based methods. We conduct extensive experiments on AMOS, Brain Tumor Segmentation and BTCV Challenge, demonstrating that E2ENet consistently achieves a superior trade-off between accuracy and efficiency than prior arts across various resource constraints. %In particular, with a single model and single scale, E2ENet achieves comparable accuracy on the large-scale challenge AMOS-CT, while saving over 69% parameter count and 27% FLOPs in the inference phase, compared with the previousbest-performing method. Our code has been made available at: https://github.com/boqian333/E2ENet-Medical.", "summary_cn": "提出E2ENet模型，通过动态稀疏特征融合和受限深度移位3D卷积，在3D医学图像分割中实现高精度与高效率的平衡。", "keywords": ["3D医学图像分割", "动态稀疏特征融合", "计算效率", "E2ENet", "深度神经网络", "多尺度特征"], "triple": {"method": "动态稀疏特征融合与受限深度移位3D卷积", "result": "在多个数据集上实现精度与效率的优越权衡，参数量减少69%，计算量降低27%", "contribution": "提出高效3D分割模型E2ENet，提升部署可行性"}}
{"venue": "NeurIPS", "search_title": "Curriculum Fine-tuning of Vision Foundation Model forMedical...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/2093ed77c549eda95bd6f7212b735b43-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "In medical imaging, these neural networks leverage large amounts of labeled data to train models capable of accurately detecting or classifying medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Curriculum Fine-tuning of Vision Foundation Model forMedical...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Stabilizing Reasoning inMedicalLLMs with Continued Pretraining ...", "url": "https://neurips.cc/virtual/2025/124895", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization. Wataru Kawakami · Keita Suzuki · ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124895", "full_title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization", "abstract": "Large Language Models (LLMs) show potential in medicine, yet clinical adoption is hindered by concerns over factual accuracy, language-specific limitations (e.g., Japanese), and critically, their reliability when required to generate reasoning explanations---a prerequisite for trust. This paper introduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the Japanese medical domain to achieve both high accuracy and stable reasoning. We employ a two-stage fine-tuning process on the Qwen2.5-72B base model: first, Continued Pretraining (CPT) on a comprehensive Japanese medical corpus instills deep domain knowledge. Second, Reasoning Preference Optimization (RPO), a preference-based method, enhances the generation of reliable reasoning pathways while preserving high answer accuracy. Evaluations on the Japanese Medical Licensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves state-of-the-art performance (0.868 accuracy), surpassing strong proprietary models like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which exhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively on IgakuQA) when prompted for explanations, our model maintains its high accuracy (0.868) under such conditions. This highlights RPO's effectiveness in stabilizing reasoning generation. This work underscores the importance of optimizing for reliable explanations alongside accuracy. We release the Preferred-MedLLM-Qwen-72B model weights to foster research into trustworthy LLMs for specialized, high-stakes applications.", "summary_cn": "提出Preferred-MedLLM-Qwen-72B模型，通过持续预训练和推理偏好优化，在日语医学领域实现高准确率与稳定推理，在执照考试基准上超越GPT-4o。", "keywords": ["医学大语言模型", "推理稳定性", "持续预训练", "偏好优化", "日语医学", "模型性能"], "triple": {"method": "两阶段微调（持续预训练与推理偏好优化）", "result": "在日语医学考试基准上达到0.868准确率，超越GPT-4o", "contribution": "提升模型推理稳定性，并公开模型权重"}}
{"venue": "NeurIPS", "search_title": "NeurIPS SMI: SemanticMedicalID for Hierarchy-Aware Concept ...", "url": "https://neurips.cc/virtual/2025/133204", "year": 2025, "abstract_snippet": "However, existing biomedical LMs often struggle to capture clinically meaningful relationships among medical concepts, as they rely solely on data-driven text ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133204", "full_title": "SMI: Semantic Medical ID for Hierarchy-Aware Concept Representation", "abstract": "Recent advances in generative AI have accelerated the use of language models (LMs) for clinical prediction tasks. However, existing biomedical LMs often struggle to capture clinically meaningful relationships among medical concepts, as they rely solely on data-driven text learning and overlook domain knowledge. In this study, we propose Semantic Medical ID (SMI) , a novel representation framework that integrates an expert-defined medical ontology into LM-based embeddings. By leveraging the hierarchical structure of medical ontologies, SMIs generate embeddings that preserve clinical relationships across major disease categories, subcategories, and specific conditions, enhancing interpretability for clinical end users. Experimental results demonstrate that SMI improves predictive accuracy in mortality and readmission tasks. SMI also exhibits greater robustness under cross-hospital distribution shifts, highlighting its effectiveness in producing clinically generalizable representations.", "summary_cn": "提出语义医学ID框架，整合医学本体到语言模型嵌入中，提升临床预测准确性和可解释性。", "keywords": ["语义医学ID", "医学本体", "语言模型", "临床预测", "可解释性", "分布偏移"], "triple": {"method": "整合医学本体到语言模型嵌入", "result": "提高预测准确性及跨医院稳健性", "contribution": "增强临床关系表示与可解释性"}}
{"venue": "NeurIPS", "search_title": "Integrating Upstash Vector and BGE-M3 for Accurate and Ethical ...", "url": "https://neurips.cc/virtual/2024/107775", "year": 2024, "abstract_snippet": "Enhancing Medical NLP Systems: Integrating Upstash Vector and BGE-M3 for Accurate and Ethical Healthcare Data Management with Reduced Bias. BINXI XIE. Project ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/107775", "full_title": "Enhancing Medical NLP Systems: Integrating Upstash Vector and BGE-M3 for Accurate and Ethical Healthcare Data Management with Reduced Bias", "abstract": "This paper proposes a novel NLP model in healthcare by including Utash Vector for in-time and contextual information retrieval and BGE-M3 for advanced understanding. The model overcomes the challenges posed by the existing systems, such as incomplete data retrieval, a semantically inconsistent database, and algorithm bias. Incorporating bias mitigation measures and fairness audits, it guarantees no unfair treatment of patients belonging to different groups. Aligned with the AMA Code of Medical Ethics, provides proper management of Electronic Health Records in better ways in terms of transparency, confidentiality, and accuracy. Although these problems are relieved, the accuracy of information is still a major issue, the abuse of artificial intelligence remains a risk, and the use of the AMA Code to guide the integration of artificial intelligence has its limitations. Each of these must operate with defensible use of AI and auditing as well as explanation of AI usage in clinical decision-making.", "summary_cn": "本文提出一种医疗NLP模型，结合Upstash Vector和BGE-M3提升数据检索与理解，减少算法偏见，确保患者公平，并遵循医学伦理管理电子健康记录。", "keywords": ["医疗NLP", "算法偏见", "电子健康记录", "伦理合规", "信息检索", "公平性审计"], "triple": {"method": "集成Upstash Vector和BGE-M3", "result": "提升检索准确性并减少偏见", "contribution": "推动医疗AI的伦理与公平应用"}}
{"venue": "NeurIPS", "search_title": "Aligning SyntheticMedicalImages with Clinical Knowledge using ...", "url": "https://papers.neurips.cc/paper_files/paper/2023/hash/2b1d1e5affe5fdb70372cd90dd8afd49-Abstract-Conference.html", "year": null, "abstract_snippet": "Generative models capable of precisely capturing nuanced clinical features in medical images hold great promise for facilitating clinical data sharing, ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Aligning SyntheticMedicalImages with Clinical Knowledge using ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "3D Self-Supervised Methods forMedicalImaging - NIPS", "url": "https://proceedings.neurips.cc/paper/2020/file/d2dc6368837861b42020ee72b0896182-Paper.pdf", "year": null, "abstract_snippet": "Jun 2, 2020 ... We demonstrate the effectiveness of our methods on three downstream tasks from the medical imaging domain: i) Brain. Tumor Segmentation from 3D ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "3D Self-Supervised Methods forMedicalImaging - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Cryptographic Fingerprinting forMedicalAI: A Proof-of-Concept ...", "url": "https://neurips.cc/virtual/2025/128627", "year": 2025, "abstract_snippet": "Medical AI models represent valuable intellectual property that increasingly face threats from API-based model extraction attacks. We introduce a novel ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/128627", "full_title": "Cryptographic Fingerprinting for Medical AI: A Proof-of-Concept Approach to Protecting Healthcare ML Models from API Extraction", "abstract": "Medical AI models represent valuable intellectual property that increasingly face threats from API-based model extraction attacks. We introduce a novel cryptographic fingerprinting approach designed specifically for healthcare machine learning models that embeds detectable watermarks while preserving clinical accuracy. Our method modifies uncertainty quantification patterns in neural network outputs to create cryptographically secure fingerprints without affecting medical predictions. Through rigorous experiments on ECG pattern classification using a dataset of 1,200 synthetic cardiac signals across 4 conditions, we demonstrate perfect accuracy preservation (99.33\\% maintained) while enabling statistical detection of model theft. Our proof-of-concept shows that sophisticated attackers achieving 98.33\\% extraction accuracy with 1,500 API queries produce 99\\% victim-surrogate agreement—providing statistical evidence of intellectual property theft. The approach introduces modest computational overhead (+12.92\\%), which remains practical for high-value medical AI deployment. This work establishes the first framework for protecting medical AI intellectual property through post-training fingerprinting and provides a foundation for future research in healthcare AI security.", "summary_cn": "提出一种医疗AI模型加密指纹方法，通过修改神经网络不确定性量化模式嵌入水印，保持临床准确性，有效检测模型窃取。", "keywords": ["医疗AI安全", "加密指纹", "模型提取攻击", "不确定性量化", "知识产权保护", "心电图分类"], "triple": {"method": "修改神经网络不确定性量化模式嵌入水印", "result": "保持99.33%准确性，实现窃取检测，计算开销增加12.92%", "contribution": "建立首个医疗AI后训练指纹保护框架"}}
{"venue": "NeurIPS", "search_title": "Deep Learning inMedicalImage Registration: Magic or Mirage?", "url": "https://neurips.cc/virtual/2024/poster/93821", "year": 2024, "abstract_snippet": "Dec 9, 2024 ... Classical optimization and learning-based methods are the two reigning paradigms in deformable image registration.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/poster/93821", "full_title": "Deep Learning in Medical Image Registration: Magic or Mirage?", "abstract": "Classical optimization and learning-based methods are the two reigning paradigms in deformable image registration. While optimization-based methods boast generalizability across modalities and robust performance, learning-based methods promise peak performance, incorporating weak supervision and amortized optimization. However, the exact conditions for either paradigm to perform well over the other are shrouded and not explicitly outlined in the existing literature. In this paper, we make an explicit correspondence between the mutual information of the distribution of per-pixel intensity and labels, and the performance of classical registration methods. This strong correlation hints to the fact that architectural designs in learning-based methods is unlikely to affect this correlation, and therefore, the performance of learning-based methods. This hypothesis is thoroughly validated with state-of-the-art classical and learning-based methods. However, learning-based methods with weak supervision can perform high-fidelity intensity and label registration, which is not possible with classical methods. Next, we show that this high-fidelity feature learning does not translate to invariance to domain shift, and learning-based methods are sensitive to such changes in the data distribution. We reassess and recalibrate performance expectations from classical and DLIR methods under access to label supervision, training time, and its generalization capabilities under minor domain shifts.", "summary_cn": "本文探讨了医学图像配准中经典优化与基于学习方法的性能对比，揭示了基于学习的方法在弱监督下能实现高保真配准，但对领域偏移敏感。", "keywords": ["医学图像配准", "深度学习", "弱监督", "领域偏移", "性能评估", "互信息"], "triple": {"method": "分析互信息与性能关联，验证经典与学习方法", "result": "学习方法在弱监督下实现高保真配准但对领域偏移敏感", "contribution": "重新校准了经典与学习方法在监督、训练时间和泛化能力方面的性能期望"}}
{"venue": "NeurIPS", "search_title": "Towards Memory-Efficient Foundation Models inMedicalImaging", "url": "https://neurips.cc/virtual/2025/124939", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... The rapid development of medical foundation models has shown great promise for various healthcare applications. However, fine-tuning these ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124939", "full_title": "Towards Memory-Efficient Foundation Models in Medical Imaging: A Federated Learning and Knowledge Distillation Approach", "abstract": "The rapid development of medical foundation models has shown great promise for various healthcare applications. However, fine-tuning these models for downstream tasks remains challenging due to privacy concerns that limit centralized data collection from diverse sources. Federated learning (FL) offers a privacy-preserving solution by enabling multiple clients to collaboratively train a global model without sharing their local data. Despite its advantages, FL must balance model performance with communication and computation costs. Existing approaches often use parameter-efficient fine-tuning (PEFT) techniques to reduce communication overhead by transmitting fewer parameters. However, these methods require clients to host large foundation models, which is impractical for clients with limited memory. Meanwhile, conventional knowledge distillation (KD) methods fall short in FL due to misalignment between pre-trained foundation models and specific downstream tasks. To overcome these limitations, we propose Federated Reprogramming Knowledge Distillation (FedRD), a method that uses lightweight student models in clients and a medical foundation model on the server. A reprogramming module aligns the foundation model's feature space with the downstream task, enabling student models to mimic this representation collaboratively. FedRD significantly reduces memory and computation requirements while maintaining high accuracy. Experiments on three medical imaging datasets under non-IID data distributions demonstrate that FedRD outperforms federated KD and PEFT methods, offering an effective trade-off between accuracy, communication, and computational efficiency.", "summary_cn": "提出FedRD方法，结合联邦学习与知识蒸馏，使用轻量学生模型和服务器基础模型，在保护隐私下降低内存与计算需求，提升医疗影像任务性能。", "keywords": ["联邦学习", "知识蒸馏", "医疗影像", "内存高效", "隐私保护", "非独立同分布数据"], "triple": {"method": "FedRD结合联邦学习与知识蒸馏", "result": "降低内存计算需求，保持高准确率", "contribution": "实现隐私、效率与性能的平衡"}}
{"venue": "NeurIPS", "search_title": "SynLLM: A Comparative Analysis of Large Language Models for ...", "url": "https://neurips.cc/virtual/2025/124918", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... We evaluate SynLLM across three public medical datasets, including Diabetes, Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124918", "full_title": "SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering", "abstract": "Access to real-world medical data is often restricted due to privacy regulations, posing a significant barrier to the advancement of healthcare research. Synthetic data offers a promising alternative; however, generating realistic, clinically valid, and privacy-conscious records remains a major challenge. Recent advancements in Large Language Models (LLMs) offer new opportunities for structured data generation; however, existing approaches frequently lack systematic prompting strategies and comprehensive, multi-dimensional evaluation frameworks. In this paper, we present SynLLM, a modular framework for generating high-quality synthetic medical tabular data using 20 state-of-the-art open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by structured prompts. We propose four distinct prompt types, ranging from example-driven to rule-based constraints, that encode schema, metadata, and domain knowledge to control generation without model fine-tuning. Our framework features a comprehensive evaluation pipeline that rigorously assesses generated data across statistical fidelity, clinical consistency, and privacy preservation. We evaluate SynLLM across three public medical datasets, including Diabetes, Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt engineering significantly impacts data quality and privacy risk, with rule-based prompts achieving the best privacy-quality balance. SynLLM establishes that, when guided by well-designed prompts and evaluated with robust, multi-metric criteria, LLMs can generate synthetic medical data that is both clinically plausible and privacy-aware, paving the way for safer and more effective data sharing in healthcare research.", "summary_cn": "SynLLM框架利用20种开源大语言模型，通过提示工程生成高质量医疗表格合成数据，在统计保真度、临床一致性和隐私保护方面表现优异。", "keywords": ["合成数据", "大语言模型", "提示工程", "医疗数据", "隐私保护", "评估框架"], "triple": {"method": "提示工程与多模型框架", "result": "基于规则的提示实现最佳隐私-质量平衡", "contribution": "提供高质量、隐私安全的医疗合成数据生成方案"}}
{"venue": "NeurIPS", "search_title": "MedPAIR: Measuring Physicians and AI Relevance Alignment in ...", "url": "https://neurips.cc/virtual/2025/133199", "year": 2025, "abstract_snippet": "Large Language Models (LLMs) have demonstrated remarkable performance on various medical question-answering (QA) benchmarks, including standardized medical ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133199", "full_title": "MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on various medical question-answering (QA) benchmarks, including standardized medical exams. However, correct answers alone do not ensure correct logic, and models may reach accurate conclusions through flawed processes. In this study, we introduce the MedPAIR (Medical Dataset Comparing Physicians and AI Relevance Estimation and Question Answering) dataset to evaluate how physician trainees and LLMs prioritize relevant information when answering QA questions. We obtain annotations on 1,300 QA pairs from 36 physician trainees, labeling each sentence within the question components for relevance. We compare these relevance estimates to those for LLMs, and further evaluate the impact of these \"relevant\" subsets on downstream task performance for both physician trainees and LLMs. We find that LLMs are frequently not aligned with the content relevance estimates of physician trainees. After filtering out physician trainee-labeled irrelevant sentences, accuracy improves for both the trainees and the LLMs.", "summary_cn": "研究引入MedPAIR数据集，评估医生与LLMs在医学问答中的信息相关性判断差异。发现LLMs与医生相关性估计常不一致，过滤无关句子可提升双方准确率。", "keywords": ["医学问答", "大型语言模型", "相关性对齐", "数据集", "医生评估", "性能提升"], "triple": {"method": "构建MedPAIR数据集并标注句子相关性", "result": "LLMs与医生相关性判断常不一致，过滤无关句子提高准确率", "contribution": "提出评估框架揭示LLMs逻辑缺陷，促进医疗AI可靠性"}}
{"venue": "NeurIPS", "search_title": "Demo: SanitizingMedicalDocuments with Differential Privacy using ...", "url": "https://neurips.cc/virtual/2025/124873", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Medical documents often contain sensitive information such as disease history and symptoms. Regulations like GDPR strictly prohibit leakage ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124873", "full_title": "Demo: Sanitizing Medical Documents with Differential Privacy using Large Language Models", "abstract": "Medical documents often contain sensitive information such as disease history and symptoms. Regulations like GDPR strictly prohibit leakage of such content.  A natural solution is to sanitize documents with large language models (LLMs) before sending them to untrusted providers. However, LLM-based paraphrasing remains vulnerable to membership inference attacks (MIA), which can reveal what private tokens were present in the input. Differentially Private Inference (DPI) offers formal guarantees against such leakage, but standard approaches severely degrade utility. Recent methods improve trade-offs by applying DP only to private tokens, yet this requires accurate tagging of private spans. In practice, privacy in medical text is highly context dependent and varies across organizations/jurisdictions, leading existing taggers to perform poorly. LLM-based taggers achieve higher accuracy but require costly fine-tuning and risk leaking private data through memorization.  We address this by introducing constitutional classifiers for private information tagging. Here, we learn a constitution i.e a set of natural language rules, directly from a small annotated subset, achieving stronger performance than existing taggers while requiring no fine-tuning. Importantly, the learned rules remain interpretable and auditable, allowing human experts to verify or edit them for compliance. We integrate our constitutional tagger with DPI through DP-Fusion, yielding an end-to-end pipeline for utility-preserving medical document sanitization using LLMs. The system is deployed and publicly available at www.documentprivacy.com .", "summary_cn": "提出基于宪法分类器的隐私信息标注方法，结合差分隐私推理，实现医疗文档去敏感化，在保护隐私的同时保持实用性。", "keywords": ["差分隐私", "大语言模型", "医疗文档", "隐私保护", "宪法分类器", "去敏感化"], "triple": {"method": "宪法分类器标注隐私信息并集成差分隐私推理", "result": "提升隐私保护效果且保持文档实用性", "contribution": "提供可审计的端到端医疗文档去敏感化方案"}}
{"venue": "NeurIPS", "search_title": "Generative AI EnablesMedicalImage Segmentation in Ultra Low ...", "url": "https://neurips.cc/virtual/2025/126033", "year": 2025, "abstract_snippet": "Semantic segmentation of medical images is pivotal in applications like disease diagnosis and treatment planning. While deep learning automates this task ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/126033", "full_title": "Generative AI Enables Medical Image Segmentation in Ultra Low-Data Regimes", "abstract": "Semantic segmentation of medical images is pivotal in applications like disease diagnosis and treatment planning. While deep learning automates this task effectively, it struggles in ultra low-data regimes for the scarcity of annotated segmentation masks. To address this, we propose a generative deep learning framework that produces high-quality image-mask pairs as auxiliary training data. Unlike traditional generative models that separate data generation from model training, ours uses multi-level optimization for end-to-end data generation. This allows segmentation performance to guide the generation process, producing data tailored to improve segmentation outcomes. Our method demonstrates strong generalization across 11 medical image segmentation tasks and 19 datasets, covering various diseases, organs, and modalities. It improves performance by 10–20% (absolute) in both same- and out-of-domain settings and requires 8–20 times less training data than existing approaches. This greatly enhances the feasibility and cost-effectiveness of deep learning in data-limited medical imaging scenarios.", "summary_cn": "提出生成式深度学习框架，通过端到端优化生成高质量图像-掩码对，显著提升超低数据场景下的医学图像分割性能，减少数据需求。", "keywords": ["生成式AI", "医学图像分割", "超低数据", "端到端优化", "数据增强", "泛化能力"], "triple": {"method": "生成式深度学习框架", "result": "性能提升10-20%，数据需求减少8-20倍", "contribution": "增强数据受限场景下的分割可行性与成本效益"}}
{"venue": "NeurIPS", "search_title": "VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised ...", "url": "https://neurips.cc/virtual/2025/poster/118930", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... Abstract. Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/118930", "full_title": "VQ-Seg: Vector-Quantized Token Perturbation for Semi-Supervised Medical Image Segmentation", "abstract": "Consistency learning with feature perturbation is a widely used strategy in semi-supervised medical image segmentation. However, many existing perturbation methods rely on dropout, and thus require a careful manual tuning of the dropout rate, which is a sensitive hyperparameter and often difficult to optimize and may lead to suboptimal regularization. To overcome this limitation, we propose VQ-Seg, the first approach to employ vector quantization (VQ) to discretize the feature space and introduce a novel and controllable Quantized Perturbation Module (QPM) that replaces dropout. Our QPM perturbs discrete representations by shuffling the spatial locations of codebook indices, enabling effective and controllable regularization. To mitigate potential information loss caused by quantization, we design a dual-branch architecture where the post-quantization feature space is shared by both image reconstruction and segmentation tasks. Moreover, we introduce a Post-VQ Feature Adapter (PFA) to incorporate guidance from a foundation model (FM), supplementing the high-level semantic information lost during quantization. Furthermore, we collect a large-scale Lung Cancer (LC) dataset comprising 828 CT scans annotated for central-type lung carcinoma. Extensive experiments on the LC dataset and other public benchmarks demonstrate the effectiveness of our method, which outperforms state-of-the-art approaches. Codes will be released.", "summary_cn": "VQ-Seg提出基于向量量化的特征扰动方法，用于半监督医学图像分割，通过量化扰动模块和双分支架构提升性能，在肺癌CT数据集上表现优异。", "keywords": ["半监督分割", "向量量化", "特征扰动", "医学图像", "肺癌CT", "一致性学习"], "triple": {"method": "向量量化特征扰动与双分支架构", "result": "在肺癌等数据集上超越现有方法", "contribution": "提出可控扰动模块，减少超参数调优需求"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Examining the Vulnerability of Multi-AgentMedicalSystems ...", "url": "https://neurips.cc/virtual/2025/130246", "year": 2025, "abstract_snippet": "Human interventions at fault points can alter the diagnostic accuracy of multi-agent medical systems. We defined fault points as moments in doctor-patient ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/130246", "full_title": "Examining the Vulnerability of Multi-Agent Medical Systems to Human Interventions for Clinical Reasoning", "abstract": "Human interventions at fault points can alter the diagnostic accuracy of multi-agent medical systems. We defined fault points as moments in doctor-patient conversations, where the Doctor Agent's reasoning became most vulnerable to external influence and change. Using a MedQA dataset, this study analyzed simulated doctor-patient conversations to measure how fault point interventions shifted reasoning and accuracy. Correct intervention methods showed an improvement in baseline diagnostic accuracy up to 40\\%, while incorrect or bias-related interventions degraded performance by up to 6\\%, and increased diagnostic drift and uncertainty. Beyond accuracy, the analysis revealed behavioral patterns between cognitive biases in simulated Medical AI and real-world clinical practice. Examples included premature closure and susceptibility to misleading cues, which are concerning in healthcare, where reliability and fairness are critical. This makes fault points natural audit checkpoints for oversight or human verification. Overall, the findings reveal that priming large language models (LLMs) at fault points can improve reliability, expose drift and bias, and support stress-testing for certification.", "summary_cn": "研究多智能体医疗系统在医患对话故障点受人为干预的影响，正确干预可提升诊断准确率40%，错误干预则降低6%，并揭示认知偏差模式。", "keywords": ["多智能体医疗系统", "故障点干预", "诊断准确率", "认知偏差", "大语言模型", "临床推理"], "triple": {"method": "基于MedQA数据集模拟医患对话分析", "result": "正确干预提升准确率40%，错误干预降低6%并增加偏差", "contribution": "揭示故障点作为审计检查点，支持系统可靠性测试与认证"}}
{"venue": "NeurIPS", "search_title": "Unveiling the Interplay Between Interpretability and Generative ...", "url": "https://neurips.cc/virtual/2023/82471", "year": 2023, "abstract_snippet": "Generative diffusion models are showing promising utility in medical imaging, particularly in synthesizing high-quality images like MRI scans and 4D data.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Unveiling the Interplay Between Interpretability and Generative ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Chiron-o1: Igniting Multimodal Large Language Models towards ...", "url": "https://neurips.cc/virtual/2025/poster/116739", "year": 2025, "abstract_snippet": "Dec 5, 2025 ... ... medical domain remains in its early stages. Constructing chain-of ... medical MLLMs. However, existing approaches exhibit a deficiency ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/116739", "full_title": "Chiron-o1: Igniting Multimodal Large Language Models towards Generalizable Medical Reasoning via Mentor-Intern Collaborative Search", "abstract": "Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1,  a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at https://github.com/Yankai96/Chiron-o1", "summary_cn": "提出MICS方法生成医学推理链数据，构建MMRP数据集和Chiron-o1模型，在医学视觉问答基准上实现最优性能。", "keywords": ["多模态大语言模型", "医学推理", "思维链", "导师-实习生协作搜索", "课程学习", "视觉问答"], "triple": {"method": "MICS方法生成推理链数据", "result": "Chiron-o1在医学基准上达到最优", "contribution": "提升医学MLLM的泛化推理能力"}}
{"venue": "NeurIPS", "search_title": "Pushing the Limits ofMedicalLLM Reasoning with Minimalist Rule ...", "url": "https://neurips.cc/virtual/2025/124866", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... In this work, we present AlphaMed, the first medical LLM to show that reasoning capability can emerge purely through reinforcement learning (RL) ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124866", "full_title": "Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL", "abstract": "Improving performance on complex tasks and enabling interpretable decision making in large language models (LLMs), especially for clinical applications, requires effective reasoning. Yet this remains challenging without supervised fine-tuning (SFT) on costly chain-of-thought (CoT) data distilled from closed-source models (e.g., GPT-4o). In this work, we present AlphaMed, the first medical LLM to show that reasoning capability can emerge purely through reinforcement learning (RL), using minimalist rule-based rewards on public multiple-choice QA datasets, without relying on SFT or distilled CoT data. AlphaMed achieves state-of-the-art results on six medical QA benchmarks, outperforming models trained with conventional SFT+RL pipelines. On challenging benchmarks (e.g., MedXpert), AlphaMed even surpasses larger or closed-source models such as DeepSeek-V3-671B and Claude-3.5-Sonnet. To understand the factors behind this success, we conduct a comprehensive data-centric analysis guided by three questions:(i) Can minimalist rule-based RL incentivize reasoning without distilled CoT supervision? (ii) How do dataset quantity and diversity impact reasoning? (iii) How does question difficulty shape the emergence and generalization of reasoning? Our findings show that dataset informativeness is a key driver of reasoning performance, and that minimalist RL on informative, multiple-choice QA data is effective at inducing reasoning without CoT supervision. We also observe divergent trends across benchmarks, underscoring limitations in current evaluation and the need for more challenging, reasoning-oriented medical QA benchmarks. The code and pretrained model weights will be publicly released upon acceptance.", "summary_cn": "AlphaMed 模型仅通过基于规则的强化学习，无需监督微调或思维链数据，在多项医疗问答基准测试中取得最优性能。", "keywords": ["医疗大语言模型", "强化学习", "推理能力", "规则奖励", "问答基准", "数据驱动分析"], "triple": {"method": "基于规则的强化学习", "result": "在六个医疗QA基准上达到最优", "contribution": "首次证明无需监督微调即可激发医疗LLM推理能力"}}
{"venue": "NeurIPS", "search_title": "NeurIPS MedBrowseComp: BenchmarkingMedicalDeep Research ...", "url": "https://neurips.cc/virtual/2025/122474", "year": 2025, "abstract_snippet": "MedBrowseComp: Benchmarking Medical Deep Research and Computer Use. Shan Chen · Pedro Moreira · Yuxin Xiao · Samuel Schmidgall · Jeremy Warner · Hugo Aerts · ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/122474", "full_title": "MedBrowseComp: Benchmarking Medical Deep Research and Computer Use", "abstract": "Large language models (LLMs) are increasingly envisioned as decision-support tools in clinical practice, yet safe clinical reasoning demands the integration of heterogeneous knowledge bases—trials, primary studies, regulatory documents, and cost data—under strict accuracy constraints. Existing evaluations typically rely on synthetic prompts, reduce the task to single-hop factoid queries, or conflate reasoning with open-ended text generation, leaving their real-world utility unclear. To close this gap, we present \\textbf{MedBrowseComp}, the first benchmark that systematically tests an agent’s ability to reliably retrieve and synthesize multi-hop medical facts from up-to-date, domain-specific knowledge bases. MedBrowseComp holds 1,000+ human-curated questions that mirror clinical scenarios in which practitioners must reconcile information fragmented over many sources that are potentially conflicting. Applying MedBrowseComp to frontier agentic systems reveals \\textbf{marked performance shortfalls as low as 10\\%}. MedBrowseComp reveals critical gaps between current LLM performance and clinical usage, providing a testbed to guide future model and toolchain improvements for reliable medical information seeking.", "summary_cn": "提出MedBrowseComp基准，评估LLM在临床多源信息检索与合成中的能力，发现现有系统性能显著不足，仅达10%。", "keywords": ["医学基准", "大语言模型", "临床决策支持", "多跳推理", "信息检索", "性能评估"], "triple": {"method": "构建人类标注的临床问题基准", "result": "前沿系统性能低至10%", "contribution": "揭示LLM与临床应用的差距，指导模型改进"}}
{"venue": "NeurIPS", "search_title": "Collaborative Feature and Persona Enhancement for Trustworthy ...", "url": "https://neurips.cc/virtual/2025/133194", "year": 2025, "abstract_snippet": "Foundation models promise to democratize access to high-quality medical image segmentation, but they can still exhibit patient-dependent performance differences ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133194", "full_title": "Collaborative Feature and Persona Enhancement for Trustworthy Medical Foundation Models", "abstract": "Foundation models promise to democratize access to high-quality medical image segmentation, but they can still exhibit patient-dependent performance differences. We explore whether conditioning a compact U-shaped backbone on simple demographic metadata can improve worst-group segmentation without hurting overall accuracy or incurring significant computational overhead. We propose CEIGM-UNet, a compact U-shaped backbone that interleaves collaborative feature enhancement layers (CFEL) and Group Mamba blocks and integrates a Conditional Feature Recalibration (CFR) module that maps a low-dimensional metadata vector to FiLM-like channel-wise scale and shift parameters. Because public benchmarks rarely provide reliable age or sex labels, we simulate demographic variability on Synapse by grouping cases into small, medium, and large organ-volume subgroups and evaluate fairness using equal opportunity differences and generalized Dice disparities across these volume-defined cohorts. On Synapse and ACDC, our metadata-conditioned CEIGM-UNet achieves competitive Dice and HD95 compared with recent CNN-, Transformer-, and Mamba-based U-Nets, while modestly narrowing performance gaps between volume-based subgroups with negligible overhead. We discuss limitations of this proxy setup and outline how such metadata conditioning could be integrated into larger medical foundation models in a principled, fairness-aware way.", "summary_cn": "提出CEIGM-UNet模型，通过整合人口统计元数据，在保持整体精度的同时，缩小了医学图像分割中基于器官体积分组的性能差距，提升了公平性。", "keywords": ["医学图像分割", "公平性", "元数据条件化", "CEIGM-UNet", "性能差距", "U型网络"], "triple": {"method": "使用元数据条件化与CFR模块增强紧凑U型网络", "result": "在Synapse和ACDC上竞争性精度，缩小体积分组性能差距", "contribution": "为医学基础模型提供公平感知的元数据集成方法"}}
{"venue": "NeurIPS", "search_title": "Temporal Fine-tuning ofMedicalVision-Language Representation", "url": "https://neurips.cc/virtual/2023/82500", "year": 2023, "abstract_snippet": "Workshop: Medical Imaging meets NeurIPS. Temporal Fine-tuning of Medical Vision-Language Representation. Haoxu Huang · Kyunghyun Cho · Sumit Chopra · Divyam ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Temporal Fine-tuning ofMedicalVision-Language Representation", "abstract": null}
{"venue": "NeurIPS", "search_title": "Systematic Comparison of Unsupervised and Supervised Learning ...", "url": "https://neurips.cc/virtual/2024/109023", "year": 2024, "abstract_snippet": "Systematic Comparison of Unsupervised and Supervised Learning for Medical Image Segmentation. Sharon Cristell Quispe Carhuapoma · Ingrid Arellano · Pedro ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/109023", "full_title": "Systematic Comparison of Unsupervised and Supervised Learning for Medical Image Segmentation", "abstract": null, "llm_error": "abstract_not_found"}
{"venue": "NeurIPS", "search_title": "NeurIPS RPRO: Ranked Preference Reinforcement Optimization for ...", "url": "https://neurips.cc/virtual/2025/124920", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Medical question answering requires advanced reasoning that integrates domain knowledge with logical inference. However, existing large ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124920", "full_title": "RPRO: Ranked Preference Reinforcement Optimization for Enhancing  Medical QA and Diagnostic Reasoning", "abstract": "Medical question answering requires advanced reasoning that integrates domain knowledge with logical inference. However, existing large language models (LLMs) often generate reasoning chains that lack factual accuracy and clinical reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a novel framework that uniquely combines reinforcement learning with preference-driven reasoning refinement to enhance clinical chain-of-thought (CoT) performance. RPRO differentiates itself from prior approaches by employing task-adaptive reasoning templates and a probabilistic evaluation mechanism that aligns outputs with established clinical workflows, while automatically identifying and correcting low-quality reasoning chains. Unlike traditional pairwise preference methods, RPRO introduces a groupwise ranking optimization based on the Bradley–Terry model and incorporates KL-divergence regularization for stable training.  Experiments on PubMedQA and MedQA-USMLE show consistent improvements over strong baselines. Remarkably, our 1.1B parameter model outperforms much larger 7B–13B models, including medical-specialized variants. These findings demonstrate that combining preference optimization with quality-driven refinement offers a scalable and effective approach to building more reliable, clinically grounded medical LLMs.", "summary_cn": "提出RPRO框架，结合强化学习与偏好优化，提升医学问答的推理准确性和临床可靠性，在PubMedQA和MedQA-USMLE上优于更大模型。", "keywords": ["医学问答", "强化学习", "偏好优化", "推理链", "临床可靠性", "Bradley-Terry模型"], "triple": {"method": "RPRO框架结合强化学习与偏好优化", "result": "在PubMedQA和MedQA-USMLE上表现优于更大模型", "contribution": "提升医学问答的临床可靠性和推理准确性"}}
{"venue": "NeurIPS", "search_title": "the many lives of a publicly availablemedicalimaging dataset", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/cdbeaeb8a0313940a5752c4ec8838ca6-Abstract-Datasets_and_Benchmarks_Track.html", "year": 2024, "abstract_snippet": "Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/cdbeaeb8a0313940a5752c4ec8838ca6-Abstract-Datasets_and_Benchmarks_Track.html", "full_title": "Copycats: the many lives of a publicly available medical imaging dataset", "abstract": "Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets' context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.", "summary_cn": "分析社区贡献平台上的公开医学影像数据集，发现其治理模式存在数据质量、文档和维护问题，影响AI算法的准确性和公平性。", "keywords": ["医学影像数据集", "社区贡献平台", "数据治理", "数据质量", "人工智能", "医疗保健"], "triple": {"method": "分析公开数据集", "result": "发现许可证模糊、元数据缺失等问题", "contribution": "促进医疗数据负责任管理"}}
{"venue": "NeurIPS", "search_title": "RAxSS: Retrieval-Augmented Sparse Sampling for Explainable ...", "url": "https://neurips.cc/virtual/2025/132323", "year": 2025, "abstract_snippet": "Medical time series analysis is challenging due to data sparsity, noise, and highly variable recording lengths. Prior work has shown that stochastic sparse ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/132323", "full_title": "RAxSS: Retrieval-Augmented Sparse Sampling for Explainable Variable-Length Medical Time Series Classification", "abstract": "Medical time series analysis is challenging due to data sparsity, noise, and highly variable recording lengths. Prior work has shown that stochastic sparse sampling effectively handles variable-length signals, while retrieval-augmented approaches improve explainability and robustness to noise and weak temporal correlations. In this study, we generalize the stochastic sparse sampling framework for retrieval-informed classification. Specifically, we weight window predictions by within-channel similarity and aggregate them in probability space, yielding convex series-level scores and an explicit evidence trail for explainability. Our method achieves competitive iEEG classification performance and provides practitioners with greater transparency and explainability. We evaluate our method in iEEG recordings collected in four medical centers, demonstrating its potential for reliable and explainable clinical variable-length time series classification.", "summary_cn": "本研究提出RAxSS方法，结合检索增强与稀疏采样，用于可变长度医疗时间序列分类，提升可解释性与鲁棒性，在iEEG数据上验证有效。", "keywords": ["检索增强", "稀疏采样", "医疗时间序列", "可解释性", "可变长度", "iEEG分类"], "triple": {"method": "检索增强稀疏采样框架", "result": "在iEEG分类中表现竞争性，提供透明证据追踪", "contribution": "实现可靠且可解释的临床时间序列分类"}}
{"venue": "NeurIPS", "search_title": "Knowledge-Empowered Dynamic Graph Network for Irregularly ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/7c04aea54c2a60a632a47bd451cd2849-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Irregularly Sampled Medical Time Series (ISMTS) are commonly found in the healthcare domain, where different variables exhibit unique temporal patterns.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Knowledge-Empowered Dynamic Graph Network for Irregularly ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS The Biased Oracle: Assessing LLMs' Understandability and ...", "url": "https://neurips.cc/virtual/2025/124876", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... We assess two leading LLMs on medical diagnostic scenarios, measuring understandability with readability metrics and empathy through LLM-as-a- ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124876", "full_title": "The Biased Oracle: Assessing LLMs’ Understandability and Empathy in Medical Diagnoses", "abstract": "Large language models (LLMs) show promise for supporting diagnostic communication by generating explanations and guidance for patients. Yet their ability to produce outputs that are both understandable and empathetic remains uncertain. We assess two leading LLMs on medical diagnostic scenarios, measuring understandability with readability metrics and empathy through LLM-as-a-Judge compared to human ratings. Our results indicate that LLMs adapt explanations to sociodemographic variables and patient conditions. However, they also generate overly complex content and display biased affective empathy, leading to uneven accessibility and support. These patterns underscore the need for systematic calibration to ensure equitable patient communication.", "summary_cn": "评估大语言模型在医疗诊断中的可理解性与共情能力，发现其能适应患者背景但存在内容复杂和情感偏见，需系统校准以确保公平沟通。", "keywords": ["大语言模型", "医疗诊断", "可理解性", "共情能力", "偏见", "患者沟通"], "triple": {"method": "使用可读性指标和LLM-as-a-Judge评估", "result": "模型适应患者背景但内容复杂且情感偏见", "contribution": "揭示模型偏见，强调系统校准的必要性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Large Language Models asMedicalCodes Selectors", "url": "https://neurips.cc/virtual/2025/124915", "year": 2025, "abstract_snippet": "Dec 6, 2025 ... Background: Medical coding structures healthcare data for research, quality monitoring, and policy. This study assesses the potential of ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/124915", "full_title": "Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care", "abstract": "Background: Medical coding structures healthcare data for research, quality monitoring, and policy. This study assesses the potential of large language models (LLMs) to assign ICPC-2 codes using the output of a domain-specific search engine.Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's text-embedding-3-large) retrieved candidates from 73,563 labeled concepts. Thirty-three LLMs were prompted with each query and retrieved results to select the best-matching ICPC-2 code. Performance was evaluated using F1-score, along with token usage, cost, response time, and format adherence. Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever optimization can improve performance by up to 4 points. Most models returned valid codes in the expected format, with reduced hallucinations. Smaller models (<3B) struggled with formatting and input length.Conclusions: LLMs show strong potential for automating ICPC-2 coding, even without fine-tuning. This work offers a benchmark and highlights challenges, but findings are limited by dataset scope and setup. Broader, multilingual, end-to-end evaluations are needed for clinical validation.", "summary_cn": "研究评估33个大语言模型自动分配ICPC-2医疗编码的能力，多数模型F1分数>0.8，显示无需微调即可有效辅助编码，但小模型存在格式和输入长度限制。", "keywords": ["大语言模型", "医疗编码", "ICPC-2", "语义搜索", "基准测试", "自动化"], "triple": {"method": "使用语义搜索检索候选编码，提示LLMs选择最佳匹配", "result": "28个模型F1>0.8，优化检索可提升4%性能", "contribution": "建立LLMs医疗编码选择基准，证明其自动化潜力"}}
{"venue": "NeurIPS", "search_title": "Temporal Gaze Dynamics as Zero-Shot Prompts for Volumetric ...", "url": "https://neurips.cc/virtual/2025/132346", "year": 2025, "abstract_snippet": "Guiding foundation models like SAM-2 for volumetric medical segmentation typically relies on inefficient manual prompts. We introduce a more efficient ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/132346", "full_title": "Temporal Gaze Dynamics as Zero-Shot Prompts for Volumetric Medical Segmentation", "abstract": "Guiding foundation models like SAM-2 for volumetric medical segmentation typically relies on inefficient manual prompts. We introduce a more efficient, multimodal approach using eye gaze—a continuous physiological time series—to steer the model's focus in a zero-shot manner. By fusing a user's temporal gaze stream with spatial image data, we enable dynamic, interactive 3D segmentation. Evaluating with SAM-2 and its medical variant, MedSAM-2, our gaze-based method proves significantly more time-efficient (e.g., 62 vs. 88 seconds per volume) than manual bounding boxes, with a modest accuracy trade-off. This work establishes a practical framework for incorporating human physiological signals into sequential, human-in-the-loop clinical tasks, paving the way for more intuitive AI interfaces.", "summary_cn": "提出利用眼动时序数据作为零样本提示，引导SAM-2等基础模型进行三维医学图像分割，实现高效动态交互，在时间效率上优于手动标注。", "keywords": ["眼动追踪", "零样本提示", "三维医学分割", "SAM-2", "人机交互", "多模态融合"], "triple": {"method": "融合眼动时序与图像空间数据", "result": "分割时间显著缩短，精度略有下降", "contribution": "建立生理信号引导的交互式临床任务框架"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Sparse Partial Bayesian Networks: Efficient Uncertainty ...", "url": "https://neurips.cc/virtual/2024/108946", "year": 2024, "abstract_snippet": "Sparse Partial Bayesian Networks: Efficient Uncertainty Quantification in Medical Image Analysis. Zeinab Abboud · Herve Lombaert · Samuel Kadoury. Chat is not ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/108946", "full_title": "Sparse Partial Bayesian Networks: Efficient Uncertainty Quantification in Medical Image Analysis", "abstract": null, "llm_error": "abstract_not_found"}
{"venue": "NeurIPS", "search_title": "Understanding Transfer Learning forMedicalImaging - NeurIPS", "url": "https://proceedings.neurips.cc/paper/2019/file/eb1e78328c46506b46a4ac4a1e378b91-Reviews.html", "year": null, "abstract_snippet": "Reviewer 1. The authors investigate the current transfer learning scheme for deep learning applications to medical imaging. They thoroughly assess and compare ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Understanding Transfer Learning forMedicalImaging - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Hetero-UNet: Heterogeneous Transformer with Mamba forMedical...", "url": "https://neurips.cc/virtual/2024/103876", "year": 2024, "abstract_snippet": "Convolutional Neural Networks (CNNs) have significantly advanced medical image segmentation, offering unparalleled local feature extraction capabilities.", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103876", "full_title": "Hetero-UNet: Heterogeneous Transformer with Mamba for Medical Image Segmentation", "abstract": "Convolutional Neural Networks (CNNs) have significantly advanced medical image segmentation, offering unparalleled local feature extraction capabilities. However, CNNs face limitations in capturing long-range dependencies due to the local nature of convolutional operations. Recently, State-Space Models (SSMs), such as Mamba, have presented an efficient solution by incorporating gating, convolutions, and data-dependent filtering mechanisms for long-range interaction modeling. However, as an attention-free mechanism, SSMs are less efficient at handling variable distance token-to-token interactions compared to attention. In this paper, we introduce Hetero-UNet, a novel hybrid U-Net architecture that incorporates SSMs and attention mechanisms to map long-range dependencies. Featuring a hybrid Transformer-Mamba encoder within original U-Net architecture, it excels at extracting both local and global features. Our extensive experiments across diverse tasks—abdominal organ segmentation in CT and MR, instrument segmentation in endoscopy, and cell segmentation in microscopy—demonstrates Hetero-UNet's superior performance over previous state-of-the-art segmentation models, paving the way for hybrid long-range dependency modeling in medical imaging. The code is available at https://github.com/ZhilingYan/Hetero-UNet.", "summary_cn": "提出Hetero-UNet，结合Transformer与Mamba，在U-Net中融合注意力与状态空间模型，有效建模长程依赖，提升医学图像分割性能。", "keywords": ["医学图像分割", "Transformer", "Mamba", "长程依赖", "混合架构", "U-Net"], "triple": {"method": "融合Transformer与Mamba的混合U-Net编码器", "result": "在多种医学图像分割任务中超越现有最佳模型", "contribution": "为医学成像中的混合长程依赖建模开辟新途径"}}
{"venue": "NeurIPS", "search_title": "NeurIPS SynthFair: A Semi-SyntheticMedicalImaging Dataset to ...", "url": "https://neurips.cc/virtual/2025/125803", "year": 2025, "abstract_snippet": "SynthFair: A Semi-Synthetic Medical Imaging Dataset to Propel Research on Bias Detection & Mitigation. Fabio De Sousa Ribeiro · Estanislao Claucich · Emma ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/125803", "full_title": "SynthFair: A Semi-Synthetic Medical Imaging Dataset to Propel Research on Bias Detection & Mitigation", "abstract": "The scarcity of large-scale datasets capable of capturing the rich diversity of the global population is currently a major limitation for the development of equitable AI tools in the medical domain. Underrepresentation of certain subpopulations renders the evaluation of bias audits and subsequent mitigation difficult in general, and practically unfeasible when it comes to intersectional studies. Moreover, spurious correlations in these datasets, which are challenging to identify, have a tendency to result in shortcut learning whereby models base their decisions on features unrelated to the task, which may lead to catastrophic failure at test time. Current fairness benchmarks are not representative of real-world data, making it difficult to draw conclusions that are relevant for clinical practice. SynthFair aims to bridge this gap by leveraging cutting-edge technology in generative AI. The use of GenAI will allow us to create a massive semi-synthetic dataset of chest x-ray images, augmenting a rich international collection of databases by means of counterfactual image generation. SynthFair is the result of an international collaboration with a proven track record in synthetic image creation, database curation, as well as in bias detection and mitigation in the context of medical imaging.", "summary_cn": "SynthFair利用生成AI创建大规模半合成胸部X光数据集，以解决医学AI中数据多样性和偏见检测的挑战。", "keywords": ["半合成数据集", "偏见检测", "生成AI", "医学影像", "公平性", "胸部X光"], "triple": {"method": "生成AI与反事实图像生成", "result": "创建大规模半合成胸部X光数据集", "contribution": "推动医学AI偏见检测与缓解研究"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Enhancing SmallMedicalLearners with Privacy-preserving ...", "url": "https://neurips.cc/virtual/2023/82888", "year": 2023, "abstract_snippet": "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Enhancing SmallMedicalLearners with Privacy-preserving ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster MIRA:MedicalTime Series Foundation Model for ...", "url": "https://neurips.cc/virtual/2025/poster/119424", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... A unified foundation model for medical time series—pretrained on open access and ethically reviewed medical corpora—offers the potential to ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/119424", "full_title": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "abstract": "A unified foundation model for medical time series—pretrained on open access and ethically reviewed medical corpora—offers the potential to reduce annotation burdens, minimize model customization, and enable robust transfer across clinical institutions, modalities, and tasks, particularly in data-scarce or privacy-constrained environments.  However, existing time series foundation models struggle to handle medical time series data due to its inherent challenges, including irregular intervals, heterogeneous sampling rates, and frequent missingness. To address these challenges, we introduce MIRA, a unified foundation model specifically designed for medical time series forecasting. MIRA incorporates a Continuous-Time Rotary Positional Encoding that enables fine-grained modeling of variable time intervals, a frequency-specific mixture-of-experts layer that routes computation across latent frequency regimes to further promote temporal specialization, and a Continuous Dynamics Extrapolation Block based on Neural ODE that models the continuous trajectory of latent states, enabling accurate forecasting at arbitrary target timestamps. Pretrained on a large-scale and diverse medical corpus comprising over 454 billion time points collect from publicly available datasets, MIRA achieving reductions in forecasting errors by an average of 8% and 6% in out-of-distribution and in-distribution scenarios, respectively. We also introduce a comprehensive benchmark spanning multiple downstream clinical tasks, establishing a foundation for future research in medical time series modeling.", "summary_cn": "MIRA是专为医疗时间序列设计的统一基础模型，通过连续时间编码和专家层处理不规则数据，在预测任务中平均降低误差6-8%。", "keywords": ["医疗时间序列", "基础模型", "连续时间建模", "预测误差降低", "不规则数据", "神经ODE"], "triple": {"method": "连续时间旋转位置编码与专家层", "result": "预测误差平均降低6-8%", "contribution": "提出首个专用于医疗时间序列的统一基础模型"}}
{"venue": "NeurIPS", "search_title": "Magical:MedicalLay Language Generation via Semantic Invariance ...", "url": "https://neurips.cc/virtual/2025/poster/116222", "year": 2025, "abstract_snippet": "Dec 4, 2025 ... Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of complex scientific content for broader audiences ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/116222", "full_title": "Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation", "abstract": "Medical Lay Language Generation (MLLG) plays a vital role in improving the accessibility of complex scientific content for broader audiences. Recent literature to MLLG commonly employ parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using paired expert-lay language datasets. However, LoRA struggles with the challenges posed by multi-source heterogeneous MLLG datasets. Specifically, through a series of exploratory experiments, we reveal that standard LoRA fail to meet the requirement for semantic fidelity and diverse lay-style generation in MLLG task. To address these limitations, we propose Magical, an asymmetric LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical employs a shared matrix A for abstractive summarization, along with multiple isolated matrices B for diverse lay-style generation. To preserve semantic fidelity during the lay language generation process, Magical introduces a Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix A. Furthermore, to better adapt to diverse lay-style generation, Magical incorporates the Recommendation-guided Switch, an externally interface to prompt the LLM to switch between different matrices B. Experimental results on three real-world lay language generation datasets demonstrate that Magical consistently outperforms prompt-based methods, vanilla LoRA, and its recent variants, while also reducing trainable parameters by 31.66%. Our code is publicly available at https://github.com/tianlwang/Magical.git.", "summary_cn": "Magical提出非对称LoRA架构，通过语义不变约束和推荐引导切换，提升医学通俗语言生成的语义保真度和风格多样性，减少可训练参数。", "keywords": ["医学通俗语言生成", "非对称LoRA", "语义不变约束", "推荐引导切换", "参数高效微调", "异构数据"], "triple": {"method": "非对称LoRA架构", "result": "性能优于现有方法，参数减少31.66%", "contribution": "提升语义保真与风格多样性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS EWC-Guided Diffusion Replay for Exemplar-Free Continual ...", "url": "https://neurips.cc/virtual/2025/123872", "year": 2025, "abstract_snippet": "Medical imaging foundation models must adapt continually, but retraining is limited by privacy and cost. We propose an exemplar-free framework combining ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/123872", "full_title": "EWC-Guided Diffusion Replay for Exemplar-Free Continual Learning in Medical Imaging", "abstract": "Medical imaging foundation models must adapt continually, but retraining is limited by privacy and cost. We propose an exemplar-free framework combining class-conditional diffusion replay (DDPMs) with synaptic stability from Elastic Weight Consolidation (EWC). A compact Vision Transformer backbone is evaluated across eight MedMNIST v2 tasks and CheXpert. Our method attains 0.851 AUROC on CheXpert, cuts forgetting by over 30\\% versus DER++, and approaches joint training (0.869), while preserving privacy and efficiency. Analysis links forgetting to replay fidelity and parameter stability, underscoring the complementary roles of DDPM and EWC. This establishes a scalable, privacy-preserving route for continual FM adaptation.", "summary_cn": "提出结合扩散重放与弹性权重巩固的免示例持续学习框架，在医学影像任务中减少遗忘超30%，接近联合训练性能，保护隐私与效率。", "keywords": ["持续学习", "扩散模型", "医学影像", "隐私保护", "弹性权重巩固", "免示例学习"], "triple": {"method": "扩散重放与弹性权重巩固结合", "result": "减少遗忘超30%，接近联合训练性能", "contribution": "建立可扩展、隐私保护的持续适应路径"}}
{"venue": "NeurIPS", "search_title": "Towards ProspectiveMedicalImage Reconstruction via Knowledge ...", "url": "https://neurips.cc/virtual/2025/poster/115475", "year": 2025, "abstract_snippet": "Medical image reconstruction from measurement data is a vital but challenging inverse problem. Deep learning approaches have achieved promising results, but ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/115475", "full_title": "Towards Prospective Medical Image Reconstruction via Knowledge-Informed Dynamic Optimal Transport", "abstract": "Medical image reconstruction from measurement data is a vital but challenging inverse problem. Deep learning approaches have achieved promising results, but often requires paired measurement and high-quality images, which is typically simulated through a forward model, i.e., retrospective reconstruction. However, training on simulated pairs commonly leads to performance degradation on real prospective data due to the retrospective-to-prospective gap caused by incomplete imaging knowledge in simulation. To address this challenge, this paper introduces imaging Knowledge-Informed Dynamic Optimal Transport (KIDOT), a novel dynamic optimal transport framework with optimality in the sense of preserving consistency with imaging physics in transport, that conceptualizes reconstruction as finding a dynamic transport path. KIDOT learns from unpaired data by modeling reconstruction as a continuous evolution path from measurements to images, guided by an imaging knowledge-informed cost function and transport equation. This dynamic and knowledge-aware approach enhances robustness and better leverages unpaired data while respecting acquisition physics. Theoretically, we demonstrate that KIDOT naturally generalizes dynamic optimal transport, ensuring its mathematical rationale and solution existence. Extensive experiments on MRI and CT reconstruction demonstrate KIDOT's superior performance. Code is available at https://github.com/TaoranZheng717/KIDOT.", "summary_cn": "提出KIDOT框架，利用动态最优传输和成像物理知识，从非配对数据中学习医学图像重建，减少模拟与真实数据间的差距，提升MRI和CT重建性能。", "keywords": ["医学图像重建", "动态最优传输", "非配对学习", "成像物理知识", "MRI", "CT"], "triple": {"method": "知识引导动态最优传输框架", "result": "在MRI和CT重建中表现优异", "contribution": "减少模拟与真实数据差距，提升重建鲁棒性"}}
{"venue": "NeurIPS", "search_title": "SHF: Symmetrical Hierarchical Forest with Pretrained Vision ...", "url": "https://neurips.cc/virtual/2025/poster/120046", "year": 2025, "abstract_snippet": "Dec 3, 2025 ... SHF: Symmetrical Hierarchical Forest with Pretrained Vision Transformer Encoder for High-Resolution Medical Segmentation. Enzhi Zhang · Peng ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/120046", "full_title": "SHF: Symmetrical Hierarchical Forest with Pretrained Vision Transformer Encoder for High-Resolution Medical Segmentation", "abstract": "The NeurIPS Logo above may be used on presentations. Right-click and choose\n                            download. It is a vector graphic and may be used at any scale.", "summary_cn": "提出SHF模型，结合预训练视觉Transformer编码器与对称分层森林，用于高分辨率医学图像分割，提升精度与效率。", "keywords": ["医学图像分割", "视觉Transformer", "对称分层森林", "高分辨率", "预训练编码器", "深度学习"], "triple": {"method": "对称分层森林与预训练视觉Transformer编码器", "result": "提升高分辨率医学图像分割精度与效率", "contribution": "提出SHF模型，优化分割性能"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Spotlight 2 - Abhishek Moturu: Volume-based Performance ...", "url": "https://neurips.cc/virtual/2022/63227", "year": 2022, "abstract_snippet": "... Medical Imaging. Abhishek Moturu. 2022 Spotlight Talk in. Workshop: I Can't Believe It's Not Better: Understanding Deep Learning Through Empirical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Spotlight 2 - Abhishek Moturu: Volume-based Performance ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Review for NeurIPS paper: Contrastive learning of global and local ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/949686ecef4ee20a62d16b4a2d7ccca3-Review.html", "year": 2020, "abstract_snippet": "Particularly, to this end, authors integrate medical imaging context in a global contrastive loss and propose a local contrastive loss on the features of the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Review for NeurIPS paper: Contrastive learning of global and local ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "A Neural Expert System with Automated Extraction of Fuzzy If-Then ...", "url": "https://proceedings.neurips.cc/paper/1990/file/82cec96096d4281b7c95cd7e74623496-Paper.pdf", "year": null, "abstract_snippet": "a fuzzy neural expert system for medical diagnosis has been developed. 1 INTRODUCTION. Expert systems that have neural networks for their knowledge bases are ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Neural Expert System with Automated Extraction of Fuzzy If-Then ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "RETAIN: An Interpretable Predictive Model for Healthcare using ...", "url": "http://papers.neurips.cc/paper/6321-retain-an-interpretable-predictive-model-for-healthcare-using-reverse-time-attention-mechanism.pdf", "year": null, "abstract_snippet": "medical visits from a single patient. Traditional machine learning tools summarize this ensemble into aggregate features, ignoring the temporal and sequence ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "RETAIN: An Interpretable Predictive Model for Healthcare using ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Q-Pain: A Question Answering Dataset to Measure Social Bias in ...", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/65b9eea6e1cc6bb9f0cd2a47751a186f-Paper-round1.pdf", "year": null, "abstract_snippet": "Therefore, before medical QA systems are further deployed and even incorporated into medical workflows for applications such as mental health conversations and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Q-Pain: A Question Answering Dataset to Measure Social Bias in ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Bi-directional Weakly Supervised Knowledge Distillation for Whole ...", "url": "https://papers.neurips.cc/paper_files/paper/2022/file/62c9aa4d48329a85d1e36d5b6d0a6a32-Paper-Conference.pdf", "year": null, "abstract_snippet": "Medical . Image Analysis, 54:280–296, 2019. [5] Philip Chikontwe, Meejeong Kim, Soo Jeong Nam, Heounjeong Go, and Sang Hyun Park. Multiple instance learning with ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Bi-directional Weakly Supervised Knowledge Distillation for Whole ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Unleashing Potential of Segmenting Ambiguous Objects in SAM", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/50ee6db59fca8643dc625829d4a0eab9-Paper-Conference.pdf", "year": 2024, "abstract_snippet": "Medical sam adapter: Adapting segment anything model for medical image segmentation. arXiv preprint arXiv:2304.12620, 2023. [59] J. M. Y. Y. Wuyang Li ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Unleashing Potential of Segmenting Ambiguous Objects in SAM", "abstract": null}
{"venue": "NeurIPS", "search_title": "On Image Segmentation With Noisy Labels - NeurIPS", "url": "https://papers.neurips.cc/paper_files/paper/2022/file/ddf6eeeaa92957d3100b217a4428d819-Paper-Conference.pdf", "year": null, "abstract_snippet": "We study two of the most popular performance metrics in medical image segmen- tation, Accuracy and Dice, when the target labels are noisy. For both metrics,.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "On Image Segmentation With Noisy Labels - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "An Electrocardiogram-Based Risk Score for Cardiovascular Mortality", "url": "https://neurips.cc/virtual/2022/60034", "year": 2022, "abstract_snippet": "... [ Medical Center 1], and with AUCs of 0.79 and 0.83 when independently evaluated at [ Medical Center 2] and [ Medical Center 3] respectively. SEER predicts 5 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "An Electrocardiogram-Based Risk Score for Cardiovascular Mortality", "abstract": null}
{"venue": "NeurIPS", "search_title": "Knowledge-based in silico models and dataset for the comparative ...", "url": "https://neurips.cc/virtual/2023/78368", "year": 2023, "abstract_snippet": "... medical devices, AI models need to be evaluated on a diverse population of ... We propose an evaluation approach for testing medical imaging AI models ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Knowledge-based in silico models and dataset for the comparative ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Workshop: MLPH: Machine Learning in Public Health - NeurIPS 2020", "url": "https://neurips.cc/virtual/2020/public/workshop_16119.html", "year": 2020, "abstract_snippet": "We expect that work featured in this workshop will differ from Machine Learning in Healthcare as it will focus on data and algorithms related to the non- medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Workshop: MLPH: Machine Learning in Public Health - NeurIPS 2020", "abstract": null}
{"venue": "NeurIPS", "search_title": "Oral Session II – Image Analysis and Segmentation - NeurIPS", "url": "https://neurips.cc/virtual/2019/16006", "year": 2019, "abstract_snippet": "Workshop: Medical Imaging meets NeurIPS. Abstract. 11:15 – Multimodal Self-Supervised Learning for Medical Image Analysis – Taleb, Lippert, Nabi, Klein 11:35 ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Oral Session II – Image Analysis and Segmentation - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "ProtoEEGNet: An Interpretable Approach for Detecting Interictal ...", "url": "https://neurips.cc/virtual/2023/82515", "year": 2023, "abstract_snippet": "Workshop: Medical Imaging meets NeurIPS ... ProtoEEGNet can therefore help medical professionals effectively detect IEDs while maintaining a transparent decision- ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "ProtoEEGNet: An Interpretable Approach for Detecting Interictal ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Towards disease-aware image editing of chest X-rays - NeurIPS 2025", "url": "https://neurips.cc/virtual/2020/20997", "year": 2020, "abstract_snippet": "... medical domain, however, is still in its infancy. Working with the CheXpert data set, here we show that StyleGAN can be trained to generate realistic chest ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards disease-aware image editing of chest X-rays - NeurIPS 2025", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Workshops Day 2", "url": "https://blog.neurips.cc/2021/12/14/neurips-workshops-day-2/", "year": null, "abstract_snippet": "Dec 14, 2021 ... Machine learning from ground truth: New medical imaging datasets for unsolved medical problems. 4:00pm – 9:00pm. Physical Reasoning and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Workshops Day 2", "abstract": null}
{"venue": "NeurIPS", "search_title": "Classification of Shoulder Impingement Syndrome using Transfer ...", "url": "https://neurips.cc/virtual/2021/33454", "year": 2021, "abstract_snippet": "... medical entity. In contrast, hereby propose that regardless of the dataset size, we can use transfer learning model as baseline to gained knowledge ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Classification of Shoulder Impingement Syndrome using Transfer ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Unsupervised Approaches for Out-Of-Distribution Dermoscopic ...", "url": "https://neurips.cc/virtual/2021/36817", "year": 2021, "abstract_snippet": "... medical data. Here, we present preliminary findings of our unsupervised OOD detection algorithm, SimCLR-LOF, as well as a recent state of the art approach ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Unsupervised Approaches for Out-Of-Distribution Dermoscopic ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Towards Trustworthy Automatic Diagnosis Systems by Emulating ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/9b6c8c4a5aeb6a37c9efa963e30993d9-Paper-Conference.pdf", "year": 2022, "abstract_snippet": "After the medical history and physical examination are completed, the physician will decide if additional tests are necessary to establish the final diagnosis.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Trustworthy Automatic Diagnosis Systems by Emulating ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Training deep learning based denoisers without ground truth data", "url": "http://papers.neurips.cc/paper/7587-training-deep-learning-based-denoisers-without-ground-truth-data", "year": null, "abstract_snippet": "... medical imaging. In this article, we propose a method based on Stein's unbiased risk estimator (SURE) for training deep neural network denoisers only based ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Training deep learning based denoisers without ground truth data", "abstract": null}
{"venue": "NeurIPS", "search_title": "A Linear Programming Approach to Novelty Detection - NIPS", "url": "http://papers.neurips.cc/paper/1822-a-linear-programming-approach-to-novelty-detection", "year": null, "abstract_snippet": "It has potential applications in many areas such as detection of ma(cid:173) chine damage or highlighting abnormal features in medical data. One approach is ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Linear Programming Approach to Novelty Detection - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Neural Jump Stochastic Differential Equations - NIPS", "url": "http://papers.neurips.cc/paper/9177-neural-jump-stochastic-differential-equations", "year": null, "abstract_snippet": "... medical records, and earthquake monitoring. Name Change Policy. ×. Requests for name changes in the electronic proceedings will be accepted with no questions ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Neural Jump Stochastic Differential Equations - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "HealthAlign-Agents: Reflective Self-Play for Culturally Safe Health ...", "url": "https://neurips.cc/media/neurips-2025/Slides/135933.pdf", "year": null, "abstract_snippet": "Same medical facts — but emotionally safe, culturally resonant, and easier to follow. Aura Arefeh Yavary. HealthAlign-Agents. CLRLC-LLMs Workshop @ NeurIPS ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "HealthAlign-Agents: Reflective Self-Play for Culturally Safe Health ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "A Recall On Thin Structures - NeurIPS", "url": "https://neurips.cc/virtual/2023/82494", "year": 2023, "abstract_snippet": "Workshop: Medical Imaging meets NeurIPS. A Recall On Thin Structures. Yannick Kirchhoff · Maximilian R. Rokuss · Saikat Roy · Balint Kovacs · Constantin ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Recall On Thin Structures - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Getting Ready for NeurIPS (2): Location, Facilities, Safety", "url": "https://blog.neurips.cc/2022/10/27/getting-ready-for-neurips-2-location-facilities-safety/", "year": null, "abstract_snippet": "Oct 27, 2022 ... Medical emergencies. All attendees should ensure that they have appropriate travel insurance. As always, we have on-site paramedics for the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Getting Ready for NeurIPS (2): Location, Facilities, Safety", "abstract": null}
{"venue": "NeurIPS", "search_title": "Conditioning 3D Diffusion Models with 2D Images - NeurIPS", "url": "https://neurips.cc/virtual/2024/106859", "year": 2024, "abstract_snippet": "High anisotropy in volumetric medical images can lead to the inconsistent quantification of anatomical and pathological structures. Particularly in optical ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106859", "full_title": "Conditioning 3D Diffusion Models with 2D Images: Towards Standardized OCT Volumes through En Face-Informed Super-Resolution", "abstract": "High anisotropy in volumetric medical images can lead to the inconsistent quantification of anatomical and pathological structures. Particularly in optical coherence tomography (OCT), slice spacing can substantially vary across and within datasets, studies, and clinical practices. We propose to standardize OCT volumes to less anisotropic volumes by conditioning 3D diffusion models with en face scanning laser ophthalmoscopy (SLO) imaging data, a 2D modality already commonly available in clinical practice. We trained and evaluated on data from the multicenter and multimodal MACUSTAR study. While upsampling the number of slices by a factor of 8, our method outperforms tricubic interpolation and diffusion models without en face conditioning in terms of perceptual similarity metrics. Qualitative results demonstrate improved coherence and structural similarity. Our approach allows for better informed generative decisions, potentially reducing hallucinations. We hope this work will provide the next step towards standardized high-quality volumetric imaging, enabling more consistent quantifications.", "summary_cn": "本研究提出利用2D SLO图像条件化3D扩散模型，对OCT体积进行超分辨率标准化，以减少各向异性，提升图像质量和一致性。", "keywords": ["光学相干断层扫描", "扩散模型", "超分辨率", "图像标准化", "各向异性", "生成模型"], "triple": {"method": "基于2D SLO图像条件化的3D扩散模型", "result": "在感知相似性指标上优于三三次插值和无条件扩散模型", "contribution": "推动OCT体积标准化，减少幻觉，提升量化一致性"}}
{"venue": "NeurIPS", "search_title": "Do Histopathological Foundation Models Eliminate Batch Effects? A ...", "url": "https://neurips.cc/virtual/2024/103891", "year": 2024, "abstract_snippet": "Our work provides a novel perspective on the evaluation of medical foundation models, paving the way for more robust pretraining strategies and downstream ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103891", "full_title": "Do Histopathological Foundation Models Eliminate Batch Effects? A Comparative Study", "abstract": "Deep learning has led to remarkable advancements in computational histopathology, e.g., in diagnostics, biomarker prediction, and outcome prognosis. Yet, the lack of annotated data and the impact of batch effects, e.g., systematic technical data differences across hospitals, hamper model robustness and generalization. Recent histopathological foundation models --- pretrained on millions to billions of images --- have been reported to improve generalization performances on various downstream tasks. However, it has not been systematically assessed whether they fully eliminate batch effects. In this study, we empirically show that the feature embeddings of the foundation models still contain distinct hospital signatures that can lead to biased predictions and misclassifications. We further find that the signatures are not removed by stain normalization methods, dominate distances in feature space, and are evident across various principal components. Our work provides a novel perspective on the evaluation of medical foundation models, paving the way for more robust pretraining strategies and downstream predictors.", "summary_cn": "研究发现，组织病理学基础模型虽提升下游任务性能，但未能完全消除医院间的批次效应，可能导致预测偏差。", "keywords": ["基础模型", "批次效应", "组织病理学", "特征嵌入", "泛化性能", "医院签名"], "triple": {"method": "实证分析特征嵌入", "result": "模型仍含医院签名，影响预测", "contribution": "为医学基础模型评估提供新视角"}}
{"venue": "NeurIPS", "search_title": "RespLLM: Unifying Audio and Text with Multimodal LLMs ... - NeurIPS", "url": "https://neurips.cc/virtual/2024/103923", "year": 2024, "abstract_snippet": "However, the data involved, spanning demographics, medical history, symptoms, and respiratory audio, are heterogeneous and complex. Existing approaches are ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103923", "full_title": "RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction", "abstract": "The high incidence and mortality rates associated with respiratory diseases underscores the importance of early screening. Machine learning models can automate clinical consultations and auscultation, offering vital support in this area. However, the data involved, spanning demographics, medical history, symptoms, and respiratory audio, are heterogeneous and complex. Existing approaches are insufficient and lack generalizability, as they typically rely on limited training data, basic fusion techniques, and task-specific design. In this paper, we propose RespLLM, a novel multimodal large language model (LLM) framework that unifies text and audio representations for respiratory health prediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs and enables effective audio-text fusion through cross-modal attentions. Instruction tuning is employed to integrate diverse data from multiple sources, ensuring generalizability and versatility of the model. Experiments on five real-world datasets demonstrate that RespLLM outperforms leading baselines by an average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates zero-shot predictions for new tasks. Our work lays the foundation for multimodal models that can perceive, listen to, and understand heterogeneous data, paving the way for scalable respiratory health diagnosis.", "summary_cn": "提出RespLLM多模态大模型，统一文本与音频表征，通过跨模态注意力和指令调优提升呼吸健康预测的泛化能力，在多个数据集上表现优异。", "keywords": ["多模态大模型", "呼吸健康预测", "音频-文本融合", "跨模态注意力", "指令调优", "泛化能力"], "triple": {"method": "跨模态注意力与指令调优", "result": "在训练任务上平均提升4.6%，未见数据集上提升7.9%", "contribution": "提出统一多模态框架，增强泛化与零样本预测能力"}}
{"venue": "NeurIPS", "search_title": "Learning Decision Theoretic Utilities through Reinforcement Learning", "url": "http://papers.neurips.cc/paper/1185-learning-decision-theoretic-utilities-through-reinforcement-learning.pdf", "year": null, "abstract_snippet": "Automated fault or medical diagnosis is an interesting and important application for deci- sion theory. It is a sequential decision problem that includes ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Learning Decision Theoretic Utilities through Reinforcement Learning", "abstract": null}
{"venue": "NeurIPS", "search_title": "Instruction Tuning Large Language Models to Understand Electronic ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/62986e0a78780fe5f17b495aeded5bab-Paper-Datasets_and_Benchmarks_Track.pdf", "year": 2024, "abstract_snippet": "Mar 11, 2024 ... We adopt the Medical Event Data Standard [Arnrich et al.] and represent each patient's EHR data as a stream of clinical events (e.g., procedures ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Instruction Tuning Large Language Models to Understand Electronic ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Region-specific Diffeomorphic Metric Mapping - NIPS", "url": "http://papers.neurips.cc/paper/8394-region-specific-diffeomorphic-metric-mapping.pdf", "year": null, "abstract_snippet": "Quantitative analysis of medical images frequently requires the estimation of spatial correspondences,. i.e.image registration. For example, one may be ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Region-specific Diffeomorphic Metric Mapping - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Non-Linear Domain Adaptation with Boosting - NIPS - NeurIPS", "url": "http://papers.neurips.cc/paper/5200-non-linear-domain-adaptation-with-boosting", "year": null, "abstract_snippet": "However, there are many problems when this assumption is grossly violated, as in bio- medical applications where different acquisitions can generate drastic ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Non-Linear Domain Adaptation with Boosting - NIPS - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Capturing implicit hierarchical structure in 3D biomedical images ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/291d43c696d8c3704cdbe0a72ade5f6c-Paper.pdf", "year": 2021, "abstract_snippet": "On the real-world medical image dataset (BraTS Brain Tumor. Segmentation Challenge) [Menze et al., 2014, Bakas et al., 2017, 2018], we show that our method.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Capturing implicit hierarchical structure in 3D biomedical images ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Active Learning from Weak and Strong Labelers - NIPS", "url": "http://papers.neurips.cc/paper/5988-active-learning-from-weak-and-strong-labelers", "year": null, "abstract_snippet": "... medical resident (weak labeler). Our goal is to learn a classifier with low error on data labeled by the oracle, while using the weak labeler to reduce the ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Active Learning from Weak and Strong Labelers - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "MoCo-Transfer: Investigating out-of-distribution contrastive learning ...", "url": "https://neurips.cc/virtual/2023/82516", "year": 2023, "abstract_snippet": "Medical imaging data is often siloed within hospitals, limiting the amount of data available for specialized model development. With limited in-domain data ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MoCo-Transfer: Investigating out-of-distribution contrastive learning ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Reliable Off-Policy Learning for Dosage Combinations - NeurIPS", "url": "https://papers.neurips.cc/paper_files/paper/2023/file/d69103d7895f4e2083f24b664003d386-Paper-Conference.pdf", "year": null, "abstract_snippet": "Yet, this is unrealistic in medical practice as there are generally drug-drug interactions. To address this, we later model the joint effect of multiple ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Reliable Off-Policy Learning for Dosage Combinations - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Learning to Compose Domain-Specific Transformations for Data ...", "url": "https://papers.neurips.cc/paper_files/paper/2017/hash/f26dab9bf6a137c3b6782e562794c2f2-Abstract.html", "year": null, "abstract_snippet": "... medical imaging dataset as compared to standard heuristic augmentation approaches. Name Change Policy. ×. Requests for name changes in the electronic ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Learning to Compose Domain-Specific Transformations for Data ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Adversarial Attacks on Stochastic Bandits - NIPS", "url": "https://proceedings.neurips.cc/paper/2018/hash/85f007f8c50dd25f5a45fca73cad64bd-Abstract.html", "year": null, "abstract_snippet": "The result means the attacker can easily hijack the behavior of the bandit algorithm to promote or obstruct certain actions, say, a particular medical treatment ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Adversarial Attacks on Stochastic Bandits - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Attention Shift: Interpretability Study of Texture-based Data ...", "url": "https://neurips.cc/virtual/2021/36799", "year": 2021, "abstract_snippet": "Texture smoothing has recently become a promising data augmentation method to enhance the performance of deep learning segmentation methods in medical image ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Attention Shift: Interpretability Study of Texture-based Data ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Improving Instrument Detection for a Robotic Scrub Nurse ...", "url": "https://neurips.cc/virtual/2022/63453", "year": 2022, "abstract_snippet": "... medical procedure, and therefore, near-perfect performance is required. Despite constituting powerful potential solutions, deep learning methods are subject ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Improving Instrument Detection for a Robotic Scrub Nurse ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS Using Temporal Similarity in Contrastive Learning for Multi ...", "url": "https://neurips.cc/virtual/2021/36809", "year": 2021, "abstract_snippet": "Creating ground truth segmentations for medical imaging is labour and time intensive. While promising, contemporary contrastive learning techniques commonly ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Using Temporal Similarity in Contrastive Learning for Multi ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Synthetic Tumors Make AI Segment Tumors Better - NeurIPS", "url": "https://neurips.cc/virtual/2022/63385", "year": 2022, "abstract_snippet": "... medical professionals can confuse with real tumors; (2) effective for training AI models, which can perform liver tumor segmentation similarly to the model ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Synthetic Tumors Make AI Segment Tumors Better - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Elevating Large Language Models for Clinical Diagnosis Prediction", "url": "https://neurips.cc/virtual/2024/106864", "year": 2024, "abstract_snippet": "... medical practice. We apply hierarchical contrastive learning on a disease candidate ranking list to alleviate the large decision space issue. With concept ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106864", "full_title": "Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction", "abstract": "Clinical diagnosis prediction models, when provided with a patient's medical history, aim to detect potential diseases early, facilitating timely intervention and improving prognostic outcomes. However, the inherent scarcity of patient data and large disease candidate space often pose challenges in developing satisfactory models for this intricate task. The exploration of leveraging modern Large Language Models (LLMs) for encapsulating clinical decision processes has been limited. We introduce MERA, a clinical diagnosis prediction model that bridges pertaining natural language knowledge with medical practice. We apply hierarchical contrastive learning on a disease candidate ranking list to alleviate the large decision space issue. With concept memorization through fine-tuning, we bridge the natural language clinical knowledge with medical codes. Experimental results on MIMIC datasets show that MERA achieves the state-of-the-art for diagnosis prediction.", "summary_cn": "MERA模型通过分层对比学习和概念记忆，将自然语言知识融入医疗实践，提升临床诊断预测性能，在MIMIC数据集上达到最优。", "keywords": ["临床诊断预测", "大型语言模型", "分层对比学习", "概念记忆", "MIMIC数据集", "疾病候选排序"], "triple": {"method": "分层对比学习与概念记忆微调", "result": "在MIMIC数据集上实现最优诊断预测", "contribution": "融合自然语言知识与医疗实践，缓解大数据稀缺和决策空间大问题"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Detecting Adversarial Attacks On Breast Cancer Diagnostic ...", "url": "https://neurips.cc/virtual/2022/63467", "year": 2022, "abstract_snippet": "... medical systems for breast cancer detection using the ABC metric. Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies for essential ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Detecting Adversarial Attacks On Breast Cancer Diagnostic ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Improving the Fairness of Deep Chest X-ray Classifiers - NeurIPS", "url": "https://neurips.cc/virtual/2021/36782", "year": 2021, "abstract_snippet": "... medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such classifiers can exhibit biases in the form of ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Improving the Fairness of Deep Chest X-ray Classifiers - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS CellMixer: Annotation-free Semantic Cell Segmentation of ...", "url": "https://neurips.cc/virtual/2023/82514", "year": 2023, "abstract_snippet": "... medical imaging, cellular biology, and diagnostics. Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies for essential functions only ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS CellMixer: Annotation-free Semantic Cell Segmentation of ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Can Large Language Models Build Causal Graphs? - NeurIPS", "url": "https://neurips.cc/virtual/2022/61740", "year": 2022, "abstract_snippet": "... medical literature. By encoding common and medical knowledge, large language models (LLMs) represent an opportunity to ease this process by automatically ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Can Large Language Models Build Causal Graphs? - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "MDPs with Non-Deterministic Policies", "url": "http://papers.neurips.cc/paper/3504-mdps-with-non-deterministic-policies.pdf", "year": null, "abstract_snippet": "choices in the context of medical decision support systems [1, 2, 3, 4]. Given an adequate MDP model (or data source), many methods can be used to find a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "MDPs with Non-Deterministic Policies", "abstract": null}
{"venue": "NeurIPS", "search_title": "Modelling Spatially Correlated Aleatoric Uncertainty - NeurIPS", "url": "https://papers.neurips.cc/paper_files/paper/2020/file/95f8d9901ca8878e291552f001f67692-Paper.pdf", "year": null, "abstract_snippet": "In image segmentation, there is often more than one plausible solution for a given input. In medical imaging, for example, experts will often disagree about ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Modelling Spatially Correlated Aleatoric Uncertainty - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Attentive State-Space Modeling of Disease Progression - NeurIPS", "url": "http://papers.neurips.cc/paper/9311-attentive-state-space-modeling-of-disease-progression.pdf", "year": null, "abstract_snippet": "To learn the model parameters from medical records, we develop an inference algo- rithm that jointly learns a compiled inference network and the model ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Attentive State-Space Modeling of Disease Progression - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Neuropathic Pain Diagnosis Simulator for Causal Discovery ...", "url": "http://papers.neurips.cc/paper/9440-neuropathic-pain-diagnosis-simulator-for-causal-discovery-algorithm-evaluation", "year": null, "abstract_snippet": "In this work, we handle the problem of evaluating causal discovery algorithms by building a flexible simulator in the medical setting. We develop a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Neuropathic Pain Diagnosis Simulator for Causal Discovery ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Robust semi-supervised segmentation with timestep ensembling ...", "url": "https://neurips.cc/virtual/2023/82472", "year": 2023, "abstract_snippet": "Our research focuses on Semi-Supervised medical image Segmentation (SSS) using Denoising Diffusion Probabilistic Models latent representations and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Robust semi-supervised segmentation with timestep ensembling ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Synthetic Tumor Manipulation: With Radiomics Features - NeurIPS", "url": "https://neurips.cc/virtual/2023/82485", "year": 2023, "abstract_snippet": "... medical imaging research and potential clinical applications. Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies for essential ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Synthetic Tumor Manipulation: With Radiomics Features - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Simulating k-space artifacts for robust CNNs - NeurIPS", "url": "https://neurips.cc/virtual/2022/63415", "year": 2022, "abstract_snippet": "... Medical Segmentation Decathlon (n=750) and The Cancer Imaging Archive (n=243). Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Simulating k-space artifacts for robust CNNs - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis ...", "url": "https://papers.neurips.cc/paper_files/paper/2023/file/39736af1b9d87a1fddad9f84a6bcf64c-Paper-Datasets_and_Benchmarks.pdf", "year": null, "abstract_snippet": "Existing medical imaging datasets are small in size [67], do not include diverse data modalities [44], or have few diagnosis/prognosis labels [38]. Addressing ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS ECG for high-throughput screening of multiple diseases", "url": "https://neurips.cc/virtual/2021/36834", "year": 2021, "abstract_snippet": "... medical conditions and >2 million ECGs to identify a wide range of diseases that could be accurately diagnosed from the patient's first in-hospital ECG. Our ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS ECG for high-throughput screening of multiple diseases", "abstract": null}
{"venue": "NeurIPS", "search_title": "A Probabilistic U-Net for Segmentation of Ambiguous Images - NIPS", "url": "http://papers.neurips.cc/paper/7928-a-probabilistic-u-net-for-segmentation-of-ambiguous-images.pdf", "year": null, "abstract_snippet": "Such ambiguities are common in medical imaging applications, e.g., in lung abnormalities segmentation from CT images. A lesion might be clearly visible, but the.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Probabilistic U-Net for Segmentation of Ambiguous Images - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Contactless Oxygen Monitoring with Gated Transformer - NeurIPS", "url": "https://neurips.cc/virtual/2022/60060", "year": 2022, "abstract_snippet": "... medical indices (e.g., gender, sleep stages). It has multiple predictive heads and selects the most suitable head via a gate controlled by the person's ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Contactless Oxygen Monitoring with Gated Transformer - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS 2024 Papers", "url": "https://neurips.cc/virtual/2024/papers.html", "year": 2024, "abstract_snippet": "Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation? MMScan: A Multi-Modal 3D Scene Dataset with ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS 2024 Papers", "abstract": null}
{"venue": "NeurIPS", "search_title": "A tale of limited and imbalanced data that models won't hear - NeurIPS", "url": "https://neurips.cc/virtual/2021/36669", "year": 2021, "abstract_snippet": "The collection of such labeled medical data is a challenging and expensive task in itself. The current study is the first to examine models in a real-world ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A tale of limited and imbalanced data that models won't hear - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Typicalness-Aware Learning for Failure Detection", "url": "https://neurips.cc/media/neurips-2024/Slides/95120_1gAbHe9.pdf", "year": null, "abstract_snippet": "Nov 4, 2024 ... medical diagnosis. Classifier prediction confidence. Can I trust the prediction? input. Page 4. prediction: horse gt: cow confidence: 0.99.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Typicalness-Aware Learning for Failure Detection", "abstract": null}
{"venue": "NeurIPS", "search_title": "Heterogenous Analysis of KeyBERT, BERTopic, PyCaret and LDAs ...", "url": "https://neurips.cc/virtual/2022/57534", "year": 2022, "abstract_snippet": "... medical data. This paper explores the heterogeneity of keyBERT, BERTopic, PyCaret and LDAs as key phrase generators and topic model extractors with P53 in ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Heterogenous Analysis of KeyBERT, BERTopic, PyCaret and LDAs ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Large Margin Taxonomy Embedding with an Application to ...", "url": "http://papers.neurips.cc/paper/3597-large-margin-taxonomy-embedding-for-document-categorization.pdf", "year": null, "abstract_snippet": "Experiments on the OHSUMED medical journal data base yield state-of-the-art results on topic categorization. 1 Introduction. Multi-class classification is a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Large Margin Taxonomy Embedding with an Application to ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense ...", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/hash/03c6b06952c750899bb03d998e631860-Abstract-round2.html", "year": 2021, "abstract_snippet": "Magnetic resonance imaging (MRI) is a cornerstone of modern medical imaging. However, long image acquisition times, the need for qualitative expert analysis ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Benchmarking Bayesian Deep Learning on Diabetic Retinopathy ...", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/ac1dd209cbcc5e5d1c6e28598e8cbbe8-Abstract-round2.html", "year": null, "abstract_snippet": "Specifically, we curate two publicly available datasets of high-resolution human retina images exhibiting varying degrees of diabetic retinopathy, a medical ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Benchmarking Bayesian Deep Learning on Diabetic Retinopathy ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "NeurIPS 2:30 - 3:30 PM: M3H: Multimodal Multitask ML for Healthcare", "url": "https://neurips.cc/virtual/2024/109305", "year": 2024, "abstract_snippet": "Online Oral in. Workshop: AIM-FM: Advancements In Medical Foundation Models: Explainability, Robustness, Security, and Beyond ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/109305", "full_title": "2:30 - 3:30 PM: M3H: Multimodal Multitask ML for Healthcare", "abstract": "M3H: Multimodal Multitask ML for Healthcare, NIPS Oral for AIM-FM Workshop", "summary_cn": "M3H提出多模态多任务机器学习框架，应用于医疗健康领域，提升模型性能与效率。", "keywords": ["多模态学习", "多任务学习", "机器学习", "医疗健康", "NIPS", "AIM-FM"], "triple": {"method": "多模态多任务机器学习框架", "result": "提升医疗模型性能与效率", "contribution": "推动医疗AI应用发展"}}
{"venue": "NeurIPS", "search_title": "A Dataset ofMedicalEntity and Targeted Sentiment on COVID-19 ...", "url": "https://neurips.cc/media/neurips-2022/Slides/55656.pdf", "year": null, "abstract_snippet": "Drug. Figure 1: Examples of medical entities and targeted sentiments in tweets. Contribution: •. We released METS-CoV ( Medical Entities and Targeted Sentiments ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "A Dataset ofMedicalEntity and Targeted Sentiment on COVID-19 ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Chest ImaGenome Dataset for Clinical Reasoning", "url": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/17e62166fc8586dfa4d1bc0e1742c08b-Paper-round2.pdf", "year": null, "abstract_snippet": "In the non- medical domain, large locally labeled graph datasets (e.g., Visual Genome dataset [26]) have enabled the development of algorithms that can integrate ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Chest ImaGenome Dataset for Clinical Reasoning", "abstract": null}
{"venue": "NeurIPS", "search_title": "On Image Segmentation With Noisy Labels - OpenReview", "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/ddf6eeeaa92957d3100b217a4428d819-Paper-Conference.pdf", "year": 2022, "abstract_snippet": "We study two of the most popular performance metrics in medical image segmen- tation, Accuracy and Dice, when the target labels are noisy. For both metrics ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "On Image Segmentation With Noisy Labels - OpenReview", "abstract": null}
{"venue": "NeurIPS", "search_title": "Topology-Preserving Deep Image Segmentation - NeurIPS", "url": "http://papers.neurips.cc/paper/8803-topology-preserving-deep-image-segmentation.pdf", "year": null, "abstract_snippet": "Ridge-based vessel segmentation in color images of the retina. IEEE transactions on medical imaging, 23(4):501–509, 2004. [40] Jan Stuhmer, Peter Schroder, and ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Topology-Preserving Deep Image Segmentation - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Predicting the Risk of Complications in Coronary Artery Bypass ...", "url": "https://papers.neurips.cc/paper_files/paper/1994/file/168908dd3227b8358eababa07fcaf091-Paper.pdf", "year": null, "abstract_snippet": "Classifiers were used to predict mortality, post- operative strokes, and renal failure. Predictions were made after a patient's medical history was obtained ( ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Predicting the Risk of Complications in Coronary Artery Bypass ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Keynote 3: Martin J McKeown - NeurIPS 2025", "url": "https://neurips.cc/virtual/2023/84588", "year": 2023, "abstract_snippet": "Workshop: Medical Imaging meets NeurIPS. Keynote 3: Martin J McKeown. 2023 Keynote in. Workshop: Medical Imaging meets NeurIPS. Video. It appears you are a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Keynote 3: Martin J McKeown - NeurIPS 2025", "abstract": null}
{"venue": "NeurIPS", "search_title": "Disease Trajectory Maps - NIPS", "url": "http://papers.neurips.cc/paper/6177-disease-trajectory-maps.pdf", "year": null, "abstract_snippet": "We propose a stochastic variational inference algorithm for learning the DTM that allows the model to scale to large modern medical datasets. To demonstrate ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Disease Trajectory Maps - NIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Towards Semi-Structured Automatic ICD Coding via Tree-based ...", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/d74f9efa1d8ca30b31d65cef8de7c2bf-Paper-Conference.pdf", "year": 2023, "abstract_snippet": "The process of extracting ICD codes from clinical notes is referred to as. ICD coding and is a crucial task in medical services such as medical records ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Semi-Structured Automatic ICD Coding via Tree-based ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes", "url": "http://papers.neurips.cc/paper/9496-near-optimal-reinforcement-learning-in-dynamic-treatment-regimes.pdf", "year": null, "abstract_snippet": "In medical practice, a patient typically has to be treated at multiple stages; the physician repeatedly adapts each treatment, tailored to the patient's ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes", "abstract": null}
{"venue": "NeurIPS", "search_title": "Joint Active Feature Acquisition and Classification with Variable ...", "url": "http://papers.neurips.cc/paper/7411-joint-active-feature-acquisition-and-classification-with-variable-size-set-encoding.pdf", "year": null, "abstract_snippet": "We evaluate our model on a carefully designed synthetic dataset for the active feature acquisition as well as several medical datasets. Our framework shows ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Joint Active Feature Acquisition and Classification with Variable ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Multimodal Clinical Benchmark for Emergency Care (MC-BEC)", "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/8f61049e8fe5b9ed714860b951066f1e-Paper-Datasets_and_Benchmarks.pdf", "year": 2023, "abstract_snippet": "Nov 7, 2023 ... Existing medical AI benchmarks fall short in comprehensively evaluating generalist medical AI. (GMAI) and clinical foundation models. GMAI ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Multimodal Clinical Benchmark for Emergency Care (MC-BEC)", "abstract": null}
{"venue": "NeurIPS", "search_title": "Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR ...", "url": "http://papers.neurips.cc/paper/1815-sequentially-fitting-inclusive-trees-for-inference-in-noisy-or-networks.pdf", "year": null, "abstract_snippet": "For example, in medical diagnosis, the presence of a symptom can be expressed as a noisy-OR of the diseases that may cause the symptom - on some occasions, a ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Bayesian Image Super-Resolution", "url": "http://papers.neurips.cc/paper/2315-bayesian-image-super-resolution.pdf", "year": null, "abstract_snippet": "such as remote sensing, surveillance, medical imaging and the ex- traction of still images from video. Typical approaches are based on the use of cross ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Bayesian Image Super-Resolution", "abstract": null}
{"venue": "NeurIPS", "search_title": "Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS ...", "url": "http://papers.neurips.cc/paper/2114-analog-soft-pattern-matching-classifier-using-floating-gate-mos-technology.pdf", "year": null, "abstract_snippet": "The test chip was fabri- cated in a 0.6-µm CMOS technology and successfully applied to hand-written pattern recognition and medical radiograph analysis using.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Analog Soft-Pattern-Matching Classifier using Floating-Gate MOS ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "SyncTwin: Treatment Effect Estimation with Longitudinal Outcomes", "url": "https://neurips.cc/virtual/2021/poster/27560", "year": 2021, "abstract_snippet": "Dec 5, 2021 ... Most of the medical observational studies estimate the causal treatment effects using electronic health records (EHR), where a patient's ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "SyncTwin: Treatment Effect Estimation with Longitudinal Outcomes", "abstract": null}
{"venue": "NeurIPS", "search_title": "Noise Suppression Based on Neurophysiologically-motivated SNR ...", "url": "http://papers.neurips.cc/paper/1902-noise-suppression-based-on-neurophysiologically-motivated-snr-estimation-for-robust-speech-recognition.pdf", "year": null, "abstract_snippet": "Medical Physics Group. Oldenburg University. 26111 Oldenburg. Germany tch@medi.physik.uni-oldenburg.de. Michael Kleinschmidt. Medical Physics Group. Oldenburg ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Noise Suppression Based on Neurophysiologically-motivated SNR ...", "abstract": null}
{"venue": "NeurIPS", "search_title": "Cognitive Machine Learning for Reducing Survey Fatigue in Clinical ...", "url": "https://neurips.cc/virtual/2025/133792", "year": 2025, "abstract_snippet": "Clinical trials are essential to advancing medical knowledge, but current data collection methods impose heavy cognitive demands on participants [1]. A ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133792", "full_title": "Cognitive Machine Learning for Reducing Survey Fatigue in Clinical Trials", "abstract": "Clinical trials are essential to advancing medical knowledge, but current data collection methods impose heavy cognitive demands on participants [1]. A major challenge is survey fatigue, particularly in electronic patient-reported outcomes (ePROs), where repeated questionnaires lead to habituation, superficial responses, and disengagement [2]. These effects undermine data reliability and erode trust in the trial process. We propose a cognitive machine learning framework that addresses this problem by embedding insights from cognitive science into ML-driven trial design [3].    We created a phased roadmap for combining cognitive science and ML in clinical research. Phase 1 introduces lightweight cognitive overlays into ePRO systems: adaptive phrasing, variable timing, and reinforcement learning-based adjustments designed to minimize cognitive load [1] while sustaining engagement through strategies analogous to cognitive behavioral techniques such as reframing and gradual exposure [4]. Phase 2 integrates a patient-first cognitive ML model trained with behavioral priors (e.g., Centaur-style models [5]) to sustain engagement and predict dropouts. This model delivers calibrated summaries and defers low-confidence cases to clinicians. Phase 3 reframes trials as cognitive ecosystems, where participant engagement metrics—such as attention, comprehension, and trust—become first-class endpoints alongside biomarkers.   We illustrate the feasibility of our approach through a survey fatigue case study. A conversational overlay adaptively rephrases questions, detects hesitation cues, and introduces cognitive scaffolding to sustain attention. Outputs are mapped back into standard ePRO formats with auditable traces. Early results suggest this approach can reduce missingness, improve response quality, and lower dropout risks while preserving regulatory compliance and clinician oversight [6].   Our work represents both an epistemic and ethical shift. It reframes survey responses not as noisy compliance data but as cognitively mediated signals. And by modeling participant comprehension, attention, and engagement, cognitive ML provides pathways to reduce attrition, improve inclusivity, and strengthen patient trust. This case study demonstrates how cognitively aware trials can enhance reliability, equity, and participant-centeredness.  References  [1] J. Sweller. Cognitive load during problem solving: effects on learning. Cognitive Science, 12(2):257–285, 1988.  [2] S. Rolstad, J. Adler, and A. Rydén. Response burden and questionnaire length: is shorter better? A review and meta-analysis. Value in Health, 14(8):1101–1108, 2011.  [3] A. Tversky and D. Kahneman. Judgment under uncertainty: heuristics and biases. Science, 185(4157):1124–1131, 1974.  [4] F. Lieder and T. L. Griffiths. Resource-rational analysis: understanding human cognition as the optimal use of limited computational resources. Behavioral and Brain Sciences, 43:e1, 2020.  [5] M. Binz, E. Akata, M. Bethge, et al. A foundation model to predict and capture human cognition. Nature, 644:1002–1009, 2025. doi:10.1038/s41586-025-09215-4.  [6] E. Basch, A. M. Deal, A. C. Dueck, H. I. Scher, M. G. Kris, C. Hudis, and D. Schrag. Overall survival results of a trial assessing patient-reported outcomes for symptom monitoring during routine cancer treatment. JAMA, 318(2):197–198, 2017.", "summary_cn": "提出认知机器学习框架，通过自适应提问、认知支架等技术减少临床试验中的问卷疲劳，提升数据质量和参与者参与度。", "keywords": ["认知机器学习", "问卷疲劳", "临床试验", "电子患者报告结局", "参与度", "自适应系统"], "triple": {"method": "认知科学+机器学习的三阶段框架", "result": "减少数据缺失、提升回答质量、降低退出风险", "contribution": "将问卷响应重构为认知信号，提升试验可靠性与以患者为中心"}}
{"venue": "NeurIPS", "search_title": "Subclass-Aware Inclusive Classifier via Repulsive Hidden Strata", "url": "https://neurips.cc/virtual/2025/133906", "year": 2025, "abstract_snippet": "... medical imaging. We introduce Subclass-Aware Inclusive Classification (SAIC), a framework shown in Figure 1 that explicitly addresses hidden stratification ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133906", "full_title": "Subclass-Aware Inclusive Classifier via Repulsive Hidden Strata", "abstract": "Classification models in machine learning are typically trained with coarse-grained class labels,  which overlook fine-grained subclass variations. This phenomenon, known as hidden stratification [1], results in asymmetric performance; models excel on dominant subclasses but struggle on rare or underrepresented ones. Such biases critically undermine fairness and robustness, especially in safety-sensitive applications such as medical imaging. We introduce Subclass-Aware Inclusive Classification (SAIC), a framework shown in Figure 1 that explicitly addresses hidden stratification. SAIC operates in two stages: (i) unsupervised subclass identification using a repulsive point process (k-DPP [2]) to uncover diverse and representative latent subclasses without prior assumptions, and (ii) subclass-aware classification with Group Distributionally Robust Optimization (GDRO), which emphasizes minimizing worst-case subclass loss. Extensive experiments on four benchmark datasets (MNIST, CIFAR-10, Waterbirds, and CelebA) show that SAIC consistently improves robustness without compromising overall accuracy. Specifically, we compare against K-means- and GMM-generated subclasses [3, 1] and also give the accuracy obtained using true subclass labels, as given in Table 1. Beyond overall accuracy, SAIC’s clustering module demonstrates superior subclass identification, closely matching true subclass counts, preserving rare subclass purity, and maintaining moderate runtime efficiency. SAIC provides a scalable solution to hidden stratification by combining diversity-aware subclass discovery with robust optimization, thereby enhancing fairness and reliability in high-stakes classification tasks.", "summary_cn": "提出SAIC框架解决隐藏分层问题，通过无监督子类识别与分布鲁棒优化，提升模型在罕见子类上的性能，增强公平性与鲁棒性。", "keywords": ["隐藏分层", "子类识别", "分布鲁棒优化", "公平性", "无监督学习", "分类模型"], "triple": {"method": "k-DPP子类识别与GDRO优化", "result": "提升罕见子类性能，保持整体精度", "contribution": "增强分类公平性与鲁棒性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster Beyond Average Value Function in Precision Medicine", "url": "https://neurips.cc/virtual/2025/poster/118678", "year": 2025, "abstract_snippet": "Dec 4, 2025 ... ... medical and healthcare research. Current reinforcement learning (RL) algorithms have only been applied to time-to-event data, with the ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/poster/118678", "full_title": "Beyond Average Value Function in Precision Medicine: Maximum Probability-Driven Reinforcement Learning for  Survival Analysis", "abstract": "Constructing multistage optimal decisions for alternating recurrent event data is critically important in medical and healthcare research. Current reinforcement learning (RL) algorithms have only been applied to time-to-event data, with the objective of maximizing expected survival time. However, alternating recurrent event data has a different structure, which motivates us to model the probability and frequency of event occurrences rather than a single terminal outcome.  In this paper, we introduce an RL framework specifically designed for alternating recurrent event data. Our goal is to maximize the probability that the duration between consecutive events exceeds a clinically meaningful threshold. To achieve this, we identify a lower bound of this probability, which transforms the problem into maximizing a cumulative sum of log probabilities, thus enabling direct application of standard RL algorithms. We establish the theoretical properties of the resulting optimal policy and demonstrate through numerical experiments that our proposed algorithm yields a larger probability of that the time between events exceeds a critical threshold compared with existing state-of-the-art algorithms.", "summary_cn": "本文提出一种强化学习框架，针对交替复发事件数据，旨在最大化事件间隔超过临床阈值的概率，而非传统生存时间。", "keywords": ["强化学习", "生存分析", "交替复发事件", "概率最大化", "精准医疗", "最优策略"], "triple": {"method": "提出最大化事件间隔概率的强化学习框架", "result": "算法在数值实验中优于现有方法，提高事件间隔超过阈值的概率", "contribution": "为交替复发事件数据提供新强化学习目标，扩展精准医疗应用"}}
{"venue": "NeurIPS", "search_title": "Fine-Tuning Large Language Models on EHR Data for Early ...", "url": "https://neurips.cc/virtual/2025/133856", "year": 2025, "abstract_snippet": "... medical experts using standardized keyword-based criteria. These notes were segmented, tokenized, and encoded. The LLMs LLaMA, Gemma, GatorTron, and GPT-4o ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2025/133856", "full_title": "Fine-Tuning Large Language Models on EHR Data for Early Endometriosis Diagnosis in Adolescents", "abstract": "Fine-Tuning Large Language Models on EHR Data for Early Endometriosis Diagnosis in Adolescents  Background. Endometriosis is a chronic condition affecting approximately 10% of women, with adolescents often experiencing diagnostic delays up to three times longer than adults.1 Contributing factors include a lack of non-invasive diagnostic methods and symptom overlap with other conditions. Genetic variants may influence the risk of developing endometriosis2-4, but integrating genomic data into clinical decision-making remains underexplored. This project aims to combine large language models (LLMs) with genetic biomarkers to develop multi-modal, fine-tuned models for early and accurate detection of endometriosis in adolescents.  Methods. We collected 7,221 clinical notes from the Mount Sinai Data Warehouse (MSDW) for 125 patients (ages 13–19) diagnosed with endometriosis. A subset of 700 notes from 26 patients was annotated by medical experts using standardized keyword-based criteria. These notes were segmented, tokenized, and encoded. The LLMs LLaMA, Gemma, GatorTron, and GPT-4o were fine-tuned for clinical natural language processing (NLP) tasks and evaluated using accuracy, precision, recall, and F1 metrics. In addition to the clinical notes, we obtained access to the Mount Sinai Million Health Discoveries Program for genetic data and are in the process of conducting a genome-wide association study (GWAS) to identify endometriosis-associated markers. These genomic features, including SNPs and polygenic risk scores (PRS), will be integrated as structured inputs alongside unstructured clinical text to improve predictive accuracy and support personalized diagnosis.  Results. Across nine clinical symptom categories, GPT-4o-chat achieved the strongest overall performance, with an average F1 of 0.486 and accuracy of 0.871. Gemma performed moderately (F1: 0.261, Acc: 0.869), while LLaMA showed comparable accuracy (0.905) but a lower F1 (0.258). GatorTron obtained the lowest F1 (0.189) despite competitive accuracy (0.887). For endometriosis classification specifically, all models achieved relatively high accuracy (>0.62), though GPT-4o-chat led with the highest F1 (0.771). These results indicate that GPT-4o-chat provided the best balance between precision and recall. However, performance varied widely by symptom, with models excelling in structured signals like pelvic tenderness but struggling on more non-specific categories such as GI symptoms. LLaMa exhibited the longest training and evaluation times.   Discussion. This study is one of the first systematic evaluations of open-source, trainable LLMs for NLP-based detection of adolescent endometriosis from unstructured EHR data. GPT-4o-chat demonstrated the strongest performance while maintaining computational efficiency, underscoring its potential scalability in resource-constrained clinical settings. By fine-tuning LLMs using EHR notes, these models can uncover subtle diagnostic patterns that are often missed in conventional workflows. Incorporating genetic information following GWAS will further enhance predictive power by enabling the models to capture both symptomatic presentation and underlying biological risk. Together, these findings highlight the promise of multi-modal frameworks to support earlier, more accurate diagnoses, guide personalized treatment strategies, and advance equitable care.  References DiVasta, A. D., Vitonis, A. F., Laufer, M. R., & Missmer, S. A. (2018). Spectrum of symptoms in women diagnosed with endometriosis during adolescence vs adulthood. American journal of obstetrics and gynecology, 218(3), 324.e1–324.e11.  Mackenzie, S. C., et al. (2024). Genome-wide association reveals a locus in neuregulin 3 associated with gabapentin efficacy in women with chronic pelvic pain. iScience, 27(8), 110370.  Dimitrakov, J., & Guthrie, D. (2009). Genetics and phenotyping of urological chronic pelvic pain syndrome. The Journal of urology, 181(4), 1550–1557. Li, Y. Z., & Ji, R. R. (2024). Gene therapy for chronic pain management. Cell reports. Medicine, 5(10), 101756.", "summary_cn": "研究通过微调大语言模型分析青少年子宫内膜异位症患者的电子健康记录，结合基因组数据提升早期诊断准确性。GPT-4o-chat表现最佳，为多模态诊断框架提供支持。", "keywords": ["子宫内膜异位症", "大语言模型", "电子健康记录", "基因组数据", "早期诊断", "青少年"], "triple": {"method": "微调LLMs分析EHR与基因组数据", "result": "GPT-4o-chat在症状分类中F1达0.486，诊断F1为0.771", "contribution": "提出多模态框架，提升青少年子宫内膜异位症早期诊断准确性"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Jogging the Memory of Unlearned LLMs Through Targeted ...", "url": "https://neurips.cc/virtual/2024/106237", "year": 2024, "abstract_snippet": "For example, we show that relearning on public medical articles can lead an unlearned LLM to output harmful knowledge about bioweapons, relearning general ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106237", "full_title": "Jogging the Memory of Unlearned LLMs Through Targeted Relearning Attacks", "abstract": "Machine unlearning is a promising approach to mitigate undesirable memorization of training data in ML models. However, in this work we show that existing approaches for unlearning in LLMs are surprisingly susceptible to a simple set of targeted relearning attacks . With access to only a small and potentially loosely related set of data, we find that we can “jog” the memory of unlearned models to reverse the effects of unlearning. For example, we show that relearning on public medical articles can lead an unlearned LLM to output harmful knowledge about bioweapons, relearning general wiki information about the book series Harry Potter can force the model to output verbatim memorized text. We formalize this unlearning-relearning pipeline, explore the attack across three popular unlearning benchmarks, and discuss future works and guidelines that result from our study.", "summary_cn": "研究发现，现有大语言模型遗忘方法易受针对性再学习攻击，少量数据即可恢复遗忘内容，揭示遗忘机制脆弱性。", "keywords": ["大语言模型", "遗忘机制", "再学习攻击", "数据安全", "模型脆弱性", "记忆恢复"], "triple": {"method": "针对性再学习攻击", "result": "少量数据可逆转遗忘效果", "contribution": "揭示遗忘机制脆弱性并提出指南"}}
{"venue": "NeurIPS", "search_title": "Towards Conversational AI for Spina Bifida Care - NeurIPS", "url": "https://neurips.cc/virtual/2024/104984", "year": 2024, "abstract_snippet": "... medical challenges of SB. We introduce an \\textit{inverse prompting} technique designed to guide LLMs through a step-wise diagnostic process by ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/104984", "full_title": "Towards Conversational AI for Spina Bifida Care", "abstract": "Spina Bifida (SB) is a complex neural tube defect that presents multifaceted healthcare challenges requiring multidisciplinary management. While advances in foundation models (FMs), offer promising avenues for enhancing SB care through intelligent, context-aware support, existing models struggle to accurately identify and reason about SB's diverse symptoms. This study benchmarks eight widely used large language models (LLMs) through qualitative and quantitative evaluations, focusing on their ability to address the unique medical challenges of SB. We introduce an \\textit{inverse prompting} technique designed to guide LLMs through a step-wise diagnostic process by incorporating a predefined symptom set relevant to SB, thereby preventing premature conclusions and improving diagnostic reasoning. Our evaluations reveal significant limitations in the LLMs' abilities to accurately diagnose SB-related conditions, underscoring the need for specialized approaches. Building on these findings, we propose a novel framework that integrates a structured, symptom-based knowledge base specific to SB, enhancing the models' contextual understanding and reasoning capabilities. This work highlights the potential of tailored AI solutions in improving access to care for individuals with SB, particularly in populations where gaps in knowledgeable providers persist. By addressing the shortcomings of general-purpose LLMs, our suggested framework aims to streamline SB care and improve patient outcomes, paving the way for more effective AI-assisted healthcare interventions in complex chronic conditions.", "summary_cn": "本研究评估了八种大语言模型在脊柱裂护理中的表现，发现其诊断能力有限。提出了一种结合症状知识库的框架，通过逆提示技术提升模型推理，以改善复杂慢性病的AI辅助医疗。", "keywords": ["脊柱裂", "大语言模型", "逆提示", "诊断推理", "医疗AI", "症状知识库"], "triple": {"method": "逆提示技术与症状知识库集成", "result": "模型诊断能力有限，但新框架提升推理", "contribution": "为脊柱裂护理提供定制化AI解决方案"}}
{"venue": "NeurIPS", "search_title": "Adversarial Resilience in Sequential Prediction via Abstention", "url": "https://neurips.cc/virtual/2023/poster/69996", "year": 2023, "abstract_snippet": "... medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Adversarial Resilience in Sequential Prediction via Abstention", "abstract": null}
{"venue": "NeurIPS", "search_title": "Finding Interior Optimum of Black-box Constrained Objective with ...", "url": "https://neurips.cc/virtual/2024/98894", "year": 2024, "abstract_snippet": "... medical therapies, industrial process optimization, and hyperparameter optimization. One popular approach to handle these complex scenarios is Bayesian ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/98894", "full_title": "Finding Interior Optimum of Black-box Constrained Objective with Bayesian Optimization", "abstract": "Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is a common scenario in real-world applications such as the design of medical therapies, industrial process optimization, and hyperparameter optimization. One popular approach to handle these complex scenarios is Bayesian Optimization (BO). However, when it comes to the theoretical understanding of constrained Bayesian optimization (CBO), the existing framework often relies on heuristics, approximations, or relaxation of objectives and, therefore, lacks the same level of theoretical guarantees as in canonical BO. In this paper, we exclude the boundary candidates that could be compromised by noise perturbation and aim to find the interior optimum of the black-box-constrained objective. We rely on the insight that optimizing the objective and learning the constraints can both help identify the high-confidence regions of interest (ROI) that potentially contain the interior optimum. We propose an efficient CBO framework that intersects the ROIs identified from each aspect on a discretized search space to determine the general ROI. Then, on the ROI, we optimize the acquisition functions, balancing the learning of the constraints and the optimization of the objective. We showcase the efficiency and robustness of our proposed CBO framework through the high probability regret bounds for the algorithm and extensive empirical evidence.", "summary_cn": "提出一种高效约束贝叶斯优化框架，通过排除边界候选点并交叉高置信兴趣区域，寻找黑盒约束目标的内点最优解，具有理论保证和实证验证。", "keywords": ["约束贝叶斯优化", "黑盒函数", "内点最优", "兴趣区域", "高概率遗憾界", "噪声鲁棒性"], "triple": {"method": "交叉高置信兴趣区域并优化获取函数", "result": "实现高效鲁棒的内点最优解搜索", "contribution": "提供理论保证的约束贝叶斯优化框架"}}
{"venue": "NeurIPS", "search_title": "NeurIPS Poster Identification of Nonlinear Latent Hierarchical Models", "url": "https://neurips.cc/virtual/2023/poster/71500", "year": 2023, "abstract_snippet": "... medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "NeurIPS Poster Identification of Nonlinear Latent Hierarchical Models", "abstract": null}
{"venue": "NeurIPS", "search_title": "Brant: Foundation Model for Intracranial Neural Signal - NeurIPS", "url": "https://neurips.cc/media/neurips-2023/Slides/72383.pdf", "year": null, "abstract_snippet": "– In medical scenarios, collecting labeled data is a huge investment… Model Analysis. Page ... directly participate in other medical research and treatment.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Brant: Foundation Model for Intracranial Neural Signal - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Geometric Deep Learning with Quasiconformal Neural Networks", "url": "https://neurips.cc/virtual/2024/103474", "year": 2024, "abstract_snippet": "... medical imaging. Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies for essential functions only. We do not sell your personal ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/103474", "full_title": "Geometric Deep Learning with Quasiconformal Neural Networks: An Introduction", "abstract": "We introduce Quasiconformal Neural Networks (QNNs), a novel framework that integrates quasiconformal maps into neural architectures, providing a rigorous mathematical basis for handling non-Euclidean data. QNNs control geometric distortions using bounded maximal dilatation across network layers, preserving essential data structures. We present theoretical results that guarantee the stability and geometric consistency of QNNs. This work opens new avenues in geometric deep learning, particularly for applications involving complex topologies, with significant implications for fields such as image registration and medical imaging.", "summary_cn": "本文提出拟共形神经网络（QNNs），将拟共形映射融入神经网络，为处理非欧几里得数据提供数学基础，控制几何失真并保证稳定性，推动几何深度学习在图像配准和医学成像等领域的应用。", "keywords": ["拟共形神经网络", "几何深度学习", "非欧几里得数据", "几何失真控制", "图像配准", "医学成像"], "triple": {"method": "集成拟共形映射到神经网络", "result": "控制几何失真并保证稳定性", "contribution": "为处理非欧数据提供新框架"}}
{"venue": "NeurIPS", "search_title": "AnyPrefer: An Automatic Framework for Preference Data Synthesis", "url": "https://neurips.cc/virtual/2024/106177", "year": 2024, "abstract_snippet": "... medical image analysis datasets, and 14.50 in four visuo-motor control tasks. Show more. Chat is not available. Successful Page Load. NeurIPS uses cookies for ...", "is_main_conference": true, "abstract_source_venue": "NeurIPS", "abstract_source_url": "https://neurips.cc/virtual/2024/106177", "full_title": "AnyPrefer: An Automatic Framework for Preference Data Synthesis", "abstract": "High-quality preference data is essential for aligning foundation models with human values through preference learning. However, manual annotation of such data is often time-consuming and costly. Recent methods adopt a self-rewarding approach, where the target model generates and annotates its own preference data, but this can lead to inaccuracies due to the reward model sharing weights with the target model, amplifying inherent biases. To address these issues, we propose Anyprefer, a framework designed to synthesize high-quality preference data for the target model. Anyprefer frames the data synthesis process as a cooperative two-player Markov Game, where the target model and a judge model collaborate. Here, a series of external tools are introduced to assist the judge model in accurately rewarding the target model’s responses, mitigating biases in the process. We also introduce a feedback mechanism to optimize prompts for both models, enhancing collaboration and improving data quality. The synthesized data is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K high-quality preference pairs. Extensive experiments show that Anyprefer significantly improves model alignment across four applications, covering 21 datasets, achieving average improvements of 18.55 in five natural language generation datasets, 3.66 in nine vision-language understanding datasets, 30.05 in three medical image analysis datasets, and 14.50 in four visuo-motor control tasks.", "summary_cn": "Anyprefer框架通过双智能体协作与外部工具辅助，自动合成高质量偏好数据，提升基础模型对齐效果。", "keywords": ["偏好数据合成", "模型对齐", "双智能体协作", "外部工具辅助", "反馈机制", "Anyprefer-V1"], "triple": {"method": "双智能体协作与外部工具辅助", "result": "合成58K高质量偏好对，模型对齐性能显著提升", "contribution": "提出自动偏好数据合成框架，减少人工标注依赖"}}
{"venue": "NeurIPS", "search_title": "2025 Conference", "url": "https://neurips.cc/", "year": null, "abstract_snippet": "Latest Announcements · NeurIPS 2026 will be held in Sydney Australia 6-12 December 2026 · Scholar Inbox for NeurIPS 2025 is available · Accessibility Guidelines ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "2025 Conference", "abstract": null}
{"venue": "NeurIPS", "search_title": "Presenter: Mengxi Xiao 2025.10.24 - NeurIPS", "url": "https://neurips.cc/media/neurips-2025/Slides/119452.pdf", "year": null, "abstract_snippet": "Oct 24, 2025 ... suitable for scenarios with insufficient primary medical resources, facilitating early screening of mood disorders. Angel.R. Angel.D. Angel.C.", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Presenter: Mengxi Xiao 2025.10.24 - NeurIPS", "abstract": null}
{"venue": "NeurIPS", "search_title": "Towards Distribution-Agnostic Generalized Category Discovery", "url": "https://neurips.cc/virtual/2023/poster/71084", "year": 2023, "abstract_snippet": "... medical image recognition. arXiv preprint arXiv:2305.17421, 2023. [16] Yonatan Geifman and Ran El-Yaniv. Deep active learning over the long tail. arXiv ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Towards Distribution-Agnostic Generalized Category Discovery", "abstract": null}
{"venue": "NeurIPS", "search_title": "Call For Papers 2025 - NeurIPS", "url": "https://neurips.cc/Conferences/2025/CallForPapers", "year": null, "abstract_snippet": "Abstract submission deadline: May 11, 2025 AoE · Full paper submission deadline: May 15, 2025 AOE (all authors must have an OpenReview profile when submitting) ...", "is_main_conference": false, "abstract_source_venue": null, "abstract_source_url": null, "full_title": "Call For Papers 2025 - NeurIPS", "abstract": null}
{"venue": "ICLR", "search_title": "Cancer-Myth: Evaluating Large Language Models on Patient Questions with False Presuppositions", "full_title": "Cancer-Myth: Evaluating Large Language Models on Patient Questions with False Presuppositions", "url": "https://openreview.net/forum?id=fOXLhZIaUj", "year": 2026, "is_main_conference": true, "abstract_snippet": "Cancer patients are increasingly turning to large language models (LLMs) for medical information, making it critical to assess how well these models handle complex, personalized questions. \nHowever, current medical benchmarks focus on medical exams or consumer-searched questions and do not evaluate LLMs on real patient questions with patient details. \nIn this paper, we first have three hematology-oncology physicians evaluate cancer-related questions drawn from real patients. \nWhile LLM responses are generally accurate, the models frequently fail to recognize or address false presuppositions} in the questions, posing risks to safe medical decision-making.\nTo study this limitation systematically, we introduce Cancer-Myth, an expert-verified adversarial dataset of 585 cancer-related questions with false presuppositions.\nOn this benchmark, no frontier LLM---including GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet---corrects these false presuppositions more than $43\\%$ of the time.\nTo study mitigation strategies, we further construct a 150-question Cancer-Myth-NFP set, in which physicians confirm the absence of false presuppositions.\nWe find typical mitigation strategies, such as adding precautionary prompts with GEPA optimization, can raise accuracy on Cancer-Myth to $80\\%$, but at the cost of misidentifying presuppositions in $41\\%$ of Cancer-Myth-NFP questions and causing a $10\\%$ relative performance drop on other medical benchmarks.\nThese findings highlight a critical gap in the reliability of LLMs, show that prompting alone is not a reliable remedy for false presuppositions, and underscore the need for more robust safeguards in medical AI systems.", "abstract": "Cancer patients are increasingly turning to large language models (LLMs) for medical information, making it critical to assess how well these models handle complex, personalized questions. \nHowever, current medical benchmarks focus on medical exams or consumer-searched questions and do not evaluate LLMs on real patient questions with patient details. \nIn this paper, we first have three hematology-oncology physicians evaluate cancer-related questions drawn from real patients. \nWhile LLM responses are generally accurate, the models frequently fail to recognize or address false presuppositions} in the questions, posing risks to safe medical decision-making.\nTo study this limitation systematically, we introduce Cancer-Myth, an expert-verified adversarial dataset of 585 cancer-related questions with false presuppositions.\nOn this benchmark, no frontier LLM---including GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet---corrects these false presuppositions more than $43\\%$ of the time.\nTo study mitigation strategies, we further construct a 150-question Cancer-Myth-NFP set, in which physicians confirm the absence of false presuppositions.\nWe find typical mitigation strategies, such as adding precautionary prompts with GEPA optimization, can raise accuracy on Cancer-Myth to $80\\%$, but at the cost of misidentifying presuppositions in $41\\%$ of Cancer-Myth-NFP questions and causing a $10\\%$ relative performance drop on other medical benchmarks.\nThese findings highlight a critical gap in the reliability of LLMs, show that prompting alone is not a reliable remedy for false presuppositions, and underscore the need for more robust safeguards in medical AI systems.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=fOXLhZIaUj", "openreview_id": "fOXLhZIaUj", "openreview_forum_id": "fOXLhZIaUj", "authors": [], "pdf_url": "https://openreview.net/pdf/a21f83e80e84a8f0b6d4546a959c75408be46cd2.pdf", "summary_cn": "研究评估大语言模型处理癌症患者提问中错误预设的能力，发现前沿模型识别率不足43%，现有缓解策略效果有限且存在副作用。", "keywords": ["大语言模型", "癌症患者提问", "错误预设", "医疗AI安全", "对抗数据集", "缓解策略"], "triple": {"method": "构建专家验证的对抗数据集Cancer-Myth", "result": "前沿LLMs纠正错误预设率<43%，缓解策略效果有限且有副作用", "contribution": "揭示LLMs处理医疗错误预设的缺陷，警示单纯提示优化的局限性"}}
{"venue": "ICLR", "search_title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow", "full_title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow", "url": "https://openreview.net/forum?id=ZOuU0udyA4", "year": 2026, "is_main_conference": true, "abstract_snippet": "Modern clinical diagnosis relies on the comprehensive analysis of multi-modal patient data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in Vision–Language Models (VLMs) and agent-based methods are reshaping medical diagnosis by effectively integrating multi-modal information. However, they often output direct answers and empirical-driven conclusions without clinical evidence supported by quantitative analysis, which compromises their reliability and hinders clinical usability. \nHere we propose MedAgent-Pro, an agentic reasoning paradigm that mirrors modern diagnosis principles via a hierarchical diagnostic workflow, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, a retrieval-augmented generation agent is designed to access medical guidelines for alignment with clinical standards.  For patient-level reasoning, MedAgent-Pro leverages professional tools such as visual models to take various actions to analyze multi-modal input, and performs evidence-based reflection to iteratively adjust memory, enforcing rigorous reasoning throughout the process. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro over mainstream VLMs, agentic systems and leading expert models. Ablation studies and expert evaluation further confirm its robustness and clinical relevance. Anonymized code link is available in the reproducibility statement.", "abstract": "Modern clinical diagnosis relies on the comprehensive analysis of multi-modal patient data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in Vision–Language Models (VLMs) and agent-based methods are reshaping medical diagnosis by effectively integrating multi-modal information. However, they often output direct answers and empirical-driven conclusions without clinical evidence supported by quantitative analysis, which compromises their reliability and hinders clinical usability. \nHere we propose MedAgent-Pro, an agentic reasoning paradigm that mirrors modern diagnosis principles via a hierarchical diagnostic workflow, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, a retrieval-augmented generation agent is designed to access medical guidelines for alignment with clinical standards.  For patient-level reasoning, MedAgent-Pro leverages professional tools such as visual models to take various actions to analyze multi-modal input, and performs evidence-based reflection to iteratively adjust memory, enforcing rigorous reasoning throughout the process. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro over mainstream VLMs, agentic systems and leading expert models. Ablation studies and expert evaluation further confirm its robustness and clinical relevance. Anonymized code link is available in the reproducibility statement.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ZOuU0udyA4", "openreview_id": "ZOuU0udyA4", "openreview_forum_id": "ZOuU0udyA4", "authors": [], "pdf_url": "https://openreview.net/pdf/e7110936d04fac257223b380ae256b851b59bfa3.pdf", "summary_cn": "提出MedAgent-Pro代理推理范式，通过分层诊断工作流整合多模态数据，实现基于证据的医学诊断，提升临床可靠性和实用性。", "keywords": ["医学诊断", "多模态", "代理推理", "证据驱动", "临床指南", "视觉语言模型"], "triple": {"method": "分层代理工作流（疾病级规划与患者级推理）", "result": "超越主流视觉语言模型和专家模型", "contribution": "提升诊断可靠性与临床相关性"}}
{"venue": "ICLR", "search_title": "Beyond Classification Accuracy:  Neural-MedBench and the Need for Deeper Reasoning Benchmarks", "full_title": "Beyond Classification Accuracy:  Neural-MedBench and the Need for Deeper Reasoning Benchmarks", "url": "https://openreview.net/forum?id=KKA59ai0x6", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recent advances in vision-language models (VLMs) have achieved remarkable performance on standard medical benchmarks, yet their true clinical reasoning ability remains unclear. Existing datasets predominantly emphasize classification accuracy, creating an evaluation illusion in which models appear proficient while still failing at high-stakes diagnostic reasoning.\nWe introduce \\texttt{Neural-MedBench}, a compact yet reasoning-intensive benchmark specifically designed to probe the limits of multimodal clinical reasoning in neurology. Neural-MedBench integrates multi-sequence MRI scans, structured electronic health records, and clinical notes, and encompasses three core task families: differential diagnosis, lesion recognition, and rationale generation. To ensure reliable evaluation, we develop a hybrid scoring pipeline that combines LLM-based graders, clinician validation, and semantic similarity metrics.\nThrough systematic evaluation of state-of-the-art VLMs, including GPT-4o, Claude-4, and MedGemma, we observe a sharp performance drop compared to conventional datasets. Error analysis shows that reasoning failures, rather than perceptual errors, dominate model shortcomings.\nOur findings highlight the necessity of a Two-Axis Evaluation Framework: breadth-oriented large datasets for statistical generalization, and depth-oriented, compact benchmarks such as Neural-MedBench for reasoning fidelity. We release Neural-MedBench as an open and extensible diagnostic testbed, which guides the expansion of future benchmarks and enables rigorous yet cost-effective assessment of clinically trustworthy AI.", "abstract": "Recent advances in vision-language models (VLMs) have achieved remarkable performance on standard medical benchmarks, yet their true clinical reasoning ability remains unclear. Existing datasets predominantly emphasize classification accuracy, creating an evaluation illusion in which models appear proficient while still failing at high-stakes diagnostic reasoning.\nWe introduce \\texttt{Neural-MedBench}, a compact yet reasoning-intensive benchmark specifically designed to probe the limits of multimodal clinical reasoning in neurology. Neural-MedBench integrates multi-sequence MRI scans, structured electronic health records, and clinical notes, and encompasses three core task families: differential diagnosis, lesion recognition, and rationale generation. To ensure reliable evaluation, we develop a hybrid scoring pipeline that combines LLM-based graders, clinician validation, and semantic similarity metrics.\nThrough systematic evaluation of state-of-the-art VLMs, including GPT-4o, Claude-4, and MedGemma, we observe a sharp performance drop compared to conventional datasets. Error analysis shows that reasoning failures, rather than perceptual errors, dominate model shortcomings.\nOur findings highlight the necessity of a Two-Axis Evaluation Framework: breadth-oriented large datasets for statistical generalization, and depth-oriented, compact benchmarks such as Neural-MedBench for reasoning fidelity. We release Neural-MedBench as an open and extensible diagnostic testbed, which guides the expansion of future benchmarks and enables rigorous yet cost-effective assessment of clinically trustworthy AI.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=KKA59ai0x6", "openreview_id": "KKA59ai0x6", "openreview_forum_id": "KKA59ai0x6", "authors": [], "pdf_url": "https://openreview.net/pdf/39b1448e43d0d09d35c213c1470436fa8ffa3066.pdf", "summary_cn": "提出Neural-MedBench基准，评估神经学多模态临床推理能力，发现现有模型在深度推理任务上表现显著下降，强调需结合广度与深度评估框架。", "keywords": ["临床推理", "多模态基准", "神经学", "评估框架", "视觉语言模型", "诊断准确性"], "triple": {"method": "构建Neural-MedBench基准与混合评分流程", "result": "模型在推理任务上表现显著下降，错误主要由推理失败导致", "contribution": "提出两轴评估框架，促进临床可信AI的严格评估"}}
{"venue": "ICLR", "search_title": "How Do Medical MLLMs Fail?  A Study on Visual Grounding in Medical Images", "full_title": "How Do Medical MLLMs Fail?  A Study on Visual Grounding in Medical Images", "url": "https://openreview.net/forum?id=dXshexyFKx", "year": 2026, "is_main_conference": true, "abstract_snippet": "Generalist multimodal large language models (MLLMs) have achieved impressive performance across a wide range of vision-language tasks. However, their performance on medical tasks—particularly in zero-shot settings where generalization is critical—remains suboptimal. A key research gap is the limited understanding of why medical MLLMs underperform in medical image interpretation.\n**In this work**, we present a pioneering systematic investigation into the visual grounding capabilities of state-of-the-art medical MLLMs. To disentangle *visual grounding* from *semantic grounding*, we design VGMED, a novel evaluation dataset developed with expert clinical guidance, explicitly assessing the visual grounding capability of medical MLLMs. \nWe introduce new quantitative metrics and conduct detailed qualitative analyses. Our study across **eight** state-of-the-art (SOTA) medical MLLMs validates that they often fail to ground their predictions in clinically relevant image regions. We note that this finding is specific to medical image analysis; in contrast, prior work has shown that MLLMs are capable of grounding their predictions in the correct image regions when applied to natural scene images.\nMotivated by these findings, we propose VGRefine, a simple yet effective inference-time method that refines attention distribution to improve visual grounding in medical settings. Our approach achieves SOTA performance across  6 diverse Med-VQA benchmarks (over 110K VQA samples from 8 imaging modalities) \nwithout requiring additional training or external expert models.  Overall, our work, for the first time, systematically validates inadequate visual grounding as one of the key contributing factors for medical MLLMs' under-performance.\nCode and additional experiments are included in the Supp.", "abstract": "Generalist multimodal large language models (MLLMs) have achieved impressive performance across a wide range of vision-language tasks. However, their performance on medical tasks—particularly in zero-shot settings where generalization is critical—remains suboptimal. A key research gap is the limited understanding of why medical MLLMs underperform in medical image interpretation.\n**In this work**, we present a pioneering systematic investigation into the visual grounding capabilities of state-of-the-art medical MLLMs. To disentangle *visual grounding* from *semantic grounding*, we design VGMED, a novel evaluation dataset developed with expert clinical guidance, explicitly assessing the visual grounding capability of medical MLLMs. \nWe introduce new quantitative metrics and conduct detailed qualitative analyses. Our study across **eight** state-of-the-art (SOTA) medical MLLMs validates that they often fail to ground their predictions in clinically relevant image regions. We note that this finding is specific to medical image analysis; in contrast, prior work has shown that MLLMs are capable of grounding their predictions in the correct image regions when applied to natural scene images.\nMotivated by these findings, we propose VGRefine, a simple yet effective inference-time method that refines attention distribution to improve visual grounding in medical settings. Our approach achieves SOTA performance across  6 diverse Med-VQA benchmarks (over 110K VQA samples from 8 imaging modalities) \nwithout requiring additional training or external expert models.  Overall, our work, for the first time, systematically validates inadequate visual grounding as one of the key contributing factors for medical MLLMs' under-performance.\nCode and additional experiments are included in the Supp.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=dXshexyFKx", "openreview_id": "dXshexyFKx", "openreview_forum_id": "dXshexyFKx", "authors": [], "pdf_url": "https://openreview.net/pdf/7cb8fa11ac03e56e2f46f49fda6b98a1212d9360.pdf", "summary_cn": "本研究系统评估了医学MLLMs在视觉定位上的不足，并提出VGRefine方法提升性能，在多个医学VQA基准上实现最优。", "keywords": ["医学MLLMs", "视觉定位", "评估数据集", "VGRefine", "医学图像", "零样本学习"], "triple": {"method": "设计VGMED数据集与VGRefine推理方法", "result": "医学MLLMs视觉定位不足，VGRefine在6个基准上达最优", "contribution": "首次系统验证视觉定位不足是医学MLLMs性能差的关键因素"}}
{"venue": "ICLR", "search_title": "Anatomy-aware Representation Learning for Medical Ultrasound", "full_title": "Anatomy-aware Representation Learning for Medical Ultrasound", "url": "https://openreview.net/forum?id=5ThIWuDkEf", "year": 2026, "is_main_conference": true, "abstract_snippet": "Diagnostic accuracy of ultrasound imaging is limited by qualitative variability and its reliance on the expertise of medical professionals. Such challenges increase demand for computer-aided diagnostic systems that enhance diagnostic accuracy and efficiency. However, the unique texture and structural attributes of ultrasound images, and the scarcity of large-scale ultrasound datasets hinder the effective application of conventional machine learning methodologies. To address the challenges, we propose Anatomy-aware Representation Learning (ARL), a novel self-supervised representation learning framework specifically designed for medical ultrasound imaging. ARL incorporates an anatomy-adaptive Vision Transformer (A-ViT). The A-ViT is parameterized, using the proposed large-scale medical ultrasound dataset, to provide anatomy-aware feature representations. Through extensive experiments across various ultrasound-based diagnostic tasks, including breast and thyroid cancer, cardiac view classification, and gallbladder tumor and COVID-19 identification, we demonstrate that ARL significantly outperforms existing self-supervised learning baselines. The experiments demonstrate the potential of ARL in advancing medical ultrasound diagnostics by providing anatomy-specific feature representation", "abstract": "Diagnostic accuracy of ultrasound imaging is limited by qualitative variability and its reliance on the expertise of medical professionals. Such challenges increase demand for computer-aided diagnostic systems that enhance diagnostic accuracy and efficiency. However, the unique texture and structural attributes of ultrasound images, and the scarcity of large-scale ultrasound datasets hinder the effective application of conventional machine learning methodologies. To address the challenges, we propose Anatomy-aware Representation Learning (ARL), a novel self-supervised representation learning framework specifically designed for medical ultrasound imaging. ARL incorporates an anatomy-adaptive Vision Transformer (A-ViT). The A-ViT is parameterized, using the proposed large-scale medical ultrasound dataset, to provide anatomy-aware feature representations. Through extensive experiments across various ultrasound-based diagnostic tasks, including breast and thyroid cancer, cardiac view classification, and gallbladder tumor and COVID-19 identification, we demonstrate that ARL significantly outperforms existing self-supervised learning baselines. The experiments demonstrate the potential of ARL in advancing medical ultrasound diagnostics by providing anatomy-specific feature representation", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=5ThIWuDkEf", "openreview_id": "5ThIWuDkEf", "openreview_forum_id": "5ThIWuDkEf", "authors": [], "pdf_url": "https://openreview.net/pdf/3052db98077cd2b176bd3c54a499e2af51fe13a6.pdf", "summary_cn": "提出解剖感知表示学习框架，结合解剖自适应视觉Transformer，在多种超声诊断任务中显著优于现有自监督方法，提升诊断准确性。", "keywords": ["解剖感知表示学习", "自监督学习", "医学超声", "视觉Transformer", "诊断任务", "特征表示"], "triple": {"method": "解剖自适应视觉Transformer", "result": "在多种超声诊断任务中表现优异", "contribution": "提升超声诊断准确性"}}
{"venue": "ICLR", "search_title": "Can Large Language Models Match the Conclusions of Systematic Reviews?", "full_title": "Can Large Language Models Match the Conclusions of Systematic Reviews?", "url": "https://openreview.net/forum?id=uIJyYkOgAy", "year": 2026, "is_main_conference": true, "abstract_snippet": "Systematic reviews (SR), in which experts summarize and analyze evidence across\nindividual studies to provide insights on a specialized topic, are a cornerstone\nfor evidence-based clinical decision-making, research, and policy. Given the exponential growth of scientific articles, there is growing interest in using large\nlanguage models (LLMs) to automate SR generation. However, the ability of\nLLMs to critically assess evidence and reason across multiple documents to provide recommendations at the same proficiency as domain experts remains poorly\ncharacterized. We therefore ask: Can LLMs match the conclusions of systematic\nreviews written by clinical experts when given access to the same studies?\nTo explore this question, we present MedEvidence, a benchmark pairing findings\nfrom 100 SRs with the studies they are based on. We benchmark 24 LLMs on\nMedEvidence, including reasoning, non-reasoning, medical specialist, and models\nacross varying sizes (from 7B-700B). Through our systematic evaluation, we find\nthat reasoning does not necessarily improve performance, larger models do not\nconsistently yield greater gains, and knowledge-based fine-tuning degrades accuracy on MedEvidence. Instead, most models exhibit similar behavior: performance\ntends to degrade as token length increases, their responses show overconfidence,\nand, contrary to human experts, all models show a lack of scientific skepticism\ntoward low-quality findings. These results suggest that more work is still required\nbefore LLMs can reliably match the observations from expert-conducted SRs, even\nthough these systems are already deployed and being used by clinicians. We release our codebase\nand benchmark\nto the broader research community to further\ninvestigate LLM-based SR systems.", "abstract": "Systematic reviews (SR), in which experts summarize and analyze evidence across\nindividual studies to provide insights on a specialized topic, are a cornerstone\nfor evidence-based clinical decision-making, research, and policy. Given the exponential growth of scientific articles, there is growing interest in using large\nlanguage models (LLMs) to automate SR generation. However, the ability of\nLLMs to critically assess evidence and reason across multiple documents to provide recommendations at the same proficiency as domain experts remains poorly\ncharacterized. We therefore ask: Can LLMs match the conclusions of systematic\nreviews written by clinical experts when given access to the same studies?\nTo explore this question, we present MedEvidence, a benchmark pairing findings\nfrom 100 SRs with the studies they are based on. We benchmark 24 LLMs on\nMedEvidence, including reasoning, non-reasoning, medical specialist, and models\nacross varying sizes (from 7B-700B). Through our systematic evaluation, we find\nthat reasoning does not necessarily improve performance, larger models do not\nconsistently yield greater gains, and knowledge-based fine-tuning degrades accuracy on MedEvidence. Instead, most models exhibit similar behavior: performance\ntends to degrade as token length increases, their responses show overconfidence,\nand, contrary to human experts, all models show a lack of scientific skepticism\ntoward low-quality findings. These results suggest that more work is still required\nbefore LLMs can reliably match the observations from expert-conducted SRs, even\nthough these systems are already deployed and being used by clinicians. We release our codebase\nand benchmark\nto the broader research community to further\ninvestigate LLM-based SR systems.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=uIJyYkOgAy", "openreview_id": "uIJyYkOgAy", "openreview_forum_id": "uIJyYkOgAy", "authors": [], "pdf_url": "https://openreview.net/pdf/e64591af8710a96009a869c36280c05af2acd40d.pdf", "summary_cn": "研究评估大语言模型能否匹配专家系统综述的结论，发现模型在证据评估上存在局限，如过度自信和缺乏科学怀疑，尚无法可靠替代专家。", "keywords": ["大语言模型", "系统综述", "医学证据评估", "基准测试", "临床决策", "自动化生成"], "triple": {"method": "构建MedEvidence基准，评估24个LLM", "result": "模型表现受限于文本长度、过度自信且缺乏科学怀疑", "contribution": "揭示LLM在匹配专家系统综述结论上的不足，提供开放基准促进研究"}}
{"venue": "ICLR", "search_title": "MedGMAE: Gaussian Masked Autoencoders for Medical Volumetric Representation Learning", "full_title": "MedGMAE: Gaussian Masked Autoencoders for Medical Volumetric Representation Learning", "url": "https://openreview.net/forum?id=Z2XIRLv535", "year": 2026, "is_main_conference": true, "abstract_snippet": "Self-supervised pre-training has emerged as a critical paradigm for learning transferable representations from unlabeled medical volumetric data. Masked autoencoder based methods have garnered significant attention, yet their application to volumetric medical image faces fundamental limitations from the discrete voxel-level reconstruction objective, which neglects comprehensive anatomical structure continuity. To address this challenge, We propose MedGMAE, a novel framework that replaces traditional voxel reconstruction with 3D Gaussian primitives reconstruction as new perspectives on representation learning. Our approach learns to predict complete sets of 3D Gaussian parameters as semantic abstractions to represent the entire 3D volume, from sparse visible image patches. MedGMAE demonstrates dual utility across medical imaging applications. For representation learning, sparse Gaussian prediction produces superior encoder representations that outperform traditional MAE baselines on downstream segmentation, classification, and registration tasks. For volumetric reconstruction, the Gaussian decoder leverages pretrained anatomical priors to accelerate 3D CT volume reconstruction convergence. Extensive experiments across multiple medical imaging datasets demonstrate that our approach achieves superior performance, establishing a new paradigm for medical image pre-training. Code will be released soon.", "abstract": "Self-supervised pre-training has emerged as a critical paradigm for learning transferable representations from unlabeled medical volumetric data. Masked autoencoder based methods have garnered significant attention, yet their application to volumetric medical image faces fundamental limitations from the discrete voxel-level reconstruction objective, which neglects comprehensive anatomical structure continuity. To address this challenge, We propose MedGMAE, a novel framework that replaces traditional voxel reconstruction with 3D Gaussian primitives reconstruction as new perspectives on representation learning. Our approach learns to predict complete sets of 3D Gaussian parameters as semantic abstractions to represent the entire 3D volume, from sparse visible image patches. MedGMAE demonstrates dual utility across medical imaging applications. For representation learning, sparse Gaussian prediction produces superior encoder representations that outperform traditional MAE baselines on downstream segmentation, classification, and registration tasks. For volumetric reconstruction, the Gaussian decoder leverages pretrained anatomical priors to accelerate 3D CT volume reconstruction convergence. Extensive experiments across multiple medical imaging datasets demonstrate that our approach achieves superior performance, establishing a new paradigm for medical image pre-training. Code will be released soon.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=Z2XIRLv535", "openreview_id": "Z2XIRLv535", "openreview_forum_id": "Z2XIRLv535", "authors": [], "pdf_url": "https://openreview.net/pdf/c8a8ac67bb2b3ddd8bcb4bc1e35d3a649f009034.pdf", "summary_cn": "提出MedGMAE框架，用3D高斯基元重建替代传统体素重建，从稀疏图像块学习医学体积表示，提升下游任务性能并加速CT重建。", "keywords": ["自监督学习", "掩码自编码器", "3D高斯基元", "医学体积图像", "表示学习", "CT重建"], "triple": {"method": "3D高斯基元重建", "result": "下游任务性能提升，CT重建加速", "contribution": "提出医学图像预训练新范式"}}
{"venue": "ICLR", "search_title": "Medical Interpretability and Knowledge Maps of Large Language Models", "full_title": "Medical Interpretability and Knowledge Maps of Large Language Models", "url": "https://openreview.net/forum?id=BhqFWlYKUi", "year": 2026, "is_main_conference": true, "abstract_snippet": "We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama and (iv) Gemma-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied. We attached our source code to the paper for reproducibility.", "abstract": "We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama and (iv) Gemma-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied. We attached our source code to the paper for reproducibility.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=BhqFWlYKUi", "openreview_id": "BhqFWlYKUi", "openreview_forum_id": "BhqFWlYKUi", "authors": [], "pdf_url": "https://openreview.net/pdf/3099e3d88d3c3c3e889a42f9a81f08b16dfa679e.pdf", "summary_cn": "本研究系统探索大语言模型在医学领域的可解释性，通过四种技术分析模型如何存储和处理医学知识，发现医学知识主要集中在前半层，并揭示年龄、疾病进展等编码特性。", "keywords": ["大语言模型", "医学可解释性", "知识图谱", "层间分析", "激活映射", "模型优化"], "triple": {"method": "UMAP投影、梯度显著性、层切除、激活修补", "result": "医学知识集中在前半层，年龄编码非线性，疾病表示非单调，药物按专科聚类", "contribution": "为医学任务微调、去偏提供层间指导"}}
{"venue": "ICLR", "search_title": "Identity-Free Deferral For Unseen Experts", "full_title": "Identity-Free Deferral For Unseen Experts", "url": "https://openreview.net/forum?id=4YG9ufFg58", "year": 2026, "is_main_conference": true, "abstract_snippet": "Learning to Defer (L2D) improves AI reliability in decision-critical environments, such as healthcare, by training a model to either make its own prediction or delerejector the decision to a human expert. A key challenge is adapting to unseen experts: those who were not involved during the system's training process. Current methods for this task, however, can falter when unseen experts are out-of-distribution (OOD) relative to the training population. We identify a core architectural flaw as the cause: they learn identity-conditioned policies by processing class-indexed signals in fixed coordinates, creating shortcuts that violate the problem's inherent permutation symmetry. We introduce Identity-Free Deferral (IFD), an architecture that enforces this symmetry by construction. From a few-shot context, IFD builds a query-independent Bayesian competence profile for each expert. It then supplies the deferral rejector with a low-dimensional, role-indexed state containing only structural information, such as the model's confidence in its top-ranked class and the expert's estimated skill for that same role, which obscures absolute class identities. We train IFD using an uncertainty-aware, context-only objective that removes the need for expensive query-time expert labels. We formally prove the permutation invariance of our approach, contrasting it with the generic non-invariance of standard population encoders. Experiments on medical imaging benchmarks and ImageNet-16H with real human annotators show that IFD consistently improves generalization to unseen experts, with significant gains in OOD settings, all while using fewer annotations than competing methods.", "abstract": "Learning to Defer (L2D) improves AI reliability in decision-critical environments, such as healthcare, by training a model to either make its own prediction or delerejector the decision to a human expert. A key challenge is adapting to unseen experts: those who were not involved during the system's training process. Current methods for this task, however, can falter when unseen experts are out-of-distribution (OOD) relative to the training population. We identify a core architectural flaw as the cause: they learn identity-conditioned policies by processing class-indexed signals in fixed coordinates, creating shortcuts that violate the problem's inherent permutation symmetry. We introduce Identity-Free Deferral (IFD), an architecture that enforces this symmetry by construction. From a few-shot context, IFD builds a query-independent Bayesian competence profile for each expert. It then supplies the deferral rejector with a low-dimensional, role-indexed state containing only structural information, such as the model's confidence in its top-ranked class and the expert's estimated skill for that same role, which obscures absolute class identities. We train IFD using an uncertainty-aware, context-only objective that removes the need for expensive query-time expert labels. We formally prove the permutation invariance of our approach, contrasting it with the generic non-invariance of standard population encoders. Experiments on medical imaging benchmarks and ImageNet-16H with real human annotators show that IFD consistently improves generalization to unseen experts, with significant gains in OOD settings, all while using fewer annotations than competing methods.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=4YG9ufFg58", "openreview_id": "4YG9ufFg58", "openreview_forum_id": "4YG9ufFg58", "authors": [], "pdf_url": "https://openreview.net/pdf/2b84d8ab31b821240426f0893469ad42c0049b23.pdf", "summary_cn": "提出身份无关延迟（IFD）架构，通过强制排列对称性，提升AI在医疗等关键决策环境中对未见专家的泛化能力，减少标注需求。", "keywords": ["学习延迟", "未见专家", "排列对称性", "贝叶斯能力分析", "医疗影像", "分布外泛化"], "triple": {"method": "构建查询无关的贝叶斯能力档案，提供低维角色索引状态", "result": "在医疗影像和ImageNet-16H基准上提升对未见专家的泛化性能，尤其在分布外场景表现更佳", "contribution": "提出身份无关延迟架构，通过强制排列对称性解决未见专家适应问题，减少标注成本"}}
{"venue": "ICLR", "search_title": "MedVR: Annotation-Free Medical Visual Reasoning via Agentic Reinforcement Learning", "full_title": "MedVR: Annotation-Free Medical Visual Reasoning via Agentic Reinforcement Learning", "url": "https://openreview.net/forum?id=cK35kNVm5r", "year": 2026, "is_main_conference": true, "abstract_snippet": "Medical Vision-Language Models (VLMs) hold immense promise for complex clinical tasks, but their reasoning capabilities are often constrained by text-only paradigms that fail to ground inferences in visual evidence. This limitation not only curtails performance on tasks requiring fine-grained visual analysis but also introduces risks of visual hallucination in safety-critical applications. Thus, we introduce MedVR, a novel reinforcement learning framework that enables annotation-free visual reasoning for medical VLMs. Its core innovation lies in two synergistic mechanisms: Entropy-guided Visual Regrounding (EVR) uses model uncertainty to direct exploration, while Consensus-based Credit Assignment (CCA) distills pseudo-supervision from rollout agreement. Without any human annotations for intermediate steps, MedVR achieves state-of-the-art performance on diverse public medical VQA benchmarks, significantly outperforming existing models. By learning to reason directly with visual evidence, MedVR promotes the robustness and transparency essential for accelerating the clinical deployment of medical AI.", "abstract": "Medical Vision-Language Models (VLMs) hold immense promise for complex clinical tasks, but their reasoning capabilities are often constrained by text-only paradigms that fail to ground inferences in visual evidence. This limitation not only curtails performance on tasks requiring fine-grained visual analysis but also introduces risks of visual hallucination in safety-critical applications. Thus, we introduce MedVR, a novel reinforcement learning framework that enables annotation-free visual reasoning for medical VLMs. Its core innovation lies in two synergistic mechanisms: Entropy-guided Visual Regrounding (EVR) uses model uncertainty to direct exploration, while Consensus-based Credit Assignment (CCA) distills pseudo-supervision from rollout agreement. Without any human annotations for intermediate steps, MedVR achieves state-of-the-art performance on diverse public medical VQA benchmarks, significantly outperforming existing models. By learning to reason directly with visual evidence, MedVR promotes the robustness and transparency essential for accelerating the clinical deployment of medical AI.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=cK35kNVm5r", "openreview_id": "cK35kNVm5r", "openreview_forum_id": "cK35kNVm5r", "authors": [], "pdf_url": "https://openreview.net/pdf/4afcb83673664833a6bdb762a4f9a5988b6c7ddd.pdf", "summary_cn": "MedVR通过强化学习实现无标注医学视觉推理，利用熵引导视觉重定位和共识信用分配，在医学VQA基准上取得最优性能，提升临床AI的鲁棒性和透明度。", "keywords": ["医学视觉语言模型", "强化学习", "视觉推理", "无标注学习", "医学VQA", "鲁棒性"], "triple": {"method": "熵引导视觉重定位与共识信用分配", "result": "医学VQA基准上性能最优", "contribution": "提升临床AI鲁棒性与透明度"}}
{"venue": "ICLR", "search_title": "MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning", "full_title": "MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning", "url": "https://openreview.net/forum?id=2awntLXwR6", "year": 2026, "is_main_conference": true, "abstract_snippet": "Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential in multimodal diagnostic tasks. However, existing single-agent models struggle to generalize across diverse medical specialties, limiting their performance. Recent efforts introduce multi-agent collaboration frameworks inspired by clinical workflows, where general practitioners (GPs) and specialists interact in a fixed sequence. Despite improvements, these static pipelines lack flexibility and adaptability in reasoning. To address this, we propose MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that enables dynamic, optimized collaboration among medical agents. Specifically, we train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to assign patients to appropriate specialties, while the attending physician integrates the judgments from multi-specialists and its own knowledge to make final decisions. To address the inconsistency in specialist outputs, we introduce a curriculum learning (CL)-guided RL strategy with dynamic entropy regulation, progressively teaching the attending physician to balance between imitating specialists and correcting their mistakes. Experiments on five medical VQA benchmarks demonstrate that MMedAgent-RL outperforms both open-source and proprietary Med-LVLMs. Notably, it achieves an average performance gain of 23.6\\% over strong baselines.", "abstract": "Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential in multimodal diagnostic tasks. However, existing single-agent models struggle to generalize across diverse medical specialties, limiting their performance. Recent efforts introduce multi-agent collaboration frameworks inspired by clinical workflows, where general practitioners (GPs) and specialists interact in a fixed sequence. Despite improvements, these static pipelines lack flexibility and adaptability in reasoning. To address this, we propose MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that enables dynamic, optimized collaboration among medical agents. Specifically, we train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to assign patients to appropriate specialties, while the attending physician integrates the judgments from multi-specialists and its own knowledge to make final decisions. To address the inconsistency in specialist outputs, we introduce a curriculum learning (CL)-guided RL strategy with dynamic entropy regulation, progressively teaching the attending physician to balance between imitating specialists and correcting their mistakes. Experiments on five medical VQA benchmarks demonstrate that MMedAgent-RL outperforms both open-source and proprietary Med-LVLMs. Notably, it achieves an average performance gain of 23.6\\% over strong baselines.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=2awntLXwR6", "openreview_id": "2awntLXwR6", "openreview_forum_id": "2awntLXwR6", "authors": [], "pdf_url": "https://openreview.net/pdf/3703f8cac22754f38c452da028e9c4d2a92fe408.pdf", "summary_cn": "提出MMedAgent-RL强化学习框架，优化多智能体协作进行医学多模态推理，在五个医学VQA基准上显著超越现有模型。", "keywords": ["多智能体协作", "强化学习", "医学多模态推理", "课程学习", "医学视觉问答"], "triple": {"method": "基于强化学习的动态多智能体协作框架", "result": "在五个医学VQA基准上平均性能提升23.6%", "contribution": "提出课程学习引导的强化学习策略，优化多专家协作决策"}}
{"venue": "ICLR", "search_title": "MedAraBench: Large-scale Arabic Medical Question Answering Dataset and Benchmark", "full_title": "MedAraBench: Large-scale Arabic Medical Question Answering Dataset and Benchmark", "url": "https://openreview.net/forum?id=1BXojAgNrg", "year": 2026, "is_main_conference": true, "abstract_snippet": "Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.", "abstract": "Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=1BXojAgNrg", "openreview_id": "1BXojAgNrg", "openreview_forum_id": "1BXojAgNrg", "authors": [], "pdf_url": "https://openreview.net/pdf/84fcd1a697860dbc63db8aa5b1fc055edf61dd1d.pdf", "summary_cn": "本文推出MedAraBench，一个大规模阿拉伯语医学问答数据集，涵盖19个专科和5个难度级别，用于评估大语言模型在医学领域的多语言能力。", "keywords": ["阿拉伯语医学问答", "多语言大语言模型", "医学数据集", "专家评估", "模型基准测试", "临床部署"], "triple": {"method": "手动数字化医学资料构建数据集，采用专家和LLM评估质量", "result": "数据集高质量且多样，评估显示现有模型需领域增强", "contribution": "提供开源数据集与基准，促进LLM多语言医学应用发展"}}
{"venue": "ICLR", "search_title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding", "full_title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding", "url": "https://openreview.net/forum?id=S7KyLgHqJf", "year": 2026, "is_main_conference": true, "abstract_snippet": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models by encouraging step-by-step intermediate reasoning, and recent advances have extended this paradigm to Multimodal Large Language Models (MLLMs). In the medical domain, where diagnostic decisions depend on nuanced visual cues and sequential reasoning, CoT aligns naturally with clinical thinking processes. However, Current benchmarks for medical image understanding generally focus on the final answer while ignoring the reasoning path. An opaque process lacks reliable bases for judgment, making it difficult to assist doctors in diagnosis. \nTo address this gap, we introduce a new M3CoTBench benchmark specifically designed to evaluate the correctness, efficiency, impact, and consistency of CoT reasoning in medical image understanding. M3CoTBench features  (1) a diverse, multi-level difficulty dataset covering 24 examination types, (2) 13 varying-difficulty tasks,  (3) a suite of CoT-specific evaluation metrics (correctness, efficiency, impact, and consistency) tailored to clinical reasoning,  and (4) a performance analysis of multiple MLLMs. M3CoTBench systematically evaluates CoT reasoning across diverse medical imaging tasks, revealing current limitations of MLLMs in generating reliable and clinically interpretable reasoning, and aims to foster the development of transparent, trustworthy, and diagnostically accurate AI systems for healthcare.", "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models by encouraging step-by-step intermediate reasoning, and recent advances have extended this paradigm to Multimodal Large Language Models (MLLMs). In the medical domain, where diagnostic decisions depend on nuanced visual cues and sequential reasoning, CoT aligns naturally with clinical thinking processes. However, Current benchmarks for medical image understanding generally focus on the final answer while ignoring the reasoning path. An opaque process lacks reliable bases for judgment, making it difficult to assist doctors in diagnosis. \nTo address this gap, we introduce a new M3CoTBench benchmark specifically designed to evaluate the correctness, efficiency, impact, and consistency of CoT reasoning in medical image understanding. M3CoTBench features  (1) a diverse, multi-level difficulty dataset covering 24 examination types, (2) 13 varying-difficulty tasks,  (3) a suite of CoT-specific evaluation metrics (correctness, efficiency, impact, and consistency) tailored to clinical reasoning,  and (4) a performance analysis of multiple MLLMs. M3CoTBench systematically evaluates CoT reasoning across diverse medical imaging tasks, revealing current limitations of MLLMs in generating reliable and clinically interpretable reasoning, and aims to foster the development of transparent, trustworthy, and diagnostically accurate AI systems for healthcare.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=S7KyLgHqJf", "openreview_id": "S7KyLgHqJf", "openreview_forum_id": "S7KyLgHqJf", "authors": [], "pdf_url": "https://openreview.net/pdf/6f6b51141d2fbf8154142e47841c71d2c0d1ec99.pdf", "summary_cn": "提出M3CoTBench基准，评估多模态大语言模型在医学图像理解中的思维链推理，涵盖多任务与评价指标，揭示模型局限性，促进医疗AI透明化发展。", "keywords": ["思维链推理", "多模态大语言模型", "医学图像理解", "基准评估", "临床推理", "医疗AI"], "triple": {"method": "构建多任务、多难度数据集与评价指标", "result": "揭示MLLMs在可靠临床推理上的局限", "contribution": "推动透明可信医疗AI系统发展"}}
{"venue": "ICLR", "search_title": "Improving 2D Diffusion Models for 3D Medical Imaging with Inter‑Slice Consistent Stochasticity", "full_title": "Improving 2D Diffusion Models for 3D Medical Imaging with Inter‑Slice Consistent Stochasticity", "url": "https://openreview.net/forum?id=R5ETdN6ifA", "year": 2026, "is_main_conference": true, "abstract_snippet": "3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high‑quality data priors.  However, learning the 3D data distribution with diffusion models in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the diffusion model on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter‑slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the $z$‑axis, which introduces sensitive hyper‑parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter‑Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages inter‑slice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps.  Importantly, the proposed ISCS is plug‑and‑play and can be dropped into any 2D‑trained diffusion‑based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter‑slice stochasticity is a principled and practically attractive route toward high‑fidelity 3D medical imaging with 2D diffusion priors. The code is available at: [https://anonymous.4open.science/r/ICLR-ISCS-3281](https://anonymous.4open.science/r/ICLR-ISCS-3281).", "abstract": "3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high‑quality data priors.  However, learning the 3D data distribution with diffusion models in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the diffusion model on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter‑slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the $z$‑axis, which introduces sensitive hyper‑parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter‑Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages inter‑slice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps.  Importantly, the proposed ISCS is plug‑and‑play and can be dropped into any 2D‑trained diffusion‑based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter‑slice stochasticity is a principled and practically attractive route toward high‑fidelity 3D medical imaging with 2D diffusion priors. The code is available at: [https://anonymous.4open.science/r/ICLR-ISCS-3281](https://anonymous.4open.science/r/ICLR-ISCS-3281).", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=R5ETdN6ifA", "openreview_id": "R5ETdN6ifA", "openreview_forum_id": "R5ETdN6ifA", "authors": [], "pdf_url": "https://openreview.net/pdf/b06641f87b59e63130e23a7ff694f90bc746596a.pdf", "summary_cn": "提出ISCS方法，通过控制扩散采样中的噪声一致性，解决2D扩散模型重建3D医学影像时的切片间不连续问题，无需额外计算成本。", "keywords": ["3D医学影像", "扩散模型", "切片一致性", "随机噪声控制", "图像重建", "计算效率"], "triple": {"method": "控制扩散采样噪声一致性", "result": "提升3D重建质量与切片连续性", "contribution": "无需额外训练的即插即用方案"}}
{"venue": "ICLR", "search_title": "Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs", "full_title": "Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs", "url": "https://openreview.net/forum?id=ULMWcNduE3", "year": 2026, "is_main_conference": true, "abstract_snippet": "Large Multimodal Models (LMMs) are increasingly capable of answering medical questions that require joint reasoning over images and text, yet training general medical VQA systems is impeded by the lack of large, openly usable, high-quality corpora. We present \\textbf{MedVLSynther}, a rubric-guided generator-verifier framework that synthesizes high-quality multiple-choice VQA items directly from open biomedical literature by conditioning on figures, captions, and in-text references. The generator produces self-contained stems and parallel, mutually exclusive options under a machine-checkable JSON schema; a multi-stage verifier enforces essential gates (self-containment, single correct answer, clinical validity, image-text consistency), awards fine-grained positive points, and penalizes common failure modes before acceptance. Applying this pipeline to PubMed Central yields \\textit{MedVLSynther-13K}: 13,087 audited questions over 14,803 images spanning 13 imaging modalities and 28 anatomical regions. Training open-weight LMMs with reinforcement learning using verifiable rewards improves accuracy across six medical VQA benchmarks, achieving averages of 55.85 (3B) and 57.56 (7B), with up to 77.21 on VQA-RAD and 66.36 on PathVQA, outperforming strong medical LMMs. Ablations verify that both generation and verification are necessary and that more verified data consistently helps, and a targeted contamination analysis detects no leakage from evaluation suites. By operating entirely on open literature and open-weight models, MedVLSynther offers an auditable, reproducible, and privacy-preserving path to scalable medical VQA training data.", "abstract": "Large Multimodal Models (LMMs) are increasingly capable of answering medical questions that require joint reasoning over images and text, yet training general medical VQA systems is impeded by the lack of large, openly usable, high-quality corpora. We present \\textbf{MedVLSynther}, a rubric-guided generator-verifier framework that synthesizes high-quality multiple-choice VQA items directly from open biomedical literature by conditioning on figures, captions, and in-text references. The generator produces self-contained stems and parallel, mutually exclusive options under a machine-checkable JSON schema; a multi-stage verifier enforces essential gates (self-containment, single correct answer, clinical validity, image-text consistency), awards fine-grained positive points, and penalizes common failure modes before acceptance. Applying this pipeline to PubMed Central yields \\textit{MedVLSynther-13K}: 13,087 audited questions over 14,803 images spanning 13 imaging modalities and 28 anatomical regions. Training open-weight LMMs with reinforcement learning using verifiable rewards improves accuracy across six medical VQA benchmarks, achieving averages of 55.85 (3B) and 57.56 (7B), with up to 77.21 on VQA-RAD and 66.36 on PathVQA, outperforming strong medical LMMs. Ablations verify that both generation and verification are necessary and that more verified data consistently helps, and a targeted contamination analysis detects no leakage from evaluation suites. By operating entirely on open literature and open-weight models, MedVLSynther offers an auditable, reproducible, and privacy-preserving path to scalable medical VQA training data.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ULMWcNduE3", "openreview_id": "ULMWcNduE3", "openreview_forum_id": "ULMWcNduE3", "authors": [], "pdf_url": "https://openreview.net/pdf/07267a23e557728e5f3739f58171c4213ddc7ddc.pdf", "summary_cn": "提出MedVLSynther框架，通过生成-验证流程从开放生物医学文献合成高质量医学视觉问答数据，训练LMM模型在多个基准测试中表现优异。", "keywords": ["医学视觉问答", "数据合成", "生成-验证框架", "大型多模态模型", "强化学习", "开放文献"], "triple": {"method": "基于生成-验证框架从文献合成VQA数据", "result": "训练LMM在六个医学VQA基准上提升准确率", "contribution": "提供可扩展、可审计的医学VQA训练数据生成方法"}}
{"venue": "ICLR", "search_title": "CRONOS: Continuous time reconstruction for 4D medical longitudinal series", "full_title": "CRONOS: Continuous time reconstruction for 4D medical longitudinal series", "url": "https://openreview.net/forum?id=XxqdbYD74l", "year": 2026, "is_main_conference": true, "abstract_snippet": "Forecasting how 3D medical scans evolve along time is important for disease progression, treatment planning, and developmental assessment. Yet existing models either rely on a single prior scan, fixed grid times, or target global labels, which limits voxel-level forecasting under irregular sampling. We present CRONOS, a unified framework for many-to-one prediction from multiple past scans that supports both discrete (grid-based) and continuous (real-valued) timestamps in one model, to the best of our knowledge the first to achieve continuous sequence-to-image forecasting for 3D medical data. CRONOS learns a spatio-temporal velocity field that transports context volumes toward a target volume at an arbitrary time, while operating directly in 3D voxel space. Across three public datasets spanning Cine-MRI, perfusion CT, and longitudinal MRI, CRONOS outperforms other baselines, while remaining computationally competitive. We will release code and evaluation protocols to enable reproducible, multi-dataset benchmarking of multi-context, continuous-time forecasting.", "abstract": "Forecasting how 3D medical scans evolve along time is important for disease progression, treatment planning, and developmental assessment. Yet existing models either rely on a single prior scan, fixed grid times, or target global labels, which limits voxel-level forecasting under irregular sampling. We present CRONOS, a unified framework for many-to-one prediction from multiple past scans that supports both discrete (grid-based) and continuous (real-valued) timestamps in one model, to the best of our knowledge the first to achieve continuous sequence-to-image forecasting for 3D medical data. CRONOS learns a spatio-temporal velocity field that transports context volumes toward a target volume at an arbitrary time, while operating directly in 3D voxel space. Across three public datasets spanning Cine-MRI, perfusion CT, and longitudinal MRI, CRONOS outperforms other baselines, while remaining computationally competitive. We will release code and evaluation protocols to enable reproducible, multi-dataset benchmarking of multi-context, continuous-time forecasting.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=XxqdbYD74l", "openreview_id": "XxqdbYD74l", "openreview_forum_id": "XxqdbYD74l", "authors": [], "pdf_url": "https://openreview.net/pdf/b3aa5ba5021b8762beb2cce46d9b07cb76ff541f.pdf", "summary_cn": "CRONOS提出首个支持连续时间戳的3D医学影像预测框架，通过时空速度场实现多对一预测，在多个数据集上优于基线方法。", "keywords": ["连续时间预测", "3D医学影像", "时空速度场", "多对一预测", "纵向序列", "疾病进展"], "triple": {"method": "学习时空速度场", "result": "在三个数据集上优于基线", "contribution": "首个支持连续时间戳的3D医学预测框架"}}
{"venue": "ICLR", "search_title": "AttTok: Marrying Attribute Tokens with Generative Pre-trained Vision-Language Models towards Medical Image Understanding", "full_title": "AttTok: Marrying Attribute Tokens with Generative Pre-trained Vision-Language Models towards Medical Image Understanding", "url": "https://openreview.net/forum?id=UjSoF5CM09", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recent generative pre-trained vision–language (GPTv) models have achieved remarkable success in multi-modal understanding, inspiring their adaptation to medical imaging tasks such as disease diagnosis and visual question answering (VQA). However, current instruction-tuned GPTv models suffer from two key challenges: (1) medical attributes (e.g., disease names, severity grades) are encoded as plain text tokens, collapsing semantically distinct concepts into nearly identical textual sequences; and (2) inadequate textual supervision weakens visual representation learning, leading to severe inter-attribute confusion and misaligned vision–language embeddings. To address these limitations, we introduce attribute tokens (AttTok), a set of pre‑defined special tokens that uniquely encode clinical attributes (e.g., imaging modality, diagnosis, severity) within a structured token space. Complemented by attribute‑centric embedding books, AttTok serves as anchor points for aligning both visual and textual modalities into a shared, discriminative representation space. Building on this foundation, we design two key components: an attribute‑centric cross attention (ACC) adapter, which breaks the vision‑to‑text information‑flow bottleneck and enriches the visual encoder with discriminative attribute knowledge, and an attribute‑centric matching (ACM) loss, which enforces robust multi‑modal alignment centered on the attribute tokens. Extensive experiments on five medical classification benchmarks and three VQA datasets demonstrate that AttTok substantially improves both discriminative accuracy and medical knowledge reasoning, establishing a new paradigm for medical GPTv models with clinically discriminative understanding.", "abstract": "Recent generative pre-trained vision–language (GPTv) models have achieved remarkable success in multi-modal understanding, inspiring their adaptation to medical imaging tasks such as disease diagnosis and visual question answering (VQA). However, current instruction-tuned GPTv models suffer from two key challenges: (1) medical attributes (e.g., disease names, severity grades) are encoded as plain text tokens, collapsing semantically distinct concepts into nearly identical textual sequences; and (2) inadequate textual supervision weakens visual representation learning, leading to severe inter-attribute confusion and misaligned vision–language embeddings. To address these limitations, we introduce attribute tokens (AttTok), a set of pre‑defined special tokens that uniquely encode clinical attributes (e.g., imaging modality, diagnosis, severity) within a structured token space. Complemented by attribute‑centric embedding books, AttTok serves as anchor points for aligning both visual and textual modalities into a shared, discriminative representation space. Building on this foundation, we design two key components: an attribute‑centric cross attention (ACC) adapter, which breaks the vision‑to‑text information‑flow bottleneck and enriches the visual encoder with discriminative attribute knowledge, and an attribute‑centric matching (ACM) loss, which enforces robust multi‑modal alignment centered on the attribute tokens. Extensive experiments on five medical classification benchmarks and three VQA datasets demonstrate that AttTok substantially improves both discriminative accuracy and medical knowledge reasoning, establishing a new paradigm for medical GPTv models with clinically discriminative understanding.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=UjSoF5CM09", "openreview_id": "UjSoF5CM09", "openreview_forum_id": "UjSoF5CM09", "authors": [], "pdf_url": "https://openreview.net/pdf/62f6bcc030ff6b7c05a473fe65715fee129d35f9.pdf", "summary_cn": "提出AttTok方法，通过属性令牌和嵌入书增强GPTv模型，解决医学属性混淆问题，提升分类和问答性能。", "keywords": ["属性令牌", "视觉-语言模型", "医学图像理解", "跨模态对齐", "生成预训练"], "triple": {"method": "引入属性令牌和嵌入书，结合ACC适配器和ACM损失", "result": "在多个医学数据集上提升准确性和推理能力", "contribution": "建立临床可区分的医学GPTv模型新范式"}}
{"venue": "ICLR", "search_title": "ProstaTD: Bridging Surgical Triplet from Classification to Fully Supervised Detection", "full_title": "ProstaTD: Bridging Surgical Triplet from Classification to Fully Supervised Detection", "url": "https://openreview.net/forum?id=0NkXZ98BjJ", "year": 2026, "is_main_conference": true, "abstract_snippet": "Surgical triplet detection is a critical task in surgical video analysis, with significant implications for performance assessment and training novice surgeons. However, existing datasets like CholecT50 lack precise spatial bounding box annotations, rendering triplet classification at the image level insufficient for practical applications. The inclusion of bounding box annotations is essential to make this task meaningful, as they provide the spatial context necessary for accurate analysis and improved model generalizability. To address these shortcomings, we introduce ProstaTD, a large-scale, multi-institutional dataset for surgical triplet detection, developed from the technically demanding domain of robot-assisted prostatectomy. ProstaTD offers clinically defined temporal boundaries and high-precision bounding box annotations for each structured triplet activity. The dataset comprises 71,775 video frames and 196,490 annotated triplet instances, collected from 21 surgeries performed across multiple institutions, reflecting a broad range of surgical practices and intraoperative conditions. The annotation process was conducted under rigorous medical supervision and involved more than 60 contributors, including practicing surgeons and medically trained annotators, through multiple iterative phases of labeling and verification. To further facilitate future general-purpose surgical annotation, we developed two tailored labeling tools to improve efficiency and scalability in our annotation workflows. In addition, we created a surgical triplet detection evaluation toolkit that enables standardized and reproducible performance assessment across studies. ProstaTD is the largest and most diverse surgical triplet dataset to date, moving the field from simple classification to full detection with precise spatial and temporal boundaries and thereby providing a robust foundation for fair benchmarking.", "abstract": "Surgical triplet detection is a critical task in surgical video analysis, with significant implications for performance assessment and training novice surgeons. However, existing datasets like CholecT50 lack precise spatial bounding box annotations, rendering triplet classification at the image level insufficient for practical applications. The inclusion of bounding box annotations is essential to make this task meaningful, as they provide the spatial context necessary for accurate analysis and improved model generalizability. To address these shortcomings, we introduce ProstaTD, a large-scale, multi-institutional dataset for surgical triplet detection, developed from the technically demanding domain of robot-assisted prostatectomy. ProstaTD offers clinically defined temporal boundaries and high-precision bounding box annotations for each structured triplet activity. The dataset comprises 71,775 video frames and 196,490 annotated triplet instances, collected from 21 surgeries performed across multiple institutions, reflecting a broad range of surgical practices and intraoperative conditions. The annotation process was conducted under rigorous medical supervision and involved more than 60 contributors, including practicing surgeons and medically trained annotators, through multiple iterative phases of labeling and verification. To further facilitate future general-purpose surgical annotation, we developed two tailored labeling tools to improve efficiency and scalability in our annotation workflows. In addition, we created a surgical triplet detection evaluation toolkit that enables standardized and reproducible performance assessment across studies. ProstaTD is the largest and most diverse surgical triplet dataset to date, moving the field from simple classification to full detection with precise spatial and temporal boundaries and thereby providing a robust foundation for fair benchmarking.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=0NkXZ98BjJ", "openreview_id": "0NkXZ98BjJ", "openreview_forum_id": "0NkXZ98BjJ", "authors": [], "pdf_url": "https://openreview.net/pdf/2c909942f08c64bdaeed29ff3e4f40b0c007aefc.pdf", "summary_cn": "ProstaTD是首个大规模、多机构的手术三元组检测数据集，提供精确时空边界框标注，推动领域从分类转向全监督检测，支持标准化评估。", "keywords": ["手术三元组检测", "数据集", "边界框标注", "机器人辅助前列腺切除术", "多机构", "评估工具包"], "triple": {"method": "开发ProstaTD数据集与标注工具", "result": "包含71,775帧和196,490标注实例，支持精确检测", "contribution": "提供首个大规模手术三元组检测基准，促进领域发展"}}
{"venue": "ICLR", "search_title": "Towards Text-Mask Consistency in Medical Image Segmentation", "full_title": "Towards Text-Mask Consistency in Medical Image Segmentation", "url": "https://openreview.net/forum?id=riOevy2RwZ", "year": 2026, "is_main_conference": true, "abstract_snippet": "Vision-language models for medical image segmentation often produce masks that conflict with the accompanying text, especially under multi-site/multi-lesion descriptions. We trace this failure to two factors: (i) highly templated and repetitive clinical language causes one-to-one hard contrastive learning to yield numerous false negatives, weakening cross-modal alignment; and (ii) predominantly vision-driven, one-way cross-attention lacks a language-dominant, spatially aware pathway, hindering effective injection of textual semantics into the spatial visual domain. To this end, we propose Consistency-enhanced Two-stage Segmentation (C2Seg). In the pretraining stage, Cluster-aware Contrastive Learning uses a frozen strong baseline to construct an intra-batch text similarity matrix as soft labels, thereby alleviating false negative conflicts and producing more discriminative visual representations. In the fusion stage, we introduce a Bidirectional Complementary Attention Module, where each modality dominates attention along its own path, fostering deep interaction and structural consistency between visual and textual representations. In order to enhance the expressive power of multimodal features, we further adopt KAN-based Attention Gating. Without updating the language encoder, our approach significantly improves text-mask consistency and segmentation accuracy on four public medical imaging datasets. Code is provided in the supplementary material.", "abstract": "Vision-language models for medical image segmentation often produce masks that conflict with the accompanying text, especially under multi-site/multi-lesion descriptions. We trace this failure to two factors: (i) highly templated and repetitive clinical language causes one-to-one hard contrastive learning to yield numerous false negatives, weakening cross-modal alignment; and (ii) predominantly vision-driven, one-way cross-attention lacks a language-dominant, spatially aware pathway, hindering effective injection of textual semantics into the spatial visual domain. To this end, we propose Consistency-enhanced Two-stage Segmentation (C2Seg). In the pretraining stage, Cluster-aware Contrastive Learning uses a frozen strong baseline to construct an intra-batch text similarity matrix as soft labels, thereby alleviating false negative conflicts and producing more discriminative visual representations. In the fusion stage, we introduce a Bidirectional Complementary Attention Module, where each modality dominates attention along its own path, fostering deep interaction and structural consistency between visual and textual representations. In order to enhance the expressive power of multimodal features, we further adopt KAN-based Attention Gating. Without updating the language encoder, our approach significantly improves text-mask consistency and segmentation accuracy on four public medical imaging datasets. Code is provided in the supplementary material.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=riOevy2RwZ", "openreview_id": "riOevy2RwZ", "openreview_forum_id": "riOevy2RwZ", "authors": [], "pdf_url": "https://openreview.net/pdf/134e94d0dd7e5251464f348554a30d11034c3f4f.pdf", "summary_cn": "针对医学图像分割中文本与掩码不一致问题，提出C2Seg方法，通过聚类感知对比学习和双向互补注意力模块，提升跨模态对齐与分割精度。", "keywords": ["医学图像分割", "视觉语言模型", "跨模态对齐", "对比学习", "注意力机制", "文本掩码一致性"], "triple": {"method": "C2Seg（聚类感知对比学习与双向互补注意力）", "result": "提升文本掩码一致性与分割准确率", "contribution": "增强多模态医学图像分割的跨模态对齐"}}
{"venue": "ICLR", "search_title": "CARE: Towards Clinical Accountability in Multi-Modal Medical Reasoning with an Evidence-Grounded Agentic Framework", "full_title": "CARE: Towards Clinical Accountability in Multi-Modal Medical Reasoning with an Evidence-Grounded Agentic Framework", "url": "https://openreview.net/forum?id=whRAOJiyHM", "year": 2026, "is_main_conference": true, "abstract_snippet": "Large visual language models (VLMs) have shown strong multi-modal medical reasoning ability, but most operate as end-to-end black boxes, diverging from clinicians’ evidence-based, staged workflows and hindering clinical accountability. Complementarily, expert visual grounding models can accurately localize regions of interest (ROIs), providing explicit, reliable evidence that improves both reasoning accuracy and trust. In this paper, we introduce **CARE**, advancing **C**linical **A**ccountability in multi-modal medical **R**easoning with an **E**vidence-grounded agentic framework. Unlike existing approaches that couple grounding and reasoning within a single generalist model, CARE decomposes the task into coordinated sub-modules to reduce shortcut learning and hallucination: a compact VLM proposes relevant medical entities; an expert entity-referring segmentation model produces pixel-level ROI evidence; and a grounded VLM reasons over the full image augmented by ROI hints. The VLMs are optimized with reinforcement learning with verifiable rewards to align answers with supporting evidence. Furthermore, a VLM coordinator plans tool invocation and reviews evidence-answer consistency, providing agentic control and final verification. Evaluated on standard medical VQA benchmarks, our **CARE-Flow** (coordinator-free) improves average accuracy by **10.9%** over the same size (10B) state-of-the-art (SOTA). With dynamic planning and answer review, our **CARE-Coord** yields a further gain, outperforming the heavily pre-trained SOTA by **5.2%**. Our experiments demonstrate that an agentic framework that emulates clinical workflows, incorporating decoupled specialized models and explicit evidence, yields more accurate and accountable medical AI.", "abstract": "Large visual language models (VLMs) have shown strong multi-modal medical reasoning ability, but most operate as end-to-end black boxes, diverging from clinicians’ evidence-based, staged workflows and hindering clinical accountability. Complementarily, expert visual grounding models can accurately localize regions of interest (ROIs), providing explicit, reliable evidence that improves both reasoning accuracy and trust. In this paper, we introduce **CARE**, advancing **C**linical **A**ccountability in multi-modal medical **R**easoning with an **E**vidence-grounded agentic framework. Unlike existing approaches that couple grounding and reasoning within a single generalist model, CARE decomposes the task into coordinated sub-modules to reduce shortcut learning and hallucination: a compact VLM proposes relevant medical entities; an expert entity-referring segmentation model produces pixel-level ROI evidence; and a grounded VLM reasons over the full image augmented by ROI hints. The VLMs are optimized with reinforcement learning with verifiable rewards to align answers with supporting evidence. Furthermore, a VLM coordinator plans tool invocation and reviews evidence-answer consistency, providing agentic control and final verification. Evaluated on standard medical VQA benchmarks, our **CARE-Flow** (coordinator-free) improves average accuracy by **10.9%** over the same size (10B) state-of-the-art (SOTA). With dynamic planning and answer review, our **CARE-Coord** yields a further gain, outperforming the heavily pre-trained SOTA by **5.2%**. Our experiments demonstrate that an agentic framework that emulates clinical workflows, incorporating decoupled specialized models and explicit evidence, yields more accurate and accountable medical AI.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=whRAOJiyHM", "openreview_id": "whRAOJiyHM", "openreview_forum_id": "whRAOJiyHM", "authors": [], "pdf_url": "https://openreview.net/pdf/5755ff044220ed351936c6120448bd372cd6498d.pdf", "summary_cn": "CARE框架通过分解任务、引入专家分割模型和强化学习，提升多模态医疗推理的准确性和临床可问责性，在基准测试中显著优于现有方法。", "keywords": ["多模态医疗推理", "临床可问责性", "证据基础框架", "专家分割模型", "强化学习", "智能体协调"], "triple": {"method": "分解任务为实体提议、分割和推理模块，结合强化学习与智能体协调", "result": "CARE-Flow准确率提升10.9%，CARE-Coord进一步超越SOTA 5.2%", "contribution": "提出模拟临床工作流的智能体框架，增强医疗AI的准确性与可问责性"}}
{"venue": "ICLR", "search_title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis", "full_title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis", "url": "https://openreview.net/forum?id=ZkoojtEm3W", "year": 2026, "is_main_conference": true, "abstract_snippet": "Deep learning-based respiratory auscultation is currently hindered by two fundamental disconnects: the representation gap, where compressing signals into spectrograms discards transient acoustic events and clinical context, and the data gap, characterized by severe class imbalance and scarcity. To bridge these gaps, we present **_Resp-Agent_**, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A²CA). Unlike static pipelines, the Thinker-A²CA acts as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. Under this unified orchestration, we propose two specialized architectural solutions. First, to address the representation gap, we introduce a Modality Weaving Diagnoser. This module moves beyond standard fusion by explicitly interleaving electronic health records (EHR) with audio tokens and employs Strategic Global Attention to capture long-range clinical dependencies while retaining sensitivity to millisecond-level transient events via sparse audio anchors. Second, to resolve the data gap, we design a Flow Matching Generator that retools a text-only Large Language Model (LLM) via modality injection. Guided by the Thinker-A²CA, this generator decouples pathological content from acoustic style to programmatically synthesize high-fidelity, hard-to-diagnose samples that remedy the system’s boundary errors. To support this work, we construct **_Resp-229k_**, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that our agentic co-design consistently outperforms prior approaches, advancing robust and deployable respiratory intelligence. Data and code will be released upon acceptance.", "abstract": "Deep learning-based respiratory auscultation is currently hindered by two fundamental disconnects: the representation gap, where compressing signals into spectrograms discards transient acoustic events and clinical context, and the data gap, characterized by severe class imbalance and scarcity. To bridge these gaps, we present **_Resp-Agent_**, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A²CA). Unlike static pipelines, the Thinker-A²CA acts as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. Under this unified orchestration, we propose two specialized architectural solutions. First, to address the representation gap, we introduce a Modality Weaving Diagnoser. This module moves beyond standard fusion by explicitly interleaving electronic health records (EHR) with audio tokens and employs Strategic Global Attention to capture long-range clinical dependencies while retaining sensitivity to millisecond-level transient events via sparse audio anchors. Second, to resolve the data gap, we design a Flow Matching Generator that retools a text-only Large Language Model (LLM) via modality injection. Guided by the Thinker-A²CA, this generator decouples pathological content from acoustic style to programmatically synthesize high-fidelity, hard-to-diagnose samples that remedy the system’s boundary errors. To support this work, we construct **_Resp-229k_**, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that our agentic co-design consistently outperforms prior approaches, advancing robust and deployable respiratory intelligence. Data and code will be released upon acceptance.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ZkoojtEm3W", "openreview_id": "ZkoojtEm3W", "openreview_forum_id": "ZkoojtEm3W", "authors": [], "pdf_url": "https://openreview.net/pdf/651f4a33c71e5e7e4bb800b593c05b685f65f94d.pdf", "summary_cn": "提出Resp-Agent系统，通过主动对抗课程代理协调多模态诊断与生成，解决呼吸音诊断中的表示与数据鸿沟，提升诊断性能。", "keywords": ["呼吸音诊断", "多模态学习", "主动对抗课程", "数据生成", "表示学习", "电子健康记录"], "triple": {"method": "主动对抗课程代理协调多模态诊断与生成", "result": "系统性能超越现有方法", "contribution": "解决表示与数据鸿沟，提升呼吸音诊断鲁棒性"}}
{"venue": "ICLR", "search_title": "Random Anchors with Low-rank Decorrelated Learning: A Minimalist Pipeline for Class-Incremental Medical Image Classification", "full_title": "Random Anchors with Low-rank Decorrelated Learning: A Minimalist Pipeline for Class-Incremental Medical Image Classification", "url": "https://openreview.net/forum?id=mduCc7XKXH", "year": 2026, "is_main_conference": true, "abstract_snippet": "Class-incremental learning (CIL) in medical image-guided diagnosis requires models to preserve knowledge of historical disease classes while adapting to emerging categories. Pre-trained models (PTMs) with well-generalized features provide a strong foundation, yet most PTM-based CIL strategies, such as prompt tuning, task-specific adapters and model mixtures, rely on increasingly complex designs. While effective in general-domain benchmarks, these methods falter in medical imaging, where low intra-class variability and high inter-domain shifts (from scanners, protocols and institutions) make CIL particularly prone to representation collapse and domain misalignment. Under such conditions, we find that lightweight representation calibration strategies, often dismissed in general-domain CIL for their modest gains, can be remarkably effective for adapting PTMs in medical settings. To this end, we introduce Random Anchors with Low-rank Decorrelated Learning (RA-LDL), a minimalist representation-based framework that combines (a) PTM-based feature extraction with optional ViT-Adapter tuning, (b) feature calibration via frozen Random Anchor projection and a single-session-trained Low-Rank Projection (LRP), and (c) analytical closed-form decorrelated learning. The entire pipeline requires only one training session and minimal task-specific tuning, making it appealing for efficient deployment. Despite its simplicity, RA-LDL achieves consistent and substantial improvements across both general-domain and medical-specific PTMs, and outperforms recent state-of-the-art methods on four diverse medical imaging datasets. These results highlight that minimalist representation recalibration, rather than complex architectural modifications, can unlock the underexplored potential of PTMs in medical CIL. We hope this work establishes a practical and extensible foundation for future research in class-incremental image-guided diagnosis. Code will be made publicly available.", "abstract": "Class-incremental learning (CIL) in medical image-guided diagnosis requires models to preserve knowledge of historical disease classes while adapting to emerging categories. Pre-trained models (PTMs) with well-generalized features provide a strong foundation, yet most PTM-based CIL strategies, such as prompt tuning, task-specific adapters and model mixtures, rely on increasingly complex designs. While effective in general-domain benchmarks, these methods falter in medical imaging, where low intra-class variability and high inter-domain shifts (from scanners, protocols and institutions) make CIL particularly prone to representation collapse and domain misalignment. Under such conditions, we find that lightweight representation calibration strategies, often dismissed in general-domain CIL for their modest gains, can be remarkably effective for adapting PTMs in medical settings. To this end, we introduce Random Anchors with Low-rank Decorrelated Learning (RA-LDL), a minimalist representation-based framework that combines (a) PTM-based feature extraction with optional ViT-Adapter tuning, (b) feature calibration via frozen Random Anchor projection and a single-session-trained Low-Rank Projection (LRP), and (c) analytical closed-form decorrelated learning. The entire pipeline requires only one training session and minimal task-specific tuning, making it appealing for efficient deployment. Despite its simplicity, RA-LDL achieves consistent and substantial improvements across both general-domain and medical-specific PTMs, and outperforms recent state-of-the-art methods on four diverse medical imaging datasets. These results highlight that minimalist representation recalibration, rather than complex architectural modifications, can unlock the underexplored potential of PTMs in medical CIL. We hope this work establishes a practical and extensible foundation for future research in class-incremental image-guided diagnosis. Code will be made publicly available.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=mduCc7XKXH", "openreview_id": "mduCc7XKXH", "openreview_forum_id": "mduCc7XKXH", "authors": [], "pdf_url": "https://openreview.net/pdf/4635dbbdf87223e050131fe34fbd5ace48241da8.pdf", "summary_cn": "提出RA-LDL框架，通过随机锚点和低秩解相关学习，以极简设计实现医学图像类增量分类，在多个数据集上超越现有方法。", "keywords": ["类增量学习", "医学图像分类", "预训练模型", "表示校准", "低秩投影", "解相关学习"], "triple": {"method": "随机锚点与低秩解相关学习", "result": "在四个医学影像数据集上超越先进方法", "contribution": "为医学类增量学习提供极简有效框架"}}
{"venue": "ICLR", "search_title": "Rethinking Model Calibration through Spectral Entropy Regularization in Medical Image Segmentation", "full_title": "Rethinking Model Calibration through Spectral Entropy Regularization in Medical Image Segmentation", "url": "https://openreview.net/forum?id=SOFSVaZXSj", "year": 2026, "is_main_conference": true, "abstract_snippet": "Deep neural networks for medical image segmentation often produce overconfident predictions, posing clinical risks due to miscalibrated uncertainty estimates. In this work, we rethink model calibration from a frequency-domain perspective and identify two critical factors causing miscalibration: spectral bias, where models overemphasize low-frequency components, and confidence saturation, which suppresses overall power spectral density in confidence maps. To address these challenges, we propose a novel frequency-aware calibration framework integrating spectral entropy regularization and power spectral smoothing. The spectral entropy term promotes a balanced frequency spectrum and enhances overall spectral power,  enabling better modeling of high-frequency boundary and low-frequency structural uncertainty. The smoothing module stabilizes frequency-wise statistics across training batches, reducing sample-specific fluctuations. Extensive experiments on six public medical imaging datasets and multiple segmentation architectures demonstrate that our approach consistently improves calibration metrics without sacrificing segmentation accuracy.", "abstract": "Deep neural networks for medical image segmentation often produce overconfident predictions, posing clinical risks due to miscalibrated uncertainty estimates. In this work, we rethink model calibration from a frequency-domain perspective and identify two critical factors causing miscalibration: spectral bias, where models overemphasize low-frequency components, and confidence saturation, which suppresses overall power spectral density in confidence maps. To address these challenges, we propose a novel frequency-aware calibration framework integrating spectral entropy regularization and power spectral smoothing. The spectral entropy term promotes a balanced frequency spectrum and enhances overall spectral power,  enabling better modeling of high-frequency boundary and low-frequency structural uncertainty. The smoothing module stabilizes frequency-wise statistics across training batches, reducing sample-specific fluctuations. Extensive experiments on six public medical imaging datasets and multiple segmentation architectures demonstrate that our approach consistently improves calibration metrics without sacrificing segmentation accuracy.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=SOFSVaZXSj", "openreview_id": "SOFSVaZXSj", "openreview_forum_id": "SOFSVaZXSj", "authors": [], "pdf_url": "https://openreview.net/pdf/3edf752b836f423bf28a6a0183ab178f54a9dc61.pdf", "summary_cn": "提出基于频域视角的医学图像分割模型校准框架，通过谱熵正则化和功率谱平滑解决谱偏置和置信饱和问题，提升不确定性估计准确性。", "keywords": ["模型校准", "医学图像分割", "谱熵正则化", "频域分析", "不确定性估计", "深度学习"], "triple": {"method": "谱熵正则化与功率谱平滑", "result": "校准指标提升，分割精度未下降", "contribution": "频域视角校准框架"}}
{"venue": "ICLR", "search_title": "COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics", "full_title": "COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics", "url": "https://openreview.net/forum?id=uBy4TCgGiT", "year": 2026, "is_main_conference": true, "abstract_snippet": "In clinical applications, the utility of segmentation models is often based on the accuracy of derived downstream metrics such as organ size, rather than by the pixel-level accuracy of the segmentation masks themselves. Thus, uncertainty quantification for such metrics is crucial for decision-making. Conformal prediction (CP) is a popular framework to derive such principled uncertainty guarantees, but applying CP naively to the final scalar metric is inefficient because it treats the complex, non-linear segmentation-to-metric pipeline as a black box. We introduce COMPASS, a practical framework that generates efficient, metric-based CP intervals for image segmentation models by leveraging the inductive biases of their underlying deep neural networks. COMPASS performs calibration directly in the model's representation space by perturbing intermediate features along low-dimensional subspaces maximally sensitive to the target metric. We prove that COMPASS achieves valid marginal coverage under the assumption of exchangeability. Empirically, we demonstrate that COMPASS produces significantly tighter intervals than traditional CP baselines on four medical image segmentation tasks for area estimation of skin lesions and anatomical structures. Furthermore, we show that leveraging learned internal features to estimate importance weights allows COMPASS to also recover target coverage under covariate shifts. COMPASS paves the way for practical, metric-based uncertainty quantification for medical image segmentation.", "abstract": "In clinical applications, the utility of segmentation models is often based on the accuracy of derived downstream metrics such as organ size, rather than by the pixel-level accuracy of the segmentation masks themselves. Thus, uncertainty quantification for such metrics is crucial for decision-making. Conformal prediction (CP) is a popular framework to derive such principled uncertainty guarantees, but applying CP naively to the final scalar metric is inefficient because it treats the complex, non-linear segmentation-to-metric pipeline as a black box. We introduce COMPASS, a practical framework that generates efficient, metric-based CP intervals for image segmentation models by leveraging the inductive biases of their underlying deep neural networks. COMPASS performs calibration directly in the model's representation space by perturbing intermediate features along low-dimensional subspaces maximally sensitive to the target metric. We prove that COMPASS achieves valid marginal coverage under the assumption of exchangeability. Empirically, we demonstrate that COMPASS produces significantly tighter intervals than traditional CP baselines on four medical image segmentation tasks for area estimation of skin lesions and anatomical structures. Furthermore, we show that leveraging learned internal features to estimate importance weights allows COMPASS to also recover target coverage under covariate shifts. COMPASS paves the way for practical, metric-based uncertainty quantification for medical image segmentation.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=uBy4TCgGiT", "openreview_id": "uBy4TCgGiT", "openreview_forum_id": "uBy4TCgGiT", "authors": [], "pdf_url": "https://openreview.net/pdf/be0d7cb1bd9858b9f20a14c4bdbd95eeefc05290.pdf", "summary_cn": "COMPASS提出一种医学图像分割不确定性量化框架，通过在特征空间扰动生成高效置信区间，提升下游指标预测的鲁棒性。", "keywords": ["医学图像分割", "不确定性量化", "保形预测", "特征扰动", "下游指标", "协变量偏移"], "triple": {"method": "特征空间扰动与保形预测", "result": "置信区间更紧，覆盖目标指标", "contribution": "提升医学分割指标不确定性量化效率"}}
{"venue": "ICLR", "search_title": "Repurposing Foundation Model for Generalizable Medical Time Series Classification", "full_title": "Repurposing Foundation Model for Generalizable Medical Time Series Classification", "url": "https://openreview.net/forum?id=wNEzRYiyZM", "year": 2026, "is_main_conference": true, "abstract_snippet": "Medical time series (MedTS) classification suffers from poor generalizability\nin real-world deployment due to inter- and intra-dataset heterogeneity, such as varying\nnumbers of channels, signal lengths, task definitions, and patient characteristics.\n% implicit patient characteristics, variable channel configurations, time series lengths, and diagnostic tasks.\nTo address this, we propose FORMED, a novel framework for repurposing a backbone foundation model, pre-trained on generic time series, to enable highly generalizable MedTS classification on unseen datasets.\nFORMED combines the backbone with a novel classifier comprising two components: (1) task-specific channel embeddings and label queries, dynamically sized to match any number of channels and target classes, and (2) a shared decoding attention layer, jointly trained across datasets to capture medical domain knowledge through task-agnostic feature-query interactions. After repurposing, FORMED achieves seamless adaptation to unseen MedTS datasets through lightweight label query training (0.1\\% of parameters), eliminating the need for full fine-tuning or architectural redesign.\nWe evaluate FORMED on 5 diverse MedTS datasets, benchmarking against 11 Task-Specific Models (TSM) and 4 Task-Specific Adaptation (TSA) methods. Our results demonstrate FORMED's dominant performance, achieving up to 35\\% absolute improvement in F1-score (on ADFTD dataset) over specialized baselines.\nBy decoupling domain-invariant representation learning from task-specific adaptation, FORMED establishes a scalable and resource-efficient paradigm for foundation model repurposing in healthcare. This approach prioritizes clinical adaptability over rigid task-centric design, offering a practical pathway for real-world implementation.", "abstract": "Medical time series (MedTS) classification suffers from poor generalizability\nin real-world deployment due to inter- and intra-dataset heterogeneity, such as varying\nnumbers of channels, signal lengths, task definitions, and patient characteristics.\n% implicit patient characteristics, variable channel configurations, time series lengths, and diagnostic tasks.\nTo address this, we propose FORMED, a novel framework for repurposing a backbone foundation model, pre-trained on generic time series, to enable highly generalizable MedTS classification on unseen datasets.\nFORMED combines the backbone with a novel classifier comprising two components: (1) task-specific channel embeddings and label queries, dynamically sized to match any number of channels and target classes, and (2) a shared decoding attention layer, jointly trained across datasets to capture medical domain knowledge through task-agnostic feature-query interactions. After repurposing, FORMED achieves seamless adaptation to unseen MedTS datasets through lightweight label query training (0.1\\% of parameters), eliminating the need for full fine-tuning or architectural redesign.\nWe evaluate FORMED on 5 diverse MedTS datasets, benchmarking against 11 Task-Specific Models (TSM) and 4 Task-Specific Adaptation (TSA) methods. Our results demonstrate FORMED's dominant performance, achieving up to 35\\% absolute improvement in F1-score (on ADFTD dataset) over specialized baselines.\nBy decoupling domain-invariant representation learning from task-specific adaptation, FORMED establishes a scalable and resource-efficient paradigm for foundation model repurposing in healthcare. This approach prioritizes clinical adaptability over rigid task-centric design, offering a practical pathway for real-world implementation.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=wNEzRYiyZM", "openreview_id": "wNEzRYiyZM", "openreview_forum_id": "wNEzRYiyZM", "authors": [], "pdf_url": "https://openreview.net/pdf/b8992f1f53acaa99ad82b32ab99ea8f24e9e2451.pdf", "summary_cn": "提出FORMED框架，通过重用基础模型和动态分类器，实现医疗时间序列分类的高泛化性，仅需少量参数适应新数据集。", "keywords": ["医疗时间序列分类", "基础模型重用", "泛化性", "动态分类器", "轻量适应", "跨数据集学习"], "triple": {"method": "重用基础模型与动态分类器", "result": "在5个数据集上优于基线，F1分数提升达35%", "contribution": "建立可扩展、资源高效的医疗基础模型重用范式"}}
{"venue": "ICLR", "search_title": "ATPO: ADAPTIVE TREE POLICY OPTIMIZATION FOR MULTI-TURN MEDICAL DIALOGUE", "full_title": "ATPO: ADAPTIVE TREE POLICY OPTIMIZATION FOR MULTI-TURN MEDICAL DIALOGUE", "url": "https://openreview.net/forum?id=2bv3B8B9bl", "year": 2026, "is_main_conference": true, "abstract_snippet": "Effective information seeking in multi-turn medical dialogues is critical for accurate diagnosis, especially when dealing with incomplete information. Aligning Large Language Models (LLMs) for these interactive scenarios is challenging due to the uncertainty inherent in user-agent interactions, which we formulate as a Hierarchical Markov Decision Process (H-MDP). While conventional Reinforcement Learning (RL) methods like Group Relative Policy Optimization (GRPO) struggle with long-horizon credit assignment and Proximal Policy Optimization (PPO) suffers from unstable value estimation in this context, we propose a novel uncertainty-aware Adaptive Tree Policy Optimization (ATPO) algorithm. Our method adaptively allocates the rollout budget to states with high uncertainty, quantified by a composite metric of Bellman error and action-value variance. This strategy enables more accurate value estimation, while fostering more efficient and diverse exploration. To mitigate the high computational cost of tree-based RL, we introduce two key optimizations: an uncertainty-guided pruning mechanism to minimize the number of rollouts, and an asynchronous search architecture that leverages KV cache reuse to maximize inference throughput. Extensive experiments on three public medical dialogue benchmarks demonstrate that our algorithm significantly outperforms several strong baselines, culminating in Qwen3-8B model surpassing the much larger GPT-4o (+0.92% accuracy).", "abstract": "Effective information seeking in multi-turn medical dialogues is critical for accurate diagnosis, especially when dealing with incomplete information. Aligning Large Language Models (LLMs) for these interactive scenarios is challenging due to the uncertainty inherent in user-agent interactions, which we formulate as a Hierarchical Markov Decision Process (H-MDP). While conventional Reinforcement Learning (RL) methods like Group Relative Policy Optimization (GRPO) struggle with long-horizon credit assignment and Proximal Policy Optimization (PPO) suffers from unstable value estimation in this context, we propose a novel uncertainty-aware Adaptive Tree Policy Optimization (ATPO) algorithm. Our method adaptively allocates the rollout budget to states with high uncertainty, quantified by a composite metric of Bellman error and action-value variance. This strategy enables more accurate value estimation, while fostering more efficient and diverse exploration. To mitigate the high computational cost of tree-based RL, we introduce two key optimizations: an uncertainty-guided pruning mechanism to minimize the number of rollouts, and an asynchronous search architecture that leverages KV cache reuse to maximize inference throughput. Extensive experiments on three public medical dialogue benchmarks demonstrate that our algorithm significantly outperforms several strong baselines, culminating in Qwen3-8B model surpassing the much larger GPT-4o (+0.92% accuracy).", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=2bv3B8B9bl", "openreview_id": "2bv3B8B9bl", "openreview_forum_id": "2bv3B8B9bl", "authors": [], "pdf_url": "https://openreview.net/pdf/395d01fff7735f828ef2f7ac13031b841b7af2f4.pdf", "summary_cn": "提出ATPO算法，通过自适应分配探索预算和优化计算，提升多轮医疗对话中LLM的信息寻求能力，在多个基准上超越基线模型。", "keywords": ["自适应树策略优化", "多轮医疗对话", "不确定性感知", "强化学习", "大语言模型", "计算优化"], "triple": {"method": "ATPO算法（自适应树策略优化）", "result": "在三个医疗对话基准上超越基线，Qwen3-8B模型准确率超过GPT-4o", "contribution": "提升多轮医疗对话中LLM的信息寻求准确性和效率"}}
{"venue": "ICLR", "search_title": "Cross-Timestep: 3D Diffusion Model with Trans-temporal Memory LSTM and Adaptive Priori Decoding Strategy for Medical Segmentation", "full_title": "Cross-Timestep: 3D Diffusion Model with Trans-temporal Memory LSTM and Adaptive Priori Decoding Strategy for Medical Segmentation", "url": "https://openreview.net/forum?id=TE3asYO8PQ", "year": 2026, "is_main_conference": true, "abstract_snippet": "Diffusion models have recently demonstrated significant robustness in medical image segmentation, effectively accommodating variations across different imaging styles. However, their applications remain limited due to: (i) current successes being primarily confined to 2D segmentation tasks—we observe that diffusion models tend to collapse at the early stage when applied to 3D medical tasks; and (ii) the inherently isolated iteration along timesteps during training and inference. To tackle these limitations, we propose a novel framework named Cross-Timestep, which incorporates two key innovations: an Adaptive Priori Decoding Strategy (APDS) and a trans-temporal memory LSTM (tLSTM) mechanism. (i) The APDS provides prior guidance during the diffusion process by employing a Priori Decoder(PD) that focuses solely on the conditional branch, successfully stabilizing the reverse diffusion process. (ii) The tLSTM integrates convolution and linear layers into the LSTM gating structure, and enhances the memory cell mechanism to retain temporal state, explicitly preserving and propagating continuous temporal states across timesteps. Experimental results demonstrate that Cross-Timestep performs favorably on heterogeneous 3D medical datasets. Three experiments further analyze the collapse phenomenon in 3D medical diffusion models and validate that APDS effectively prevents initial-stage collapse without excessively constraining the model, while tLSTM facilitates the performance and scalability of diffusion models.", "abstract": "Diffusion models have recently demonstrated significant robustness in medical image segmentation, effectively accommodating variations across different imaging styles. However, their applications remain limited due to: (i) current successes being primarily confined to 2D segmentation tasks—we observe that diffusion models tend to collapse at the early stage when applied to 3D medical tasks; and (ii) the inherently isolated iteration along timesteps during training and inference. To tackle these limitations, we propose a novel framework named Cross-Timestep, which incorporates two key innovations: an Adaptive Priori Decoding Strategy (APDS) and a trans-temporal memory LSTM (tLSTM) mechanism. (i) The APDS provides prior guidance during the diffusion process by employing a Priori Decoder(PD) that focuses solely on the conditional branch, successfully stabilizing the reverse diffusion process. (ii) The tLSTM integrates convolution and linear layers into the LSTM gating structure, and enhances the memory cell mechanism to retain temporal state, explicitly preserving and propagating continuous temporal states across timesteps. Experimental results demonstrate that Cross-Timestep performs favorably on heterogeneous 3D medical datasets. Three experiments further analyze the collapse phenomenon in 3D medical diffusion models and validate that APDS effectively prevents initial-stage collapse without excessively constraining the model, while tLSTM facilitates the performance and scalability of diffusion models.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=TE3asYO8PQ", "openreview_id": "TE3asYO8PQ", "openreview_forum_id": "TE3asYO8PQ", "authors": [], "pdf_url": "https://openreview.net/pdf/16572ba3a99ea04f2196d08d1577d9b17d94324f.pdf", "summary_cn": "提出Cross-Timestep框架，结合自适应先验解码策略和跨时间记忆LSTM，解决3D医学扩散模型早期崩溃问题，提升分割鲁棒性。", "keywords": ["3D医学分割", "扩散模型", "自适应先验解码", "跨时间记忆LSTM", "模型稳定性", "异构数据集"], "triple": {"method": "自适应先验解码策略(APDS)与跨时间记忆LSTM(tLSTM)", "result": "在异构3D医学数据集上表现优异，有效防止早期崩溃", "contribution": "提升3D扩散模型稳定性与性能"}}
{"venue": "ICLR", "search_title": "Dual-Kernel Adapter: Expanding Spatial Horizons for Data-Constrained Medical Image Analysis", "full_title": "Dual-Kernel Adapter: Expanding Spatial Horizons for Data-Constrained Medical Image Analysis", "url": "https://openreview.net/forum?id=Z6KGt1veeP", "year": 2026, "is_main_conference": true, "abstract_snippet": "Adapters have become a widely adopted strategy for efficient fine-tuning of foundation models, particularly in resource-constrained settings. However, their performance under extreme data scarcity—common in medical imaging due to high annotation costs, privacy regulations, and fragmented datasets—remains underexplored. In this work, we present the first comprehensive study of adapter-based fine-tuning for vision foundation models in low-data medical imaging scenarios. We find that, contrary to their promise, conventional Adapters can degrade performance under severe data constraints, performing even worse than simple linear probing when trained on less than 1\\% of the corresponding training data. Through systematic analysis, we identify a sharp reduction in Effective Receptive Field (ERF) as a key factor behind this degradation. Motivated by these findings, we propose the Dual-Kernel Adapter (DKA), a lightweight module that expands spatial context via large-kernel convolutions while preserving local detail with small-kernel counterparts. Extensive experiments across diverse classification and segmentation benchmarks show that DKA significantly outperforms existing Adapter methods, establishing new leading results in both data-constrained and data-rich regimes.", "abstract": "Adapters have become a widely adopted strategy for efficient fine-tuning of foundation models, particularly in resource-constrained settings. However, their performance under extreme data scarcity—common in medical imaging due to high annotation costs, privacy regulations, and fragmented datasets—remains underexplored. In this work, we present the first comprehensive study of adapter-based fine-tuning for vision foundation models in low-data medical imaging scenarios. We find that, contrary to their promise, conventional Adapters can degrade performance under severe data constraints, performing even worse than simple linear probing when trained on less than 1\\% of the corresponding training data. Through systematic analysis, we identify a sharp reduction in Effective Receptive Field (ERF) as a key factor behind this degradation. Motivated by these findings, we propose the Dual-Kernel Adapter (DKA), a lightweight module that expands spatial context via large-kernel convolutions while preserving local detail with small-kernel counterparts. Extensive experiments across diverse classification and segmentation benchmarks show that DKA significantly outperforms existing Adapter methods, establishing new leading results in both data-constrained and data-rich regimes.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=Z6KGt1veeP", "openreview_id": "Z6KGt1veeP", "openreview_forum_id": "Z6KGt1veeP", "authors": [], "pdf_url": "https://openreview.net/pdf/48fb73f36e655637acbff413c9b570c35666be74.pdf", "summary_cn": "针对医学图像数据稀缺问题，提出双核适配器（DKA），通过大小核卷积扩展空间感受野，在低数据和高数据场景下均优于现有适配器方法。", "keywords": ["医学图像分析", "适配器微调", "数据稀缺", "感受野", "双核卷积", "轻量模块"], "triple": {"method": "双核适配器（DKA）", "result": "在分类和分割任务中显著超越现有适配器方法", "contribution": "提升低数据下视觉基础模型性能"}}
{"venue": "ICLR", "search_title": "Medical thinking with multiple images", "full_title": "Medical thinking with multiple images", "url": "https://openreview.net/forum?id=h2p5eOFpcF", "year": 2026, "is_main_conference": true, "abstract_snippet": "Large language models and vision-language models score high on many medical QA benchmarks; however, real-world clinical reasoning remains challenging because cases often involve multiple images and require cross-view fusion. We present MedThinkVQA, a benchmark that asks models to think with multiple images: read each image, merge evidence across views, and pick a diagnosis with stepwise supervision. We make three parts explicit: multi-image questions, expert-annotated stepwise supervision, and beyond-accuracy evaluation. Only MedThinkVQA combines all these parts in one expert-annotated benchmark. The dataset has 8,481 cases in total, with 751 test cases, and on average 6.51 images per case; it is expert-annotated and, at this level, larger and more image-dense than prior work (earlier maxima < 1.43 images per case). On the test set, GPT-5 achieves 57.39% accuracy, approximately 15 percentage points below the strongest result on the most challenging prior benchmark of a similar kind, while other strong models are lower (Qwen2.5-VL-32B: 39.54%, MedGemma-27B: 37.55%, InternVL3.5-38B: 43.14%). Giving expert findings and summaries brings clear gains, but using models' self-generated ones brings small or negative gains. Step-level evaluation shows where models stumble: errors center on image reading and cross-view integration in both decisive and non-decisive steps (>70%); when a step is decisive for the final choice, reasoning slips become more common (32.26%), while scenario and pure-knowledge slips are relatively rare (<10%). These patterns isolate and quantify the core obstacle: extracting and integrating cross-image evidence, rather than language-only inference.", "abstract": "Large language models and vision-language models score high on many medical QA benchmarks; however, real-world clinical reasoning remains challenging because cases often involve multiple images and require cross-view fusion. We present MedThinkVQA, a benchmark that asks models to think with multiple images: read each image, merge evidence across views, and pick a diagnosis with stepwise supervision. We make three parts explicit: multi-image questions, expert-annotated stepwise supervision, and beyond-accuracy evaluation. Only MedThinkVQA combines all these parts in one expert-annotated benchmark. The dataset has 8,481 cases in total, with 751 test cases, and on average 6.51 images per case; it is expert-annotated and, at this level, larger and more image-dense than prior work (earlier maxima < 1.43 images per case). On the test set, GPT-5 achieves 57.39% accuracy, approximately 15 percentage points below the strongest result on the most challenging prior benchmark of a similar kind, while other strong models are lower (Qwen2.5-VL-32B: 39.54%, MedGemma-27B: 37.55%, InternVL3.5-38B: 43.14%). Giving expert findings and summaries brings clear gains, but using models' self-generated ones brings small or negative gains. Step-level evaluation shows where models stumble: errors center on image reading and cross-view integration in both decisive and non-decisive steps (>70%); when a step is decisive for the final choice, reasoning slips become more common (32.26%), while scenario and pure-knowledge slips are relatively rare (<10%). These patterns isolate and quantify the core obstacle: extracting and integrating cross-image evidence, rather than language-only inference.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=h2p5eOFpcF", "openreview_id": "h2p5eOFpcF", "openreview_forum_id": "h2p5eOFpcF", "authors": [], "pdf_url": "https://openreview.net/pdf/70b16123ab381aec4897235755e6f1e6926423dc.pdf", "summary_cn": "提出MedThinkVQA基准，要求模型处理多图像临床推理，包含专家标注的逐步监督。测试显示现有模型在图像阅读和跨视图融合上存在显著困难，准确率较低。", "keywords": ["多图像推理", "临床基准", "跨视图融合", "逐步监督", "医学VQA", "专家标注"], "triple": {"method": "构建MedThinkVQA基准，含多图像问题与逐步监督", "result": "GPT-5准确率57.39%，模型在图像阅读与跨视图融合步骤错误率高", "contribution": "首次结合多图像、逐步监督与超准确率评估，量化多图像推理核心障碍"}}
{"venue": "ICLR", "search_title": "Boosting Medical Visual Understanding From Multi-Granular Language Learning", "full_title": "Boosting Medical Visual Understanding From Multi-Granular Language Learning", "url": "https://openreview.net/forum?id=ccjukmExrB", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recent advances in image-text pretraining have significantly enhanced visual understanding by aligning visual and textual representations. Contrastive Language-Image Pretraining (CLIP) has played a pivotal role in multimodal learning. However, its focus on single-label, single-granularity alignment limits its effectiveness in complex domains such as medical imaging, where images often correspond to multiple labels across different levels of granularity. To address this, we propose Multi-Granular Language Learning (MGLL), a contrastive learning framework designed to improve both multi-label and cross-granularity alignment. MGLL leverages structured multi-label supervision, integrates textual descriptions across granularities, and introduces soft-label supervision with point-wise constraints to enhance alignment. MGLL employs smooth Kullback–Leibler (KL) divergence to ensure cross-granularity consistency while maintaining computational efficiency as a plug-and-play module for vision-language models. Pretrained on our constructed large-scale multi-granular datasets and evaluated across multiple datasets, MGLL outperforms other state-of-the-art methods in downstream tasks. The code will be available on GitHub.", "abstract": "Recent advances in image-text pretraining have significantly enhanced visual understanding by aligning visual and textual representations. Contrastive Language-Image Pretraining (CLIP) has played a pivotal role in multimodal learning. However, its focus on single-label, single-granularity alignment limits its effectiveness in complex domains such as medical imaging, where images often correspond to multiple labels across different levels of granularity. To address this, we propose Multi-Granular Language Learning (MGLL), a contrastive learning framework designed to improve both multi-label and cross-granularity alignment. MGLL leverages structured multi-label supervision, integrates textual descriptions across granularities, and introduces soft-label supervision with point-wise constraints to enhance alignment. MGLL employs smooth Kullback–Leibler (KL) divergence to ensure cross-granularity consistency while maintaining computational efficiency as a plug-and-play module for vision-language models. Pretrained on our constructed large-scale multi-granular datasets and evaluated across multiple datasets, MGLL outperforms other state-of-the-art methods in downstream tasks. The code will be available on GitHub.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ccjukmExrB", "openreview_id": "ccjukmExrB", "openreview_forum_id": "ccjukmExrB", "authors": [], "pdf_url": "https://openreview.net/pdf/a1b1dc07736c81471788af3503db007b695c4246.pdf", "summary_cn": "提出多粒度语言学习框架MGLL，通过多标签监督和跨粒度文本整合，提升医学图像理解能力，在多个数据集上表现优异。", "keywords": ["多粒度学习", "医学图像理解", "对比学习", "多标签对齐", "跨粒度一致性", "视觉语言模型"], "triple": {"method": "多粒度对比学习框架MGLL", "result": "下游任务性能超越现有方法", "contribution": "提升医学图像多标签跨粒度对齐"}}
{"venue": "ICLR", "search_title": "Missingness Bias Calibration in Feature Attribution Explanations", "full_title": "Missingness Bias Calibration in Feature Attribution Explanations", "url": "https://openreview.net/forum?id=9AbJO130G8", "year": 2026, "is_main_conference": true, "abstract_snippet": "Popular explanation methods often produce unreliable feature importance scores due to \"missingness bias\", a systematic distortion that arises when models are probed with ablated, out-of-distribution inputs.\nExisting solutions treat this as a deep representational flaw that requires expensive retraining or architectural modifications.\nIn this work, we challenge this assumption and show that missingness bias can be effectively treated as a superficial artifact of the model's output space.\nWe introduce MCal, a lightweight post-hoc method that corrects this bias by fine-tuning a simple linear head on the outputs of a frozen base model.\nSurprisingly, we find this simple correction consistently reduces missingness bias and is competitive with, or even outperforms, prior heavyweight approaches across diverse medical benchmarks spanning vision, language, and tabular domains.", "abstract": "Popular explanation methods often produce unreliable feature importance scores due to \"missingness bias\", a systematic distortion that arises when models are probed with ablated, out-of-distribution inputs.\nExisting solutions treat this as a deep representational flaw that requires expensive retraining or architectural modifications.\nIn this work, we challenge this assumption and show that missingness bias can be effectively treated as a superficial artifact of the model's output space.\nWe introduce MCal, a lightweight post-hoc method that corrects this bias by fine-tuning a simple linear head on the outputs of a frozen base model.\nSurprisingly, we find this simple correction consistently reduces missingness bias and is competitive with, or even outperforms, prior heavyweight approaches across diverse medical benchmarks spanning vision, language, and tabular domains.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=9AbJO130G8", "openreview_id": "9AbJO130G8", "openreview_forum_id": "9AbJO130G8", "authors": [], "pdf_url": "https://openreview.net/pdf/a477e5d0544adc8930aaf12e4797ca7b6ad03c2d.pdf", "summary_cn": "本文提出MCal方法，通过微调线性头校正特征归因中的缺失性偏差，无需重新训练模型，在多种医学任务中表现优异。", "keywords": ["缺失性偏差", "特征归因", "后处理校正", "医学机器学习", "模型解释性"], "triple": {"method": "微调线性头进行后处理校正", "result": "有效减少偏差，性能优于或媲美现有方法", "contribution": "提出轻量级方法解决特征归因偏差问题"}}
{"venue": "ICLR", "search_title": "Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation", "full_title": "Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation", "url": "https://openreview.net/forum?id=fmWlDfCFMR", "year": 2026, "is_main_conference": true, "abstract_snippet": "Lightweight 3D medical image segmentation remains constrained by a fundamental \"efficiency / robustness conflict\", particularly when processing complex anatomical structures and heterogeneous modalities. In this paper, we study how to redesign the framework based on the characteristics of high-dimensional 3D images, and explore data synergy to overcome the fragile representation of lightweight methods. Our approach, VeloxSeg, begins with a deployable and extensible dual-stream CNN-Transformer architecture composed of Paired Window Attention (PWA) and Johnson-Lindenstrauss lemma-guided convolution (JLC). For each 3D image, we invoke a \"glance-and-focus\" principle, where PWA rapidly retrieves multi-scale information, and JLC ensures robust local feature extraction with minimal parameters, significantly enhancing the model's ability to operate with low computational budget. Followed by an extension of the dual-stream architecture that incorporates modal interaction into the multi-scale image-retrieval process, VeloxSeg efficiently models heterogeneous modalities. Finally, Spatially Decoupled Knowledge Transfer (SDKT) via Gram matrices injects the texture prior extracted by a self-supervised network into the segmentation network, yielding stronger representations than baselines at no extra inference cost. Experimental results on multimodal benchmarks show that VeloxSeg achieves a 26\\% Dice improvement, alongside increasing GPU throughput by 11x, CPU by 48x, and reducing training peak GPU memory usage by 1/20, inference by 1/24.", "abstract": "Lightweight 3D medical image segmentation remains constrained by a fundamental \"efficiency / robustness conflict\", particularly when processing complex anatomical structures and heterogeneous modalities. In this paper, we study how to redesign the framework based on the characteristics of high-dimensional 3D images, and explore data synergy to overcome the fragile representation of lightweight methods. Our approach, VeloxSeg, begins with a deployable and extensible dual-stream CNN-Transformer architecture composed of Paired Window Attention (PWA) and Johnson-Lindenstrauss lemma-guided convolution (JLC). For each 3D image, we invoke a \"glance-and-focus\" principle, where PWA rapidly retrieves multi-scale information, and JLC ensures robust local feature extraction with minimal parameters, significantly enhancing the model's ability to operate with low computational budget. Followed by an extension of the dual-stream architecture that incorporates modal interaction into the multi-scale image-retrieval process, VeloxSeg efficiently models heterogeneous modalities. Finally, Spatially Decoupled Knowledge Transfer (SDKT) via Gram matrices injects the texture prior extracted by a self-supervised network into the segmentation network, yielding stronger representations than baselines at no extra inference cost. Experimental results on multimodal benchmarks show that VeloxSeg achieves a 26\\% Dice improvement, alongside increasing GPU throughput by 11x, CPU by 48x, and reducing training peak GPU memory usage by 1/20, inference by 1/24.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=fmWlDfCFMR", "openreview_id": "fmWlDfCFMR", "openreview_forum_id": "fmWlDfCFMR", "authors": [], "pdf_url": "https://openreview.net/pdf/f5f3f2eaf8238a7826e2ac164d45dc3f018ba9d9.pdf", "summary_cn": "提出VeloxSeg轻量3D医学分割网络，结合双流CNN-Transformer与知识迁移，在提升分割精度的同时大幅降低计算与内存开销。", "keywords": ["3D医学分割", "轻量网络", "双流架构", "知识迁移", "多模态", "高效推理"], "triple": {"method": "双流CNN-Transformer与知识迁移", "result": "Dice提升26%，推理速度提升11-48倍，内存减少1/20-1/24", "contribution": "解决轻量3D分割的效率与鲁棒性冲突"}}
{"venue": "ICLR", "search_title": "You Point, I Learn: Online Adaptation of Interactive Segmentation Models for Handling Distribution Shifts in Medical Imaging", "full_title": "You Point, I Learn: Online Adaptation of Interactive Segmentation Models for Handling Distribution Shifts in Medical Imaging", "url": "https://openreview.net/forum?id=n0vHjCiLD2", "year": 2026, "is_main_conference": true, "abstract_snippet": "Interactive segmentation uses real-time user inputs, such as mouse clicks, to iteratively refine model predictions. Although not originally designed to address distribution shifts, this paradigm naturally lends itself to such challenges. In medical imaging, where distribution shifts are common, interactive methods can use user inputs to guide models towards improved predictions.\nMoreover, once a model is deployed, user corrections can be used to adapt the network parameters to the new data distribution, mitigating distribution shift. Based on these insights, we aim to develop a practical, effective method for improving the adaptive capabilities of interactive segmentation models to new data distributions in medical imaging.  Firstly, we found that strengthening the model's responsiveness to clicks is important for the initial training process. Moreover, we show that by treating the post-interaction user-refined model output as pseudo-ground-truth, we can design a lean, practical online adaptation method that enables a model to learn effectively across sequential test images. The framework includes two components: (i) a Post-Interaction adaptation process, updating the model after the user has completed interactive refinement of an image, and (ii) a Mid-Interaction adaptation process, updating incrementally after each click. Both processes include a Click-Centered Gaussian loss that strengthens the model's reaction to clicks and enhances focus on user-guided, clinically relevant regions. Experiments on 5 fundus and 4 brain‑MRI databases show that our approach consistently outperforms existing methods under diverse distribution shifts, including unseen imaging modalities and pathologies.\nCode and pretrained models will be released upon publication.", "abstract": "Interactive segmentation uses real-time user inputs, such as mouse clicks, to iteratively refine model predictions. Although not originally designed to address distribution shifts, this paradigm naturally lends itself to such challenges. In medical imaging, where distribution shifts are common, interactive methods can use user inputs to guide models towards improved predictions.\nMoreover, once a model is deployed, user corrections can be used to adapt the network parameters to the new data distribution, mitigating distribution shift. Based on these insights, we aim to develop a practical, effective method for improving the adaptive capabilities of interactive segmentation models to new data distributions in medical imaging.  Firstly, we found that strengthening the model's responsiveness to clicks is important for the initial training process. Moreover, we show that by treating the post-interaction user-refined model output as pseudo-ground-truth, we can design a lean, practical online adaptation method that enables a model to learn effectively across sequential test images. The framework includes two components: (i) a Post-Interaction adaptation process, updating the model after the user has completed interactive refinement of an image, and (ii) a Mid-Interaction adaptation process, updating incrementally after each click. Both processes include a Click-Centered Gaussian loss that strengthens the model's reaction to clicks and enhances focus on user-guided, clinically relevant regions. Experiments on 5 fundus and 4 brain‑MRI databases show that our approach consistently outperforms existing methods under diverse distribution shifts, including unseen imaging modalities and pathologies.\nCode and pretrained models will be released upon publication.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=n0vHjCiLD2", "openreview_id": "n0vHjCiLD2", "openreview_forum_id": "n0vHjCiLD2", "authors": [], "pdf_url": "https://openreview.net/pdf/d108a2a3b541e3ad83fd01d0cd44feb2eebc1f36.pdf", "summary_cn": "提出在线自适应交互式分割方法，利用用户点击修正模型，增强对医学图像分布偏移的适应性，在眼底和脑MRI数据上表现优异。", "keywords": ["交互式分割", "在线自适应", "分布偏移", "医学图像", "用户点击", "高斯损失"], "triple": {"method": "点击中心高斯损失与在线自适应", "result": "在多个数据库上超越现有方法", "contribution": "提升模型对分布偏移的适应性"}}
{"venue": "ICLR", "search_title": "Decentralized Attention Fails Centralized Signals: Rethinking Transformers for Medical Time Series", "full_title": "Decentralized Attention Fails Centralized Signals: Rethinking Transformers for Medical Time Series", "url": "https://openreview.net/forum?id=oZJFY2BQt2", "year": 2026, "is_main_conference": true, "abstract_snippet": "Accurate analysis of Medical time series (MedTS) data, such as Electroencephalography (EEG) and Electrocardiography (ECG), plays a pivotal role in healthcare applications, including the diagnosis of brain and heart diseases. MedTS data typically exhibits two critical patterns: **temporal dependencies** within individual channels and **channel dependencies** across multiple channels. While recent advances in deep learning have leveraged Transformer-based models to effectively capture temporal dependencies, they often struggle to model channel dependencies. This limitation stems from a structural mismatch: ***MedTS signals are inherently centralized, whereas the Transformer's attention is decentralized***, making it less effective at capturing global synchronization and unified waveform patterns. To bridge this gap, we propose **CoTAR** (Core Token Aggregation-Redistribution), a centralized MLP-based module tailored to replace the decentralized attention. Instead of allowing all tokens to interact directly, as in attention, CoTAR introduces a global core token that acts as a proxy to facilitate the inter-token interaction, thereby enforcing a centralized aggregation and redistribution strategy. This design not only better aligns with the centralized nature of MedTS signals but also reduces computational complexity from quadratic to linear. Experiments on five benchmarks validate the superiority of our method in both effectiveness and efficiency, achieving up to a **12.13%** improvement on the APAVA dataset, with merely 33% memory usage and 20% inference time compared to the previous state-of-the-art. Code and all training scripts are available in this [**Link**](https://anonymous.4open.science/r/TeCh-24).", "abstract": "Accurate analysis of Medical time series (MedTS) data, such as Electroencephalography (EEG) and Electrocardiography (ECG), plays a pivotal role in healthcare applications, including the diagnosis of brain and heart diseases. MedTS data typically exhibits two critical patterns: **temporal dependencies** within individual channels and **channel dependencies** across multiple channels. While recent advances in deep learning have leveraged Transformer-based models to effectively capture temporal dependencies, they often struggle to model channel dependencies. This limitation stems from a structural mismatch: ***MedTS signals are inherently centralized, whereas the Transformer's attention is decentralized***, making it less effective at capturing global synchronization and unified waveform patterns. To bridge this gap, we propose **CoTAR** (Core Token Aggregation-Redistribution), a centralized MLP-based module tailored to replace the decentralized attention. Instead of allowing all tokens to interact directly, as in attention, CoTAR introduces a global core token that acts as a proxy to facilitate the inter-token interaction, thereby enforcing a centralized aggregation and redistribution strategy. This design not only better aligns with the centralized nature of MedTS signals but also reduces computational complexity from quadratic to linear. Experiments on five benchmarks validate the superiority of our method in both effectiveness and efficiency, achieving up to a **12.13%** improvement on the APAVA dataset, with merely 33% memory usage and 20% inference time compared to the previous state-of-the-art. Code and all training scripts are available in this [**Link**](https://anonymous.4open.science/r/TeCh-24).", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=oZJFY2BQt2", "openreview_id": "oZJFY2BQt2", "openreview_forum_id": "oZJFY2BQt2", "authors": [], "pdf_url": "https://openreview.net/pdf/80970c2cd39d934142d21e9e2f6390b98de793b1.pdf", "summary_cn": "针对医疗时间序列信号集中化特点，提出CoTAR模块替代Transformer分散注意力，通过核心令牌聚合再分配策略，提升性能并降低计算复杂度。", "keywords": ["医疗时间序列", "Transformer", "注意力机制", "CoTAR", "计算效率", "信号处理"], "triple": {"method": "CoTAR模块（核心令牌聚合再分配）", "result": "性能提升12.13%，内存和推理时间大幅减少", "contribution": "提出集中化方法更好匹配医疗信号特性"}}
{"venue": "ICLR", "search_title": "K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical Image Segmentation Model", "full_title": "K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical Image Segmentation Model", "url": "https://openreview.net/forum?id=gvRf95K4im", "year": 2026, "is_main_conference": true, "abstract_snippet": "Medical image segmentation is fundamental to clinical decision-making, yet existing models remain fragmented. They are usually trained on single knowledge sources and specific to individual tasks, modalities, or organs. This fragmentation contrasts sharply with clinical practice, where experts seamlessly integrate diverse knowledge: anatomical priors from training, exemplar-based reasoning from reference cases, and iterative refinement through real-time interaction. We present $\\textbf{K-Prism}$, a unified segmentation framework that mirrors this clinical flexibility by systematically integrating three knowledge paradigms: (i) $\\textit{semantic priors}$ learned from annotated datasets, (ii) $\\textit{in-context knowledge}$ from few-shot reference examples, and (iii) $\\textit{interactive feedback}$ from user inputs like clicks or scribbles. Our key insight is that these heterogeneous knowledge sources can be encoded into a dual-prompt representation: 1-D sparse prompts defining $\\textit{what}$ to segment and 2-D dense prompts indicating $\\textit{where}$ to attend, which are then dynamically routed through a Mixture-of-Experts (MoE) decoder. This design enables flexible switching between paradigms and joint training across diverse tasks without architectural modifications. Comprehensive experiments on 18 public datasets spanning diverse modalities (CT, MRI, X-ray, pathology, ultrasound, etc.) demonstrate that K-Prism achieves state-of-the-art performance across semantic, in-context, and interactive segmentation settings. Code will be released upon publication.", "abstract": "Medical image segmentation is fundamental to clinical decision-making, yet existing models remain fragmented. They are usually trained on single knowledge sources and specific to individual tasks, modalities, or organs. This fragmentation contrasts sharply with clinical practice, where experts seamlessly integrate diverse knowledge: anatomical priors from training, exemplar-based reasoning from reference cases, and iterative refinement through real-time interaction. We present $\\textbf{K-Prism}$, a unified segmentation framework that mirrors this clinical flexibility by systematically integrating three knowledge paradigms: (i) $\\textit{semantic priors}$ learned from annotated datasets, (ii) $\\textit{in-context knowledge}$ from few-shot reference examples, and (iii) $\\textit{interactive feedback}$ from user inputs like clicks or scribbles. Our key insight is that these heterogeneous knowledge sources can be encoded into a dual-prompt representation: 1-D sparse prompts defining $\\textit{what}$ to segment and 2-D dense prompts indicating $\\textit{where}$ to attend, which are then dynamically routed through a Mixture-of-Experts (MoE) decoder. This design enables flexible switching between paradigms and joint training across diverse tasks without architectural modifications. Comprehensive experiments on 18 public datasets spanning diverse modalities (CT, MRI, X-ray, pathology, ultrasound, etc.) demonstrate that K-Prism achieves state-of-the-art performance across semantic, in-context, and interactive segmentation settings. Code will be released upon publication.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=gvRf95K4im", "openreview_id": "gvRf95K4im", "openreview_forum_id": "gvRf95K4im", "authors": [], "pdf_url": "https://openreview.net/pdf/1b0797940c7421dd109dfb45d43517b8b17ca647.pdf", "summary_cn": "K-Prism提出统一医学图像分割框架，集成语义先验、上下文知识与交互反馈，通过双提示与MoE解码器实现多任务SOTA性能。", "keywords": ["医学图像分割", "知识引导", "提示集成", "混合专家", "多模态", "统一框架"], "triple": {"method": "双提示表示与MoE解码器", "result": "在18个数据集上实现SOTA", "contribution": "提出统一分割框架K-Prism"}}
{"venue": "ICLR", "search_title": "Modeling the Density of Pixel-level Self-supervised Embeddings for Unsupervised Pathology Segmentation in Medical CT", "full_title": "Modeling the Density of Pixel-level Self-supervised Embeddings for Unsupervised Pathology Segmentation in Medical CT", "url": "https://openreview.net/forum?id=i7YnUW0uWg", "year": 2026, "is_main_conference": true, "abstract_snippet": "Accurate detection of all pathological findings in 3D medical images remains a significant challenge, as supervised models are limited to detecting only the few pathology classes annotated in existing datasets. To address this, we frame pathology detection as an unsupervised visual anomaly segmentation (UVAS) problem, leveraging the inherent rarity of pathological patterns compared to healthy ones. We enhance the existing density-based UVAS framework with two key innovations: (1) dense self-supervised learning for feature extraction, eliminating the need for supervised pretraining, and (2) learned, masking-invariant dense features as conditioning variables, replacing hand-crafted positional encodings. Trained on over 30,000 unlabeled 3D CT volumes, our fully self-supervised model, Screener, outperforms existing UVAS methods on four large-scale test datasets comprising 1,820 scans with diverse pathologies. Furthermore, in a low-shot supervised fine-tuning setting, Screener surpasses existing self-supervised pretraining methods, establishing it as a state-of-the-art foundation for pathology segmentation. The code and pretrained models will be made publicly available.", "abstract": "Accurate detection of all pathological findings in 3D medical images remains a significant challenge, as supervised models are limited to detecting only the few pathology classes annotated in existing datasets. To address this, we frame pathology detection as an unsupervised visual anomaly segmentation (UVAS) problem, leveraging the inherent rarity of pathological patterns compared to healthy ones. We enhance the existing density-based UVAS framework with two key innovations: (1) dense self-supervised learning for feature extraction, eliminating the need for supervised pretraining, and (2) learned, masking-invariant dense features as conditioning variables, replacing hand-crafted positional encodings. Trained on over 30,000 unlabeled 3D CT volumes, our fully self-supervised model, Screener, outperforms existing UVAS methods on four large-scale test datasets comprising 1,820 scans with diverse pathologies. Furthermore, in a low-shot supervised fine-tuning setting, Screener surpasses existing self-supervised pretraining methods, establishing it as a state-of-the-art foundation for pathology segmentation. The code and pretrained models will be made publicly available.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=i7YnUW0uWg", "openreview_id": "i7YnUW0uWg", "openreview_forum_id": "i7YnUW0uWg", "authors": [], "pdf_url": "https://openreview.net/pdf/c5674969451511c7c5004fb3f5d4ca4b0a0095a5.pdf", "summary_cn": "提出Screener模型，通过密集自监督学习和掩码不变特征，实现医学CT图像的无监督病理分割，在多个数据集上超越现有方法。", "keywords": ["无监督病理分割", "自监督学习", "CT图像", "异常检测", "密集特征", "掩码不变性"], "triple": {"method": "密集自监督学习与掩码不变特征", "result": "在四个大规模测试集上超越现有UVAS方法", "contribution": "提供无需监督预训练的高性能病理分割基础模型"}}
{"venue": "ICLR", "search_title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity", "full_title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity", "url": "https://openreview.net/forum?id=sWWAZVHtke", "year": 2026, "is_main_conference": true, "abstract_snippet": "Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.", "abstract": "Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=sWWAZVHtke", "openreview_id": "sWWAZVHtke", "openreview_forum_id": "sWWAZVHtke", "authors": [], "pdf_url": "https://openreview.net/pdf/3d21fa2c3d308d779a5848e66683dd42df646ead.pdf", "summary_cn": "本研究提出一种临床基础方法，通过合成电子病历和多智能体对话生成，构建首个大规模精神病共病诊断对话数据集，提升诊断准确性和治疗规划。", "keywords": ["精神病共病", "诊断对话", "电子病历合成", "多智能体框架", "临床验证", "数据集构建"], "triple": {"method": "合成电子病历与多智能体对话生成", "result": "构建包含3000个对话的数据集，经精神科医生验证具有高保真度", "contribution": "提供首个支持共病研究的大规模诊断对话资源"}}
{"venue": "ICLR", "search_title": "Moving Beyond Medical Exams: A Clinician-Annotated Fairness Dataset of Real-World Tasks and Ambiguity in Mental Healthcare", "full_title": "Moving Beyond Medical Exams: A Clinician-Annotated Fairness Dataset of Real-World Tasks and Ambiguity in Mental Healthcare", "url": "https://openreview.net/forum?id=tSy7OtONsg", "year": 2026, "is_main_conference": true, "abstract_snippet": "Current medical language model (LM) benchmarks often over-simplify the complexities of day-to-day clinical practice tasks and instead rely on evaluating LMs on multiple-choice board exam questions. \nIn psychiatry especially, these challenges are worsened by fairness and bias issues, since models can be swayed by patient demographics even when those factors should not influence clinical decisions. \nThus, we present an expert-created and annotated dataset spanning five critical domains of decision-making in mental healthcare: treatment, diagnosis, documentation, monitoring, and triage. \nThis U.S. centric dataset — created without any LM assistance — is designed to capture the nuanced clinical reasoning and daily ambiguities mental health practitioners encounter, reflecting the inherent complexities of care delivery that are missing from existing datasets. \nAlmost all base questions with five answer options each have had the decision-irrelevant demographic patient information removed and replaced with variables, e.g., for age or ethnicity, and are available for male, female, or non-binary-coded patients. \nThis design enables systematic evaluations of model performance and bias by studying how demographic factors affect decision-making. \nFor question categories dealing with ambiguity and multiple valid answer options, we create a preference dataset with uncertainties from the expert annotations.\nWe outline a series of intended use cases and demonstrate the usability of our dataset by evaluating sixteen off-the-shelf\nand six (mental) health fine-tuned LMs on category-specific task accuracy, on the fairness impact of patient demographic information on decision-making, and how consistently free-form responses deviate from human-annotated samples.", "abstract": "Current medical language model (LM) benchmarks often over-simplify the complexities of day-to-day clinical practice tasks and instead rely on evaluating LMs on multiple-choice board exam questions. \nIn psychiatry especially, these challenges are worsened by fairness and bias issues, since models can be swayed by patient demographics even when those factors should not influence clinical decisions. \nThus, we present an expert-created and annotated dataset spanning five critical domains of decision-making in mental healthcare: treatment, diagnosis, documentation, monitoring, and triage. \nThis U.S. centric dataset — created without any LM assistance — is designed to capture the nuanced clinical reasoning and daily ambiguities mental health practitioners encounter, reflecting the inherent complexities of care delivery that are missing from existing datasets. \nAlmost all base questions with five answer options each have had the decision-irrelevant demographic patient information removed and replaced with variables, e.g., for age or ethnicity, and are available for male, female, or non-binary-coded patients. \nThis design enables systematic evaluations of model performance and bias by studying how demographic factors affect decision-making. \nFor question categories dealing with ambiguity and multiple valid answer options, we create a preference dataset with uncertainties from the expert annotations.\nWe outline a series of intended use cases and demonstrate the usability of our dataset by evaluating sixteen off-the-shelf\nand six (mental) health fine-tuned LMs on category-specific task accuracy, on the fairness impact of patient demographic information on decision-making, and how consistently free-form responses deviate from human-annotated samples.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=tSy7OtONsg", "openreview_id": "tSy7OtONsg", "openreview_forum_id": "tSy7OtONsg", "authors": [], "pdf_url": "https://openreview.net/pdf/e748f56b1764bf478a530593b94f9db7d8cc793b.pdf", "summary_cn": "研究创建了一个专家标注的心理健康临床决策数据集，涵盖治疗、诊断等五个领域，用于评估语言模型的公平性和临床推理能力。", "keywords": ["心理健康", "临床决策", "公平性评估", "语言模型", "专家标注", "数据集"], "triple": {"method": "创建专家标注数据集，移除无关人口信息并引入变量", "result": "评估了16个现成和6个微调语言模型在任务准确性、公平性和一致性方面的表现", "contribution": "填补现有数据集空白，支持系统化评估模型公平性和临床复杂性"}}
{"venue": "ICLR", "search_title": "MedLesionVQA: A Multimodal Benchmark Emulating Clinical Visual Diagnosis for Body Surface Health", "full_title": "MedLesionVQA: A Multimodal Benchmark Emulating Clinical Visual Diagnosis for Body Surface Health", "url": "https://openreview.net/forum?id=BYtqk6AVuL", "year": 2026, "is_main_conference": true, "abstract_snippet": "Body-surface health conditions, spanning diverse clinical departments, represent some of the most frequent diagnostic scenarios and a primary target for medical multimodal large language models (MLLMs). \nYet existing medical benchmarks are either built from publicly available sources with limited expert curation or focus narrowly on disease classification, failing to reflect the stepwise recognition and reasoning processes physicians follow in real practice. \nTo address this gap, we introduce MedLesionVQA, the first benchmark explicitly designed to evaluate MLLMs on the visual diagnostic workflow for body-surface conditions in large scale. \nAll questions are derived from authentic clinical visual diagnosis scenarios and verified by medical experts with over 20 years of experience, while the data are drawn from 10k+ real patient visits, ensuring authenticity, clinical reality and diversity.\nMedLesionVQA consists of 12K in-house volunteer images (never publicly leaked) and 19K expert-verified question–answer pairs, with fine-grained annotations of 94 lesion types, 110 body regions, and 96 diseases. \nWe evaluate 20+ state-of-the-art MLLMs against human physicians: the best model reaches 56.2% accuracy, far below primary physicians (61.4%) and senior specialists (73.2%). These results expose the persistent gap between MLLMs and clinical expertise, underscoring the need for the multimodal benchmarks to drive trustworthy medical AI.", "abstract": "Body-surface health conditions, spanning diverse clinical departments, represent some of the most frequent diagnostic scenarios and a primary target for medical multimodal large language models (MLLMs). \nYet existing medical benchmarks are either built from publicly available sources with limited expert curation or focus narrowly on disease classification, failing to reflect the stepwise recognition and reasoning processes physicians follow in real practice. \nTo address this gap, we introduce MedLesionVQA, the first benchmark explicitly designed to evaluate MLLMs on the visual diagnostic workflow for body-surface conditions in large scale. \nAll questions are derived from authentic clinical visual diagnosis scenarios and verified by medical experts with over 20 years of experience, while the data are drawn from 10k+ real patient visits, ensuring authenticity, clinical reality and diversity.\nMedLesionVQA consists of 12K in-house volunteer images (never publicly leaked) and 19K expert-verified question–answer pairs, with fine-grained annotations of 94 lesion types, 110 body regions, and 96 diseases. \nWe evaluate 20+ state-of-the-art MLLMs against human physicians: the best model reaches 56.2% accuracy, far below primary physicians (61.4%) and senior specialists (73.2%). These results expose the persistent gap between MLLMs and clinical expertise, underscoring the need for the multimodal benchmarks to drive trustworthy medical AI.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=BYtqk6AVuL", "openreview_id": "BYtqk6AVuL", "openreview_forum_id": "BYtqk6AVuL", "authors": [], "pdf_url": "https://openreview.net/pdf/fa117d1fb4924f46fb476831b350ea1121a71f7f.pdf", "summary_cn": "MedLesionVQA是首个模拟体表健康临床视觉诊断流程的大规模多模态基准，包含真实患者图像与专家验证问答，评估显示当前MLLMs性能仍显著低于医生水平。", "keywords": ["多模态大语言模型", "临床视觉诊断", "体表健康", "医学基准", "专家验证", "性能评估"], "triple": {"method": "构建基于真实临床数据与专家验证的多模态基准", "result": "最佳模型准确率56.2%，低于初级医生(61.4%)和资深专家(73.2%)", "contribution": "填补临床诊断流程评估空白，推动可信医疗AI发展"}}
{"venue": "ICLR", "search_title": "U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding", "full_title": "U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding", "url": "https://openreview.net/forum?id=jU10qDevGg", "year": 2026, "is_main_conference": true, "abstract_snippet": "Ultrasound is a widely-used imaging modality critical to global healthcare, yet its interpretation remains challenging due to its varying image quality on operators, noises, and anatomical structures. Although large vision-language models (LVLMs) have demonstrated impressive multimodal capabilities across natural and medical domains, their performance on ultrasound remains largely unexplored. We introduce U2-BENCH, the first comprehensive benchmark to evaluate LVLMs on ultrasound understanding across classification, detection, regression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning 15 anatomical regions and defines 8 clinically inspired tasks, such as diagnosis, view recognition, lesion localization, clinical value estimation, and report generation, across 50 ultrasound application scenarios. We evaluate 23 state-of-the-art LVLMs, both open- and closed-source, general-purpose and medical-specific. Our results reveal strong performance on image-level classification, but persistent challenges in spatial reasoning and clinical language generation. U2-BENCH establishes a rigorous and unified testbed to assess and accelerate LVLM research in the uniquely multimodal domain of medical ultrasound imaging.", "abstract": "Ultrasound is a widely-used imaging modality critical to global healthcare, yet its interpretation remains challenging due to its varying image quality on operators, noises, and anatomical structures. Although large vision-language models (LVLMs) have demonstrated impressive multimodal capabilities across natural and medical domains, their performance on ultrasound remains largely unexplored. We introduce U2-BENCH, the first comprehensive benchmark to evaluate LVLMs on ultrasound understanding across classification, detection, regression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning 15 anatomical regions and defines 8 clinically inspired tasks, such as diagnosis, view recognition, lesion localization, clinical value estimation, and report generation, across 50 ultrasound application scenarios. We evaluate 23 state-of-the-art LVLMs, both open- and closed-source, general-purpose and medical-specific. Our results reveal strong performance on image-level classification, but persistent challenges in spatial reasoning and clinical language generation. U2-BENCH establishes a rigorous and unified testbed to assess and accelerate LVLM research in the uniquely multimodal domain of medical ultrasound imaging.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=jU10qDevGg", "openreview_id": "jU10qDevGg", "openreview_forum_id": "jU10qDevGg", "authors": [], "pdf_url": "https://openreview.net/pdf/1698db9b292ef3704023c3319a6ece1246485d4b.pdf", "summary_cn": "U2-BENCH是首个评估大型视觉语言模型在超声理解上的综合基准，涵盖多任务与解剖区域，揭示模型在空间推理和临床语言生成方面的挑战。", "keywords": ["超声理解", "大型视觉语言模型", "基准测试", "多模态", "医学影像", "临床任务"], "triple": {"method": "构建U2-BENCH基准，包含7241个案例和8个临床任务", "result": "模型在图像分类表现强，但空间推理和语言生成仍存挑战", "contribution": "为超声领域提供首个统一评估框架，推动LVLM研究"}}
{"venue": "ICLR", "search_title": "KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning", "full_title": "KnowGuard: Knowledge-Driven Abstention for Multi-Round Clinical Reasoning", "url": "https://openreview.net/forum?id=gQRefH8upx", "year": 2026, "is_main_conference": true, "abstract_snippet": "In clinical practice, physicians refrain from making decisions when patient information is insufficient. This behavior, known as abstention, is a critical safety mechanism preventing potentially harmful misdiagnoses. Recent investigations have reported the application of large language models (LLMs) in medical scenarios. However, existing LLMs struggle with the abstentions, frequently providing overconfident responses despite incomplete information. This limitation stems from conventional abstention methods relying solely on model self-assessments, which lack systematic strategies to identify knowledge boundaries with external medical evidences. To address this, we propose \\textbf{KnowGuard}, a novel \\textit{investigate-before-abstain} paradigm that integrates systematic knowledge graph exploration for clinical decision-making. Our approach consists of two key stages operating on a shared contextualized evidence pool: 1) an evidence discovery stage that systematically explores the medical knowledge space through graph expansion and direct retrieval, and 2) an evidence evaluation stage that ranks evidence using multiple factors to adapt exploration based on patient context and conversation history. This two-stage approach enables systematic knowledge graph exploration, allowing models to trace structured reasoning paths and recognize insufficient medical evidence. We evaluate our abstention approach using open-ended multi-round clinical benchmarks that mimic realistic diagnostic scenarios, assessing abstention quality through accuracy-efficiency trade-offs beyond existing closed-form evaluations. Experimental evidence clearly demonstrates that KnowGuard outperforms state-of-the-art abstention approaches, improving diagnostic accuracy by 3.93\\% through effective diagnostic interactions averaging 5.74 conversation turns.", "abstract": "In clinical practice, physicians refrain from making decisions when patient information is insufficient. This behavior, known as abstention, is a critical safety mechanism preventing potentially harmful misdiagnoses. Recent investigations have reported the application of large language models (LLMs) in medical scenarios. However, existing LLMs struggle with the abstentions, frequently providing overconfident responses despite incomplete information. This limitation stems from conventional abstention methods relying solely on model self-assessments, which lack systematic strategies to identify knowledge boundaries with external medical evidences. To address this, we propose \\textbf{KnowGuard}, a novel \\textit{investigate-before-abstain} paradigm that integrates systematic knowledge graph exploration for clinical decision-making. Our approach consists of two key stages operating on a shared contextualized evidence pool: 1) an evidence discovery stage that systematically explores the medical knowledge space through graph expansion and direct retrieval, and 2) an evidence evaluation stage that ranks evidence using multiple factors to adapt exploration based on patient context and conversation history. This two-stage approach enables systematic knowledge graph exploration, allowing models to trace structured reasoning paths and recognize insufficient medical evidence. We evaluate our abstention approach using open-ended multi-round clinical benchmarks that mimic realistic diagnostic scenarios, assessing abstention quality through accuracy-efficiency trade-offs beyond existing closed-form evaluations. Experimental evidence clearly demonstrates that KnowGuard outperforms state-of-the-art abstention approaches, improving diagnostic accuracy by 3.93\\% through effective diagnostic interactions averaging 5.74 conversation turns.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=gQRefH8upx", "openreview_id": "gQRefH8upx", "openreview_forum_id": "gQRefH8upx", "authors": [], "pdf_url": "https://openreview.net/pdf/c3900b8d95d625edf60a2e0b400cb766bc55edc3.pdf", "summary_cn": "KnowGuard提出知识驱动的临床推理弃权机制，通过两阶段知识图谱探索，提升大语言模型在信息不足时的诊断准确性与安全性。", "keywords": ["临床推理", "知识图谱", "弃权机制", "大语言模型", "多轮对话", "诊断准确性"], "triple": {"method": "两阶段知识图谱探索（证据发现与评估）", "result": "诊断准确率提升3.93%，平均5.74轮对话", "contribution": "提出知识驱动的临床弃权新范式"}}
{"venue": "ICLR", "search_title": "Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning", "full_title": "Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning", "url": "https://openreview.net/forum?id=vQGHTyL0Jw", "year": 2026, "is_main_conference": true, "abstract_snippet": "The professionalism of a human doctor in outpatient service depends on two core abilities: the ability to make accurate medical decisions and the medical consultation skill to conduct strategic, empathetic patient inquiry. Existing Large Language Models (LLMs) have achieved remarkable accuracy on medical decision-making benchmarks. However, they often lack the ability to conduct the strategic and empathetic consultation, which is essential for real-world clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor agent trained to master both of the capabilities by ask high-yield questions and conduct strategic multi-turn inquiry to guide decision-making. Our framework introduces three key components: a multi-agent interactive environment, a two-tiered reward architecture that separately optimizes clinical decision-making and communicative inquiry skills, and an experience repository to ground policy learning in high-quality prior trajectories. We evaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across multi-facet metrics, such as communication quality, user experience, and task accuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source specialized LLMs by a substantial margin with higher parameter efficiency and outperforms powerful proprietary models. Furthermore, the human evaluations show a strong preference for Doctor-R1 to generate human-preferred clinical dialogue, demonstrating the effectiveness of the framework.", "abstract": "The professionalism of a human doctor in outpatient service depends on two core abilities: the ability to make accurate medical decisions and the medical consultation skill to conduct strategic, empathetic patient inquiry. Existing Large Language Models (LLMs) have achieved remarkable accuracy on medical decision-making benchmarks. However, they often lack the ability to conduct the strategic and empathetic consultation, which is essential for real-world clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor agent trained to master both of the capabilities by ask high-yield questions and conduct strategic multi-turn inquiry to guide decision-making. Our framework introduces three key components: a multi-agent interactive environment, a two-tiered reward architecture that separately optimizes clinical decision-making and communicative inquiry skills, and an experience repository to ground policy learning in high-quality prior trajectories. We evaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across multi-facet metrics, such as communication quality, user experience, and task accuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source specialized LLMs by a substantial margin with higher parameter efficiency and outperforms powerful proprietary models. Furthermore, the human evaluations show a strong preference for Doctor-R1 to generate human-preferred clinical dialogue, demonstrating the effectiveness of the framework.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=vQGHTyL0Jw", "openreview_id": "vQGHTyL0Jw", "openreview_forum_id": "vQGHTyL0Jw", "authors": [], "pdf_url": "https://openreview.net/pdf/b32af93cfd4fe18618df90adfb090dc5332b550a.pdf", "summary_cn": "Doctor-R1通过多智能体交互环境和双层奖励架构，结合经验库，在临床决策与沟通问诊上超越现有模型，生成更受人类偏好的对话。", "keywords": ["Doctor-R1", "临床问诊", "强化学习", "多智能体交互", "双层奖励", "经验库"], "triple": {"method": "多智能体交互环境与双层奖励强化学习", "result": "在HealthBench和MAQuE上超越开源与专有模型，生成人类偏好对话", "contribution": "提升AI医生在战略共情问诊与决策的综合性能力"}}
{"venue": "ICLR", "search_title": "AbdCTBench: Learning Clinical Biomarker Representations from Abdominal Surface Geometry", "full_title": "AbdCTBench: Learning Clinical Biomarker Representations from Abdominal Surface Geometry", "url": "https://openreview.net/forum?id=dKRAo0a9Gm", "year": 2026, "is_main_conference": true, "abstract_snippet": "Body composition analysis through CT and MRI imaging provides critical insights for cardio-metabolic health assessment but remains limited by accessibility barriers including radiation exposure, high costs, and infrastructure requirements. We present AbdCTBench, a large-scale dataset containing 23,506 CT-derived abdominal surface meshes from 18,719 patients, paired with 87 comorbidity labels, 31 specific diagnosis codes, and 16 CT-derived biomarkers. Our key insight is that external surface geometry is predictive of internal tissue composition, enabling accessible health screening through consumer devices. We establish comprehensive benchmarks across seven computer vision architectures (ResNet-18/34/50, DenseNet-121, EfficientNet-B0, ViT-Small, Swin Transformer-Base), demonstrating that models can learn robust surface-to-biomarker representations directly from 2D mesh projections. Our best-performing models achieve clinically relevant accuracy: age prediction with MAE 6.22 years (R²=0.757), mortality prediction with AUROC 0.839, and diabetes (with chronic complications) detection with AUROC 0.801. Notably, smaller architectures consistently matched or surpassed larger models, while medical-domain pre-training (RadImageNet) and self-supervised pre-training (DINOv2) showed competitive but not superior performance. AbdCTBench represents the largest publicly available dataset bridging external body geometry with internal clinical measurements, enabling future research in accessible medical AI. We plan to release the dataset, evaluation protocols, and baseline models to accelerate research in representation learning for medical applications, immediately following the review period.", "abstract": "Body composition analysis through CT and MRI imaging provides critical insights for cardio-metabolic health assessment but remains limited by accessibility barriers including radiation exposure, high costs, and infrastructure requirements. We present AbdCTBench, a large-scale dataset containing 23,506 CT-derived abdominal surface meshes from 18,719 patients, paired with 87 comorbidity labels, 31 specific diagnosis codes, and 16 CT-derived biomarkers. Our key insight is that external surface geometry is predictive of internal tissue composition, enabling accessible health screening through consumer devices. We establish comprehensive benchmarks across seven computer vision architectures (ResNet-18/34/50, DenseNet-121, EfficientNet-B0, ViT-Small, Swin Transformer-Base), demonstrating that models can learn robust surface-to-biomarker representations directly from 2D mesh projections. Our best-performing models achieve clinically relevant accuracy: age prediction with MAE 6.22 years (R²=0.757), mortality prediction with AUROC 0.839, and diabetes (with chronic complications) detection with AUROC 0.801. Notably, smaller architectures consistently matched or surpassed larger models, while medical-domain pre-training (RadImageNet) and self-supervised pre-training (DINOv2) showed competitive but not superior performance. AbdCTBench represents the largest publicly available dataset bridging external body geometry with internal clinical measurements, enabling future research in accessible medical AI. We plan to release the dataset, evaluation protocols, and baseline models to accelerate research in representation learning for medical applications, immediately following the review period.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=dKRAo0a9Gm", "openreview_id": "dKRAo0a9Gm", "openreview_forum_id": "dKRAo0a9Gm", "authors": [], "pdf_url": "https://openreview.net/pdf/69dbc4906a996120b5a52367af59d2c9d358f815.pdf", "summary_cn": "AbdCTBench数据集包含23,506个腹部表面网格，用于从几何预测临床生物标志物。七种视觉模型在年龄、死亡率和糖尿病预测上达到临床相关精度，小模型表现优异。", "keywords": ["腹部表面几何", "临床生物标志物", "计算机视觉", "健康筛查", "数据集", "表示学习"], "triple": {"method": "使用2D网格投影和七种视觉架构学习表面到生物标志物表示", "result": "年龄预测MAE 6.22年，死亡率AUROC 0.839，糖尿病检测AUROC 0.801", "contribution": "提供最大公开数据集，连接外部几何与内部测量，促进可访问医疗AI研究"}}
{"venue": "ICLR", "search_title": "Photon: Speedup Volume Understanding with Efficient Multimodal Large Language Models", "full_title": "Photon: Speedup Volume Understanding with Efficient Multimodal Large Language Models", "url": "https://openreview.net/forum?id=xsSJw6jJBL", "year": 2026, "is_main_conference": true, "abstract_snippet": "Multimodal large language models are promising for clinical visual question answering tasks, but scaling to 3D imaging is hindered by high computational costs. Prior methods often rely on 2D slices or fixed-length token compression, disrupting volumetric continuity and obscuring subtle findings. We present Photon, a framework that represents 3D medical volumes with token sequences of variable length.  Photon introduces instruction-conditioned token scheduling and surrogate gradient propagation to adaptively reduce tokens during both training and inference, which lowers computational cost while mitigating the attention dilution caused by redundant tokens. It incorporates a custom backpropagation rule with gradient restoration to enable differentiable optimization despite discrete token drop. To stabilize token compression and ensure reliable use of visual evidence, Photon further applies regularization objectives that mitigate language-only bias and improve reliability. Experiments on diverse medical visual question answering tasks show that Photon achieves state-of-the-art accuracy while reducing resource usage and accelerating both training and inference.", "abstract": "Multimodal large language models are promising for clinical visual question answering tasks, but scaling to 3D imaging is hindered by high computational costs. Prior methods often rely on 2D slices or fixed-length token compression, disrupting volumetric continuity and obscuring subtle findings. We present Photon, a framework that represents 3D medical volumes with token sequences of variable length.  Photon introduces instruction-conditioned token scheduling and surrogate gradient propagation to adaptively reduce tokens during both training and inference, which lowers computational cost while mitigating the attention dilution caused by redundant tokens. It incorporates a custom backpropagation rule with gradient restoration to enable differentiable optimization despite discrete token drop. To stabilize token compression and ensure reliable use of visual evidence, Photon further applies regularization objectives that mitigate language-only bias and improve reliability. Experiments on diverse medical visual question answering tasks show that Photon achieves state-of-the-art accuracy while reducing resource usage and accelerating both training and inference.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=xsSJw6jJBL", "openreview_id": "xsSJw6jJBL", "openreview_forum_id": "xsSJw6jJBL", "authors": [], "pdf_url": "https://openreview.net/pdf/855cc8440056500cb6fb01abe0738c9662188062.pdf", "summary_cn": "Photon框架通过可变长度令牌序列和自适应令牌调度，高效处理3D医学影像，降低计算成本并保持体积连续性，在医学视觉问答任务中实现高精度与资源节省。", "keywords": ["3D医学影像", "多模态大语言模型", "令牌压缩", "自适应调度", "视觉问答", "计算效率"], "triple": {"method": "可变长度令牌序列与自适应令牌调度", "result": "降低计算成本，加速训练推理，保持高精度", "contribution": "提出高效3D医学影像理解框架，提升多模态模型可扩展性"}}
{"venue": "ICLR", "search_title": "LiveClin: A Live Clinical Benchmark without Leakage", "full_title": "LiveClin: A Live Clinical Benchmark without Leakage", "url": "https://openreview.net/forum?id=E0WSAugJ0j", "year": 2026, "is_main_conference": true, "abstract_snippet": "The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for the faithful replication of clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. We find that the era of \"free lunch\" improvements from simple model scaling is over, as newer models do not consistently outperform their predecessors. Furthermore, our analysis uncovers distinct reasoning weaknesses across model classes. LiveClin thus provides a continuously evolving, clinically-grounded framework to steer the development of medical LLMs towards greater reliability and real-world utility.", "abstract": "The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for the faithful replication of clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. We find that the era of \"free lunch\" improvements from simple model scaling is over, as newer models do not consistently outperform their predecessors. Furthermore, our analysis uncovers distinct reasoning weaknesses across model classes. LiveClin thus provides a continuously evolving, clinically-grounded framework to steer the development of medical LLMs towards greater reliability and real-world utility.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=E0WSAugJ0j", "openreview_id": "E0WSAugJ0j", "openreview_forum_id": "E0WSAugJ0j", "authors": [], "pdf_url": "https://openreview.net/pdf/6847a1d5164668634b9180636389b5edd155ac03.pdf", "summary_cn": "LiveClin是一个动态更新的临床基准，基于真实病例构建，用于评估医学大语言模型。评估显示模型在复杂临床场景中表现不佳，准确率仅35.7%，揭示了模型扩展的局限性。", "keywords": ["医学大语言模型", "临床基准", "数据污染", "动态评估", "病例报告", "模型性能"], "triple": {"method": "基于真实病例构建动态多模态基准", "result": "顶级模型准确率仅35.7%，新模型未持续超越旧模型", "contribution": "提供持续演进的临床评估框架"}}
{"venue": "ICLR", "search_title": "VLM-SubtleBench: How Far Are VLMs from Human-Level Subtle Comparative Reasoning?", "full_title": "VLM-SubtleBench: How Far Are VLMs from Human-Level Subtle Comparative Reasoning?", "url": "https://openreview.net/forum?id=pBTXsu1i77", "year": 2026, "is_main_conference": true, "abstract_snippet": "The ability to distinguish subtle differences between visually similar images is essential for diverse domains such as industrial anomaly detection, medical imaging, and aerial surveillance. While comparative reasoning benchmarks for vision-language models (VLMs) have recently emerged, they primarily focus on images with large, salient differences and fail to capture the nuanced reasoning required for real-world applications. In this work, we introduce **VLM-SubtleBench**, a benchmark designed to evaluate VLMs on *subtle comparative reasoning*. Our benchmark covers ten difference types—Attribute, State, Emotion, Temporal, Spatial, Existence, Quantity, Quality, Viewpoint, and Action—and curate paired question–image sets reflecting these fine-grained variations. Unlike prior benchmarks restricted to natural image datasets, our benchmark spans diverse domains, including industrial, aerial, and medical imagery. Through extensive evaluation of both proprietary and open-source VLMs, we reveal systematic gaps between model and human performance across difference types and domains, and provide controlled analyses highlighting where VLMs’ reasoning sharply deteriorates. Together, our benchmark and findings establish a foundation for advancing VLMs toward human-level comparative reasoning.", "abstract": "The ability to distinguish subtle differences between visually similar images is essential for diverse domains such as industrial anomaly detection, medical imaging, and aerial surveillance. While comparative reasoning benchmarks for vision-language models (VLMs) have recently emerged, they primarily focus on images with large, salient differences and fail to capture the nuanced reasoning required for real-world applications. In this work, we introduce **VLM-SubtleBench**, a benchmark designed to evaluate VLMs on *subtle comparative reasoning*. Our benchmark covers ten difference types—Attribute, State, Emotion, Temporal, Spatial, Existence, Quantity, Quality, Viewpoint, and Action—and curate paired question–image sets reflecting these fine-grained variations. Unlike prior benchmarks restricted to natural image datasets, our benchmark spans diverse domains, including industrial, aerial, and medical imagery. Through extensive evaluation of both proprietary and open-source VLMs, we reveal systematic gaps between model and human performance across difference types and domains, and provide controlled analyses highlighting where VLMs’ reasoning sharply deteriorates. Together, our benchmark and findings establish a foundation for advancing VLMs toward human-level comparative reasoning.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=pBTXsu1i77", "openreview_id": "pBTXsu1i77", "openreview_forum_id": "pBTXsu1i77", "authors": [], "pdf_url": "https://openreview.net/pdf/d0d62dc6e108ceee41ca33730cb232524d40df5d.pdf", "summary_cn": "本文提出VLM-SubtleBench基准，评估视觉语言模型在细微图像差异上的比较推理能力，发现模型与人类表现存在系统差距。", "keywords": ["视觉语言模型", "比较推理", "基准测试", "细微差异", "多领域评估", "性能差距"], "triple": {"method": "构建涵盖十类差异的多领域图像-问题对基准", "result": "模型在细微推理上显著落后于人类，性能随差异类型和领域变化", "contribution": "为提升VLM至人类水平比较推理奠定基础"}}
{"venue": "ICLR", "search_title": "Dual Distillation for Few-Shot Anomaly Detection", "full_title": "Dual Distillation for Few-Shot Anomaly Detection", "url": "https://openreview.net/forum?id=tRO6G20Qba", "year": 2026, "is_main_conference": true, "abstract_snippet": "Anomaly detection is a critical task in computer vision with profound implications for medical imaging, where identifying pathologies early can directly impact patient outcomes. While recent unsupervised anomaly detection approaches show promise, they require substantial normal training data and struggle to generalize across anatomical contexts. We introduce D$^2$4FAD, a novel dual distillation framework for few-shot anomaly detection that identifies anomalies in previously unseen tasks using only a small number of normal reference images. Our approach leverages a pre-trained encoder as a teacher network to extract multi-scale features from both support and query images, while a student decoder learns to distill knowledge from the teacher on query images and self-distill on support images. We further propose a learn-to-weight mechanism that dynamically assesses the reference value of each support image conditioned on the query, optimizing anomaly detection performance. To evaluate our method, we curate a comprehensive benchmark dataset comprising 13,084 images across four organs, four imaging modalities, and five disease categories. Extensive experiments demonstrate that D$^2$4FAD significantly outperforms existing approaches, establishing a new state-of-the-art in few-shot medical anomaly detection.", "abstract": "Anomaly detection is a critical task in computer vision with profound implications for medical imaging, where identifying pathologies early can directly impact patient outcomes. While recent unsupervised anomaly detection approaches show promise, they require substantial normal training data and struggle to generalize across anatomical contexts. We introduce D$^2$4FAD, a novel dual distillation framework for few-shot anomaly detection that identifies anomalies in previously unseen tasks using only a small number of normal reference images. Our approach leverages a pre-trained encoder as a teacher network to extract multi-scale features from both support and query images, while a student decoder learns to distill knowledge from the teacher on query images and self-distill on support images. We further propose a learn-to-weight mechanism that dynamically assesses the reference value of each support image conditioned on the query, optimizing anomaly detection performance. To evaluate our method, we curate a comprehensive benchmark dataset comprising 13,084 images across four organs, four imaging modalities, and five disease categories. Extensive experiments demonstrate that D$^2$4FAD significantly outperforms existing approaches, establishing a new state-of-the-art in few-shot medical anomaly detection.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=tRO6G20Qba", "openreview_id": "tRO6G20Qba", "openreview_forum_id": "tRO6G20Qba", "authors": [], "pdf_url": "https://openreview.net/pdf/04ed891c8e188a04145664f0c50bc9795f7972ef.pdf", "summary_cn": "提出D$^2$4FAD双蒸馏框架，用于少样本医学异常检测，仅需少量正常参考图像，在跨器官、模态和疾病的综合基准上实现最优性能。", "keywords": ["少样本异常检测", "双蒸馏框架", "医学影像", "自蒸馏", "动态加权", "跨域泛化"], "triple": {"method": "双蒸馏框架与动态加权机制", "result": "在综合医学影像基准上显著超越现有方法", "contribution": "实现少样本跨域异常检测新SOTA"}}
{"venue": "ICLR", "search_title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition", "full_title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition", "url": "https://openreview.net/forum?id=pHF5CXB0YH", "year": 2026, "is_main_conference": true, "abstract_snippet": "Most machine learning-based image segmentation models produce pixel-wise confidence scores that represent the model’s predicted probability for each class label at every pixel. While this information can be particularly valuable in high-stakes domains such as medical imaging, these scores are heuristic in nature and do not constitute rigorous quantitative uncertainty estimates.\nConformal prediction (CP) provides a principled framework for transforming heuristic confidence scores into statistically valid uncertainty estimates. However, applying CP directly to image segmentation ignores the spatial correlations between pixels, a fundamental characteristic of image data. This can result in overly conservative and less interpretable uncertainty estimates.\nTo address this, we propose CONSIGN (*Conformal Segmentation Informed by Spatial Groupings via Decomposition*), a CP-based method that incorporates spatial correlations to improve uncertainty quantification in image segmentation.\nOur method generates meaningful prediction sets that come with user-specified, high-probability error guarantees.\nIt is compatible with any pre-trained segmentation model capable of generating multiple sample outputs.\nWe evaluate CONSIGN against two CP baselines across three medical imaging datasets and two COCO dataset subsets, using three different pre-trained segmentation models. Results demonstrate that accounting for spatial structure significantly improves performance across multiple metrics and enhances the quality of uncertainty estimates.", "abstract": "Most machine learning-based image segmentation models produce pixel-wise confidence scores that represent the model’s predicted probability for each class label at every pixel. While this information can be particularly valuable in high-stakes domains such as medical imaging, these scores are heuristic in nature and do not constitute rigorous quantitative uncertainty estimates.\nConformal prediction (CP) provides a principled framework for transforming heuristic confidence scores into statistically valid uncertainty estimates. However, applying CP directly to image segmentation ignores the spatial correlations between pixels, a fundamental characteristic of image data. This can result in overly conservative and less interpretable uncertainty estimates.\nTo address this, we propose CONSIGN (*Conformal Segmentation Informed by Spatial Groupings via Decomposition*), a CP-based method that incorporates spatial correlations to improve uncertainty quantification in image segmentation.\nOur method generates meaningful prediction sets that come with user-specified, high-probability error guarantees.\nIt is compatible with any pre-trained segmentation model capable of generating multiple sample outputs.\nWe evaluate CONSIGN against two CP baselines across three medical imaging datasets and two COCO dataset subsets, using three different pre-trained segmentation models. Results demonstrate that accounting for spatial structure significantly improves performance across multiple metrics and enhances the quality of uncertainty estimates.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=pHF5CXB0YH", "openreview_id": "pHF5CXB0YH", "openreview_forum_id": "pHF5CXB0YH", "authors": [], "pdf_url": "https://openreview.net/pdf/32d4e15bc1ed0eba4523776ef3ef41b08dbfaf78.pdf", "summary_cn": "CONSIGN方法通过整合空间相关性，改进图像分割中的不确定性量化，提供统计有效的预测集，在医学影像和COCO数据集上表现优于基线。", "keywords": ["图像分割", "不确定性量化", "空间相关性", "医学影像", "统计保证"], "triple": {"method": "基于共形预测整合空间分组", "result": "提升不确定性估计性能", "contribution": "提供统计有效的预测集"}}
{"venue": "ICLR", "search_title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context", "full_title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context", "url": "https://openreview.net/forum?id=ZTAvANYFL5", "year": 2026, "is_main_conference": true, "abstract_snippet": "While LLMs have demonstrated medical knowledge and conversational ability, their deployment in clinical practice raises new risks: patients may place greater trust in LLM-generated responses than in nurses' professional judgments, potentially intensifying nurse–patient conflicts. Such risks highlight the urgent need of evaluating whether LLMs align with the core nursing values upheld by human nurses. This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: _Altruism_, _Human Dignity_, _Integrity_, _Justice_, and _Professionalism_. We define two-level tasks on the benchmark, considering the two characteristics of emerging nurse–patient conflicts. The **Easy-Level** dataset consists of 2,200 value-aligned and value-violating instances, which are collected through a five-month longitudinal field study across three hospitals of varying tiers; The **Hard-Level** dataset is comprised of 2,200 dialogue-based instances that embed contextual cues and subtle misleading signals, which increase adversarial complexity and better reflect the subjectivity and bias of narrators in the context of emerging nurse-patient conflicts. We evaluate a total of 23 SoTA LLMs on their ability to align with nursing values, and find that general LLMs outperform medical ones, and _Justice_ is the hardest value dimension. As the first real-world benchmark for healthcare value alignment, NurValues provides novel insights into how LLMs navigate ethical challenges in clinician–patient interactions.", "abstract": "While LLMs have demonstrated medical knowledge and conversational ability, their deployment in clinical practice raises new risks: patients may place greater trust in LLM-generated responses than in nurses' professional judgments, potentially intensifying nurse–patient conflicts. Such risks highlight the urgent need of evaluating whether LLMs align with the core nursing values upheld by human nurses. This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: _Altruism_, _Human Dignity_, _Integrity_, _Justice_, and _Professionalism_. We define two-level tasks on the benchmark, considering the two characteristics of emerging nurse–patient conflicts. The **Easy-Level** dataset consists of 2,200 value-aligned and value-violating instances, which are collected through a five-month longitudinal field study across three hospitals of varying tiers; The **Hard-Level** dataset is comprised of 2,200 dialogue-based instances that embed contextual cues and subtle misleading signals, which increase adversarial complexity and better reflect the subjectivity and bias of narrators in the context of emerging nurse-patient conflicts. We evaluate a total of 23 SoTA LLMs on their ability to align with nursing values, and find that general LLMs outperform medical ones, and _Justice_ is the hardest value dimension. As the first real-world benchmark for healthcare value alignment, NurValues provides novel insights into how LLMs navigate ethical challenges in clinician–patient interactions.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ZTAvANYFL5", "openreview_id": "ZTAvANYFL5", "openreview_forum_id": "ZTAvANYFL5", "authors": [], "pdf_url": "https://openreview.net/pdf/b493335d4170e574048a5f727f6cb67a2d5474a4.pdf", "summary_cn": "本研究提出首个护理价值对齐基准NurValues，基于国际护理准则定义五个核心价值维度，通过易、难两级任务评估23个LLMs，发现通用模型优于医疗模型，正义维度最难对齐。", "keywords": ["护理价值对齐", "大语言模型", "临床伦理", "基准评估", "医患冲突", "真实世界数据"], "triple": {"method": "构建两级任务基准（易级实例与难级对话）", "result": "通用LLMs优于医疗LLMs，正义维度最难对齐", "contribution": "首个真实世界护理价值对齐基准，为LLMs临床伦理评估提供新视角"}}
{"venue": "ICLR", "search_title": "CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmarking of Large Language Models in Mental Health Question Answering", "full_title": "CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmarking of Large Language Models in Mental Health Question Answering", "url": "https://openreview.net/forum?id=8MBYRZHVWT", "year": 2026, "is_main_conference": true, "abstract_snippet": "Medical question answering (QA) benchmarks often focus on multiple-choice or fact-based tasks, leaving open-ended answers to real patient questions underexplored. This gap is particularly critical in mental health, where patient questions often mix symptoms, treatment concerns, and emotional needs, requiring answers that balance clinical caution with contextual sensitivity.\nWe present CounselBench, a large-scale benchmark developed with 100 mental health professionals to evaluate and stress-test large language models (LLMs) in realistic help-seeking scenarios. The first component, CounselBench-EVAL, contains 2,000 expert evaluations of answers from GPT-4, LLaMA 3, Gemini, and online human therapists on patient questions from the public forum CounselChat. Each answer is rated across six clinically grounded dimensions, with span-level annotations and written rationales. Expert evaluations show that while LLMs achieve high scores on several dimensions, they also exhibit recurring issues, including unconstructive feedback, overgeneralization, and limited personalization or relevance. Responses were frequently flagged for safety risks, most notably unauthorized medical advice. Follow-up experiments show that LLM judges systematically overrate model responses and overlook safety concerns identified by human experts. To probe failure modes more directly, we construct CounselBench-Adv, an adversarial dataset of 120 expert-authored mental health questions designed to trigger specific model issues. Expert evaluation of 1,080 responses from nine LLMs reveals consistent, model-specific failure patterns. Together, CounselBench establishes a clinically grounded framework for benchmarking LLMs in mental health QA.", "abstract": "Medical question answering (QA) benchmarks often focus on multiple-choice or fact-based tasks, leaving open-ended answers to real patient questions underexplored. This gap is particularly critical in mental health, where patient questions often mix symptoms, treatment concerns, and emotional needs, requiring answers that balance clinical caution with contextual sensitivity.\nWe present CounselBench, a large-scale benchmark developed with 100 mental health professionals to evaluate and stress-test large language models (LLMs) in realistic help-seeking scenarios. The first component, CounselBench-EVAL, contains 2,000 expert evaluations of answers from GPT-4, LLaMA 3, Gemini, and online human therapists on patient questions from the public forum CounselChat. Each answer is rated across six clinically grounded dimensions, with span-level annotations and written rationales. Expert evaluations show that while LLMs achieve high scores on several dimensions, they also exhibit recurring issues, including unconstructive feedback, overgeneralization, and limited personalization or relevance. Responses were frequently flagged for safety risks, most notably unauthorized medical advice. Follow-up experiments show that LLM judges systematically overrate model responses and overlook safety concerns identified by human experts. To probe failure modes more directly, we construct CounselBench-Adv, an adversarial dataset of 120 expert-authored mental health questions designed to trigger specific model issues. Expert evaluation of 1,080 responses from nine LLMs reveals consistent, model-specific failure patterns. Together, CounselBench establishes a clinically grounded framework for benchmarking LLMs in mental health QA.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=8MBYRZHVWT", "openreview_id": "8MBYRZHVWT", "openreview_forum_id": "8MBYRZHVWT", "authors": [], "pdf_url": "https://openreview.net/pdf/4dd193bce232058aba85627a12cd7fcea5324adb.pdf", "summary_cn": "CounselBench 是一个由心理健康专家构建的大规模基准，用于评估大语言模型在心理健康问答中的表现。研究发现模型在安全性和个性化方面存在缺陷，专家评估揭示了系统性风险。", "keywords": ["心理健康问答", "专家评估", "大语言模型基准", "安全风险", "对抗性测试", "临床评估"], "triple": {"method": "构建包含专家评估和对抗性问题的基准", "result": "LLMs 在多个维度得分高但存在安全与个性化问题，自动评估高估模型表现", "contribution": "建立了临床基础的 LLMs 心理健康问答评估框架"}}
{"venue": "ICLR", "search_title": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis", "full_title": "OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis", "url": "https://openreview.net/forum?id=nrZI64gTvC", "year": 2026, "is_main_conference": true, "abstract_snippet": "Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both \\textbf{slice-driven} local features (e.g., sub-centimeter nodules, lesion boundaries) and \\textbf{volume-driven} spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). \nHowever, existing Large Vision–Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. \nWe present \\textbf{OmniCT}, a powerful unified slice–volume LVLM for CT scans, which makes three contributions: \n\\textbf{(i) Spatial Consistency Enhancement (SCE):} volumetric slice composition combined with tri-axial positional encoding introduces volumetric consistency, and an MoE hybird projection enables efficient slice–volume adaptation; \n\\textbf{(ii) Organ-level Semantic Enhancement (OSE):} segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; \n\\textbf{(iii) MedEval-CT:} the largest slice–volume CT dataset and hybrid benchmark integrates multi-level metrics for unified evaluation. \nOmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks, satisfies both micro-level detail sensitivity and macro-level spatial reasoning, and establishes a new paradigm for cross-dimensional medical imaging modeling. \nOur project is available at \\href{https://anonymous.4open.science/r/OmniCT}{link}.", "abstract": "Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both \\textbf{slice-driven} local features (e.g., sub-centimeter nodules, lesion boundaries) and \\textbf{volume-driven} spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). \nHowever, existing Large Vision–Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. \nWe present \\textbf{OmniCT}, a powerful unified slice–volume LVLM for CT scans, which makes three contributions: \n\\textbf{(i) Spatial Consistency Enhancement (SCE):} volumetric slice composition combined with tri-axial positional encoding introduces volumetric consistency, and an MoE hybird projection enables efficient slice–volume adaptation; \n\\textbf{(ii) Organ-level Semantic Enhancement (OSE):} segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; \n\\textbf{(iii) MedEval-CT:} the largest slice–volume CT dataset and hybrid benchmark integrates multi-level metrics for unified evaluation. \nOmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks, satisfies both micro-level detail sensitivity and macro-level spatial reasoning, and establishes a new paradigm for cross-dimensional medical imaging modeling. \nOur project is available at \\href{https://anonymous.4open.science/r/OmniCT}{link}.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=nrZI64gTvC", "openreview_id": "nrZI64gTvC", "openreview_forum_id": "nrZI64gTvC", "authors": [], "pdf_url": "https://openreview.net/pdf/2fd2a30a147c15fc0e7de70a6b4e3e705e7887a1.pdf", "summary_cn": "OmniCT提出统一切片-体积LVLM用于CT分析，通过空间一致性增强和器官级语义增强，在多种临床任务中显著优于现有方法，实现细节敏感与空间推理的平衡。", "keywords": ["CT分析", "大视觉语言模型", "切片-体积统一", "空间一致性", "器官语义增强", "医学影像建模"], "triple": {"method": "空间一致性增强与器官级语义增强", "result": "在多种临床任务中显著优于现有方法", "contribution": "建立跨维度医学影像建模新范式"}}
{"venue": "ICLR", "search_title": "Distributional Consistency Loss: Beyond Pointwise Data Terms in Inverse Problems", "full_title": "Distributional Consistency Loss: Beyond Pointwise Data Terms in Inverse Problems", "url": "https://openreview.net/forum?id=oX7fDiasfK", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recovering true signals from noisy measurements is a central challenge in inverse problems spanning medical imaging, geophysics, and signal processing. Current solutions nearly always balance prior assumptions regarding the true signal (regularization) with agreement to noisy measured data (data fidelity). Conventional data fidelity loss functions, such as mean-squared error (MSE) or negative log-likelihood, seek pointwise agreement with noisy measurements, often leading to overfitting to noise. In this work, we instead evaluate data fidelity collectively by testing whether the observed measurements are statistically consistent with the noise distributions implied by the current estimate. We adopt this aggregated perspective and introduce $\\textit{distributional consistency (DC) loss}$, a data-fidelity objective that replaces pointwise matching with distribution-level calibration. DC loss acts as a direct and practical plug-in replacement for standard data consistency terms: i) it is compatible with modern unsupervised regularizers that operate without paired measurement–ground-truth data, ii) it is optimized in the same way as traditional losses, and iii) it avoids overfitting to measurement noise even without the use of priors. Its scope naturally fits many practical inverse problems where the measurement-noise distribution is known and where the measured dataset consists of many independent noisy values. We demonstrate efficacy in two key example application areas: i) in image denoising with deep image prior, using DC instead of MSE loss removes the need for early stopping and achieves higher PSNR; ii) in medical image reconstruction from Poisson-noisy data, DC loss reduces artifacts in highly-iterated reconstructions and enhances the efficacy of hand-crafted regularization. These results position DC loss as a statistically grounded, performance-enhancing alternative to conventional fidelity losses for an important class of unsupervised noise-dominated inverse problems.", "abstract": "Recovering true signals from noisy measurements is a central challenge in inverse problems spanning medical imaging, geophysics, and signal processing. Current solutions nearly always balance prior assumptions regarding the true signal (regularization) with agreement to noisy measured data (data fidelity). Conventional data fidelity loss functions, such as mean-squared error (MSE) or negative log-likelihood, seek pointwise agreement with noisy measurements, often leading to overfitting to noise. In this work, we instead evaluate data fidelity collectively by testing whether the observed measurements are statistically consistent with the noise distributions implied by the current estimate. We adopt this aggregated perspective and introduce $\\textit{distributional consistency (DC) loss}$, a data-fidelity objective that replaces pointwise matching with distribution-level calibration. DC loss acts as a direct and practical plug-in replacement for standard data consistency terms: i) it is compatible with modern unsupervised regularizers that operate without paired measurement–ground-truth data, ii) it is optimized in the same way as traditional losses, and iii) it avoids overfitting to measurement noise even without the use of priors. Its scope naturally fits many practical inverse problems where the measurement-noise distribution is known and where the measured dataset consists of many independent noisy values. We demonstrate efficacy in two key example application areas: i) in image denoising with deep image prior, using DC instead of MSE loss removes the need for early stopping and achieves higher PSNR; ii) in medical image reconstruction from Poisson-noisy data, DC loss reduces artifacts in highly-iterated reconstructions and enhances the efficacy of hand-crafted regularization. These results position DC loss as a statistically grounded, performance-enhancing alternative to conventional fidelity losses for an important class of unsupervised noise-dominated inverse problems.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=oX7fDiasfK", "openreview_id": "oX7fDiasfK", "openreview_forum_id": "oX7fDiasfK", "authors": [], "pdf_url": "https://openreview.net/pdf/7329f559525b886abb4f9a218922757188ec6989.pdf", "summary_cn": "提出分布一致性损失，替代传统逐点数据保真度损失，通过分布级校准避免噪声过拟合，提升无监督逆问题性能。", "keywords": ["分布一致性损失", "逆问题", "数据保真度", "噪声过拟合", "无监督学习", "医学成像"], "triple": {"method": "分布级校准替代逐点匹配", "result": "提升去噪与重建质量，避免早停", "contribution": "为无监督噪声主导逆问题提供统计基础替代损失"}}
{"venue": "ICLR", "search_title": "CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models", "full_title": "CardioComposer: Leveraging Differentiable Geometry for Compositional Control of Anatomical Diffusion Models", "url": "https://openreview.net/forum?id=JyboUMeEUi", "year": 2026, "is_main_conference": true, "abstract_snippet": "Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.", "abstract": "Generative models of 3D cardiovascular anatomy can synthesize informative structures for clinical research and medical device evaluation, but face a trade-off between geometric controllability and realism. We propose CardioComposer: a programmable, inference-time framework for generating multi-class anatomical label maps based on interpretable ellipsoidal primitives. These primitives represent geometric attributes such as the size, shape, and position of discrete substructures. We specifically develop differentiable measurement functions based on voxel-wise geometric moments, enabling loss-based gradient guidance during diffusion model sampling. We demonstrate that these losses can constrain individual geometric attributes in a disentangled manner and provide compositional control over multiple substructures. Finally, we show that our method is compatible with a wide array of anatomical systems containing non-convex substructures, spanning cardiac, vascular, and skeletal organs.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=JyboUMeEUi", "openreview_id": "JyboUMeEUi", "openreview_forum_id": "JyboUMeEUi", "authors": [], "pdf_url": "https://openreview.net/pdf/8eae4e829d0b1d4ce2e4939f31af00f724977c3b.pdf", "summary_cn": "CardioComposer 提出基于可解释椭球基元的可编程框架，通过可微分几何测量函数在扩散模型采样中实现解剖结构的解耦与组合控制，提升生成真实性与可控性。", "keywords": ["解剖生成模型", "可微分几何", "扩散模型", "心血管解剖", "组合控制", "几何基元"], "triple": {"method": "基于椭球基元的可微分几何测量函数", "result": "实现解剖结构的解耦与组合控制", "contribution": "提升生成模型的真实性与几何可控性"}}
{"venue": "ICLR", "search_title": "Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization", "full_title": "Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization", "url": "https://openreview.net/forum?id=c0ERcCz6lD", "year": 2026, "is_main_conference": true, "abstract_snippet": "Deep neural networks have been increasingly used in safety-critical applications such as medical diagnosis and autonomous driving. However, many studies suggest that they are prone to being poorly calibrated and have a propensity for overconfidence, which may have disastrous consequences. In this paper, unlike standard training such as stochastic gradient descent, we show that the recently proposed sharpness-aware minimization (SAM) counteracts this tendency towards overconfidence. The theoretical analysis suggests that SAM allows us to learn models that are already well-calibrated by implicitly maximizing the entropy of the predictive distribution. Inspired by this finding, we further propose a variant of SAM, coined as CSAM, to ameliorate model calibration. Extensive experiments on various datasets, including ImageNet-1K, demonstrate the benefits of SAM in reducing calibration error. Meanwhile, CSAM performs even better than SAM and consistently achieves lower calibration error than other approaches.", "abstract": "Deep neural networks have been increasingly used in safety-critical applications such as medical diagnosis and autonomous driving. However, many studies suggest that they are prone to being poorly calibrated and have a propensity for overconfidence, which may have disastrous consequences. In this paper, unlike standard training such as stochastic gradient descent, we show that the recently proposed sharpness-aware minimization (SAM) counteracts this tendency towards overconfidence. The theoretical analysis suggests that SAM allows us to learn models that are already well-calibrated by implicitly maximizing the entropy of the predictive distribution. Inspired by this finding, we further propose a variant of SAM, coined as CSAM, to ameliorate model calibration. Extensive experiments on various datasets, including ImageNet-1K, demonstrate the benefits of SAM in reducing calibration error. Meanwhile, CSAM performs even better than SAM and consistently achieves lower calibration error than other approaches.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=c0ERcCz6lD", "openreview_id": "c0ERcCz6lD", "openreview_forum_id": "c0ERcCz6lD", "authors": [], "pdf_url": "https://openreview.net/pdf/492eab9fc0738808d289ac56d737c154dff1a45f.pdf", "summary_cn": "研究表明，锐度感知最小化（SAM）能有效减少深度神经网络的过度自信，提高校准性。提出的CSAM变体进一步优化校准性能。", "keywords": ["锐度感知最小化", "模型校准", "过度自信", "深度神经网络", "CSAM", "熵最大化"], "triple": {"method": "SAM与CSAM方法", "result": "降低校准误差，优于标准训练", "contribution": "提升模型校准性，减少过度自信"}}
{"venue": "ICLR", "search_title": "Patronus: Interpretable Diffusion Models with Prototypes", "full_title": "Patronus: Interpretable Diffusion Models with Prototypes", "url": "https://openreview.net/forum?id=1bz8CA8gPo", "year": 2026, "is_main_conference": true, "abstract_snippet": "Uncovering the opacity of diffusion-based generative models is urgently needed, as their applications continue to expand while their underlying procedures largely remain a black box. \nWith a critical question -- how can the diffusion generation process be interpreted and understood? -- we proposed \\textit{Patronus}, an interpretable diffusion model that incorporates a prototypical network to encode semantics in visual patches, revealing \\textit{what} visual patterns are learned and \\textit{where} and \\textit{when} they emerge throughout denoising.\nThis interpretability of Patronus provides deeper insights into the generative mechanism, enabling the detection of shortcut learning via unwanted correlations and the tracing of semantic emergence across timesteps. We evaluate \\textit{Patronus} on four natural image datasets and one medical imaging dataset, demonstrating both faithful interpretability and strong generative performance. With this work, we open new avenues for understanding and steering diffusion models through prototype-based interpretability.", "abstract": "Uncovering the opacity of diffusion-based generative models is urgently needed, as their applications continue to expand while their underlying procedures largely remain a black box. \nWith a critical question -- how can the diffusion generation process be interpreted and understood? -- we proposed \\textit{Patronus}, an interpretable diffusion model that incorporates a prototypical network to encode semantics in visual patches, revealing \\textit{what} visual patterns are learned and \\textit{where} and \\textit{when} they emerge throughout denoising.\nThis interpretability of Patronus provides deeper insights into the generative mechanism, enabling the detection of shortcut learning via unwanted correlations and the tracing of semantic emergence across timesteps. We evaluate \\textit{Patronus} on four natural image datasets and one medical imaging dataset, demonstrating both faithful interpretability and strong generative performance. With this work, we open new avenues for understanding and steering diffusion models through prototype-based interpretability.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=1bz8CA8gPo", "openreview_id": "1bz8CA8gPo", "openreview_forum_id": "1bz8CA8gPo", "authors": [], "pdf_url": "https://openreview.net/pdf/8782e7d4c0c0f97700ae4aa9d3595187882fad8e.pdf", "summary_cn": "Patronus是一种可解释扩散模型，通过原型网络揭示去噪过程中视觉模式的语义、位置和时序，提升模型透明度并检测捷径学习。", "keywords": ["可解释性", "扩散模型", "原型网络", "语义分析", "去噪过程", "医学影像"], "triple": {"method": "原型网络编码视觉块语义", "result": "揭示模式在去噪中的时空出现", "contribution": "提供扩散模型可解释性新途径"}}
{"venue": "ICLR", "search_title": "Reliable Evaluation of MRI Motion Correction: Dataset and Insights", "full_title": "Reliable Evaluation of MRI Motion Correction: Dataset and Insights", "url": "https://openreview.net/forum?id=5PY8HR2Zz6", "year": 2026, "is_main_conference": true, "abstract_snippet": "Correcting motion artifacts in scientific and medical imaging is important, as they significantly impact image quality. \nHowever, evaluating deep learning-based and classical motion correction methods remains fundamentally difficult due to the lack of accessible ground-truth target data. \nTo address this challenge, we study three evaluation approaches: real-world evaluation based on reference scans, simulated motion, and reference-free evaluation, each with its merits and shortcomings. \nTo enable evaluation with real-world motion artifacts, we release PMoC3D, a dataset consisting of unprocessed $\\textbf{P}$aired $\\textbf{Mo}$tion-$\\textbf{C}$orrupted $\\textbf{3D}$ brain MRI data. \nTo advance evaluation quality, we introduce MoMRISim, a  feature-space metric trained for evaluating motion reconstructions. \nWe assess each evaluation approach and find real-world evaluation together with MoMRISim, while not perfect, to be most reliable. \nEvaluation based on simulated motion systematically exaggerates algorithm performance, and reference-free evaluation overrates oversmoothed deep learning outputs.", "abstract": "Correcting motion artifacts in scientific and medical imaging is important, as they significantly impact image quality. \nHowever, evaluating deep learning-based and classical motion correction methods remains fundamentally difficult due to the lack of accessible ground-truth target data. \nTo address this challenge, we study three evaluation approaches: real-world evaluation based on reference scans, simulated motion, and reference-free evaluation, each with its merits and shortcomings. \nTo enable evaluation with real-world motion artifacts, we release PMoC3D, a dataset consisting of unprocessed $\\textbf{P}$aired $\\textbf{Mo}$tion-$\\textbf{C}$orrupted $\\textbf{3D}$ brain MRI data. \nTo advance evaluation quality, we introduce MoMRISim, a  feature-space metric trained for evaluating motion reconstructions. \nWe assess each evaluation approach and find real-world evaluation together with MoMRISim, while not perfect, to be most reliable. \nEvaluation based on simulated motion systematically exaggerates algorithm performance, and reference-free evaluation overrates oversmoothed deep learning outputs.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=5PY8HR2Zz6", "openreview_id": "5PY8HR2Zz6", "openreview_forum_id": "5PY8HR2Zz6", "authors": [], "pdf_url": "https://openreview.net/pdf/9856e6c5e67d59e4e3f1f9bb5a9e153e18eb1a90.pdf", "summary_cn": "本文提出PMoC3D数据集和MoMRISim评估指标，用于可靠评估MRI运动校正方法，发现真实世界评估结合MoMRISim最可靠。", "keywords": ["MRI运动校正", "评估方法", "PMoC3D数据集", "MoMRISim指标", "深度学习", "运动伪影"], "triple": {"method": "提出PMoC3D数据集和MoMRISim评估指标", "result": "真实世界评估结合MoMRISim最可靠，模拟运动评估高估性能", "contribution": "提供可靠评估框架，促进MRI运动校正方法发展"}}
{"venue": "ICLR", "search_title": "Critic–Adviser–Reviser Cyclic Refinement: Towards High-Quality EMR Corpus Generation with LLMs", "full_title": "Critic–Adviser–Reviser Cyclic Refinement: Towards High-Quality EMR Corpus Generation with LLMs", "url": "https://openreview.net/forum?id=7y11BdJIOp", "year": 2026, "is_main_conference": true, "abstract_snippet": "Electronic medical records (EMRs) are vital for healthcare research, but their use is limited by privacy concerns. Synthetic EMR generation offers a promising alternative, yet most existing methods merely imitate real records without adhering to rigorous clinical quality principles. To address this, we introduce LLM-CARe, a stage-wise cyclic refinement framework that progressively improves EMR quality through three stages, each targeting a specific granularity: corpus, section and document. At each stage, a Critic, an Adviser, and a Reviser collaborate iteratively to evaluate, provide feedback, and refine the drafts. This structured, multi-stage process produces records that better satisfy clinical quality standards. Experiments show that LLM-CARe significantly enhances EMR quality across all levels compared to strong baselines and yields improved performance on real-world clinical tasks such as diagnosis prediction. Unlike prior work, our method requires no real EMR text for training or prompting, demonstrating the effectiveness of stage-wise, cyclic refinement for generating high-quality, privacy-preserving EMR datasets.", "abstract": "Electronic medical records (EMRs) are vital for healthcare research, but their use is limited by privacy concerns. Synthetic EMR generation offers a promising alternative, yet most existing methods merely imitate real records without adhering to rigorous clinical quality principles. To address this, we introduce LLM-CARe, a stage-wise cyclic refinement framework that progressively improves EMR quality through three stages, each targeting a specific granularity: corpus, section and document. At each stage, a Critic, an Adviser, and a Reviser collaborate iteratively to evaluate, provide feedback, and refine the drafts. This structured, multi-stage process produces records that better satisfy clinical quality standards. Experiments show that LLM-CARe significantly enhances EMR quality across all levels compared to strong baselines and yields improved performance on real-world clinical tasks such as diagnosis prediction. Unlike prior work, our method requires no real EMR text for training or prompting, demonstrating the effectiveness of stage-wise, cyclic refinement for generating high-quality, privacy-preserving EMR datasets.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=7y11BdJIOp", "openreview_id": "7y11BdJIOp", "openreview_forum_id": "7y11BdJIOp", "authors": [], "pdf_url": "https://openreview.net/pdf/114c74ba8ea7161eaca9a9f26721f6f60428b94b.pdf", "summary_cn": "提出LLM-CARe框架，通过批评-建议-修订三阶段循环精炼，无需真实病历训练即可生成高质量、保护隐私的合成电子病历。", "keywords": ["合成电子病历", "大语言模型", "循环精炼", "隐私保护", "临床质量", "多阶段框架"], "triple": {"method": "三阶段循环精炼框架", "result": "生成高质量合成病历，提升诊断预测性能", "contribution": "无需真实病历训练，保护隐私并满足临床标准"}}
{"venue": "ICLR", "search_title": "A Structured, Tagged, and Localized Visual Question Answering Dataset with Full Sentence Answers and Scene Graphs for Chest X-ray Images", "full_title": "A Structured, Tagged, and Localized Visual Question Answering Dataset with Full Sentence Answers and Scene Graphs for Chest X-ray Images", "url": "https://openreview.net/forum?id=LrmyW9JLYq", "year": 2026, "is_main_conference": true, "abstract_snippet": "Visual Question Answering (VQA) enables targeted and context-dependent analysis of medical images, such as chest X-rays (CXRs). However, existing VQA datasets for CXRs are typically constrained by simplistic and brief answer formats, lacking localization annotations (e.g., bounding boxes) and structured tags (e.g., region or radiological finding/disease tags). To address these limitations, we introduce MIMIC-Ext-CXR-QBA (abbr. CXR-QBA), a large-scale CXR VQA dataset derived from MIMIC-CXR, comprising 42 million QA-pairs with multi-granular, multi-part answers, detailed bounding boxes, and structured tags. \nWe automatically generated our VQA dataset from scene graphs (also made available), which we constructed using LLM-based information extraction from radiology reports. After automatic quality assessment, we identified 31M pre-training and 7.5M fine-tuning grade QA-pairs, providing the largest and most sophisticated VQA dataset for CXRs to date. Tools for using our dataset and the construction pipeline are available at https://anonymous.4open.science/r/mimic-ext-cxr-qba/ .", "abstract": "Visual Question Answering (VQA) enables targeted and context-dependent analysis of medical images, such as chest X-rays (CXRs). However, existing VQA datasets for CXRs are typically constrained by simplistic and brief answer formats, lacking localization annotations (e.g., bounding boxes) and structured tags (e.g., region or radiological finding/disease tags). To address these limitations, we introduce MIMIC-Ext-CXR-QBA (abbr. CXR-QBA), a large-scale CXR VQA dataset derived from MIMIC-CXR, comprising 42 million QA-pairs with multi-granular, multi-part answers, detailed bounding boxes, and structured tags. \nWe automatically generated our VQA dataset from scene graphs (also made available), which we constructed using LLM-based information extraction from radiology reports. After automatic quality assessment, we identified 31M pre-training and 7.5M fine-tuning grade QA-pairs, providing the largest and most sophisticated VQA dataset for CXRs to date. Tools for using our dataset and the construction pipeline are available at https://anonymous.4open.science/r/mimic-ext-cxr-qba/ .", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=LrmyW9JLYq", "openreview_id": "LrmyW9JLYq", "openreview_forum_id": "LrmyW9JLYq", "authors": [], "pdf_url": "https://openreview.net/pdf/bb0c61323a0aaffe74ddc27974abe22176745846.pdf", "summary_cn": "本文提出CXR-QBA数据集，包含4200万QA对，提供完整句子答案、定位框和结构化标签，用于胸部X光视觉问答，是目前最大最复杂的数据集。", "keywords": ["视觉问答", "胸部X光", "数据集", "场景图", "结构化标签", "定位标注"], "triple": {"method": "基于LLM从放射报告构建场景图自动生成", "result": "创建含4200万QA对的大规模数据集", "contribution": "提供首个带完整答案和定位的CXR VQA数据集"}}
{"venue": "ICLR", "search_title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation", "full_title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation", "url": "https://openreview.net/forum?id=it0GTdiW9t", "year": 2026, "is_main_conference": true, "abstract_snippet": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model’s role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.", "abstract": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model’s role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=it0GTdiW9t", "openreview_id": "it0GTdiW9t", "openreview_forum_id": "it0GTdiW9t", "authors": [], "pdf_url": "https://openreview.net/pdf/e3abc2bee3bbd367d978082f4a9ddd9136dd0931.pdf", "summary_cn": "本文提出一种自适应域转移扩散模型，通过空间变化混合场和目标一致恢复项，提升跨模态图像翻译的结构保真度和语义一致性，并减少去噪步骤。", "keywords": ["扩散模型", "跨模态图像翻译", "自适应域转移", "语义一致性", "结构保真度", "去噪效率"], "triple": {"method": "嵌入空间变化混合场与目标一致恢复项", "result": "提升结构保真度和语义一致性，减少去噪步骤", "contribution": "提出自适应域转移扩散模型，优化跨模态翻译效率与质量"}}
{"venue": "ICLR", "search_title": "Pixel-Level Residual Diffusion Transformer: Scalable 3D CT Volume Generation", "full_title": "Pixel-Level Residual Diffusion Transformer: Scalable 3D CT Volume Generation", "url": "https://openreview.net/forum?id=bWtRZQ1rm2", "year": 2026, "is_main_conference": true, "abstract_snippet": "Generating high-resolution 3D CT volumes with fine details remains challenging due to substantial computational demands and optimization difficulties inherent to existing generative models. In this paper, we propose the Pixel-Level Residual Diffusion Transformer (PRDiT), a scalable generative framework that synthesizes high-quality 3D medical volumes directly at voxel-level. PRDiT introduces a two-stage training architecture comprising 1) a local denoiser in the form of an MLP-based blind estimator operating on overlapping 3D patches to separate low-frequency structures efficiently, and 2) a global residual diffusion transformer employing memory-efficient attention to model and refine high-frequency residuals across entire volumes. This coarse-to-fine modeling strategy simplifies optimization, enhances training stability, and effectively preserves subtle structures without the limitations of an autoencoder bottleneck. Extensive experiments conducted on the LIDC-IDRI and RAD-ChestCT datasets demonstrate that PRDiT consistently outperforms state-of-the-art models, such as HA-GAN, 3D LDM and WDM-3D, achieving significantly lower 3D FID, MMD and Wasserstein distance scores.", "abstract": "Generating high-resolution 3D CT volumes with fine details remains challenging due to substantial computational demands and optimization difficulties inherent to existing generative models. In this paper, we propose the Pixel-Level Residual Diffusion Transformer (PRDiT), a scalable generative framework that synthesizes high-quality 3D medical volumes directly at voxel-level. PRDiT introduces a two-stage training architecture comprising 1) a local denoiser in the form of an MLP-based blind estimator operating on overlapping 3D patches to separate low-frequency structures efficiently, and 2) a global residual diffusion transformer employing memory-efficient attention to model and refine high-frequency residuals across entire volumes. This coarse-to-fine modeling strategy simplifies optimization, enhances training stability, and effectively preserves subtle structures without the limitations of an autoencoder bottleneck. Extensive experiments conducted on the LIDC-IDRI and RAD-ChestCT datasets demonstrate that PRDiT consistently outperforms state-of-the-art models, such as HA-GAN, 3D LDM and WDM-3D, achieving significantly lower 3D FID, MMD and Wasserstein distance scores.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=bWtRZQ1rm2", "openreview_id": "bWtRZQ1rm2", "openreview_forum_id": "bWtRZQ1rm2", "authors": [], "pdf_url": "https://openreview.net/pdf/b3098f5b6d4d3efcbe7a5ee2c979504323107dd2.pdf", "summary_cn": "提出PRDiT模型，通过局部去噪与全局残差扩散Transformer两阶段训练，高效生成高质量3D CT体素图像，在多项指标上超越现有方法。", "keywords": ["3D CT生成", "扩散模型", "Transformer", "残差学习", "两阶段训练", "医学图像合成"], "triple": {"method": "两阶段训练（局部去噪MLP+全局残差扩散Transformer）", "result": "在LIDC-IDRI和RAD-ChestCT数据集上，3D FID等指标优于HA-GAN等模型", "contribution": "提出可扩展的PRDiT框架，优化训练稳定性并保留细节"}}
{"venue": "ICLR", "search_title": "SONIC: Spectral Oriented Neural Invariant Convolutions", "full_title": "SONIC: Spectral Oriented Neural Invariant Convolutions", "url": "https://openreview.net/forum?id=qDGiMrUVmc", "year": 2026, "is_main_conference": true, "abstract_snippet": "Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these limitations requires a representation that is both structured and global.  We introduce SONIC (Spectral Oriented Neural Invariant Convolutions), a continuous spectral parameterisation that models convolutional operators using a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions. Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters. These results demonstrate that continuous, orientation-aware spectral parameterisations provide a principled and scalable alternative to conventional spatial and spectral operators.", "abstract": "Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these limitations requires a representation that is both structured and global.  We introduce SONIC (Spectral Oriented Neural Invariant Convolutions), a continuous spectral parameterisation that models convolutional operators using a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions. Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters. These results demonstrate that continuous, orientation-aware spectral parameterisations provide a principled and scalable alternative to conventional spatial and spectral operators.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=qDGiMrUVmc", "openreview_id": "qDGiMrUVmc", "openreview_forum_id": "qDGiMrUVmc", "authors": [], "pdf_url": "https://openreview.net/pdf/da267ff334a55d86b0ce605f02d3ce16f60f9da1.pdf", "summary_cn": "SONIC提出连续谱参数化卷积，使用少量方向选择性组件建模全局感受野，在图像分类和医学数据中表现优异，参数更少。", "keywords": ["卷积神经网络", "谱参数化", "全局感受野", "方向选择性", "医学图像", "轻量化模型"], "triple": {"method": "连续谱参数化卷积", "result": "提升几何变换、噪声和分辨率变化的鲁棒性", "contribution": "提供结构化全局表示替代方案"}}
{"venue": "ICLR", "search_title": "AnesSuite: A Comprehensive Benchmark and Dataset Suite for Anesthesiology Reasoning in LLMs", "full_title": "AnesSuite: A Comprehensive Benchmark and Dataset Suite for Anesthesiology Reasoning in LLMs", "url": "https://openreview.net/forum?id=iKRQMeC7yO", "year": 2026, "is_main_conference": true, "abstract_snippet": "The application of large language models (LLMs) in the medical field has garnered significant attention, yet their reasoning capabilities in more specialized domains like anesthesiology remain underexplored. To bridge this gap, we introduce AnesSuite, the first comprehensive dataset suite specifically designed for anesthesiology reasoning in LLMs. The suite features AnesBench, an evaluation benchmark tailored to assess anesthesiology-related reasoning across three levels: factual retrieval (System 1), hybrid reasoning (System 1.x), and complex decision-making (System 2).  Alongside this benchmark, the suite includes three training datasets that provide an infrastructure for continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning with verifiable rewards (RLVR). Leveraging this suite, we develop Morpheus, the first baseline model collection for anesthesiology reasoning. Despite undergoing limited training with SFT and group relative policy optimization (GRPO), Morpheus demonstrates substantial performance improvements, rivaling the performance of larger-scale models. Furthermore, through comprehensive evaluations and experiments, we analyze the key factors influencing anesthesiology reasoning performance, including model characteristics, training strategies and training data. Both AnesSuite and Morpheus will be open-sourced to the public.", "abstract": "The application of large language models (LLMs) in the medical field has garnered significant attention, yet their reasoning capabilities in more specialized domains like anesthesiology remain underexplored. To bridge this gap, we introduce AnesSuite, the first comprehensive dataset suite specifically designed for anesthesiology reasoning in LLMs. The suite features AnesBench, an evaluation benchmark tailored to assess anesthesiology-related reasoning across three levels: factual retrieval (System 1), hybrid reasoning (System 1.x), and complex decision-making (System 2).  Alongside this benchmark, the suite includes three training datasets that provide an infrastructure for continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning with verifiable rewards (RLVR). Leveraging this suite, we develop Morpheus, the first baseline model collection for anesthesiology reasoning. Despite undergoing limited training with SFT and group relative policy optimization (GRPO), Morpheus demonstrates substantial performance improvements, rivaling the performance of larger-scale models. Furthermore, through comprehensive evaluations and experiments, we analyze the key factors influencing anesthesiology reasoning performance, including model characteristics, training strategies and training data. Both AnesSuite and Morpheus will be open-sourced to the public.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=iKRQMeC7yO", "openreview_id": "iKRQMeC7yO", "openreview_forum_id": "iKRQMeC7yO", "authors": [], "pdf_url": "https://openreview.net/pdf/391df963c4b7337278d7aba3b28827644e0ce3fb.pdf", "summary_cn": "本文提出首个麻醉学推理数据集套件AnesSuite及基准模型Morpheus，通过多级评估与训练数据集提升LLMs在麻醉学领域的推理能力。", "keywords": ["麻醉学推理", "大型语言模型", "评估基准", "训练数据集", "基准模型", "性能分析"], "triple": {"method": "构建AnesSuite数据集套件与Morpheus基准模型", "result": "模型性能显著提升，媲美更大规模模型", "contribution": "填补麻醉学推理评估空白并开源资源"}}
{"venue": "ICLR", "search_title": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM", "full_title": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM", "url": "https://openreview.net/forum?id=DZeic3NpHy", "year": 2026, "is_main_conference": true, "abstract_snippet": "Advancing machine intelligence requires developing the ability to perceive across multiple modalities, much as humans sense the world. We introduce OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We carefully study the design choices across model architecture and data curation. For model architecture, we present three key innovations: (i) OmniAlignNet for strengthening alignment between vision and audio embeddings in a shared omni-modal latent space; (ii) Temporal Embedding Grouping for capturing relative temporal alignment between vision and audio signals; and (iii) Constrained Rotary Time Embedding for encoding absolute temporal information in omni-modal embeddings.\nWe introduce a curation and synthesis pipeline that generates 24M single-modal and omni-modal conversations. We find that modalities reinforce one another in both perception and reasoning. Our model, OmniVinci, improves over Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while using just 0.2T training tokens — a 6× reduction compared to Qwen2.5-Omni’s 1.2T. We finally demonstrate omni-modal advantages in downstream applications spanning robotics, medical AI, and smart factory.", "abstract": "Advancing machine intelligence requires developing the ability to perceive across multiple modalities, much as humans sense the world. We introduce OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We carefully study the design choices across model architecture and data curation. For model architecture, we present three key innovations: (i) OmniAlignNet for strengthening alignment between vision and audio embeddings in a shared omni-modal latent space; (ii) Temporal Embedding Grouping for capturing relative temporal alignment between vision and audio signals; and (iii) Constrained Rotary Time Embedding for encoding absolute temporal information in omni-modal embeddings.\nWe introduce a curation and synthesis pipeline that generates 24M single-modal and omni-modal conversations. We find that modalities reinforce one another in both perception and reasoning. Our model, OmniVinci, improves over Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while using just 0.2T training tokens — a 6× reduction compared to Qwen2.5-Omni’s 1.2T. We finally demonstrate omni-modal advantages in downstream applications spanning robotics, medical AI, and smart factory.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=DZeic3NpHy", "openreview_id": "DZeic3NpHy", "openreview_forum_id": "DZeic3NpHy", "authors": [], "pdf_url": "https://openreview.net/pdf/05e72ddc6c0d6ceb8bfb486afbf9043228c8be84.pdf", "summary_cn": "OmniVinci 是一个开源全模态大语言模型，通过架构创新（如 OmniAlignNet）和数据增强，显著提升跨模态理解能力，并在多项基准测试中超越 Qwen2.5-Omni。", "keywords": ["全模态理解", "多模态对齐", "架构创新", "数据增强", "开源模型", "跨模态基准"], "triple": {"method": "提出 OmniAlignNet 等架构创新与数据增强", "result": "在 DailyOmni 等基准上显著超越 Qwen2.5-Omni", "contribution": "构建高效开源全模态模型，推动多模态 AI 应用"}}
{"venue": "ICLR", "search_title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "full_title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains", "url": "https://openreview.net/forum?id=c1bTcrDmt4", "year": 2026, "is_main_conference": true, "abstract_snippet": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for complex reasoning tasks with clear correctness signals such as math and coding. However, extending it to real-world reasoning tasks is challenging, as evaluation depends on nuanced, multi-criteria judgments rather than binary correctness. Instance-specific rubrics have recently been used in evaluation benchmarks to capture such judgments, but their potential as reward signals for on-policy post-training remains underexplored. We introduce $\\textbf{Rubrics as Rewards (\\textit{RaR})}$, an on-policy reinforcement learning method that extends RLVR beyond verifiable domains by using rubric-based feedback. Across both medical and science domains, we evaluate multiple strategies for aggregating rubric feedback into rewards. The best RaR variant achieves relative improvements of up to 31\\% on HealthBench and 7\\% on GPQA-Diamond over popular LLM-as-judge baselines that rely on direct Likert-based rewards. These results demonstrate that RaR-trained policies adapt well to diverse evaluation formats, performing strongly on both rubric-based and multiple-choice tasks. Moreover, we find that using rubrics as structured reward signals yields better alignment for smaller judges and reduces performance variance across judge scales.", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for complex reasoning tasks with clear correctness signals such as math and coding. However, extending it to real-world reasoning tasks is challenging, as evaluation depends on nuanced, multi-criteria judgments rather than binary correctness. Instance-specific rubrics have recently been used in evaluation benchmarks to capture such judgments, but their potential as reward signals for on-policy post-training remains underexplored. We introduce $\\textbf{Rubrics as Rewards (\\textit{RaR})}$, an on-policy reinforcement learning method that extends RLVR beyond verifiable domains by using rubric-based feedback. Across both medical and science domains, we evaluate multiple strategies for aggregating rubric feedback into rewards. The best RaR variant achieves relative improvements of up to 31\\% on HealthBench and 7\\% on GPQA-Diamond over popular LLM-as-judge baselines that rely on direct Likert-based rewards. These results demonstrate that RaR-trained policies adapt well to diverse evaluation formats, performing strongly on both rubric-based and multiple-choice tasks. Moreover, we find that using rubrics as structured reward signals yields better alignment for smaller judges and reduces performance variance across judge scales.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=c1bTcrDmt4", "openreview_id": "c1bTcrDmt4", "openreview_forum_id": "c1bTcrDmt4", "authors": [], "pdf_url": "https://openreview.net/pdf/23a26288538d7d0470f2cc92f491234c3e289de8.pdf", "summary_cn": "提出Rubrics as Rewards方法，利用多标准评分规则作为奖励信号，在医学和科学领域增强强化学习，超越传统可验证奖励，提升模型性能与对齐效果。", "keywords": ["强化学习", "评分规则", "奖励信号", "医学推理", "科学推理", "模型对齐"], "triple": {"method": "使用评分规则聚合反馈作为奖励", "result": "在HealthBench和GPQA-Diamond上性能提升最高达31%和7%", "contribution": "扩展RLVR至非可验证领域，提升模型适应性与对齐"}}
{"venue": "ICLR", "search_title": "Dyslexify: A Mechanistic Defense Against Typographic Attacks in CLIP", "full_title": "Dyslexify: A Mechanistic Defense Against Typographic Attacks in CLIP", "url": "https://openreview.net/forum?id=UI7mbsIZeN", "year": 2026, "is_main_conference": true, "abstract_snippet": "Typographic attacks exploit multi-modal systems by injecting text into images, leading to targeted misclassifications, malicious content generation and even Vision-Language Model jailbreaks.\nIn this work, we analyze how CLIP vision encoders behave under typographic attacks, locating specialized attention heads in the latter half of the model's layers that causally extract and transmit typographic information to the cls token.\nBuilding on these insights, we introduce Dyslexify - a method to defend CLIP models against typographic attacks by selectively ablating a typographic circuit, consisting of attention heads. Without requiring finetuning, dyslexify improves performance by up to 22.06\\% on a typographic variant of ImageNet-100, while reducing standard ImageNet-100 accuracy by less than 1\\%, and demonstrate its utility in a medical foundation model for skin lesion diagnosis. Notably, our training-free approach remains competitive with current state-of-the-art typographic defenses that rely on finetuning. To this end, we release a family of dyslexic CLIP models which are significantly more robust against typographic attacks. These models serve as suitable drop-in replacements for a broad range of safety-critical applications, where the risks of text-based manipulation outweigh the utility of text recognition.", "abstract": "Typographic attacks exploit multi-modal systems by injecting text into images, leading to targeted misclassifications, malicious content generation and even Vision-Language Model jailbreaks.\nIn this work, we analyze how CLIP vision encoders behave under typographic attacks, locating specialized attention heads in the latter half of the model's layers that causally extract and transmit typographic information to the cls token.\nBuilding on these insights, we introduce Dyslexify - a method to defend CLIP models against typographic attacks by selectively ablating a typographic circuit, consisting of attention heads. Without requiring finetuning, dyslexify improves performance by up to 22.06\\% on a typographic variant of ImageNet-100, while reducing standard ImageNet-100 accuracy by less than 1\\%, and demonstrate its utility in a medical foundation model for skin lesion diagnosis. Notably, our training-free approach remains competitive with current state-of-the-art typographic defenses that rely on finetuning. To this end, we release a family of dyslexic CLIP models which are significantly more robust against typographic attacks. These models serve as suitable drop-in replacements for a broad range of safety-critical applications, where the risks of text-based manipulation outweigh the utility of text recognition.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=UI7mbsIZeN", "openreview_id": "UI7mbsIZeN", "openreview_forum_id": "UI7mbsIZeN", "authors": [], "pdf_url": "https://openreview.net/pdf/f311ce65d6af434c5a3feb4ff0485d201261e9e0.pdf", "summary_cn": "本文提出Dyslexify方法，通过选择性消融CLIP模型中的注意力头电路，无需微调即可有效防御排版攻击，提升模型鲁棒性，适用于医疗等安全关键领域。", "keywords": ["排版攻击", "CLIP模型", "注意力头", "防御方法", "鲁棒性", "医疗诊断"], "triple": {"method": "选择性消融注意力头电路", "result": "提升排版攻击防御性能达22.06%，标准准确率下降小于1%", "contribution": "提出无需微调的防御方法，增强模型安全性与适用性"}}
{"venue": "ICLR", "search_title": "DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction", "full_title": "DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction", "url": "https://openreview.net/forum?id=YE5scJekg5", "year": 2026, "is_main_conference": true, "abstract_snippet": "Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction. DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark nine recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527, and the codebase is open-sourced at github.com/DM4CT/DM4CT.", "abstract": "Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction. DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark nine recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527, and the codebase is open-sourced at github.com/DM4CT/DM4CT.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=YE5scJekg5", "openreview_id": "YE5scJekg5", "openreview_forum_id": "YE5scJekg5", "authors": [], "pdf_url": "https://openreview.net/pdf/6c6275f2f22d44d9ad3dc21ea1c8d7155eaed09b.pdf", "summary_cn": "DM4CT是首个评估扩散模型在CT重建中性能的基准，涵盖医学与工业数据集，并在真实实验条件下对比多种方法，揭示了扩散模型的优势与局限。", "keywords": ["扩散模型", "CT重建", "基准测试", "逆问题", "稀疏视图", "噪声配置"], "triple": {"method": "构建DM4CT基准并测试九种扩散模型与七种基线方法", "result": "系统评估了扩散模型在CT重建中的表现与挑战", "contribution": "提供首个公开的CT重建扩散模型基准与代码库"}}
{"venue": "ICLR", "search_title": "Bridging Explainability and Embeddings: BEE Aware of Spuriousness", "full_title": "Bridging Explainability and Embeddings: BEE Aware of Spuriousness", "url": "https://openreview.net/forum?id=9jYpHmI8ot", "year": 2026, "is_main_conference": true, "abstract_snippet": "Current methods for detecting spurious correlations rely on data splits or error patterns, leaving many harmful shortcuts invisible when counterexamples are absent. We introduce BEE (Bridging Explainability and Embeddings), a framework that shifts the focus from model predictions to the weight space and embedding geometry underlying decisions. By analyzing how fine-tuning perturbs pretrained representations, BEE uncovers spurious correlations that remain hidden from conventional evaluation pipelines. We use linear probing as a transparent diagnostic lens, revealing spurious features that not only persist after full fine-tuning but also transfer across diverse state-of-the-art models. Our experiments cover numerous datasets and domains: vision (Waterbirds, CelebA, ImageNet-1k), language (CivilComments, MIMIC-CXR medical notes), and multiple embedding families (CLIP, CLIP-DataComp.XL, mGTE, BLIP2, SigLIP2). \nBEE consistently exposes spurious correlations: from concepts that slash the ImageNet accuracy by up to 95\\%, to clinical shortcuts in MIMIC-CXR notes that induce dangerous false negatives. Together, these results position BEE as a general and principled tool for diagnosing spurious correlations in weight space, enabling principled dataset auditing and more trustworthy foundation models. Our code is publicly available.", "abstract": "Current methods for detecting spurious correlations rely on data splits or error patterns, leaving many harmful shortcuts invisible when counterexamples are absent. We introduce BEE (Bridging Explainability and Embeddings), a framework that shifts the focus from model predictions to the weight space and embedding geometry underlying decisions. By analyzing how fine-tuning perturbs pretrained representations, BEE uncovers spurious correlations that remain hidden from conventional evaluation pipelines. We use linear probing as a transparent diagnostic lens, revealing spurious features that not only persist after full fine-tuning but also transfer across diverse state-of-the-art models. Our experiments cover numerous datasets and domains: vision (Waterbirds, CelebA, ImageNet-1k), language (CivilComments, MIMIC-CXR medical notes), and multiple embedding families (CLIP, CLIP-DataComp.XL, mGTE, BLIP2, SigLIP2). \nBEE consistently exposes spurious correlations: from concepts that slash the ImageNet accuracy by up to 95\\%, to clinical shortcuts in MIMIC-CXR notes that induce dangerous false negatives. Together, these results position BEE as a general and principled tool for diagnosing spurious correlations in weight space, enabling principled dataset auditing and more trustworthy foundation models. Our code is publicly available.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=9jYpHmI8ot", "openreview_id": "9jYpHmI8ot", "openreview_forum_id": "9jYpHmI8ot", "authors": [], "pdf_url": "https://openreview.net/pdf/03a5029a5aab6d2b065eee5ea8c09754d1133501.pdf", "summary_cn": "BEE框架通过分析微调对预训练表示的影响，从权重空间和嵌入几何角度揭示传统方法难以检测的虚假相关性，提升模型可信度。", "keywords": ["虚假相关性检测", "权重空间分析", "嵌入几何", "线性探测", "多领域验证", "模型诊断"], "triple": {"method": "分析微调扰动预训练表示", "result": "暴露跨模型和领域的虚假相关性", "contribution": "提供通用诊断工具增强模型可信度"}}
{"venue": "ICLR", "search_title": "Graph Mixing Additive Networks", "full_title": "Graph Mixing Additive Networks", "url": "https://openreview.net/forum?id=1MVeSLvfxU", "year": 2026, "is_main_conference": true, "abstract_snippet": "Real-world temporal data often consists of multiple signal types recorded at irregular, asynchronous intervals. For instance, in the medical domain, different types of blood tests can be measured at different times and frequencies, resulting in fragmented and unevenly scattered temporal data. Similar issues of irregular sampling occur in other domains, such as the monitoring of large systems using event log files. Effectively learning from such data requires handling sets of temporally sparse and heterogeneous signals. In this work, we propose Graph Mixing Additive Networks (GMAN), a novel and interpretable-by-design framework for learning directly from sets of graphs that represent such signals.\nGMAN provides diverse interpretability capabilities, including node-level, graph-level, and subset-level importance, and enables practitioners to trade finer-grained interpretability for greater expressivity when domain priors are available.\nGMAN achieves state-of-the-art performance in real-world high-stakes tasks, including predicting Crohn’s disease onset and hospital length of stay from routine blood test measurements and detecting fake news. Furthermore, we demonstrate how GMAN’s interpretability properties assist in revealing disease development phase transitions and provide crucial insights in the healthcare domain.", "abstract": "Real-world temporal data often consists of multiple signal types recorded at irregular, asynchronous intervals. For instance, in the medical domain, different types of blood tests can be measured at different times and frequencies, resulting in fragmented and unevenly scattered temporal data. Similar issues of irregular sampling occur in other domains, such as the monitoring of large systems using event log files. Effectively learning from such data requires handling sets of temporally sparse and heterogeneous signals. In this work, we propose Graph Mixing Additive Networks (GMAN), a novel and interpretable-by-design framework for learning directly from sets of graphs that represent such signals.\nGMAN provides diverse interpretability capabilities, including node-level, graph-level, and subset-level importance, and enables practitioners to trade finer-grained interpretability for greater expressivity when domain priors are available.\nGMAN achieves state-of-the-art performance in real-world high-stakes tasks, including predicting Crohn’s disease onset and hospital length of stay from routine blood test measurements and detecting fake news. Furthermore, we demonstrate how GMAN’s interpretability properties assist in revealing disease development phase transitions and provide crucial insights in the healthcare domain.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=1MVeSLvfxU", "openreview_id": "1MVeSLvfxU", "openreview_forum_id": "1MVeSLvfxU", "authors": [], "pdf_url": "https://openreview.net/pdf/7483164e7820c8dc23497c33c292b4571c032a13.pdf", "summary_cn": "提出GMAN框架，处理不规则异步时序数据，实现高精度预测与多级可解释性，应用于克罗恩病预测等任务。", "keywords": ["图神经网络", "可解释性", "时序数据", "医疗预测", "异步采样", "GMAN"], "triple": {"method": "图混合加性网络", "result": "在疾病预测等任务中达到最优性能", "contribution": "提供多级可解释性框架"}}
{"venue": "ICLR", "search_title": "Reconstruct Anything Model a lightweight foundation model for computational imaging", "full_title": "Reconstruct Anything Model a lightweight foundation model for computational imaging", "url": "https://openreview.net/forum?id=Ks9zNS6OsU", "year": 2026, "is_main_conference": true, "abstract_snippet": "Most existing learning-based methods for solving imaging inverse problems can be roughly divided into two classes: iterative algorithms, such as plug-and-play and diffusion methods leveraging pretrained denoisers, and unrolled architectures that are trained end-to-end for specific imaging problems. Iterative methods in the first class are computationally costly and often yield suboptimal reconstruction performance, whereas unrolled architectures are generally problem-specific and require expensive training. In this work, we propose a novel non-iterative, lightweight architecture that incorporates knowledge about the forward operator (acquisition physics and noise parameters) without relying on unrolling. Our model is trained to solve a wide range of inverse problems, such as deblurring, magnetic resonance imaging, computed tomography, inpainting, and super-resolution, and works on arbitrary image sizes and channels, such as grayscale, complex, and color data. The proposed model can be easily adapted to unseen inverse problems or datasets with a few fine-tuning steps (up to a few images) in a self-supervised way, without ground-truth references. Throughout a series of experiments, we demonstrate state-of-the-art performance from medical imaging to low-photon imaging and microscopy.", "abstract": "Most existing learning-based methods for solving imaging inverse problems can be roughly divided into two classes: iterative algorithms, such as plug-and-play and diffusion methods leveraging pretrained denoisers, and unrolled architectures that are trained end-to-end for specific imaging problems. Iterative methods in the first class are computationally costly and often yield suboptimal reconstruction performance, whereas unrolled architectures are generally problem-specific and require expensive training. In this work, we propose a novel non-iterative, lightweight architecture that incorporates knowledge about the forward operator (acquisition physics and noise parameters) without relying on unrolling. Our model is trained to solve a wide range of inverse problems, such as deblurring, magnetic resonance imaging, computed tomography, inpainting, and super-resolution, and works on arbitrary image sizes and channels, such as grayscale, complex, and color data. The proposed model can be easily adapted to unseen inverse problems or datasets with a few fine-tuning steps (up to a few images) in a self-supervised way, without ground-truth references. Throughout a series of experiments, we demonstrate state-of-the-art performance from medical imaging to low-photon imaging and microscopy.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=Ks9zNS6OsU", "openreview_id": "Ks9zNS6OsU", "openreview_forum_id": "Ks9zNS6OsU", "authors": [], "pdf_url": "https://openreview.net/pdf/b598ec18508dee145086208097886ddc8bc7c1cf.pdf", "summary_cn": "提出一种轻量级非迭代模型，用于解决多种成像逆问题，无需展开训练，可快速适应新任务，在医学成像等领域达到先进性能。", "keywords": ["计算成像", "逆问题", "轻量级模型", "非迭代方法", "自监督适应", "多任务学习"], "triple": {"method": "非迭代轻量架构结合前向算子知识", "result": "在去模糊、MRI等多任务中实现先进性能", "contribution": "提供通用、高效且易适应的成像重建方案"}}
{"venue": "ICLR", "search_title": "A Framework for Studying AI Agent Behavior: Evidence from Consumer Choice Experiments", "full_title": "A Framework for Studying AI Agent Behavior: Evidence from Consumer Choice Experiments", "url": "https://openreview.net/forum?id=xAPoscV2Bw", "year": 2026, "is_main_conference": true, "abstract_snippet": "Environments built for people are increasingly operated by a new class of economic actors: LLM-powered software agents making decisions on our behalf. These decisions range from our purchases to travel plans to medical treatment selection. Current evaluations of these agents largely focus on task competence, but we argue for a deeper assessment: how these agents choose when faced with realistic decisions. We introduce ABxLab, a framework for systematically probing agentic choice through controlled manipulations of option attributes and persuasive cues. We apply this to a realistic web-based shopping environment, where we vary prices, ratings, and psychological nudges, all of which are factors long known to shape human choice. We find that agent decisions shift predictably and substantially in response, revealing that agents are strongly biased choosers even without being subject to the cognitive constraints that shape human biases. This susceptibility reveals both risk and opportunity: risk, because agentic consumers may inherit and amplify human biases; opportunity, because consumer choice provides a powerful testbed for a behavioral science of AI agents, just as it has for the study of human behavior. We release our framework as an open benchmark for rigorous, scalable evaluation of agent decision-making.", "abstract": "Environments built for people are increasingly operated by a new class of economic actors: LLM-powered software agents making decisions on our behalf. These decisions range from our purchases to travel plans to medical treatment selection. Current evaluations of these agents largely focus on task competence, but we argue for a deeper assessment: how these agents choose when faced with realistic decisions. We introduce ABxLab, a framework for systematically probing agentic choice through controlled manipulations of option attributes and persuasive cues. We apply this to a realistic web-based shopping environment, where we vary prices, ratings, and psychological nudges, all of which are factors long known to shape human choice. We find that agent decisions shift predictably and substantially in response, revealing that agents are strongly biased choosers even without being subject to the cognitive constraints that shape human biases. This susceptibility reveals both risk and opportunity: risk, because agentic consumers may inherit and amplify human biases; opportunity, because consumer choice provides a powerful testbed for a behavioral science of AI agents, just as it has for the study of human behavior. We release our framework as an open benchmark for rigorous, scalable evaluation of agent decision-making.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=xAPoscV2Bw", "openreview_id": "xAPoscV2Bw", "openreview_forum_id": "xAPoscV2Bw", "authors": [], "pdf_url": "https://openreview.net/pdf/2f9583f480b2003218311f67eb597e890b3ed65a.pdf", "summary_cn": "提出ABxLab框架，通过操控选项属性和说服线索，在模拟购物环境中评估AI代理决策行为，发现其易受偏见影响，为AI行为科学提供测试基准。", "keywords": ["AI代理", "消费者选择", "行为偏见", "决策评估", "ABxLab框架", "心理暗示"], "triple": {"method": "ABxLab框架操控价格、评分和暗示", "result": "代理决策显著受偏见影响", "contribution": "为AI行为科学提供可扩展评估基准"}}
{"venue": "ICLR", "search_title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "full_title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "url": "https://openreview.net/forum?id=TpbhS1yfz0", "year": 2026, "is_main_conference": true, "abstract_snippet": "Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing.\nHowever, variability in channel dimensionality and captured wavelengths among spectral cameras impede the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability.\nTo address this bottleneck, we introduce CARL, a model for Camera-Agnostic Representation Learning across RGB, multispectral, and hyperspectral imaging modalities.\nTo enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic representation, we introduce a novel spectral encoder, featuring a self-attention-cross-attention mechanism, to distill salient spectral information into learned spectral representations.\nSpatio-spectral pre-training is achieved with a novel feature-based self-supervision strategy tailored to CARL. \nLarge-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. \nThe scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.", "abstract": "Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing.\nHowever, variability in channel dimensionality and captured wavelengths among spectral cameras impede the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability.\nTo address this bottleneck, we introduce CARL, a model for Camera-Agnostic Representation Learning across RGB, multispectral, and hyperspectral imaging modalities.\nTo enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic representation, we introduce a novel spectral encoder, featuring a self-attention-cross-attention mechanism, to distill salient spectral information into learned spectral representations.\nSpatio-spectral pre-training is achieved with a novel feature-based self-supervision strategy tailored to CARL. \nLarge-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. \nThe scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=TpbhS1yfz0", "openreview_id": "TpbhS1yfz0", "openreview_forum_id": "TpbhS1yfz0", "authors": [], "pdf_url": "https://openreview.net/pdf/0ee89a85fe26f6258b772102894b094c572577df.pdf", "summary_cn": "CARL提出相机无关表示学习方法，通过自注意力-交叉注意力机制编码光谱图像，实现跨RGB、多光谱和高光谱模态的通用表示，提升模型在医学、自动驾驶和卫星成像中的泛化能力。", "keywords": ["光谱成像", "相机无关表示", "自注意力机制", "跨模态学习", "泛化能力", "预训练策略"], "triple": {"method": "自注意力-交叉注意力编码器与特征自监督预训练", "result": "在模拟和真实跨相机光谱变化数据上表现优异", "contribution": "为光谱基础模型提供可扩展骨干网络"}}
{"venue": "ICLR", "search_title": "Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine", "full_title": "Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine", "url": "https://openreview.net/forum?id=w025bYRVkO", "year": 2026, "is_main_conference": true, "abstract_snippet": "The goal of personalized medicine is to discover a treatment regimen that optimizes a patient's clinical outcome based on their personal genetic and environmental factors. However, candidate treatments cannot be arbitrarily administered to the patient to assess their efficacy; we often instead have access to an *in silico* surrogate model that approximates the true fitness of a proposed treatment. Unfortunately, such surrogate models have been shown to fail to generalize to previously unseen patient-treatment combinations. We hypothesize that domain-specific prior knowledge—such as medical textbooks and biomedical knowledge graphs—can provide a meaningful alternative signal of the fitness of proposed treatments. To this end, we introduce **L**LM-based **E**ntropy-guided **O**ptimization with k**N**owledgeable priors (**LEON**), a mathematically principled approach to leverage large language models (LLMs) as black-box optimizers without any task-specific fine-tuning, taking advantage of their ability to contextualize unstructured domain knowledge to propose personalized treatment plans in natural language. In practice, we implement LEON via 'optimization by prompting,' which uses LLMs as stochastic engines for proposing treatment designs. Experiments on real-world optimization tasks show LEON outperforms both traditional and LLM-based methods in proposing individualized treatments for patients.", "abstract": "The goal of personalized medicine is to discover a treatment regimen that optimizes a patient's clinical outcome based on their personal genetic and environmental factors. However, candidate treatments cannot be arbitrarily administered to the patient to assess their efficacy; we often instead have access to an *in silico* surrogate model that approximates the true fitness of a proposed treatment. Unfortunately, such surrogate models have been shown to fail to generalize to previously unseen patient-treatment combinations. We hypothesize that domain-specific prior knowledge—such as medical textbooks and biomedical knowledge graphs—can provide a meaningful alternative signal of the fitness of proposed treatments. To this end, we introduce **L**LM-based **E**ntropy-guided **O**ptimization with k**N**owledgeable priors (**LEON**), a mathematically principled approach to leverage large language models (LLMs) as black-box optimizers without any task-specific fine-tuning, taking advantage of their ability to contextualize unstructured domain knowledge to propose personalized treatment plans in natural language. In practice, we implement LEON via 'optimization by prompting,' which uses LLMs as stochastic engines for proposing treatment designs. Experiments on real-world optimization tasks show LEON outperforms both traditional and LLM-based methods in proposing individualized treatments for patients.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=w025bYRVkO", "openreview_id": "w025bYRVkO", "openreview_forum_id": "w025bYRVkO", "authors": [], "pdf_url": "https://openreview.net/pdf/277ab901ee761247b3ff6acd2281d287a593724f.pdf", "summary_cn": "本文提出LEON方法，利用大型语言模型作为黑盒优化器，结合医学知识，无需微调即可生成个性化治疗方案，实验显示其优于传统方法。", "keywords": ["个性化医疗", "大型语言模型", "黑盒优化", "知识先验", "治疗计划", "自然语言处理"], "triple": {"method": "基于提示的优化，利用LLM作为随机引擎", "result": "在真实优化任务中优于传统和LLM方法", "contribution": "提出LEON框架，结合知识先验提升个性化治疗设计"}}
{"venue": "ICLR", "search_title": "Anchored Supervised Fine-Tuning", "full_title": "Anchored Supervised Fine-Tuning", "url": "https://openreview.net/forum?id=PORko7QT64", "year": 2026, "is_main_conference": true, "abstract_snippet": "Post-training of large language models involves a fundamental trade-off between\nsupervised fine-tuning (SFT), which efficiently mimics demonstrations but tends\nto memorize, and reinforcement learning (RL), which achieves better generaliza-\ntion at higher computational cost. Dynamic Fine-Tuning (DFT) recently emerged\nas a promising middle ground, reweighting SFT objectives with token probabili-\nties and achieving improvements in certain reasoning domains, though it exhibits\ninstability in other tasks. We provide a analysis of DFT through the reward-\nweighted regression (RWR) framework, revealing that it corresponds to a spe-\ncific auxiliary distribution choice that yields provably tighter RL bounds than\nstandard SFT. However, our analysis also uncovers a critical limitation: this con-\nstruction lacks distributional anchoring, leading to progressive drift that under-\nmines training stability. To address this, we propose Anchored Supervised Fine-\nTuning (ASFT), which augments DFT’s reweighting with lightweight KL regu-\nlarization to preserve tightness while ensuring stability. Empirically, ASFT con-\nsistently outperforms both SFT and DFT across mathematical reasoning, medical\nknowledge grounding, and code generation, achieving substantial improvements\nwith minimal computational overhead. Our RWR framework provides a system-\natic lens for understanding post-training methods and demonstrates that principled\ntheoretical analysis leads to both stronger guarantees and practical gains.", "abstract": "Post-training of large language models involves a fundamental trade-off between\nsupervised fine-tuning (SFT), which efficiently mimics demonstrations but tends\nto memorize, and reinforcement learning (RL), which achieves better generaliza-\ntion at higher computational cost. Dynamic Fine-Tuning (DFT) recently emerged\nas a promising middle ground, reweighting SFT objectives with token probabili-\nties and achieving improvements in certain reasoning domains, though it exhibits\ninstability in other tasks. We provide a analysis of DFT through the reward-\nweighted regression (RWR) framework, revealing that it corresponds to a spe-\ncific auxiliary distribution choice that yields provably tighter RL bounds than\nstandard SFT. However, our analysis also uncovers a critical limitation: this con-\nstruction lacks distributional anchoring, leading to progressive drift that under-\nmines training stability. To address this, we propose Anchored Supervised Fine-\nTuning (ASFT), which augments DFT’s reweighting with lightweight KL regu-\nlarization to preserve tightness while ensuring stability. Empirically, ASFT con-\nsistently outperforms both SFT and DFT across mathematical reasoning, medical\nknowledge grounding, and code generation, achieving substantial improvements\nwith minimal computational overhead. Our RWR framework provides a system-\natic lens for understanding post-training methods and demonstrates that principled\ntheoretical analysis leads to both stronger guarantees and practical gains.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=PORko7QT64", "openreview_id": "PORko7QT64", "openreview_forum_id": "PORko7QT64", "authors": [], "pdf_url": "https://openreview.net/pdf/204901b4e4fccd37b35834fefde1883f634b2682.pdf", "summary_cn": "提出锚定监督微调（ASFT），通过KL正则化增强动态微调，解决训练不稳定问题，在数学推理、医学知识和代码生成任务中优于SFT和DFT。", "keywords": ["锚定监督微调", "动态微调", "KL正则化", "奖励加权回归", "训练稳定性", "后训练方法"], "triple": {"method": "ASFT（带KL正则化的动态微调）", "result": "在多项任务中优于SFT和DFT", "contribution": "提升训练稳定性与性能"}}
{"venue": "ICLR", "search_title": "Detecting Invariant Manifolds in ReLU-Based RNNs", "full_title": "Detecting Invariant Manifolds in ReLU-Based RNNs", "url": "https://openreview.net/forum?id=EAwLAwHvhk", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recurrent Neural Networks (RNNs) have found widespread applications in machine learning for time series prediction and dynamical systems reconstruction, and experienced a recent renaissance with improved training algorithms and architectural designs. Understanding why and how trained RNNs produce their behavior is important for scientific and medical applications, and explainable AI more generally. An RNN's dynamical repertoire depends on the topological and geometrical properties of its state space. Stable and unstable manifolds of periodic points play a particularly important role: They dissect a dynamical system's state space into different basins of attraction, and their intersections lead to chaotic dynamics with fractal geometry. Here we introduce a novel algorithm for detecting these manifolds, with a focus on piecewise-linear RNNs (PLRNNs) employing rectified linear units (ReLUs) as their activation function. We demonstrate how the algorithm can be used to trace the boundaries between different basins of attraction, and hence to characterize multistability, a computationally important property. We further show its utility in finding so-called homoclinic points, the intersections between stable and unstable manifolds, and thus establish the existence of chaos in PLRNNs. Finally we show for an empirical example, electrophysiological recordings from a cortical neuron, how insights into the underlying dynamics could be gained through our method.", "abstract": "Recurrent Neural Networks (RNNs) have found widespread applications in machine learning for time series prediction and dynamical systems reconstruction, and experienced a recent renaissance with improved training algorithms and architectural designs. Understanding why and how trained RNNs produce their behavior is important for scientific and medical applications, and explainable AI more generally. An RNN's dynamical repertoire depends on the topological and geometrical properties of its state space. Stable and unstable manifolds of periodic points play a particularly important role: They dissect a dynamical system's state space into different basins of attraction, and their intersections lead to chaotic dynamics with fractal geometry. Here we introduce a novel algorithm for detecting these manifolds, with a focus on piecewise-linear RNNs (PLRNNs) employing rectified linear units (ReLUs) as their activation function. We demonstrate how the algorithm can be used to trace the boundaries between different basins of attraction, and hence to characterize multistability, a computationally important property. We further show its utility in finding so-called homoclinic points, the intersections between stable and unstable manifolds, and thus establish the existence of chaos in PLRNNs. Finally we show for an empirical example, electrophysiological recordings from a cortical neuron, how insights into the underlying dynamics could be gained through our method.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=EAwLAwHvhk", "openreview_id": "EAwLAwHvhk", "openreview_forum_id": "EAwLAwHvhk", "authors": [], "pdf_url": "https://openreview.net/pdf/dd9f88fecc0cf41fba41d05d28d22219b516df24.pdf", "summary_cn": "提出新算法检测ReLU循环神经网络中的不变流形，用于刻画多稳态和混沌，并应用于神经元电生理数据分析。", "keywords": ["循环神经网络", "不变流形", "多稳态", "混沌", "ReLU", "动力学分析"], "triple": {"method": "新算法检测不变流形", "result": "刻画多稳态与混沌", "contribution": "提供RNN动力学解释工具"}}
{"venue": "ICLR", "search_title": "GradPruner: Gradient-guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs", "full_title": "GradPruner: Gradient-guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs", "url": "https://openreview.net/forum?id=bxzJorqyYM", "year": 2026, "is_main_conference": true, "abstract_snippet": "Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight well-known datasets in downstream tasks. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is available at https://anonymous.4open.science/r/LLM-GradPrune-436D.", "abstract": "Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight well-known datasets in downstream tasks. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is available at https://anonymous.4open.science/r/LLM-GradPrune-436D.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=bxzJorqyYM", "openreview_id": "bxzJorqyYM", "openreview_forum_id": "bxzJorqyYM", "authors": [], "pdf_url": "https://openreview.net/pdf/4e3497f23d35e926fccfad5cc046a52900589fd2.pdf", "summary_cn": "GradPruner通过梯度引导层剪枝，在微调早期评估层重要性，合并同符号元素，提升LLMs训练与推理效率，参数减少40%仅精度下降0.99%。", "keywords": ["梯度引导剪枝", "层重要性评估", "高效微调", "推理加速", "参数减少", "LLMs优化"], "triple": {"method": "基于初始梯度信息累积矩阵评估层重要性并剪枝合并", "result": "参数减少40%，精度仅下降0.99%", "contribution": "同时提升LLMs下游任务训练与推理效率"}}
{"venue": "ICLR", "search_title": "CUPID: A Plug-in Framework for Joint Aleatoric and Epistemic Uncertainty Estimation with a Single Model", "full_title": "CUPID: A Plug-in Framework for Joint Aleatoric and Epistemic Uncertainty Estimation with a Single Model", "url": "https://openreview.net/forum?id=nF81AkEzXg", "year": 2026, "is_main_conference": true, "abstract_snippet": "Accurate estimation of uncertainty in deep learning is critical for deploying models in high-stakes domains such as medical diagnosis and autonomous decision-making, where overconfident predictions can lead to harmful outcomes. In practice, understanding the reason behind a model’s uncertainty and the type of uncertainty it represents can support risk-aware decisions, enhance user trust, and guide additional data collection. However, many existing methods only address a single type of uncertainty or require modifications and retraining of the base model, making them difficult to adopt in real-world systems. We introduce CUPID (Comprehensive Uncertainty Plug-in estImation moDel), a general-purpose module that jointly estimates aleatoric and epistemic uncertainty without modifying or retraining the base model. CUPID can be flexibly inserted into any layer of a pretrained network. It models aleatoric uncertainty through a learned Bayesian identity mapping and captures epistemic uncertainty by analyzing the model’s internal responses to structured perturbations. We evaluate CUPID across a range of tasks, including classification, regression, and out-of-distribution detection. The results show that it consistently delivers competitive performance while offering layer-wise insights into the origins of uncertainty. By making uncertainty estimation modular, interpretable, and model-agnostic, CUPID supports more transparent and trustworthy AI.", "abstract": "Accurate estimation of uncertainty in deep learning is critical for deploying models in high-stakes domains such as medical diagnosis and autonomous decision-making, where overconfident predictions can lead to harmful outcomes. In practice, understanding the reason behind a model’s uncertainty and the type of uncertainty it represents can support risk-aware decisions, enhance user trust, and guide additional data collection. However, many existing methods only address a single type of uncertainty or require modifications and retraining of the base model, making them difficult to adopt in real-world systems. We introduce CUPID (Comprehensive Uncertainty Plug-in estImation moDel), a general-purpose module that jointly estimates aleatoric and epistemic uncertainty without modifying or retraining the base model. CUPID can be flexibly inserted into any layer of a pretrained network. It models aleatoric uncertainty through a learned Bayesian identity mapping and captures epistemic uncertainty by analyzing the model’s internal responses to structured perturbations. We evaluate CUPID across a range of tasks, including classification, regression, and out-of-distribution detection. The results show that it consistently delivers competitive performance while offering layer-wise insights into the origins of uncertainty. By making uncertainty estimation modular, interpretable, and model-agnostic, CUPID supports more transparent and trustworthy AI.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=nF81AkEzXg", "openreview_id": "nF81AkEzXg", "openreview_forum_id": "nF81AkEzXg", "authors": [], "pdf_url": "https://openreview.net/pdf/88f150e26308fbee588017b02f97ebbe013cdbb3.pdf", "summary_cn": "CUPID是一种无需修改或重训练基础模型的插件框架，可联合估计任意和认知不确定性，提升AI透明度和可信度。", "keywords": ["不确定性估计", "插件框架", "贝叶斯学习", "模型不可知", "可解释AI", "深度学习"], "triple": {"method": "贝叶斯恒等映射与结构化扰动分析", "result": "在分类、回归等任务中表现优异，提供层级不确定性洞察", "contribution": "实现模块化、可解释的联合不确定性估计"}}
{"venue": "ICLR", "search_title": "ExpGuard: LLM Content Moderation in Specialized Domains", "full_title": "ExpGuard: LLM Content Moderation in Specialized Domains", "url": "https://openreview.net/forum?id=t5cYJlV6aJ", "year": 2026, "is_main_conference": true, "abstract_snippet": "With the growing deployment of large language models (LLMs) in real-world applications, establishing robust safety guardrails to moderate their inputs and outputs has become essential to ensure adherence to safety policies. Current guardrail models predominantly address general human-LLM interactions, rendering LLMs vulnerable to harmful and adversarial content within domain-specific contexts, particularly those rich in technical jargon and specialized concepts. To address this limitation, we introduce ExpGuard, a robust and specialized guardrail model designed to protect against harmful prompts and responses across financial, medical, and legal domains. In addition, we present ExpGuardMix, a meticulously curated dataset comprising 58,928 labeled prompts paired with corresponding refusal and compliant responses, from these specific sectors. This dataset is divided into two subsets: ExpGuardTrain, for model training, and ExpGuardTest, a high-quality test set annotated by domain experts to evaluate model robustness against technical and domain-specific content. Comprehensive evaluations conducted on ExpGuardTest and eight established public benchmarks reveal that ExpGuard delivers competitive performance across the board while demonstrating exceptional resilience to domain-specific adversarial attacks, surpassing state-of-the-art models such as WildGuard by up to 8.9% in prompt classification and 15.3% in response classification. To encourage further research and development, we open-source our code, data, and model, enabling adaptation to additional domains and supporting the creation of increasingly robust guardrail models.", "abstract": "With the growing deployment of large language models (LLMs) in real-world applications, establishing robust safety guardrails to moderate their inputs and outputs has become essential to ensure adherence to safety policies. Current guardrail models predominantly address general human-LLM interactions, rendering LLMs vulnerable to harmful and adversarial content within domain-specific contexts, particularly those rich in technical jargon and specialized concepts. To address this limitation, we introduce ExpGuard, a robust and specialized guardrail model designed to protect against harmful prompts and responses across financial, medical, and legal domains. In addition, we present ExpGuardMix, a meticulously curated dataset comprising 58,928 labeled prompts paired with corresponding refusal and compliant responses, from these specific sectors. This dataset is divided into two subsets: ExpGuardTrain, for model training, and ExpGuardTest, a high-quality test set annotated by domain experts to evaluate model robustness against technical and domain-specific content. Comprehensive evaluations conducted on ExpGuardTest and eight established public benchmarks reveal that ExpGuard delivers competitive performance across the board while demonstrating exceptional resilience to domain-specific adversarial attacks, surpassing state-of-the-art models such as WildGuard by up to 8.9% in prompt classification and 15.3% in response classification. To encourage further research and development, we open-source our code, data, and model, enabling adaptation to additional domains and supporting the creation of increasingly robust guardrail models.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=t5cYJlV6aJ", "openreview_id": "t5cYJlV6aJ", "openreview_forum_id": "t5cYJlV6aJ", "authors": [], "pdf_url": "https://openreview.net/pdf/b53f1e78e0bf8325ca73d98dc307ca27eaec61ec.pdf", "summary_cn": "ExpGuard是针对金融、医疗和法律等专业领域设计的LLM内容审核模型，通过ExpGuardMix数据集提升对有害提示和响应的检测能力，在领域特定对抗攻击中表现优异。", "keywords": ["内容审核", "专业领域", "对抗攻击", "数据集", "大语言模型", "安全防护"], "triple": {"method": "构建ExpGuardMix数据集并训练ExpGuard模型", "result": "在领域特定对抗攻击中超越现有模型，提升分类性能", "contribution": "提供开源代码、数据和模型，增强专业领域LLM安全防护"}}
{"venue": "ICLR", "search_title": "Learning Human Habits with Rule-Guided Active Inference", "full_title": "Learning Human Habits with Rule-Guided Active Inference", "url": "https://openreview.net/forum?id=FZXwkBH6s7", "year": 2026, "is_main_conference": true, "abstract_snippet": "Humans navigate daily life by combining two modes of behavior: deliberate planning in novel situations and fast, automatic responses in familiar ones. Modeling human decision-making therefore requires capturing how people switch between these modes. We present a framework for learning human habits with rule-guided active inference, extending the view of the brain as a prediction machine that minimizes mismatches between expectations and observations, and computationally modeling of human(-like) behavior and habits. In our approach, habits emerge as symbolic rules that serve as compact, interpretable shortcuts for action. To learn these rules alongside the human models, we design a biologically inspired wake--sleep algorithm. In the wake phase, the agent engages in active inference on real trajectories: reconstructing states, updating beliefs, and harvesting candidate rules that reliably reduce free energy. In the sleep phase, the agent performs generative replay with its world model, refining parameters and consolidating or pruning rules by minimizing joint free energy. This alternating rule–model consolidation lets the agent build a reusable habit library while preserving the flexibility to plan. Experiments on basketball player movements, car-following behavior, medical diagnosis, and visual game strategy demonstrate that our framework improves predictive accuracy and efficiency compared to logic-based, deep learning, LLM-based, model-based RL, and prior active inference baselines, while producing interpretable rules that mirror human-like habits.", "abstract": "Humans navigate daily life by combining two modes of behavior: deliberate planning in novel situations and fast, automatic responses in familiar ones. Modeling human decision-making therefore requires capturing how people switch between these modes. We present a framework for learning human habits with rule-guided active inference, extending the view of the brain as a prediction machine that minimizes mismatches between expectations and observations, and computationally modeling of human(-like) behavior and habits. In our approach, habits emerge as symbolic rules that serve as compact, interpretable shortcuts for action. To learn these rules alongside the human models, we design a biologically inspired wake--sleep algorithm. In the wake phase, the agent engages in active inference on real trajectories: reconstructing states, updating beliefs, and harvesting candidate rules that reliably reduce free energy. In the sleep phase, the agent performs generative replay with its world model, refining parameters and consolidating or pruning rules by minimizing joint free energy. This alternating rule–model consolidation lets the agent build a reusable habit library while preserving the flexibility to plan. Experiments on basketball player movements, car-following behavior, medical diagnosis, and visual game strategy demonstrate that our framework improves predictive accuracy and efficiency compared to logic-based, deep learning, LLM-based, model-based RL, and prior active inference baselines, while producing interpretable rules that mirror human-like habits.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=FZXwkBH6s7", "openreview_id": "FZXwkBH6s7", "openreview_forum_id": "FZXwkBH6s7", "authors": [], "pdf_url": "https://openreview.net/pdf/e69a41007b896411d39fd7fdb11d986754428027.pdf", "summary_cn": "提出基于规则引导主动推理的框架，通过醒-睡算法学习人类习惯，生成可解释的符号规则，提升行为预测的准确性和效率。", "keywords": ["主动推理", "习惯学习", "符号规则", "醒-睡算法", "行为建模", "可解释性"], "triple": {"method": "规则引导的主动推理与醒-睡算法", "result": "预测准确性提升，生成可解释习惯规则", "contribution": "统一习惯与规划，增强模型解释性"}}
{"venue": "ICLR", "search_title": "MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval", "full_title": "MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval", "url": "https://openreview.net/forum?id=TQkFiW3AEX", "year": 2026, "is_main_conference": true, "abstract_snippet": "Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF,  freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. Code will be released.", "abstract": "Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF,  freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. Code will be released.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=TQkFiW3AEX", "openreview_id": "TQkFiW3AEX", "openreview_forum_id": "TQkFiW3AEX", "authors": [], "pdf_url": "https://openreview.net/pdf/8840201e27712169511414aa1dae07ebb96a38cf.pdf", "summary_cn": "提出MRAD框架，通过记忆检索实现零样本异常检测，无需训练或仅需轻量微调，在16个数据集上表现优异。", "keywords": ["零样本异常检测", "记忆检索", "CLIP模型", "无训练方法", "跨域稳定性", "工业与医疗应用"], "triple": {"method": "构建两级记忆库进行相似性检索", "result": "在16个数据集上实现优越的异常分类与分割性能", "contribution": "提出非参数化框架，提升跨域稳定性和检测效果"}}
{"venue": "ICLR", "search_title": "Rethinking Expressivity and Degradation-Awareness in Attention for All-in-One Blind Image Restoration", "full_title": "Rethinking Expressivity and Degradation-Awareness in Attention for All-in-One Blind Image Restoration", "url": "https://openreview.net/forum?id=IBzmQVia88", "year": 2026, "is_main_conference": true, "abstract_snippet": "All-in-one image restoration (IR) aims to recover high-quality images from diverse degradations, which in real-world settings are often mixed and unknown. Unlike single-task IR, this problem requires a model to approximate a family of heterogeneous inverse functions, making it fundamentally more challenging and practically important. Although recent focus has shifted toward large multimodal models, their robustness still depends on faithful low-level inputs, and the principles that govern effective restoration remain underexplored. We revisit attention mechanisms through the lens of all-in-one IR and identify two overlooked bottlenecks in widely adopted Restormer-style backbones: \\textit{(i) the value path remains purely linear}, restricting outputs to the span of inputs and weakening expressivity, and \\textit{(ii) the absence of an explicit global slot} prevents attention from encoding degradation context. To address these issues, we propose two minimal, backbone-agnostic primitives: a nonlinear value transform that upgrades attention from a selector to a selector–transformer, and a global spatial token that provides an explicit degradation-aware slot. Together, these additions improve restoration across synthetic, mixed, underwater, and medical benchmarks, with negligible overhead and consistent performance gains. Analyses with foundation model embeddings, spectral statistics, and separability measures further clarify their roles, positioning our study as a step toward rethinking attention primitives for robust all-in-one IR.", "abstract": "All-in-one image restoration (IR) aims to recover high-quality images from diverse degradations, which in real-world settings are often mixed and unknown. Unlike single-task IR, this problem requires a model to approximate a family of heterogeneous inverse functions, making it fundamentally more challenging and practically important. Although recent focus has shifted toward large multimodal models, their robustness still depends on faithful low-level inputs, and the principles that govern effective restoration remain underexplored. We revisit attention mechanisms through the lens of all-in-one IR and identify two overlooked bottlenecks in widely adopted Restormer-style backbones: \\textit{(i) the value path remains purely linear}, restricting outputs to the span of inputs and weakening expressivity, and \\textit{(ii) the absence of an explicit global slot} prevents attention from encoding degradation context. To address these issues, we propose two minimal, backbone-agnostic primitives: a nonlinear value transform that upgrades attention from a selector to a selector–transformer, and a global spatial token that provides an explicit degradation-aware slot. Together, these additions improve restoration across synthetic, mixed, underwater, and medical benchmarks, with negligible overhead and consistent performance gains. Analyses with foundation model embeddings, spectral statistics, and separability measures further clarify their roles, positioning our study as a step toward rethinking attention primitives for robust all-in-one IR.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=IBzmQVia88", "openreview_id": "IBzmQVia88", "openreview_forum_id": "IBzmQVia88", "authors": [], "pdf_url": "https://openreview.net/pdf/19fc7a687b32ff4c8f6a30a30621e07bbeb9b010.pdf", "summary_cn": "本文针对全盲图像修复中注意力机制的局限性，提出非线性值变换和全局空间标记，提升模型表达力和退化感知能力，在多种基准测试中取得显著改进。", "keywords": ["全盲图像修复", "注意力机制", "非线性变换", "退化感知", "表达力", "全局标记"], "triple": {"method": "引入非线性值变换和全局空间标记", "result": "在合成、混合、水下和医学基准测试中提升修复效果", "contribution": "增强注意力机制的表达力和退化感知能力"}}
{"venue": "ICLR", "search_title": "Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification", "full_title": "Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification", "url": "https://openreview.net/forum?id=PWhDUWRVhM", "year": 2026, "is_main_conference": true, "abstract_snippet": "Multimodal deep learning (MDL) has achieved remarkable success across various domains, yet its practical deployment is often hindered by incomplete multimodal data. Existing incomplete MDL methods either discard missing modalities, risking the loss of valuable task-relevant information, or recover them, potentially introducing irrelevant noise, leading to the discarding-imputation dilemma. To address this dilemma, in this paper, we propose DyMo, a new inference-time dynamic modality selection framework that adaptively identifies and integrates reliable recovered modalities, fully exploring task-relevant information beyond the conventional discard-or-impute paradigm. Central to DyMo is a novel selection algorithm that maximizes multimodal task-relevant information for each test sample. Since direct estimation of such information at test time is intractable due to the unknown data distribution, we theoretically establish a connection between information and the task loss, which we compute at inference time as a tractable proxy. Building on this, a novel principled reward function is proposed to guide modality selection. In addition, we design a flexible multimodal network architecture compatible with arbitrary modality combinations, alongside a tailored training strategy for robust representation learning. Extensive experiments on diverse natural and medical datasets show that DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios. Our code will be available at https://github.com/anonymous.", "abstract": "Multimodal deep learning (MDL) has achieved remarkable success across various domains, yet its practical deployment is often hindered by incomplete multimodal data. Existing incomplete MDL methods either discard missing modalities, risking the loss of valuable task-relevant information, or recover them, potentially introducing irrelevant noise, leading to the discarding-imputation dilemma. To address this dilemma, in this paper, we propose DyMo, a new inference-time dynamic modality selection framework that adaptively identifies and integrates reliable recovered modalities, fully exploring task-relevant information beyond the conventional discard-or-impute paradigm. Central to DyMo is a novel selection algorithm that maximizes multimodal task-relevant information for each test sample. Since direct estimation of such information at test time is intractable due to the unknown data distribution, we theoretically establish a connection between information and the task loss, which we compute at inference time as a tractable proxy. Building on this, a novel principled reward function is proposed to guide modality selection. In addition, we design a flexible multimodal network architecture compatible with arbitrary modality combinations, alongside a tailored training strategy for robust representation learning. Extensive experiments on diverse natural and medical datasets show that DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios. Our code will be available at https://github.com/anonymous.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=PWhDUWRVhM", "openreview_id": "PWhDUWRVhM", "openreview_forum_id": "PWhDUWRVhM", "authors": [], "pdf_url": "https://openreview.net/pdf/5c9fa010f820f2437e520f48a480adac61df09a7.pdf", "summary_cn": "提出DyMo框架，动态选择可靠模态以解决多模态分类中数据缺失问题，超越传统丢弃或填补方法，提升性能。", "keywords": ["多模态学习", "动态模态选择", "数据缺失", "推理时间优化", "信息最大化", "医疗分类"], "triple": {"method": "基于任务损失的信息代理与奖励函数", "result": "在自然和医疗数据集上显著优于现有方法", "contribution": "提出动态模态选择框架，突破丢弃-填补困境"}}
{"venue": "ICLR", "search_title": "FETAL-GAUGE: A BENCHMARK FOR ASSESSING VISION-LANGUAGE MODELS IN FETAL ULTRASOUND", "full_title": "FETAL-GAUGE: A BENCHMARK FOR ASSESSING VISION-LANGUAGE MODELS IN FETAL ULTRASOUND", "url": "https://openreview.net/forum?id=AHZuGrWZ0d", "year": 2026, "is_main_conference": true, "abstract_snippet": "The growing demand for prenatal ultrasound imaging has intensified a global shortage of trained sonographers, creating barriers to essential fetal health monitoring. Deep learning has the potential to enhance sonographers' efficiency and support the training of new practitioners. Vision-Language Models (VLMs) are particularly promising for ultrasound interpretation, as they can jointly process images and text to perform multiple clinical tasks within a single framework. However, despite the expansion of VLMs, no standardized benchmark exists to evaluate their performance in fetal ultrasound imaging. This gap is primarily due to the modality’s challenging nature, operator dependency, and the limited public availability of datasets. To address this gap, we present Fetal-Gauge, the first and largest visual question answering benchmark specifically designed to evaluate VLMs across various fetal ultrasound tasks. Our benchmark comprises over 42,000 images and 93,000 question-answer pairs, spanning anatomical plane identification, visual grounding of anatomical structures, fetal orientation assessment, clinical view conformity, and clinical diagnosis. We systematically evaluate several state-of-the-art VLMs, including general-purpose and medical-specific models, and reveal a substantial performance gap: the best-performing model achieves only 55\\% accuracy, far below clinical requirements. Our analysis identifies critical limitations of current VLMs in fetal ultrasound interpretation, highlighting the urgent need for domain-adapted architectures and specialized training approaches. Fetal-Gauge establishes a rigorous foundation for advancing multimodal deep learning in prenatal care and provides a pathway toward addressing global healthcare accessibility challenges. Our benchmark is publicly available at www.github.com", "abstract": "The growing demand for prenatal ultrasound imaging has intensified a global shortage of trained sonographers, creating barriers to essential fetal health monitoring. Deep learning has the potential to enhance sonographers' efficiency and support the training of new practitioners. Vision-Language Models (VLMs) are particularly promising for ultrasound interpretation, as they can jointly process images and text to perform multiple clinical tasks within a single framework. However, despite the expansion of VLMs, no standardized benchmark exists to evaluate their performance in fetal ultrasound imaging. This gap is primarily due to the modality’s challenging nature, operator dependency, and the limited public availability of datasets. To address this gap, we present Fetal-Gauge, the first and largest visual question answering benchmark specifically designed to evaluate VLMs across various fetal ultrasound tasks. Our benchmark comprises over 42,000 images and 93,000 question-answer pairs, spanning anatomical plane identification, visual grounding of anatomical structures, fetal orientation assessment, clinical view conformity, and clinical diagnosis. We systematically evaluate several state-of-the-art VLMs, including general-purpose and medical-specific models, and reveal a substantial performance gap: the best-performing model achieves only 55\\% accuracy, far below clinical requirements. Our analysis identifies critical limitations of current VLMs in fetal ultrasound interpretation, highlighting the urgent need for domain-adapted architectures and specialized training approaches. Fetal-Gauge establishes a rigorous foundation for advancing multimodal deep learning in prenatal care and provides a pathway toward addressing global healthcare accessibility challenges. Our benchmark is publicly available at www.github.com", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=AHZuGrWZ0d", "openreview_id": "AHZuGrWZ0d", "openreview_forum_id": "AHZuGrWZ0d", "authors": [], "pdf_url": "https://openreview.net/pdf/44352c8c8183d482690a6b74231105e2e275690e.pdf", "summary_cn": "本文提出首个胎儿超声视觉问答基准Fetal-Gauge，包含超4.2万图像和9.3万问答对，评估多种视觉语言模型，发现最佳模型准确率仅55%，远低于临床需求。", "keywords": ["胎儿超声", "视觉语言模型", "基准评估", "视觉问答", "深度学习", "产前护理"], "triple": {"method": "构建大规模视觉问答基准", "result": "最佳模型准确率仅55%", "contribution": "填补胎儿超声VLM评估空白"}}
{"venue": "ICLR", "search_title": "Rethinking Radiology Report Generation: From Narrative Flow to Topic-Guided Findings", "full_title": "Rethinking Radiology Report Generation: From Narrative Flow to Topic-Guided Findings", "url": "https://openreview.net/forum?id=nV3SAjFlyv", "year": 2026, "is_main_conference": true, "abstract_snippet": "Vision-Language Models (VLMs) for radiology report generation are typically trained to mimic the narrative flow of human experts. However, we identify a potential limitation in this conventional paradigm. We hypothesize that optimizing for narrative coherence encourages models to rely on linguistic priors and inter-sentence correlations, which can weaken their grounding in direct visual evidence and lead to factual inaccuracies. To investigate this, we design a controlled experiment demonstrating that as textual context increases, a model's reliance on the input image systematically decays. We propose LLaVA-TA (Topic-guided and Anatomy-aware), a new fine-tuning framework that directly addresses this challenge by re-engineering the generation process. Instead of producing a linear narrative, LLaVA-TA decomposes the report into a set of independent, clinically-relevant topics. By training the model to generate a discrete finding for each topic conditioned on both the full image and its corresponding anatomical region, we reduce the model's reliance on narrative flow and enforce stricter visual grounding. Our experiments show that LLaVA-TA sets a new state of the art on the MIMIC-CXR dataset, significantly improving clinical accuracy on metrics like RadGraph F1 (from 29.4 to 44.0) and CheXpert F1-14 (from 39.5 to 71.5) over strong baselines. Our work demonstrates that dismantling a report's narrative structure to enforce independent, visually-grounded observations is a crucial and effective step toward building more accurate and reliable medical VLMs.", "abstract": "Vision-Language Models (VLMs) for radiology report generation are typically trained to mimic the narrative flow of human experts. However, we identify a potential limitation in this conventional paradigm. We hypothesize that optimizing for narrative coherence encourages models to rely on linguistic priors and inter-sentence correlations, which can weaken their grounding in direct visual evidence and lead to factual inaccuracies. To investigate this, we design a controlled experiment demonstrating that as textual context increases, a model's reliance on the input image systematically decays. We propose LLaVA-TA (Topic-guided and Anatomy-aware), a new fine-tuning framework that directly addresses this challenge by re-engineering the generation process. Instead of producing a linear narrative, LLaVA-TA decomposes the report into a set of independent, clinically-relevant topics. By training the model to generate a discrete finding for each topic conditioned on both the full image and its corresponding anatomical region, we reduce the model's reliance on narrative flow and enforce stricter visual grounding. Our experiments show that LLaVA-TA sets a new state of the art on the MIMIC-CXR dataset, significantly improving clinical accuracy on metrics like RadGraph F1 (from 29.4 to 44.0) and CheXpert F1-14 (from 39.5 to 71.5) over strong baselines. Our work demonstrates that dismantling a report's narrative structure to enforce independent, visually-grounded observations is a crucial and effective step toward building more accurate and reliable medical VLMs.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=nV3SAjFlyv", "openreview_id": "nV3SAjFlyv", "openreview_forum_id": "nV3SAjFlyv", "authors": [], "pdf_url": "https://openreview.net/pdf/068c77b0c2d8fa65c2615f2151b075e04b57103d.pdf", "summary_cn": "研究发现传统放射报告生成模型过度依赖文本叙事，导致视觉证据不足。提出LLaVA-TA框架，通过主题引导和解剖感知生成独立发现，显著提升临床准确性。", "keywords": ["放射报告生成", "视觉语言模型", "主题引导", "解剖感知", "临床准确性", "视觉基础"], "triple": {"method": "LLaVA-TA框架，基于主题引导和解剖感知生成独立发现", "result": "在MIMIC-CXR数据集上刷新SOTA，RadGraph F1从29.4提升至44.0", "contribution": "打破叙事结构，增强视觉基础，提高医学VLM准确性和可靠性"}}
{"venue": "ICLR", "search_title": "Learning Domain-Aware Task Prompt Representations for Multi-Domain All-in-One Image Restoration", "full_title": "Learning Domain-Aware Task Prompt Representations for Multi-Domain All-in-One Image Restoration", "url": "https://openreview.net/forum?id=CzVlgDOF7L", "year": 2026, "is_main_conference": true, "abstract_snippet": "Recently, significant breakthroughs have been made in all-in-one image restoration (AiOIR), which can handle multiple restoration tasks with a single model. However, existing methods typically focus on a specific image domain, such as natural scene, medical imaging, or remote sensing. In this work, we aim to extend AiOIR to multiple domains and propose the first multi-domain all-in-one image restoration method, DATPRL-IR, based on our proposed Domain-Aware Task Prompt Representation L}earning. Specifically, we first construct a task prompt pool containing multiple task prompts, in which task-related knowledge is implicitly encoded. For each input image, the model adaptively selects the most relevant task prompts and composes them into an instance-level task representation via a prompt composition mechanism (PCM). Furthermore, to endow the model with domain awareness, we introduce another domain prompt pool and distill domain priors from multimodal large language models into the domain prompts. PCM is utilized to combine the adaptively selected domain prompts into a domain representation for each input image. Finally, the two representations are fused to form a domain-aware task prompt representation which can make full use of both specific and shared knowledge across tasks and domains to guide the subsequent restoration process. Extensive experiments demonstrate that our DATRL-IR significantly outperforms existing SOTA image restoration methods, while exhibiting strong generalization capabilities. We believe that this work provides a new research paradigm and represents a step towards more unified image restoration.", "abstract": "Recently, significant breakthroughs have been made in all-in-one image restoration (AiOIR), which can handle multiple restoration tasks with a single model. However, existing methods typically focus on a specific image domain, such as natural scene, medical imaging, or remote sensing. In this work, we aim to extend AiOIR to multiple domains and propose the first multi-domain all-in-one image restoration method, DATPRL-IR, based on our proposed Domain-Aware Task Prompt Representation L}earning. Specifically, we first construct a task prompt pool containing multiple task prompts, in which task-related knowledge is implicitly encoded. For each input image, the model adaptively selects the most relevant task prompts and composes them into an instance-level task representation via a prompt composition mechanism (PCM). Furthermore, to endow the model with domain awareness, we introduce another domain prompt pool and distill domain priors from multimodal large language models into the domain prompts. PCM is utilized to combine the adaptively selected domain prompts into a domain representation for each input image. Finally, the two representations are fused to form a domain-aware task prompt representation which can make full use of both specific and shared knowledge across tasks and domains to guide the subsequent restoration process. Extensive experiments demonstrate that our DATRL-IR significantly outperforms existing SOTA image restoration methods, while exhibiting strong generalization capabilities. We believe that this work provides a new research paradigm and represents a step towards more unified image restoration.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=CzVlgDOF7L", "openreview_id": "CzVlgDOF7L", "openreview_forum_id": "CzVlgDOF7L", "authors": [], "pdf_url": "https://openreview.net/pdf/0806528f3fbff20678e5f2045e5c1f3195e5a4fd.pdf", "summary_cn": "提出DATPRL-IR方法，通过领域感知任务提示表示学习，实现多领域一体化图像恢复，显著超越现有方法并展现强泛化能力。", "keywords": ["多领域图像恢复", "任务提示表示", "领域感知", "提示组合机制", "一体化模型", "泛化能力"], "triple": {"method": "领域感知任务提示表示学习", "result": "性能显著超越现有SOTA方法", "contribution": "提出首个多领域一体化图像恢复新范式"}}
{"venue": "ICLR", "search_title": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "full_title": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "url": "https://openreview.net/forum?id=VhlSBZebEw", "year": 2026, "is_main_conference": true, "abstract_snippet": "Test-time prompt tuning (TPT) has emerged as a promising technique for adapting large vision-language models (VLMs) to unseen tasks without relying on labeled data. However, the lack of dispersion between textual features can hurt calibration performance, which raises concerns about VLMs' reliability, trustworthiness, and safety. Current TPT approaches primarily focus on improving prompt calibration by either maximizing average textual feature dispersion or enforcing orthogonality constraints to encourage angular separation. However, these methods may not always have optimal angular separation between class-wise textual features, which implies overlooking the critical role of angular diversity. To address this, we propose A-TPT, a novel TPT framework that introduces angular diversity to encourage uniformity in the distribution of normalized textual features induced by corresponding learnable prompts. This uniformity is achieved by maximizing the minimum pairwise angular distance between features on the unit hypersphere. We show that our approach consistently surpasses state-of-the-art TPT methods in reducing the aggregate average calibration error while maintaining comparable accuracy through extensive experiments with various backbones on different datasets. Notably, our approach exhibits superior zero-shot calibration performance on natural distribution shifts and generalizes well to medical datasets. We provide extensive analyses, including theoretical aspects, to establish the grounding of A-TPT. These results highlight the potency of promoting angular diversity to achieve well-dispersed textual features, significantly improving VLM calibration during test-time adaptation. Our code will be made publicly available.", "abstract": "Test-time prompt tuning (TPT) has emerged as a promising technique for adapting large vision-language models (VLMs) to unseen tasks without relying on labeled data. However, the lack of dispersion between textual features can hurt calibration performance, which raises concerns about VLMs' reliability, trustworthiness, and safety. Current TPT approaches primarily focus on improving prompt calibration by either maximizing average textual feature dispersion or enforcing orthogonality constraints to encourage angular separation. However, these methods may not always have optimal angular separation between class-wise textual features, which implies overlooking the critical role of angular diversity. To address this, we propose A-TPT, a novel TPT framework that introduces angular diversity to encourage uniformity in the distribution of normalized textual features induced by corresponding learnable prompts. This uniformity is achieved by maximizing the minimum pairwise angular distance between features on the unit hypersphere. We show that our approach consistently surpasses state-of-the-art TPT methods in reducing the aggregate average calibration error while maintaining comparable accuracy through extensive experiments with various backbones on different datasets. Notably, our approach exhibits superior zero-shot calibration performance on natural distribution shifts and generalizes well to medical datasets. We provide extensive analyses, including theoretical aspects, to establish the grounding of A-TPT. These results highlight the potency of promoting angular diversity to achieve well-dispersed textual features, significantly improving VLM calibration during test-time adaptation. Our code will be made publicly available.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=VhlSBZebEw", "openreview_id": "VhlSBZebEw", "openreview_forum_id": "VhlSBZebEw", "authors": [], "pdf_url": "https://openreview.net/pdf/55afd4785f8112ea78a4b2263d53c4780d325307.pdf", "summary_cn": "提出A-TPT框架，通过最大化文本特征间最小角距离增强角多样性，提升视觉语言模型在测试时提示调优中的校准性能，减少校准误差。", "keywords": ["测试时提示调优", "角多样性", "视觉语言模型", "校准性能", "特征分布", "零样本校准"], "triple": {"method": "最大化最小成对角距离", "result": "降低平均校准误差，保持准确率", "contribution": "提升VLM校准性能与可靠性"}}
{"venue": "ICLR", "search_title": "Bridging Radiology and Pathology Foundation Models via Concept-Based Multimodal Co-Adaptation", "full_title": "Bridging Radiology and Pathology Foundation Models via Concept-Based Multimodal Co-Adaptation", "url": "https://openreview.net/forum?id=oxgcPoDkNv", "year": 2026, "is_main_conference": true, "abstract_snippet": "Pretrained medical foundation models (FMs) have shown strong generalization across diverse imaging tasks, such as disease classification in radiology and tumor grading in histopathology. While recent advances in parameter-efficient finetuning have enabled effective adaptation of FMs to downstream tasks, these approaches are typically designed for a single modality. In contrast, many clinical workflows rely on joint diagnosis from heterogeneous domains, such as radiology and pathology, where fully leveraging the representation capacity of multiple FMs remains an open challenge. To address this gap, we propose Concept Tuning and Fusing (CTF), a parameter-efficient framework that uses clinically grounded concepts as a shared semantic interface to enable cross-modal co-adaptation before fusion. By incorporating task-specific concepts that are relevant across modalities, CTF aligns radiology and pathology representations, thereby enhancing their complementarity and enabling interpretation. We further design a Global–Context–Shared Prompt (GCSP) mechanism, which employs a small set of learnable tokens to capture domain-specific priors, shared patient-level information, and cross-domain context. The resulting concept alignment scores from each modality are then fused to produce a final prediction. Extensive experiments demonstrate that CTF outperforms strong unimodal, latent-fusion, and adapter-based baselines (e.g., AUC 0.903 on TCGA-GBMLGG). Notably, CTF achieves these gains without finetuning the full FMs, requiring only 0.15\\% additional parameters, thus highlighting the effectiveness of concept-based multimodal co-adaptation. Our code is anonymously available at: https://anonymous.4open.science/r/CTF-27C2.", "abstract": "Pretrained medical foundation models (FMs) have shown strong generalization across diverse imaging tasks, such as disease classification in radiology and tumor grading in histopathology. While recent advances in parameter-efficient finetuning have enabled effective adaptation of FMs to downstream tasks, these approaches are typically designed for a single modality. In contrast, many clinical workflows rely on joint diagnosis from heterogeneous domains, such as radiology and pathology, where fully leveraging the representation capacity of multiple FMs remains an open challenge. To address this gap, we propose Concept Tuning and Fusing (CTF), a parameter-efficient framework that uses clinically grounded concepts as a shared semantic interface to enable cross-modal co-adaptation before fusion. By incorporating task-specific concepts that are relevant across modalities, CTF aligns radiology and pathology representations, thereby enhancing their complementarity and enabling interpretation. We further design a Global–Context–Shared Prompt (GCSP) mechanism, which employs a small set of learnable tokens to capture domain-specific priors, shared patient-level information, and cross-domain context. The resulting concept alignment scores from each modality are then fused to produce a final prediction. Extensive experiments demonstrate that CTF outperforms strong unimodal, latent-fusion, and adapter-based baselines (e.g., AUC 0.903 on TCGA-GBMLGG). Notably, CTF achieves these gains without finetuning the full FMs, requiring only 0.15\\% additional parameters, thus highlighting the effectiveness of concept-based multimodal co-adaptation. Our code is anonymously available at: https://anonymous.4open.science/r/CTF-27C2.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=oxgcPoDkNv", "openreview_id": "oxgcPoDkNv", "openreview_forum_id": "oxgcPoDkNv", "authors": [], "pdf_url": "https://openreview.net/pdf/e7e3ab7ec9279cd5c0c17f1afa02346cb35f1452.pdf", "summary_cn": "提出概念调谐与融合框架，利用临床概念作为共享语义接口，实现放射学与病理学基础模型的多模态协同适应，提升跨模态预测性能。", "keywords": ["多模态学习", "基础模型", "概念对齐", "参数高效调优", "放射病理融合", "协同适应"], "triple": {"method": "概念调谐与融合框架", "result": "AUC达0.903，优于单模态及潜在融合基线", "contribution": "实现跨模态协同适应，参数效率高"}}
{"venue": "ICLR", "search_title": "ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning", "full_title": "ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning", "url": "https://openreview.net/forum?id=vcWDDfA4Ev", "year": 2026, "is_main_conference": true, "abstract_snippet": "Conventional continual pretraining (CPT) for large language model (LLM) domain adaptation often suffers from catastrophic forgetting and limited domain capacity. Existing strategies adopt layer expansion, introducing additional trainable parameters to accommodate new knowledge. However, the uniform expansion and updates still entangle general and domain learning, undermining its effectiveness. Our pilot studies reveal that LLMs exhibit functional specialization, where layers and units differentially encode general-critical capabilities, suggesting that parameter expansion and optimization should be function-aware. We then propose ADEPT, Adaptive Expansion and Dynamic Decoupled Tuning for continual pretraining, a two-stage framework for domain-adaptive CPT. ADEPT first performs General-Competence Guided Selective Layer Expansion, duplicating layers least critical for the general domain to increase representational capacity while minimizing interference with general knowledge. It then applies Adaptive Unit-Wise Decoupled Tuning, disentangling parameter units within expanded layers according to their general-domain importance and assigning asymmetric learning rates to balance knowledge injection and retention. Experiments on mathematical and medical domains show that ADEPT outperforms full-parameter CPT by up to 5.76% on the general benchmarks and 5.58% on the target domain benchmarks with only 15% of parameters tuned and less than 50% training time. Ablation studies, theoretical analysis, and extended investigations further demonstrate the necessity of targeted expansion and decoupled optimization, providing new principles for efficient and robust domain-adaptive CPT. Our code is open-sourced at https://anonymous.4open.science/r/ADEPT-F2E3", "abstract": "Conventional continual pretraining (CPT) for large language model (LLM) domain adaptation often suffers from catastrophic forgetting and limited domain capacity. Existing strategies adopt layer expansion, introducing additional trainable parameters to accommodate new knowledge. However, the uniform expansion and updates still entangle general and domain learning, undermining its effectiveness. Our pilot studies reveal that LLMs exhibit functional specialization, where layers and units differentially encode general-critical capabilities, suggesting that parameter expansion and optimization should be function-aware. We then propose ADEPT, Adaptive Expansion and Dynamic Decoupled Tuning for continual pretraining, a two-stage framework for domain-adaptive CPT. ADEPT first performs General-Competence Guided Selective Layer Expansion, duplicating layers least critical for the general domain to increase representational capacity while minimizing interference with general knowledge. It then applies Adaptive Unit-Wise Decoupled Tuning, disentangling parameter units within expanded layers according to their general-domain importance and assigning asymmetric learning rates to balance knowledge injection and retention. Experiments on mathematical and medical domains show that ADEPT outperforms full-parameter CPT by up to 5.76% on the general benchmarks and 5.58% on the target domain benchmarks with only 15% of parameters tuned and less than 50% training time. Ablation studies, theoretical analysis, and extended investigations further demonstrate the necessity of targeted expansion and decoupled optimization, providing new principles for efficient and robust domain-adaptive CPT. Our code is open-sourced at https://anonymous.4open.science/r/ADEPT-F2E3", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=vcWDDfA4Ev", "openreview_id": "vcWDDfA4Ev", "openreview_forum_id": "vcWDDfA4Ev", "authors": [], "pdf_url": "https://openreview.net/pdf/99af89d5a20d66ec436a712f5809f5767f41b6d4.pdf", "summary_cn": "ADEPT提出自适应扩展与动态解耦调优的两阶段框架，用于大语言模型持续预训练，有效缓解灾难性遗忘并提升领域适应能力。", "keywords": ["持续预训练", "灾难性遗忘", "自适应扩展", "解耦调优", "领域适应", "大语言模型"], "triple": {"method": "自适应层扩展与单元解耦调优", "result": "在数学和医学领域性能提升，训练参数和时间减少", "contribution": "提出高效鲁棒的领域自适应持续预训练新原则"}}
{"venue": "ICLR", "search_title": "Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model", "full_title": "Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model", "url": "https://openreview.net/forum?id=arms7s9dDK", "year": 2026, "is_main_conference": true, "abstract_snippet": "Uncertainty quantification is a critical aspect of reinforcement learning and deep learning, with numerous applications ranging from efficient exploration and stable offline reinforcement learning to outlier detection in medical diagnostics. The scale of modern neural networks, however, complicates the use of many theoretically well-motivated approaches such as full Bayesian inference. Approximate methods like deep ensembles can provide reliable uncertainty estimates but still remain computationally expensive. In this work, we propose contextual similarity distillation, a novel approach that explicitly estimates the variance of an ensemble of deep neural networks with a single model, without ever learning or evaluating such an ensemble in the first place. Our method builds on the predictable learning dynamics of wide neural networks, governed by the neural tangent kernel, to derive an efficient approximation of the predictive variance of an infinite ensemble. Specifically, we reinterpret the computation of ensemble variance as a supervised regression problem with kernel similarities as regression targets. The resulting model can estimate predictive variance at inference time with a single forward pass, and can make use of unlabeled target-domain data or data augmentations to refine its uncertainty estimates. We empirically validate our method across a variety of out-of-distribution detection benchmarks and sparse-reward reinforcement learning environments. We find that our single-model method performs competitively and sometimes superior to ensemble-based baselines and serves as a reliable signal for efficient exploration. These results, we believe, position contextual similarity distillation as a principled and scalable alternative for uncertainty quantification in reinforcement learning and general deep learning.", "abstract": "Uncertainty quantification is a critical aspect of reinforcement learning and deep learning, with numerous applications ranging from efficient exploration and stable offline reinforcement learning to outlier detection in medical diagnostics. The scale of modern neural networks, however, complicates the use of many theoretically well-motivated approaches such as full Bayesian inference. Approximate methods like deep ensembles can provide reliable uncertainty estimates but still remain computationally expensive. In this work, we propose contextual similarity distillation, a novel approach that explicitly estimates the variance of an ensemble of deep neural networks with a single model, without ever learning or evaluating such an ensemble in the first place. Our method builds on the predictable learning dynamics of wide neural networks, governed by the neural tangent kernel, to derive an efficient approximation of the predictive variance of an infinite ensemble. Specifically, we reinterpret the computation of ensemble variance as a supervised regression problem with kernel similarities as regression targets. The resulting model can estimate predictive variance at inference time with a single forward pass, and can make use of unlabeled target-domain data or data augmentations to refine its uncertainty estimates. We empirically validate our method across a variety of out-of-distribution detection benchmarks and sparse-reward reinforcement learning environments. We find that our single-model method performs competitively and sometimes superior to ensemble-based baselines and serves as a reliable signal for efficient exploration. These results, we believe, position contextual similarity distillation as a principled and scalable alternative for uncertainty quantification in reinforcement learning and general deep learning.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=arms7s9dDK", "openreview_id": "arms7s9dDK", "openreview_forum_id": "arms7s9dDK", "authors": [], "pdf_url": "https://openreview.net/pdf/e6c4a3600c2182e3b8909b07eeeb32e04294d41d.pdf", "summary_cn": "提出上下文相似性蒸馏方法，通过单个模型高效估计深度集成的不确定性，无需实际训练集成，在离群检测和强化学习中表现优异。", "keywords": ["不确定性量化", "上下文相似性蒸馏", "深度集成", "神经正切核", "离群检测", "强化学习"], "triple": {"method": "基于神经正切核的相似性回归", "result": "单模型不确定性估计媲美集成方法", "contribution": "提供可扩展的高效不确定性量化方案"}}
{"venue": "ICLR", "search_title": "Healthcare Insurance Fraud Detection via Continual Fiedler Vector Graph Model", "full_title": "Healthcare Insurance Fraud Detection via Continual Fiedler Vector Graph Model", "url": "https://openreview.net/forum?id=ZWDvIKMkMG", "year": 2026, "is_main_conference": true, "abstract_snippet": "Healthcare insurance fraud detection presents unique machine learning challenges: labeled data are scarce due to delayed verification processes, and fraudulent behaviors evolve rapidly, often manifesting in complex, graph-structured interactions. Existing methods struggle in such settings. Pretraining routines typically overlook structural anomalies under limited supervision, while online models often fail to adapt to changing fraud patterns without labeled updates.\nTo address these issues, we propose the Continual Fiedler Vector Graph model (ConFVG), a fraud detection framework designed for label-scarce and non-stationary environments. The framework comprises two key components. To mitigate label scarcity, we develop a Fiedler Vector-guided graph autoencoder that leverages spectral graph properties to learn structure-aware node representations. The Fiedler Vector, derived from the second smallest eigenvalue of the graph Laplacian, captures global topological signals such as community boundaries and connectivity bottlenecks, which are patterns frequently associated with collusive fraud. This enables the model to identify structurally anomalous nodes without relying on labels. To handle evolving graph streams, we propose a Subgraph Attention Fusion (SAF) module that constructs neighborhood subgraphs and applies attention-based reweighting to emphasize emerging high-risk structures. This design allows the model to adapt to new fraud patterns in real time. A Mean Teacher mechanism further stabilizes online updates and prevents forgetting of previously acquired knowledge.\nExperiments on real-world medical fraud datasets demonstrate that the Continual Fiedler Vector Graph model outperforms state-of-the-art baselines in both low-label and distribution-shift scenarios, offering a scalable and structure-sensitive solution for real-time fraud detection.", "abstract": "Healthcare insurance fraud detection presents unique machine learning challenges: labeled data are scarce due to delayed verification processes, and fraudulent behaviors evolve rapidly, often manifesting in complex, graph-structured interactions. Existing methods struggle in such settings. Pretraining routines typically overlook structural anomalies under limited supervision, while online models often fail to adapt to changing fraud patterns without labeled updates.\nTo address these issues, we propose the Continual Fiedler Vector Graph model (ConFVG), a fraud detection framework designed for label-scarce and non-stationary environments. The framework comprises two key components. To mitigate label scarcity, we develop a Fiedler Vector-guided graph autoencoder that leverages spectral graph properties to learn structure-aware node representations. The Fiedler Vector, derived from the second smallest eigenvalue of the graph Laplacian, captures global topological signals such as community boundaries and connectivity bottlenecks, which are patterns frequently associated with collusive fraud. This enables the model to identify structurally anomalous nodes without relying on labels. To handle evolving graph streams, we propose a Subgraph Attention Fusion (SAF) module that constructs neighborhood subgraphs and applies attention-based reweighting to emphasize emerging high-risk structures. This design allows the model to adapt to new fraud patterns in real time. A Mean Teacher mechanism further stabilizes online updates and prevents forgetting of previously acquired knowledge.\nExperiments on real-world medical fraud datasets demonstrate that the Continual Fiedler Vector Graph model outperforms state-of-the-art baselines in both low-label and distribution-shift scenarios, offering a scalable and structure-sensitive solution for real-time fraud detection.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=ZWDvIKMkMG", "openreview_id": "ZWDvIKMkMG", "openreview_forum_id": "ZWDvIKMkMG", "authors": [], "pdf_url": "https://openreview.net/pdf/81a0f8133f264a8cd209ce795cb83d4619fa598b.pdf", "summary_cn": "提出ConFVG模型，利用Fiedler向量捕捉图结构异常，结合子图注意力融合处理动态欺诈模式，在标签稀缺和分布变化场景下优于现有方法。", "keywords": ["医疗保险欺诈检测", "图神经网络", "Fiedler向量", "持续学习", "结构异常检测", "子图注意力"], "triple": {"method": "Fiedler向量图自编码器与子图注意力融合", "result": "在低标签和分布偏移场景中超越现有基线", "contribution": "提供可扩展、结构敏感的实时欺诈检测方案"}}
{"venue": "ICLR", "search_title": "ReLaSH: Reconstructing Joint Latent Spaces for Efficient Generation of Synthetic Hypergraphs with Hyperlink Attributes", "full_title": "ReLaSH: Reconstructing Joint Latent Spaces for Efficient Generation of Synthetic Hypergraphs with Hyperlink Attributes", "url": "https://openreview.net/forum?id=SG3kS2h44t", "year": 2026, "is_main_conference": true, "abstract_snippet": "Hypergraph network data, which capture multi-way interactions among entities, have become increasingly prevalent in the big data era, spanning fields such as social science, medical research, and biology. Generating synthetic hyperlinks with attributes from an observed hypergraph has broad applications in data augmentation, simulation, and advancing the understanding of real-world complex systems. This task, however, poses unique challenges due to special properties of hypergraphs, including discreteness, hyperlink sparsity, and the mixed data types of hyperlinks and their attributes, rendering many existing generative models unsuitable. In this paper, we introduce ReLaSH (REconstructing joint LAtent Spaces for Hypergraphs with attributes), a general generative framework for producing realistic synthetic hypergraph data with hyperlink attributes via training a likelihood-based joint embedding model and reconstructing the joint latent space. Given a hypergraph dataset, ReLaSH first embeds the hyperlinks and their attributes into a joint latent space by training a likelihood-based model, and then reconstructs this joint latent space using a distribution-free generator. The generation task is completed by first sampling embeddings from the distribution-free generator and then decoding them into hyperlinks and attributes through the trained likelihood-based model. Compared with existing generative models, ReLaSH explicitly accounts for the unique structure of hypergraphs and jointly models hyperlinks and their attributes. Moreover, the likelihood-based embedding model provides efficiency and interpretability relative to deep black-box architectures, while the distribution-free generator in the joint latent space ensures flexibility. We theoretically demonstrate consistency and generalizability of ReLaSH. Empirical results on a range of real-world datasets from diverse domains demonstrate the strong performance of ReLaSH, underscoring its broad utility and effectiveness in practical applications.", "abstract": "Hypergraph network data, which capture multi-way interactions among entities, have become increasingly prevalent in the big data era, spanning fields such as social science, medical research, and biology. Generating synthetic hyperlinks with attributes from an observed hypergraph has broad applications in data augmentation, simulation, and advancing the understanding of real-world complex systems. This task, however, poses unique challenges due to special properties of hypergraphs, including discreteness, hyperlink sparsity, and the mixed data types of hyperlinks and their attributes, rendering many existing generative models unsuitable. In this paper, we introduce ReLaSH (REconstructing joint LAtent Spaces for Hypergraphs with attributes), a general generative framework for producing realistic synthetic hypergraph data with hyperlink attributes via training a likelihood-based joint embedding model and reconstructing the joint latent space. Given a hypergraph dataset, ReLaSH first embeds the hyperlinks and their attributes into a joint latent space by training a likelihood-based model, and then reconstructs this joint latent space using a distribution-free generator. The generation task is completed by first sampling embeddings from the distribution-free generator and then decoding them into hyperlinks and attributes through the trained likelihood-based model. Compared with existing generative models, ReLaSH explicitly accounts for the unique structure of hypergraphs and jointly models hyperlinks and their attributes. Moreover, the likelihood-based embedding model provides efficiency and interpretability relative to deep black-box architectures, while the distribution-free generator in the joint latent space ensures flexibility. We theoretically demonstrate consistency and generalizability of ReLaSH. Empirical results on a range of real-world datasets from diverse domains demonstrate the strong performance of ReLaSH, underscoring its broad utility and effectiveness in practical applications.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=SG3kS2h44t", "openreview_id": "SG3kS2h44t", "openreview_forum_id": "SG3kS2h44t", "authors": [], "pdf_url": "https://openreview.net/pdf/e703e6645951c7a2d3b51da984838dc424ca2c24.pdf", "summary_cn": "ReLaSH框架通过联合嵌入与重构潜在空间，高效生成带属性的超图数据，解决了现有模型不适用的问题。", "keywords": ["超图生成", "联合潜在空间", "属性建模", "数据增强", "生成模型", "可解释性"], "triple": {"method": "训练基于似然的联合嵌入模型并重构潜在空间", "result": "在多个真实数据集上表现优异，生成逼真超图数据", "contribution": "提出灵活高效的超图生成框架，兼顾结构与属性"}}
{"venue": "ICLR", "search_title": "Unveiling the Mechanism of Continuous Representation Full-Waveform Inversion: A Wave Based Neural Tangent Kernel Framework", "full_title": "Unveiling the Mechanism of Continuous Representation Full-Waveform Inversion: A Wave Based Neural Tangent Kernel Framework", "url": "https://openreview.net/forum?id=blqYa21WOv", "year": 2026, "is_main_conference": true, "abstract_snippet": "Full-waveform inversion (FWI) estimates physical parameters in the wave equation from limited measurements and has been widely applied in geophysical exploration, medical imaging, and non-destructive testing. Conventional FWI methods are limited by their notorious sensitivity to the accuracy of the initial models. Recent progress in continuous representation FWI (CR-FWI) demonstrates that representing parameter models with a coordinate-based neural network, such as implicit neural representation (INR), can mitigate the dependence on initial models. However, its underlying mechanism remains unclear, and INR-based FWI shows slower high-frequency convergence. In this work, we investigate the general CR-FWI framework and develop a unified theoretical understanding by extending the neural tangent kernel (NTK) for FWI to establish a wave-based NTK framework. Unlike standard NTK, our analysis reveals that wave-based NTK is not constant, both at initialization and during training, due to the inherent nonlinearity of FWI. We further show that the eigenvalue decay behavior of the wave-based NTK can explain why CR-FWI alleviates the dependency on initial models and shows slower high-frequency convergence. Building on these insights, we propose several CR-FWI methods with tailored eigenvalue decay properties for FWI, including a novel hybrid representation combining INR and multi-resolution grid (termed IG-FWI) that achieves a more balanced trade-off between robustness and high-frequency convergence rate. Applications in geophysical exploration on Marmousi, 2D SEG/EAGE Salt and Overthrust, 2004 BP model, and the more realistic 2014 Chevron models show the superior performance of our proposed methods compared to conventional FWI and existing INR-based FWI methods.", "abstract": "Full-waveform inversion (FWI) estimates physical parameters in the wave equation from limited measurements and has been widely applied in geophysical exploration, medical imaging, and non-destructive testing. Conventional FWI methods are limited by their notorious sensitivity to the accuracy of the initial models. Recent progress in continuous representation FWI (CR-FWI) demonstrates that representing parameter models with a coordinate-based neural network, such as implicit neural representation (INR), can mitigate the dependence on initial models. However, its underlying mechanism remains unclear, and INR-based FWI shows slower high-frequency convergence. In this work, we investigate the general CR-FWI framework and develop a unified theoretical understanding by extending the neural tangent kernel (NTK) for FWI to establish a wave-based NTK framework. Unlike standard NTK, our analysis reveals that wave-based NTK is not constant, both at initialization and during training, due to the inherent nonlinearity of FWI. We further show that the eigenvalue decay behavior of the wave-based NTK can explain why CR-FWI alleviates the dependency on initial models and shows slower high-frequency convergence. Building on these insights, we propose several CR-FWI methods with tailored eigenvalue decay properties for FWI, including a novel hybrid representation combining INR and multi-resolution grid (termed IG-FWI) that achieves a more balanced trade-off between robustness and high-frequency convergence rate. Applications in geophysical exploration on Marmousi, 2D SEG/EAGE Salt and Overthrust, 2004 BP model, and the more realistic 2014 Chevron models show the superior performance of our proposed methods compared to conventional FWI and existing INR-based FWI methods.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=blqYa21WOv", "openreview_id": "blqYa21WOv", "openreview_forum_id": "blqYa21WOv", "authors": [], "pdf_url": "https://openreview.net/pdf/743022d9ab841f52ab407b172fccdbab8768d582.pdf", "summary_cn": "研究提出基于神经正切核的波动理论框架，揭示连续表示全波形反演机制，解释其降低初始模型依赖但高频收敛慢的原因，并提出改进方法提升性能。", "keywords": ["全波形反演", "神经正切核", "连续表示", "初始模型依赖", "高频收敛", "混合表示"], "triple": {"method": "扩展神经正切核至波动方程，建立波动NTK框架", "result": "解释CR-FWI降低初始模型依赖但高频收敛慢，提出改进方法性能更优", "contribution": "提供统一理论理解，提出平衡稳健性与收敛速度的混合表示方法"}}
{"venue": "ICLR", "search_title": "OpenPros: A Large-Scale Dataset for Limited View Prostate Ultrasound Computed Tomography", "full_title": "OpenPros: A Large-Scale Dataset for Limited View Prostate Ultrasound Computed Tomography", "url": "https://openreview.net/forum?id=kcFEpBagea", "year": 2026, "is_main_conference": true, "abstract_snippet": "Prostate cancer is one of the most common and lethal cancers among men, making its early detection critically important. Although ultrasound imaging offers greater accessibility and cost-effectiveness compared to MRI, traditional transrectal ultrasound (TRUS) methods suffer from low sensitivity, especially in detecting anteriorly located tumors. Ultrasound computed tomography (USCT) provides quantitative tissue characterization, but its clinical implementation faces significant challenges, particularly under anatomically constrained limited-angle acquisition conditions specific to prostate imaging. To address these unmet needs, we introduce OpenPros, the first large-scale benchmark dataset for limited-angle prostate USCT designed to systematically evaluate ML methods for inverse problems. Our dataset includes over 280,000 paired samples of realistic 2D speed-of-sound (SOS) phantoms and corresponding ultrasound full-waveform data, generated from anatomically accurate 3D digital prostate models derived from real clinical MRI/CT scans and ex vivo ultrasound measurements, annotated by medical experts. Simulations are conducted under clinically realistic configurations using advanced finite-difference time-domain (FDTD) and Runge-Kutta acoustic wave solvers, both provided as open-source components. Through comprehensive benchmarking, we find that deep learning methods significantly outperform traditional physics-based algorithms in inference efficiency and reconstruction accuracy. However, our results also reveal that current machine learning methods fail to deliver clinically acceptable, high-resolution reconstructions, underscoring critical gaps in generalization, robustness, and uncertainty quantification. By publicly releasing OpenPros, we provide the community with a rigorous benchmark that not only enables fair method comparison but also motivates new advances in physics-informed learning, foundation models for scientific imaging, and uncertainty-aware reconstruction—bridging the gap between academic ML research and real-world clinical deployment.", "abstract": "Prostate cancer is one of the most common and lethal cancers among men, making its early detection critically important. Although ultrasound imaging offers greater accessibility and cost-effectiveness compared to MRI, traditional transrectal ultrasound (TRUS) methods suffer from low sensitivity, especially in detecting anteriorly located tumors. Ultrasound computed tomography (USCT) provides quantitative tissue characterization, but its clinical implementation faces significant challenges, particularly under anatomically constrained limited-angle acquisition conditions specific to prostate imaging. To address these unmet needs, we introduce OpenPros, the first large-scale benchmark dataset for limited-angle prostate USCT designed to systematically evaluate ML methods for inverse problems. Our dataset includes over 280,000 paired samples of realistic 2D speed-of-sound (SOS) phantoms and corresponding ultrasound full-waveform data, generated from anatomically accurate 3D digital prostate models derived from real clinical MRI/CT scans and ex vivo ultrasound measurements, annotated by medical experts. Simulations are conducted under clinically realistic configurations using advanced finite-difference time-domain (FDTD) and Runge-Kutta acoustic wave solvers, both provided as open-source components. Through comprehensive benchmarking, we find that deep learning methods significantly outperform traditional physics-based algorithms in inference efficiency and reconstruction accuracy. However, our results also reveal that current machine learning methods fail to deliver clinically acceptable, high-resolution reconstructions, underscoring critical gaps in generalization, robustness, and uncertainty quantification. By publicly releasing OpenPros, we provide the community with a rigorous benchmark that not only enables fair method comparison but also motivates new advances in physics-informed learning, foundation models for scientific imaging, and uncertainty-aware reconstruction—bridging the gap between academic ML research and real-world clinical deployment.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=kcFEpBagea", "openreview_id": "kcFEpBagea", "openreview_forum_id": "kcFEpBagea", "authors": [], "pdf_url": "https://openreview.net/pdf/bda2427a109b6042f4892ecbe5bb4a3cb0b0b62d.pdf", "summary_cn": "OpenPros是首个大规模有限角度前列腺超声CT数据集，包含28万配对样本，用于评估ML逆问题方法。深度学习在效率和精度上优于传统算法，但临床高分辨率重建仍存差距。", "keywords": ["前列腺超声CT", "有限角度成像", "深度学习", "逆问题", "数据集", "重建精度"], "triple": {"method": "使用FDTD和Runge-Kutta声波求解器生成仿真数据", "result": "深度学习效率与精度更优，但临床高分辨率重建不足", "contribution": "提供首个大规模基准数据集，推动物理信息学习与临床部署"}}
{"venue": "ICLR", "search_title": "A Generalized Geometric Theoretical Framework of Centroid Discriminant Analysis for Linear Classification of Multi-dimensional Data", "full_title": "A Generalized Geometric Theoretical Framework of Centroid Discriminant Analysis for Linear Classification of Multi-dimensional Data", "url": "https://openreview.net/forum?id=bp9DOHb1mk", "year": 2026, "is_main_conference": true, "abstract_snippet": "With the advent of the neural network era, traditional machine learning methods have increasingly been overshadowed. Nevertheless, continuing to research about the role of geometry for learning in data science is crucial to envision and understand new principles behind the design of efficient machine learning. Linear classifiers are favored in certain tasks due to their reduced susceptibility to overfitting and their ability to provide interpretable decision boundaries. However, achieving both scalability and high predictive performance in linear classification remains a persistent challenge. Here, we propose a theoretical framework named geometric discriminant analysis (GDA). GDA includes the family of linear classifiers that can be expressed as function of a centroid discriminant basis (CDB0) - the connection line between two centroids - adjusted by geometric corrections under different constraints. We demonstrate that linear discriminant analysis (LDA) is a subcase of the GDA theoretical framework, and we show its convergence to CDB0 under certain conditions. Then, based on the GDA framework, we propose an efficient linear classifier named centroid discriminant analysis (CDA) which is defined as a special case of GDA under a 2D plane geometric constraint. CDA training is initialized starting from CDB0 and involves the iterative calculation of new adjusted centroid discriminant lines whose optimal rotations on the associated 2D planes are searched via Bayesian optimization. CDA has good scalability (quadratic time complexity) which is lower than LDA and support vectors machine (SVM) (cubic complexity). Results on 27 real datasets across classification tasks of standard images, medical images and chemical properties, offer empirical evidence that CDA outperforms other linear methods such as LDA, SVM and logistic regression (LR) in terms of scalability, performance and stability. Furthermore, we show that linear CDA can be generalized to nonlinear CDA via kernel method, demonstrating improvements on both linear CDA and kernel SVM with tests on three challenging datasets of images and chemical data. GDA general validity as a new theoretical framework may inspire the design of new classifiers under the definition of different geometric constraints, paving the way towards more deeper understanding of the role of geometry in learning from data.", "abstract": "With the advent of the neural network era, traditional machine learning methods have increasingly been overshadowed. Nevertheless, continuing to research about the role of geometry for learning in data science is crucial to envision and understand new principles behind the design of efficient machine learning. Linear classifiers are favored in certain tasks due to their reduced susceptibility to overfitting and their ability to provide interpretable decision boundaries. However, achieving both scalability and high predictive performance in linear classification remains a persistent challenge. Here, we propose a theoretical framework named geometric discriminant analysis (GDA). GDA includes the family of linear classifiers that can be expressed as function of a centroid discriminant basis (CDB0) - the connection line between two centroids - adjusted by geometric corrections under different constraints. We demonstrate that linear discriminant analysis (LDA) is a subcase of the GDA theoretical framework, and we show its convergence to CDB0 under certain conditions. Then, based on the GDA framework, we propose an efficient linear classifier named centroid discriminant analysis (CDA) which is defined as a special case of GDA under a 2D plane geometric constraint. CDA training is initialized starting from CDB0 and involves the iterative calculation of new adjusted centroid discriminant lines whose optimal rotations on the associated 2D planes are searched via Bayesian optimization. CDA has good scalability (quadratic time complexity) which is lower than LDA and support vectors machine (SVM) (cubic complexity). Results on 27 real datasets across classification tasks of standard images, medical images and chemical properties, offer empirical evidence that CDA outperforms other linear methods such as LDA, SVM and logistic regression (LR) in terms of scalability, performance and stability. Furthermore, we show that linear CDA can be generalized to nonlinear CDA via kernel method, demonstrating improvements on both linear CDA and kernel SVM with tests on three challenging datasets of images and chemical data. GDA general validity as a new theoretical framework may inspire the design of new classifiers under the definition of different geometric constraints, paving the way towards more deeper understanding of the role of geometry in learning from data.", "abstract_source_venue": "OpenReviewAPI", "abstract_source_url": "https://api2.openreview.net/notes?id=bp9DOHb1mk", "openreview_id": "bp9DOHb1mk", "openreview_forum_id": "bp9DOHb1mk", "authors": [], "pdf_url": "https://openreview.net/pdf/74ba7766a3fb0f519ee2ef9cfc48b1c861ac1e2b.pdf", "summary_cn": "提出几何判别分析（GDA）理论框架，包含基于质心判别基的线性分类器。基于GDA的质心判别分析（CDA）在27个数据集上优于LDA、SVM和逻辑回归，具有更好的可扩展性和性能。", "keywords": ["几何判别分析", "线性分类", "质心判别基", "贝叶斯优化", "可扩展性", "核方法"], "triple": {"method": "基于质心判别基的几何框架与贝叶斯优化", "result": "CDA在27个数据集上优于LDA、SVM和LR", "contribution": "提出GDA理论框架，推动几何在机器学习中的理解与应用"}}
